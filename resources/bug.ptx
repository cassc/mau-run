//
// Generated by LLVM NVPTX Back-End
//

.version 7.1
.target sm_86
.address_size 64

	// .globl	contract                // -- Begin function contract
.extern .func  (.param .b64 func_retval0) malloc
(
	.param .b64 malloc_param_0
)
;
.func evm_$_udiv_$_i256
(
	.param .b64 evm_$_udiv_$_i256_param_0,
	.param .b64 evm_$_udiv_$_i256_param_1,
	.param .b64 evm_$_udiv_$_i256_param_2
)
;
.extern .func free
(
	.param .b64 free_param_0
)
;
.func evm_$_udivrem_$_i256
(
	.param .b64 evm_$_udivrem_$_i256_param_0,
	.param .b64 evm_$_udivrem_$_i256_param_1,
	.param .b64 evm_$_udivrem_$_i256_param_2,
	.param .b64 evm_$_udivrem_$_i256_param_3
)
;
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.visible .func keccak256
(
	.param .b64 keccak256_param_0,
	.param .b32 keccak256_param_1,
	.param .b64 keccak256_param_2
)
;
.visible .func hash
(
	.param .b64 hash_param_0,
	.param .b64 hash_param_1,
	.param .b64 hash_param_2,
	.param .b64 hash_param_3,
	.param .b64 hash_param_4,
	.param .b32 hash_param_5
)
;
.visible .func __device_calldataload
(
	.param .b64 __device_calldataload_param_0,
	.param .b64 __device_calldataload_param_1,
	.param .b64 __device_calldataload_param_2
)
;
.visible .func __device_mstore
(
	.param .b64 __device_mstore_param_0,
	.param .b64 __device_mstore_param_1,
	.param .b64 __device_mstore_param_2,
	.param .b64 __device_mstore_param_3
)
;
.visible .func __device_mload
(
	.param .b64 __device_mload_param_0,
	.param .b64 __device_mload_param_1,
	.param .b64 __device_mload_param_2
)
;
.visible .func __device_sstore
(
	.param .b64 __device_sstore_param_0,
	.param .b64 __device_sstore_param_1
)
;
.visible .func __device_sload
(
	.param .b64 __device_sload_param_0,
	.param .b64 __device_sload_param_1
)
;
.visible .func  (.param .b32 func_retval0) __hashword
(
	.param .b64 __hashword_param_0
)
;
.visible .func mutateCaller
(
	.param .b64 mutateCaller_param_0
)
;
.visible .func mutateCallvalue
(
	.param .b64 mutateCallvalue_param_0
)
;
.visible .func mutateCalldata
(
	.param .b64 mutateCalldata_param_0,
	.param .b32 mutateCalldata_param_1
)
;
.visible .func cuhavoc
(
	.param .b64 cuhavoc_param_0,
	.param .b32 cuhavoc_param_1
)
;
.visible .const .align 1 .b8 __evmCode[32769] = {96, 128, 96, 64, 82, 52, 128, 21, 97, 0, 16, 87, 96, 0, 128, 253, 91, 80, 97, 3, 141, 128, 97, 0, 32, 96, 0, 57, 96, 0, 243, 0, 96, 128, 96, 64, 82, 96, 4, 54, 16, 97, 0, 142, 87, 96, 0, 53, 124, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 144, 4, 99, 255, 255, 255, 255, 22, 128, 99, 38, 74, 251, 125, 20, 97, 0, 147, 87, 128, 99, 55, 92, 88, 176, 20, 97, 0, 222, 87, 128, 99, 60, 131, 7, 19, 20, 97, 1, 41, 87, 128, 99, 70, 137, 45, 99, 20, 97, 1, 116, 87, 128, 99, 101, 55, 33, 71, 20, 97, 1, 191, 87, 128, 99, 176, 17, 82, 226, 20, 97, 1, 234, 87, 128, 99, 192, 67, 162, 84, 20, 97, 2, 53, 87, 128, 99, 255, 205, 136, 59, 20, 97, 2, 96, 87, 91, 96, 0, 128, 253, 91, 52, 128, 21, 97, 0, 159, 87, 96, 0, 128, 253, 91, 80, 97, 0, 200, 96, 4, 128, 54, 3, 129, 1, 144, 128, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 80, 80, 80, 97, 2, 171, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 52, 128, 21, 97, 0, 234, 87, 96, 0, 128, 253, 91, 80, 97, 1, 19, 96, 4, 128, 54, 3, 129, 1, 144, 128, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 80, 80, 80, 97, 2, 193, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 52, 128, 21, 97, 1, 53, 87, 96, 0, 128, 253, 91, 80, 97, 1, 94, 96, 4, 128, 54, 3, 129, 1, 144, 128, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 80, 80, 80, 97, 2, 215, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 52, 128, 21, 97, 1, 128, 87, 96, 0, 128, 253, 91, 80, 97, 1, 169, 96, 4, 128, 54, 3, 129, 1, 144, 128, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 80, 80, 80, 97, 2, 237, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 52, 128, 21, 97, 1, 203, 87, 96, 0, 128, 253, 91, 80, 97, 1, 212, 97, 3, 3, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 52, 128, 21, 97, 1, 246, 87, 96, 0, 128, 253, 91, 80, 97, 2, 31, 96, 4, 128, 54, 3, 129, 1, 144, 128, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 80, 80, 80, 97, 3, 9, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 52, 128, 21, 97, 2, 65, 87, 96, 0, 128, 253, 91, 80, 97, 2, 74, 97, 3, 31, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 52, 128, 21, 97, 2, 108, 87, 96, 0, 128, 253, 91, 80, 97, 2, 149, 96, 4, 128, 54, 3, 129, 1, 144, 128, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 80, 80, 80, 97, 3, 37, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 96, 0, 129, 131, 2, 96, 0, 129, 144, 85, 80, 96, 0, 84, 144, 80, 146, 145, 80, 80, 86, 91, 96, 0, 129, 131, 1, 96, 1, 129, 144, 85, 80, 96, 1, 84, 144, 80, 146, 145, 80, 80, 86, 91, 96, 0, 129, 131, 3, 96, 1, 129, 144, 85, 80, 96, 1, 84, 144, 80, 146, 145, 80, 80, 86, 91, 96, 0, 129, 131, 1, 96, 0, 129, 144, 85, 80, 96, 0, 84, 144, 80, 146, 145, 80, 80, 86, 91, 96, 0, 84, 129, 86, 91, 96, 0, 129, 131, 3, 96, 0, 129, 144, 85, 80, 96, 0, 84, 144, 80, 146, 145, 80, 80, 86, 91, 96, 1, 84, 129, 86, 91, 96, 0, 128, 96, 0, 96, 1, 145, 80, 96, 0, 144, 80, 91, 131, 129, 16, 21, 97, 3, 77, 87, 132, 130, 2, 145, 80, 128, 128, 96, 1, 1, 145, 80, 80, 97, 3, 51, 86, 91, 129, 96, 0, 129, 144, 85, 80, 96, 0, 84, 146, 80, 80, 80, 146, 145, 80, 80, 86, 0, 161, 101, 98, 122, 122, 114, 48, 88, 32, 130, 29, 120, 182, 84, 23, 206, 112, 126, 35, 40, 11, 74, 157, 174, 222, 197, 242, 111, 82, 199, 31, 211, 109, 208, 231, 224, 22, 84, 84, 237, 176, 0, 41, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
.visible .const .align 4 .u32 __evmCodeSize = 941;
.global .align 1 .b8 __const_$_printbytes_$_hexmap[16] = {48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 97, 98, 99, 100, 101, 102};
.global .align 1 .b8 _$_str[19] = {37, 115, 46, 32, 104, 101, 120, 32, 98, 121, 116, 101, 115, 58, 32, 37, 115, 10, 0};
.visible .const .align 8 .u64 cuTimestamp;
.visible .global .align 8 .u64 __signals;
.visible .global .align 1 .b8 __hnbs[1024];
.extern .global .align 8 .b8 l1snaps[8388608];
.extern .global .align 1 .b8 l1snap_lens[1024];
// count_class_lookup8 has been demoted
.visible .global .align 1 .b8 __virgin_bits[4096];
.visible .global .align 8 .b8 __bitmaps[8192];
.global .align 1 .b8 _$_str1[48] = {98, 117, 103, 59, 32, 116, 97, 114, 103, 101, 116, 32, 104, 105, 116, 32, 97, 116, 32, 116, 104, 114, 101, 97, 100, 35, 37, 100, 46, 32, 95, 95, 104, 110, 98, 115, 91, 116, 105, 100, 93, 32, 61, 32, 37, 100, 10, 0};
.visible .global .align 1 .b8 __cov_bits[4096];
.global .align 8 .b8 RC[192] = {1, 0, 0, 0, 0, 0, 0, 0, 130, 128, 0, 0, 0, 0, 0, 0, 138, 128, 0, 0, 0, 0, 0, 128, 0, 128, 0, 128, 0, 0, 0, 128, 139, 128, 0, 0, 0, 0, 0, 0, 1, 0, 0, 128, 0, 0, 0, 0, 129, 128, 0, 128, 0, 0, 0, 128, 9, 128, 0, 0, 0, 0, 0, 128, 138, 0, 0, 0, 0, 0, 0, 0, 136, 0, 0, 0, 0, 0, 0, 0, 9, 128, 0, 128, 0, 0, 0, 0, 10, 0, 0, 128, 0, 0, 0, 0, 139, 128, 0, 128, 0, 0, 0, 0, 139, 0, 0, 0, 0, 0, 0, 128, 137, 128, 0, 0, 0, 0, 0, 128, 3, 128, 0, 0, 0, 0, 0, 128, 2, 128, 0, 0, 0, 0, 0, 128, 128, 0, 0, 0, 0, 0, 0, 128, 10, 128, 0, 0, 0, 0, 0, 0, 10, 0, 0, 128, 0, 0, 0, 128, 129, 128, 0, 128, 0, 0, 0, 128, 128, 128, 0, 0, 0, 0, 0, 128, 1, 0, 0, 128, 0, 0, 0, 0, 8, 128, 0, 128, 0, 0, 0, 128};
.visible .global .align 4 .b8 cuda_states[4096];
.visible .global .align 4 .u32 cbconstants_length;
.visible .global .align 4 .u32 callers_pool_len;
.visible .global .align 4 .u32 addresses_pool_len;
.visible .global .align 1 .b8 addresses_pool[2048];
.visible .global .align 1 .b8 callers_pool[2048];
.visible .global .align 1 .b8 argTypeMap[64];
.const .align 1 .b8 interesting_8[9] = {128, 255, 0, 1, 16, 32, 64, 100, 127};
.const .align 2 .b8 interesting_16[38] = {128, 255, 255, 255, 0, 0, 1, 0, 16, 0, 32, 0, 64, 0, 100, 0, 127, 0, 0, 128, 127, 255, 128, 0, 255, 0, 0, 1, 0, 2, 232, 3, 0, 4, 0, 16, 255, 127};
.const .align 4 .b8 interesting_32[108] = {128, 255, 255, 255, 255, 255, 255, 255, 0, 0, 0, 0, 1, 0, 0, 0, 16, 0, 0, 0, 32, 0, 0, 0, 64, 0, 0, 0, 100, 0, 0, 0, 127, 0, 0, 0, 0, 128, 255, 255, 127, 255, 255, 255, 128, 0, 0, 0, 255, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 232, 3, 0, 0, 0, 4, 0, 0, 0, 16, 0, 0, 255, 127, 0, 0, 0, 0, 0, 128, 250, 0, 0, 250, 255, 127, 255, 255, 0, 128, 0, 0, 255, 255, 0, 0, 0, 0, 1, 0, 5, 255, 255, 5, 255, 255, 255, 127};
.visible .global .align 1 .b8 cbconstants[65536];
.visible .global .align 1 .b8 cbconstant_sizes[2048];
.extern .global .align 4 .b8 __snap_map[4096];
.extern .global .align 1 .b8 l2snap_lens[32768];
.extern .global .align 8 .b8 l2snaps[268435456];
                                        // @contract
.visible .func  (.param .b32 func_retval0) contract(
	.param .b64 contract_param_0,
	.param .b64 contract_param_1,
	.param .b64 contract_param_2,
	.param .b32 contract_param_3,
	.param .b64 contract_param_4
)
{
	.local .align 8 .b8 	__local_depot0[2208];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<271>;
	.reg .b16 	%rs<61>;
	.reg .b32 	%r<519>;
	.reg .b64 	%rd<1447>;

// %bb.0:                               // %Entry
	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd126, [contract_param_4];
	mov.u64 	%rd128, 728;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd128;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd129, [retval0+0];
	} // callseq 0
	mov.u64 	%rd130, 8192;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd130;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd131, [retval0+0];
	} // callseq 1
	ld.param.u32 	%r179, [contract_param_3];
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd126+1383], %rs1;
	add.u64 	%rd132, %SP, 0;
	add.u64 	%rd133, %SPL, 0;
	mov.u64 	%rd134, 0;
	st.local.u32 	[%rd133+28], %rd134;
	st.local.u32 	[%rd133+24], %rd134;
	st.local.u32 	[%rd133+20], %rd134;
	st.local.u32 	[%rd133+16], %rd134;
	st.local.u32 	[%rd133+12], %rd134;
	st.local.u32 	[%rd133+8], %rd134;
	st.local.u32 	[%rd133+4], %rd134;
	mov.u64 	%rd135, 128;
	st.local.u32 	[%rd133], %rd135;
	mov.u64 	%rd136, 64;
	mov.u64 	%rd137, 32;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd132;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 2
	setp.lt.u32 	%p1, %r179, 4;
	mov.u64 	%rd121, 209912;
	mov.u32 	%r171, 691;
	@%p1 bra 	LBB0_9;
	bra.uni 	LBB0_1;
LBB0_9:                                 // %.142
	setp.lt.u64 	%p270, %rd121, 16;
	@%p270 bra 	LBB0_147;
// %bb.10:
	xor.b32  	%r344, %r171, 3277;
	and.b32  	%r345, %r344, 4095;
	cvt.u64.u32 	%rd1386, %r345;
	add.s64 	%rd1387, %rd126, %rd1386;
	st.global.u8 	[%rd1387], %rs1;
LBB0_147:                               // %Abort
	{ // callseq 71, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 71
	{ // callseq 72, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd131;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 72
	mov.u32 	%r346, 0;
	st.param.b32 	[func_retval0+0], %r346;
	ret;
LBB0_1:                                 // %.13
	ld.param.u64 	%rd125, [contract_param_2];
	ld.param.u64 	%rd124, [contract_param_1];
	mov.u32 	%r173, 0;
	st.global.u8 	[%rd126+373], %rs1;
	add.u64 	%rd140, %SP, 32;
	add.u64 	%rd141, %SPL, 32;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd140;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd134;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 3
	ld.local.u32 	%rd142, [%rd141+20];
	ld.local.u32 	%rd143, [%rd141+16];
	ld.local.u32 	%rd144, [%rd141+12];
	ld.local.u32 	%rd145, [%rd141+8];
	ld.local.u32 	%rd146, [%rd141+4];
	ld.local.u32 	%rd147, [%rd141];
	ld.local.u32 	%rd148, [%rd141+28];
	ld.local.u32 	%rd149, [%rd141+24];
	add.u64 	%rd150, %SP, 64;
	add.u64 	%rd151, %SPL, 64;
	st.local.u32 	[%rd151+24], %rd149;
	st.local.u32 	[%rd151+28], %rd148;
	st.local.u32 	[%rd151], %rd147;
	st.local.u32 	[%rd151+4], %rd146;
	st.local.u32 	[%rd151+8], %rd145;
	st.local.u32 	[%rd151+12], %rd144;
	st.local.u32 	[%rd151+16], %rd143;
	st.local.u32 	[%rd151+20], %rd142;
	add.u64 	%rd152, %SP, 96;
	add.u64 	%rd153, %SPL, 96;
	st.local.u32 	[%rd153+16], %rd134;
	st.local.u32 	[%rd153+20], %rd134;
	st.local.u32 	[%rd153+24], %rd134;
	mov.u64 	%rd122, 1;
	st.local.u32 	[%rd153+28], %rd122;
	st.local.u32 	[%rd153], %rd134;
	st.local.u32 	[%rd153+4], %rd134;
	st.local.u32 	[%rd153+8], %rd134;
	st.local.u32 	[%rd153+12], %rd134;
	add.u64 	%rd154, %SP, 128;
	add.u64 	%rd155, %SPL, 128;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd150;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd152;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd154;
	call.uni 
	evm_$_udiv_$_i256, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 4
	ld.local.u32 	%rd3, [%rd155];
	xor.b64  	%rd156, %rd3, 642448253;
	setp.eq.s64 	%p2, %rd156, 0;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd121, 209720;
	mov.u32 	%r171, 483;
	mov.u64 	%rd1388, 4;
	mov.u64 	%rd1389, 36;
	mov.u32 	%r174, %r173;
	mov.u32 	%r175, %r173;
	mov.u32 	%r176, %r173;
	mov.u32 	%r177, %r173;
	@%p2 bra 	LBB0_11;
	bra.uni 	LBB0_2;
LBB0_11:                                // %.147
	setp.lt.u64 	%p10, %rd121, 96;
	@%p10 bra 	LBB0_147;
// %bb.12:
	xor.b32  	%r197, %r171, 2234;
	and.b32  	%r198, %r197, 4095;
	cvt.u64.u32 	%rd185, %r198;
	add.s64 	%rd186, %rd126, %rd185;
	st.global.u8 	[%rd186], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd187, [%rd124+16];
	ld.u32 	%rd188, [%rd124+20];
	shl.b64 	%rd189, %rd188, 32;
	or.b64  	%rd190, %rd189, %rd187;
	ld.u32 	%rd191, [%rd124];
	ld.u32 	%rd192, [%rd124+4];
	shl.b64 	%rd193, %rd192, 32;
	or.b64  	%rd194, %rd193, %rd191;
	ld.u32 	%rd195, [%rd124+24];
	ld.u32 	%rd196, [%rd124+28];
	shl.b64 	%rd197, %rd196, 32;
	or.b64  	%rd198, %rd197, %rd195;
	ld.u32 	%rd199, [%rd124+8];
	ld.u32 	%rd200, [%rd124+12];
	shl.b64 	%rd201, %rd200, 32;
	or.b64  	%rd202, %rd201, %rd199;
	or.b64  	%rd203, %rd202, %rd198;
	or.b64  	%rd204, %rd194, %rd190;
	or.b64  	%rd205, %rd204, %rd203;
	setp.eq.s64 	%p11, %rd205, 0;
	add.s64 	%rd1394, %rd122, 1;
	shl.b64 	%rd206, %rd122, 5;
	add.s64 	%rd207, %rd131, %rd206;
	st.u32 	[%rd207+48], %rd187;
	st.u32 	[%rd207+52], %rd188;
	st.u32 	[%rd207+56], %rd195;
	st.u32 	[%rd207+60], %rd196;
	st.u32 	[%rd207+32], %rd191;
	st.u32 	[%rd207+36], %rd192;
	st.u32 	[%rd207+40], %rd199;
	st.u32 	[%rd207+44], %rd200;
	mov.u32 	%r171, 1117;
	@%p11 bra 	LBB0_15;
	bra.uni 	LBB0_13;
LBB0_15:                                // %.159
	setp.lt.u64 	%p13, %rd121, 336;
	@%p13 bra 	LBB0_147;
// %bb.16:
	xor.b32  	%r200, %r171, 498;
	and.b32  	%r201, %r200, 4095;
	cvt.u64.u32 	%rd208, %r201;
	add.s64 	%rd209, %rd126, %rd208;
	st.global.u8 	[%rd209], %rs1;
	add.s64 	%rd121, %rd121, -336;
	shl.b64 	%rd210, %rd1394, 5;
	add.s64 	%rd211, %rd131, %rd210;
	add.u64 	%rd212, %SP, 160;
	add.u64 	%rd213, %SPL, 160;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd212;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1388;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 5
	ld.local.u32 	%rd215, [%rd213+12];
	ld.local.u32 	%rd216, [%rd213+8];
	ld.local.u32 	%rd217, [%rd213+4];
	ld.local.u32 	%rd218, [%rd213];
	ld.local.u32 	%rd219, [%rd213+28];
	ld.local.u32 	%rd220, [%rd213+24];
	ld.local.u32 	%rd221, [%rd213+20];
	ld.local.u32 	%rd222, [%rd213+16];
	add.u64 	%rd223, %SP, 192;
	add.u64 	%rd224, %SPL, 192;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd223;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1389;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 6
	ld.local.u32 	%rd226, [%rd224+12];
	ld.local.u32 	%rd227, [%rd224+8];
	ld.local.u32 	%rd228, [%rd224+4];
	ld.local.u32 	%rd229, [%rd224];
	ld.local.u32 	%rd230, [%rd224+28];
	ld.local.u32 	%rd231, [%rd224+24];
	ld.local.u32 	%rd232, [%rd224+20];
	ld.local.u32 	%rd233, [%rd224+16];
	st.u32 	[%rd211+16], %rd134;
	st.u32 	[%rd211+20], %rd134;
	st.u32 	[%rd211+24], %rd134;
	st.u32 	[%rd211+28], %rd134;
	mov.u64 	%rd235, 200;
	st.u32 	[%rd211], %rd235;
	st.u32 	[%rd211+4], %rd134;
	st.u32 	[%rd211+8], %rd134;
	st.u32 	[%rd211+12], %rd134;
	add.s64 	%rd122, %rd1394, 2;
	st.u32 	[%rd211+48], %rd222;
	st.u32 	[%rd211+52], %rd221;
	st.u32 	[%rd211+56], %rd220;
	st.u32 	[%rd211+60], %rd219;
	st.u32 	[%rd211+32], %rd218;
	st.u32 	[%rd211+36], %rd217;
	st.u32 	[%rd211+40], %rd216;
	st.u32 	[%rd211+44], %rd215;
	st.u32 	[%rd211+80], %rd233;
	st.u32 	[%rd211+84], %rd232;
	st.u32 	[%rd211+88], %rd231;
	st.u32 	[%rd211+92], %rd230;
	st.u32 	[%rd211+64], %rd229;
	st.u32 	[%rd211+68], %rd228;
	st.u32 	[%rd211+72], %rd227;
	st.u32 	[%rd211+76], %rd226;
	mov.u32 	%r171, 249;
LBB0_17:                                // %.683
	setp.lt.u64 	%p14, %rd121, 312;
	@%p14 bra 	LBB0_147;
// %bb.18:
	xor.b32  	%r203, %r171, 261;
	and.b32  	%r204, %r203, 4095;
	cvt.u64.u32 	%rd236, %r204;
	add.s64 	%rd237, %rd126, %rd236;
	st.global.u8 	[%rd237], %rs1;
	add.s64 	%rd121, %rd121, -312;
	shl.b64 	%rd238, %rd122, 5;
	add.s64 	%rd239, %rd131, %rd238;
	ld.u32 	%rd240, [%rd239+24];
	ld.u32 	%rd241, [%rd239+28];
	shl.b64 	%rd242, %rd241, 32;
	or.b64  	%rd243, %rd242, %rd240;
	ld.u32 	%rd244, [%rd239+16];
	ld.u32 	%rd245, [%rd239+20];
	shl.b64 	%rd246, %rd245, 32;
	or.b64  	%rd247, %rd246, %rd244;
	ld.u32 	%rd248, [%rd239+8];
	ld.u32 	%rd249, [%rd239+12];
	shl.b64 	%rd250, %rd249, 32;
	or.b64  	%rd251, %rd250, %rd248;
	ld.u32 	%rd252, [%rd239];
	ld.u32 	%rd253, [%rd239+4];
	shl.b64 	%rd254, %rd253, 32;
	or.b64  	%rd255, %rd254, %rd252;
	ld.u32 	%rd256, [%rd239+-16];
	ld.u32 	%rd257, [%rd239+-12];
	shl.b64 	%rd258, %rd257, 32;
	or.b64  	%rd259, %rd258, %rd256;
	ld.u32 	%rd260, [%rd239+-8];
	ld.u32 	%rd261, [%rd239+-4];
	shl.b64 	%rd262, %rd261, 32;
	or.b64  	%rd263, %rd262, %rd260;
	ld.u32 	%rd264, [%rd239+-24];
	ld.u32 	%rd265, [%rd239+-20];
	shl.b64 	%rd266, %rd265, 32;
	or.b64  	%rd267, %rd266, %rd264;
	ld.u32 	%rd268, [%rd239+-32];
	ld.u32 	%rd269, [%rd239+-28];
	shl.b64 	%rd270, %rd269, 32;
	or.b64  	%rd271, %rd270, %rd268;
	add.s64 	%rd122, %rd122, -2;
	ld.u32 	%rd272, [%rd239+-64];
	ld.u32 	%rd273, [%rd239+-60];
	shl.b64 	%rd274, %rd273, 32;
	or.b64  	%rd123, %rd274, %rd272;
	mul.hi.u64 	%rd275, %rd271, %rd255;
	mul.lo.s64 	%rd276, %rd267, %rd255;
	add.s64 	%rd277, %rd276, %rd275;
	setp.lt.u64 	%p15, %rd277, %rd275;
	setp.lt.u64 	%p16, %rd277, %rd276;
	selp.u64 	%rd278, 1, 0, %p16;
	selp.b64 	%rd279, 1, %rd278, %p15;
	mul.hi.u64 	%rd280, %rd267, %rd255;
	add.s64 	%rd281, %rd280, %rd279;
	mul.lo.s64 	%rd282, %rd271, %rd251;
	add.s64 	%rd283, %rd282, %rd277;
	setp.lt.u64 	%p17, %rd283, %rd277;
	setp.lt.u64 	%p18, %rd283, %rd282;
	selp.u64 	%rd284, 1, 0, %p18;
	selp.b64 	%rd285, 1, %rd284, %p17;
	mul.hi.u64 	%rd286, %rd271, %rd251;
	add.s64 	%rd287, %rd286, %rd285;
	add.s64 	%rd288, %rd281, %rd287;
	mul.lo.s64 	%rd289, %rd267, %rd251;
	add.s64 	%rd290, %rd289, %rd288;
	setp.lt.u64 	%p19, %rd290, %rd288;
	setp.lt.u64 	%p20, %rd290, %rd289;
	selp.u64 	%rd291, 1, 0, %p20;
	selp.b64 	%rd292, 1, %rd291, %p19;
	setp.lt.u64 	%p21, %rd288, %rd287;
	setp.lt.u64 	%p22, %rd288, %rd281;
	selp.u64 	%rd293, 1, 0, %p22;
	selp.b64 	%rd294, 1, %rd293, %p21;
	mul.hi.u64 	%rd295, %rd267, %rd251;
	add.s64 	%rd296, %rd295, %rd294;
	add.s64 	%rd297, %rd296, %rd292;
	mul.lo.s64 	%rd298, %rd255, %rd263;
	mul.hi.u64 	%rd299, %rd255, %rd259;
	add.s64 	%rd300, %rd299, %rd298;
	mul.lo.s64 	%rd301, %rd251, %rd259;
	add.s64 	%rd302, %rd300, %rd301;
	mul.lo.s64 	%rd303, %rd247, %rd267;
	mul.hi.u64 	%rd304, %rd247, %rd271;
	add.s64 	%rd305, %rd304, %rd303;
	mul.lo.s64 	%rd306, %rd243, %rd271;
	add.s64 	%rd307, %rd305, %rd306;
	add.s64 	%rd308, %rd307, %rd302;
	mul.lo.s64 	%rd309, %rd255, %rd259;
	mul.lo.s64 	%rd310, %rd247, %rd271;
	add.s64 	%rd311, %rd310, %rd309;
	setp.lt.u64 	%p23, %rd311, %rd309;
	setp.lt.u64 	%p24, %rd311, %rd310;
	selp.u64 	%rd312, 1, 0, %p24;
	selp.b64 	%rd313, 1, %rd312, %p23;
	add.s64 	%rd314, %rd308, %rd313;
	add.s64 	%rd315, %rd297, %rd314;
	add.s64 	%rd316, %rd290, %rd311;
	setp.lt.u64 	%p25, %rd316, %rd290;
	selp.u64 	%rd317, 1, 0, %p25;
	setp.lt.u64 	%p26, %rd316, %rd311;
	selp.b64 	%rd318, 1, %rd317, %p26;
	add.s64 	%rd319, %rd315, %rd318;
	mul.lo.s64 	%rd320, %rd271, %rd255;
	add.u64 	%rd321, %SP, 1312;
	add.u64 	%rd322, %SPL, 1312;
	st.local.u32 	[%rd322+24], %rd134;
	st.local.u32 	[%rd322+28], %rd134;
	st.local.u32 	[%rd322], %rd134;
	st.local.u32 	[%rd322+4], %rd134;
	st.local.u32 	[%rd322+8], %rd134;
	st.local.u32 	[%rd322+12], %rd134;
	st.local.u32 	[%rd322+16], %rd134;
	st.local.u32 	[%rd322+20], %rd134;
	add.u64 	%rd324, %SP, 1344;
	add.u64 	%rd325, %SPL, 1344;
	st.local.u32 	[%rd325], %rd320;
	shr.u64 	%rd326, %rd320, 32;
	st.local.u32 	[%rd325+4], %rd326;
	st.local.u32 	[%rd325+8], %rd283;
	shr.u64 	%rd327, %rd283, 32;
	st.local.u32 	[%rd325+12], %rd327;
	st.local.u32 	[%rd325+16], %rd316;
	shr.u64 	%rd328, %rd316, 32;
	st.local.u32 	[%rd325+20], %rd328;
	st.local.u32 	[%rd325+24], %rd319;
	shr.u64 	%rd329, %rd319, 32;
	st.local.u32 	[%rd325+28], %rd329;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd321;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd324;
	call.uni 
	__device_sstore, 
	(
	param0, 
	param1
	);
	} // callseq 7
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd321;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r172, [retval0+0];
	} // callseq 8
	add.u64 	%rd330, %SP, 1376;
	add.u64 	%rd331, %SPL, 1376;
	st.local.u32 	[%rd331+28], %rd134;
	st.local.u32 	[%rd331+24], %rd134;
	st.local.u32 	[%rd331+20], %rd134;
	st.local.u32 	[%rd331+16], %rd134;
	st.local.u32 	[%rd331+12], %rd134;
	st.local.u32 	[%rd331+8], %rd134;
	st.local.u32 	[%rd331+4], %rd134;
	st.local.u32 	[%rd331], %rd134;
	add.u64 	%rd332, %SP, 1408;
	add.u64 	%rd333, %SPL, 1408;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd330;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd332;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 9
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd330;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r206, [retval0+0];
	} // callseq 10
	setp.eq.s32 	%p27, %r206, %r172;
	setp.eq.s32 	%p28, %r206, %r173;
	or.pred  	%p29, %p27, %p28;
	setp.eq.s32 	%p30, %r206, %r174;
	or.pred  	%p31, %p29, %p30;
	setp.eq.s32 	%p32, %r206, %r175;
	or.pred  	%p33, %p31, %p32;
	setp.eq.s32 	%p34, %r206, %r176;
	or.pred  	%p35, %p33, %p34;
	setp.eq.s32 	%p36, %r206, %r177;
	or.pred  	%p37, %p35, %p36;
	selp.u16 	%rs14, 1, 0, %p37;
	st.global.u8 	[%rd126], %rs14;
	ld.local.u32 	%rd334, [%rd333+12];
	ld.local.u32 	%rd335, [%rd333+8];
	ld.local.u32 	%rd336, [%rd333+4];
	ld.local.u32 	%rd337, [%rd333];
	ld.local.u32 	%rd338, [%rd333+28];
	ld.local.u32 	%rd339, [%rd333+24];
	ld.local.u32 	%rd340, [%rd333+20];
	ld.local.u32 	%rd341, [%rd333+16];
	st.u32 	[%rd239+-48], %rd341;
	st.u32 	[%rd239+-44], %rd340;
	st.u32 	[%rd239+-40], %rd339;
	st.u32 	[%rd239+-36], %rd338;
	st.u32 	[%rd239+-64], %rd337;
	st.u32 	[%rd239+-60], %rd336;
	st.u32 	[%rd239+-56], %rd335;
	st.u32 	[%rd239+-52], %rd334;
	mov.u32 	%r171, 130;
	bra.uni 	LBB0_98;
LBB0_2:                                 // %.65
	st.global.u8 	[%rd126+2442], %rs1;
	xor.b64  	%rd159, %rd3, 928798896;
	setp.eq.s64 	%p3, %rd159, 0;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd122, 1;
	mov.u64 	%rd121, 209608;
	mov.u32 	%r172, 0;
	mov.u32 	%r171, 1076;
	mov.u32 	%r174, %r172;
	mov.u32 	%r175, %r172;
	mov.u32 	%r176, %r172;
	mov.u32 	%r177, %r172;
	@%p3 bra 	LBB0_21;
	bra.uni 	LBB0_3;
LBB0_21:                                // %.222
	setp.lt.u64 	%p243, %rd121, 96;
	@%p243 bra 	LBB0_147;
// %bb.22:
	xor.b32  	%r326, %r171, 2531;
	and.b32  	%r327, %r326, 4095;
	cvt.u64.u32 	%rd1257, %r327;
	add.s64 	%rd1258, %rd126, %rd1257;
	st.global.u8 	[%rd1258], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd1259, [%rd124+16];
	ld.u32 	%rd1260, [%rd124+20];
	shl.b64 	%rd1261, %rd1260, 32;
	or.b64  	%rd1262, %rd1261, %rd1259;
	ld.u32 	%rd1263, [%rd124];
	ld.u32 	%rd1264, [%rd124+4];
	shl.b64 	%rd1265, %rd1264, 32;
	or.b64  	%rd1266, %rd1265, %rd1263;
	ld.u32 	%rd1267, [%rd124+24];
	ld.u32 	%rd1268, [%rd124+28];
	shl.b64 	%rd1269, %rd1268, 32;
	or.b64  	%rd1270, %rd1269, %rd1267;
	ld.u32 	%rd1271, [%rd124+8];
	ld.u32 	%rd1272, [%rd124+12];
	shl.b64 	%rd1273, %rd1272, 32;
	or.b64  	%rd1274, %rd1273, %rd1271;
	or.b64  	%rd1275, %rd1274, %rd1270;
	or.b64  	%rd1276, %rd1266, %rd1262;
	or.b64  	%rd1277, %rd1276, %rd1275;
	setp.eq.s64 	%p244, %rd1277, 0;
	add.s64 	%rd1398, %rd122, 1;
	shl.b64 	%rd1278, %rd122, 5;
	add.s64 	%rd1279, %rd131, %rd1278;
	st.u32 	[%rd1279+48], %rd1259;
	st.u32 	[%rd1279+52], %rd1260;
	st.u32 	[%rd1279+56], %rd1267;
	st.u32 	[%rd1279+60], %rd1268;
	st.u32 	[%rd1279+32], %rd1263;
	st.u32 	[%rd1279+36], %rd1264;
	st.u32 	[%rd1279+40], %rd1271;
	st.u32 	[%rd1279+44], %rd1272;
	mov.u32 	%r171, 1265;
	@%p244 bra 	LBB0_25;
	bra.uni 	LBB0_23;
LBB0_25:                                // %.234
	setp.lt.u64 	%p246, %rd121, 336;
	@%p246 bra 	LBB0_147;
// %bb.26:
	xor.b32  	%r329, %r171, 124;
	and.b32  	%r330, %r329, 4095;
	cvt.u64.u32 	%rd1280, %r330;
	add.s64 	%rd1281, %rd126, %rd1280;
	st.global.u8 	[%rd1281], %rs1;
	add.s64 	%rd121, %rd121, -336;
	shl.b64 	%rd1282, %rd1398, 5;
	add.s64 	%rd1283, %rd131, %rd1282;
	add.u64 	%rd1284, %SP, 320;
	add.u64 	%rd1285, %SPL, 320;
	{ // callseq 65, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1284;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1388;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 65
	ld.local.u32 	%rd1287, [%rd1285+12];
	ld.local.u32 	%rd1288, [%rd1285+8];
	ld.local.u32 	%rd1289, [%rd1285+4];
	ld.local.u32 	%rd1290, [%rd1285];
	ld.local.u32 	%rd1291, [%rd1285+28];
	ld.local.u32 	%rd1292, [%rd1285+24];
	ld.local.u32 	%rd1293, [%rd1285+20];
	ld.local.u32 	%rd1294, [%rd1285+16];
	add.u64 	%rd1295, %SP, 352;
	add.u64 	%rd1296, %SPL, 352;
	{ // callseq 66, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1295;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1389;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 66
	ld.local.u32 	%rd1298, [%rd1296+12];
	ld.local.u32 	%rd1299, [%rd1296+8];
	ld.local.u32 	%rd1300, [%rd1296+4];
	ld.local.u32 	%rd1301, [%rd1296];
	ld.local.u32 	%rd1302, [%rd1296+28];
	ld.local.u32 	%rd1303, [%rd1296+24];
	ld.local.u32 	%rd1304, [%rd1296+20];
	ld.local.u32 	%rd1305, [%rd1296+16];
	st.u32 	[%rd1283+16], %rd134;
	st.u32 	[%rd1283+20], %rd134;
	st.u32 	[%rd1283+24], %rd134;
	st.u32 	[%rd1283+28], %rd134;
	mov.u64 	%rd1307, 275;
	st.u32 	[%rd1283], %rd1307;
	st.u32 	[%rd1283+4], %rd134;
	st.u32 	[%rd1283+8], %rd134;
	st.u32 	[%rd1283+12], %rd134;
	add.s64 	%rd122, %rd1398, 2;
	st.u32 	[%rd1283+48], %rd1294;
	st.u32 	[%rd1283+52], %rd1293;
	st.u32 	[%rd1283+56], %rd1292;
	st.u32 	[%rd1283+60], %rd1291;
	st.u32 	[%rd1283+32], %rd1290;
	st.u32 	[%rd1283+36], %rd1289;
	st.u32 	[%rd1283+40], %rd1288;
	st.u32 	[%rd1283+44], %rd1287;
	st.u32 	[%rd1283+80], %rd1305;
	st.u32 	[%rd1283+84], %rd1304;
	st.u32 	[%rd1283+88], %rd1303;
	st.u32 	[%rd1283+92], %rd1302;
	st.u32 	[%rd1283+64], %rd1301;
	st.u32 	[%rd1283+68], %rd1300;
	st.u32 	[%rd1283+72], %rd1299;
	st.u32 	[%rd1283+76], %rd1298;
	mov.u32 	%r171, 62;
LBB0_27:                                // %.705
	setp.lt.u64 	%p247, %rd121, 312;
	@%p247 bra 	LBB0_147;
// %bb.28:
	xor.b32  	%r332, %r171, 791;
	and.b32  	%r333, %r332, 4095;
	cvt.u64.u32 	%rd1308, %r333;
	add.s64 	%rd1309, %rd126, %rd1308;
	st.global.u8 	[%rd1309], %rs1;
	add.s64 	%rd121, %rd121, -312;
	shl.b64 	%rd1310, %rd122, 5;
	add.s64 	%rd1311, %rd131, %rd1310;
	ld.u32 	%rd1312, [%rd1311+24];
	ld.u32 	%rd1313, [%rd1311+28];
	shl.b64 	%rd1314, %rd1313, 32;
	or.b64  	%rd1315, %rd1314, %rd1312;
	ld.u32 	%rd1316, [%rd1311+16];
	ld.u32 	%rd1317, [%rd1311+20];
	shl.b64 	%rd1318, %rd1317, 32;
	or.b64  	%rd1319, %rd1318, %rd1316;
	ld.u32 	%rd1320, [%rd1311+8];
	ld.u32 	%rd1321, [%rd1311+12];
	shl.b64 	%rd1322, %rd1321, 32;
	or.b64  	%rd1323, %rd1322, %rd1320;
	ld.u32 	%rd1324, [%rd1311];
	ld.u32 	%rd1325, [%rd1311+4];
	shl.b64 	%rd1326, %rd1325, 32;
	or.b64  	%rd1327, %rd1326, %rd1324;
	ld.u32 	%rd1328, [%rd1311+-8];
	ld.u32 	%rd1329, [%rd1311+-4];
	shl.b64 	%rd1330, %rd1329, 32;
	or.b64  	%rd1331, %rd1330, %rd1328;
	ld.u32 	%rd1332, [%rd1311+-16];
	ld.u32 	%rd1333, [%rd1311+-12];
	shl.b64 	%rd1334, %rd1333, 32;
	or.b64  	%rd1335, %rd1334, %rd1332;
	ld.u32 	%rd1336, [%rd1311+-24];
	ld.u32 	%rd1337, [%rd1311+-20];
	shl.b64 	%rd1338, %rd1337, 32;
	or.b64  	%rd1339, %rd1338, %rd1336;
	ld.u32 	%rd1340, [%rd1311+-32];
	ld.u32 	%rd1341, [%rd1311+-28];
	shl.b64 	%rd1342, %rd1341, 32;
	or.b64  	%rd1343, %rd1342, %rd1340;
	add.s64 	%rd122, %rd122, -2;
	ld.u32 	%rd1344, [%rd1311+-64];
	ld.u32 	%rd1345, [%rd1311+-60];
	shl.b64 	%rd1346, %rd1345, 32;
	or.b64  	%rd123, %rd1346, %rd1344;
	add.s64 	%rd1347, %rd1343, %rd1327;
	setp.lt.u64 	%p248, %rd1347, %rd1327;
	setp.lt.u64 	%p249, %rd1347, %rd1343;
	selp.u64 	%rd1348, 1, 0, %p249;
	selp.b64 	%rd1349, 1, %rd1348, %p248;
	add.s64 	%rd1350, %rd1339, %rd1323;
	add.s64 	%rd1351, %rd1350, %rd1349;
	setp.eq.s64 	%p250, %rd1351, %rd1323;
	setp.lt.u64 	%p251, %rd1351, %rd1323;
	selp.u32 	%r334, -1, 0, %p251;
	selp.u32 	%r335, -1, 0, %p248;
	selp.b32 	%r336, %r335, %r334, %p250;
	and.b32  	%r337, %r336, 1;
	setp.eq.b32 	%p252, %r337, 1;
	setp.eq.s64 	%p253, %rd1351, %rd1339;
	setp.lt.u64 	%p254, %rd1351, %rd1339;
	selp.u32 	%r338, -1, 0, %p254;
	selp.u32 	%r339, -1, 0, %p249;
	selp.b32 	%r340, %r339, %r338, %p253;
	cvt.u64.u32 	%rd1352, %r340;
	and.b64  	%rd1353, %rd1352, 1;
	selp.b64 	%rd1354, 1, %rd1353, %p252;
	add.s64 	%rd1355, %rd1335, %rd1319;
	add.s64 	%rd1356, %rd1355, %rd1354;
	setp.lt.u64 	%p255, %rd1356, %rd1354;
	setp.lt.u64 	%p256, %rd1356, %rd1355;
	selp.u64 	%rd1357, 1, 0, %p256;
	selp.b64 	%rd1358, 1, %rd1357, %p255;
	setp.lt.u64 	%p257, %rd1355, %rd1319;
	setp.lt.u64 	%p258, %rd1355, %rd1335;
	selp.u64 	%rd1359, 1, 0, %p258;
	selp.b64 	%rd1360, 1, %rd1359, %p257;
	add.s64 	%rd1361, %rd1331, %rd1315;
	add.s64 	%rd1362, %rd1361, %rd1360;
	add.s64 	%rd1363, %rd1362, %rd1358;
	add.u64 	%rd1364, %SP, 1440;
	add.u64 	%rd1365, %SPL, 1440;
	st.local.u32 	[%rd1365+24], %rd134;
	st.local.u32 	[%rd1365+28], %rd134;
	mov.u64 	%rd1367, 1;
	st.local.u32 	[%rd1365], %rd1367;
	st.local.u32 	[%rd1365+4], %rd134;
	st.local.u32 	[%rd1365+8], %rd134;
	st.local.u32 	[%rd1365+12], %rd134;
	st.local.u32 	[%rd1365+16], %rd134;
	st.local.u32 	[%rd1365+20], %rd134;
	add.u64 	%rd1368, %SP, 1472;
	add.u64 	%rd1369, %SPL, 1472;
	st.local.u32 	[%rd1369], %rd1347;
	shr.u64 	%rd1370, %rd1347, 32;
	st.local.u32 	[%rd1369+4], %rd1370;
	st.local.u32 	[%rd1369+8], %rd1351;
	shr.u64 	%rd1371, %rd1351, 32;
	st.local.u32 	[%rd1369+12], %rd1371;
	st.local.u32 	[%rd1369+16], %rd1356;
	shr.u64 	%rd1372, %rd1356, 32;
	st.local.u32 	[%rd1369+20], %rd1372;
	st.local.u32 	[%rd1369+24], %rd1363;
	shr.u64 	%rd1373, %rd1363, 32;
	st.local.u32 	[%rd1369+28], %rd1373;
	{ // callseq 67, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1364;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1368;
	call.uni 
	__device_sstore, 
	(
	param0, 
	param1
	);
	} // callseq 67
	{ // callseq 68, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1364;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r173, [retval0+0];
	} // callseq 68
	add.u64 	%rd1374, %SP, 1504;
	add.u64 	%rd1375, %SPL, 1504;
	st.local.u32 	[%rd1375+28], %rd134;
	st.local.u32 	[%rd1375+24], %rd134;
	st.local.u32 	[%rd1375+20], %rd134;
	st.local.u32 	[%rd1375+16], %rd134;
	st.local.u32 	[%rd1375+12], %rd134;
	st.local.u32 	[%rd1375+8], %rd134;
	st.local.u32 	[%rd1375+4], %rd134;
	st.local.u32 	[%rd1375], %rd1367;
	add.u64 	%rd1376, %SP, 1536;
	add.u64 	%rd1377, %SPL, 1536;
	{ // callseq 69, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1374;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1376;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 69
	{ // callseq 70, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1374;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r342, [retval0+0];
	} // callseq 70
	setp.eq.s32 	%p259, %r342, %r172;
	setp.eq.s32 	%p260, %r342, %r173;
	or.pred  	%p261, %p259, %p260;
	setp.eq.s32 	%p262, %r342, %r174;
	or.pred  	%p263, %p261, %p262;
	setp.eq.s32 	%p264, %r342, %r175;
	or.pred  	%p265, %p263, %p264;
	setp.eq.s32 	%p266, %r342, %r176;
	or.pred  	%p267, %p265, %p266;
	setp.eq.s32 	%p268, %r342, %r177;
	or.pred  	%p269, %p267, %p268;
	selp.u16 	%rs59, 1, 0, %p269;
	st.global.u8 	[%rd126+1], %rs59;
	ld.local.u32 	%rd1378, [%rd1377+12];
	ld.local.u32 	%rd1379, [%rd1377+8];
	ld.local.u32 	%rd1380, [%rd1377+4];
	ld.local.u32 	%rd1381, [%rd1377];
	ld.local.u32 	%rd1382, [%rd1377+28];
	ld.local.u32 	%rd1383, [%rd1377+24];
	ld.local.u32 	%rd1384, [%rd1377+20];
	ld.local.u32 	%rd1385, [%rd1377+16];
	st.u32 	[%rd1311+-48], %rd1385;
	st.u32 	[%rd1311+-44], %rd1384;
	st.u32 	[%rd1311+-40], %rd1383;
	st.u32 	[%rd1311+-36], %rd1382;
	st.u32 	[%rd1311+-64], %rd1381;
	st.u32 	[%rd1311+-60], %rd1380;
	st.u32 	[%rd1311+-56], %rd1379;
	st.u32 	[%rd1311+-52], %rd1378;
	mov.u32 	%r171, 395;
	bra.uni 	LBB0_98;
LBB0_3:                                 // %.76
	st.global.u8 	[%rd126+3143], %rs1;
	xor.b64  	%rd163, %rd3, 1015219987;
	setp.eq.s64 	%p4, %rd163, 0;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd122, 1;
	mov.u64 	%rd121, 209496;
	mov.u32 	%r172, 0;
	mov.u32 	%r171, 1081;
	mov.u32 	%r173, %r172;
	mov.u32 	%r175, %r172;
	mov.u32 	%r176, %r172;
	mov.u32 	%r177, %r172;
	@%p4 bra 	LBB0_31;
	bra.uni 	LBB0_4;
LBB0_31:                                // %.297
	setp.lt.u64 	%p221, %rd121, 96;
	@%p221 bra 	LBB0_147;
// %bb.32:
	xor.b32  	%r310, %r171, 2132;
	and.b32  	%r311, %r310, 4095;
	cvt.u64.u32 	%rd1131, %r311;
	add.s64 	%rd1132, %rd126, %rd1131;
	st.global.u8 	[%rd1132], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd1133, [%rd124+16];
	ld.u32 	%rd1134, [%rd124+20];
	shl.b64 	%rd1135, %rd1134, 32;
	or.b64  	%rd1136, %rd1135, %rd1133;
	ld.u32 	%rd1137, [%rd124];
	ld.u32 	%rd1138, [%rd124+4];
	shl.b64 	%rd1139, %rd1138, 32;
	or.b64  	%rd1140, %rd1139, %rd1137;
	ld.u32 	%rd1141, [%rd124+24];
	ld.u32 	%rd1142, [%rd124+28];
	shl.b64 	%rd1143, %rd1142, 32;
	or.b64  	%rd1144, %rd1143, %rd1141;
	ld.u32 	%rd1145, [%rd124+8];
	ld.u32 	%rd1146, [%rd124+12];
	shl.b64 	%rd1147, %rd1146, 32;
	or.b64  	%rd1148, %rd1147, %rd1145;
	or.b64  	%rd1149, %rd1148, %rd1144;
	or.b64  	%rd1150, %rd1140, %rd1136;
	or.b64  	%rd1151, %rd1150, %rd1149;
	setp.eq.s64 	%p222, %rd1151, 0;
	add.s64 	%rd1402, %rd122, 1;
	shl.b64 	%rd1152, %rd122, 5;
	add.s64 	%rd1153, %rd131, %rd1152;
	st.u32 	[%rd1153+48], %rd1133;
	st.u32 	[%rd1153+52], %rd1134;
	st.u32 	[%rd1153+56], %rd1141;
	st.u32 	[%rd1153+60], %rd1142;
	st.u32 	[%rd1153+32], %rd1137;
	st.u32 	[%rd1153+36], %rd1138;
	st.u32 	[%rd1153+40], %rd1145;
	st.u32 	[%rd1153+44], %rd1146;
	mov.u32 	%r171, 1066;
	@%p222 bra 	LBB0_35;
	bra.uni 	LBB0_33;
LBB0_35:                                // %.309
	setp.lt.u64 	%p224, %rd121, 336;
	@%p224 bra 	LBB0_147;
// %bb.36:
	xor.b32  	%r313, %r171, 795;
	and.b32  	%r314, %r313, 4095;
	cvt.u64.u32 	%rd1154, %r314;
	add.s64 	%rd1155, %rd126, %rd1154;
	st.global.u8 	[%rd1155], %rs1;
	add.s64 	%rd121, %rd121, -336;
	shl.b64 	%rd1156, %rd1402, 5;
	add.s64 	%rd1157, %rd131, %rd1156;
	add.u64 	%rd1158, %SP, 480;
	add.u64 	%rd1159, %SPL, 480;
	{ // callseq 59, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1158;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1388;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 59
	ld.local.u32 	%rd1161, [%rd1159+12];
	ld.local.u32 	%rd1162, [%rd1159+8];
	ld.local.u32 	%rd1163, [%rd1159+4];
	ld.local.u32 	%rd1164, [%rd1159];
	ld.local.u32 	%rd1165, [%rd1159+28];
	ld.local.u32 	%rd1166, [%rd1159+24];
	ld.local.u32 	%rd1167, [%rd1159+20];
	ld.local.u32 	%rd1168, [%rd1159+16];
	add.u64 	%rd1169, %SP, 512;
	add.u64 	%rd1170, %SPL, 512;
	{ // callseq 60, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1169;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1389;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 60
	ld.local.u32 	%rd1172, [%rd1170+12];
	ld.local.u32 	%rd1173, [%rd1170+8];
	ld.local.u32 	%rd1174, [%rd1170+4];
	ld.local.u32 	%rd1175, [%rd1170];
	ld.local.u32 	%rd1176, [%rd1170+28];
	ld.local.u32 	%rd1177, [%rd1170+24];
	ld.local.u32 	%rd1178, [%rd1170+20];
	ld.local.u32 	%rd1179, [%rd1170+16];
	st.u32 	[%rd1157+16], %rd134;
	st.u32 	[%rd1157+20], %rd134;
	st.u32 	[%rd1157+24], %rd134;
	st.u32 	[%rd1157+28], %rd134;
	mov.u64 	%rd1181, 350;
	st.u32 	[%rd1157], %rd1181;
	st.u32 	[%rd1157+4], %rd134;
	st.u32 	[%rd1157+8], %rd134;
	st.u32 	[%rd1157+12], %rd134;
	add.s64 	%rd122, %rd1402, 2;
	st.u32 	[%rd1157+48], %rd1168;
	st.u32 	[%rd1157+52], %rd1167;
	st.u32 	[%rd1157+56], %rd1166;
	st.u32 	[%rd1157+60], %rd1165;
	st.u32 	[%rd1157+32], %rd1164;
	st.u32 	[%rd1157+36], %rd1163;
	st.u32 	[%rd1157+40], %rd1162;
	st.u32 	[%rd1157+44], %rd1161;
	st.u32 	[%rd1157+80], %rd1179;
	st.u32 	[%rd1157+84], %rd1178;
	st.u32 	[%rd1157+88], %rd1177;
	st.u32 	[%rd1157+92], %rd1176;
	st.u32 	[%rd1157+64], %rd1175;
	st.u32 	[%rd1157+68], %rd1174;
	st.u32 	[%rd1157+72], %rd1173;
	st.u32 	[%rd1157+76], %rd1172;
	mov.u32 	%r171, 397;
LBB0_37:                                // %.727
	setp.lt.u64 	%p225, %rd121, 312;
	@%p225 bra 	LBB0_147;
// %bb.38:
	xor.b32  	%r316, %r171, 2136;
	and.b32  	%r317, %r316, 4095;
	cvt.u64.u32 	%rd1182, %r317;
	add.s64 	%rd1183, %rd126, %rd1182;
	st.global.u8 	[%rd1183], %rs1;
	add.s64 	%rd121, %rd121, -312;
	shl.b64 	%rd1184, %rd122, 5;
	add.s64 	%rd1185, %rd131, %rd1184;
	ld.u32 	%rd1186, [%rd1185+24];
	ld.u32 	%rd1187, [%rd1185+28];
	shl.b64 	%rd1188, %rd1187, 32;
	or.b64  	%rd1189, %rd1188, %rd1186;
	ld.u32 	%rd1190, [%rd1185+16];
	ld.u32 	%rd1191, [%rd1185+20];
	shl.b64 	%rd1192, %rd1191, 32;
	or.b64  	%rd1193, %rd1192, %rd1190;
	ld.u32 	%rd1194, [%rd1185];
	ld.u32 	%rd1195, [%rd1185+4];
	shl.b64 	%rd1196, %rd1195, 32;
	or.b64  	%rd1197, %rd1196, %rd1194;
	ld.u32 	%rd1198, [%rd1185+8];
	ld.u32 	%rd1199, [%rd1185+12];
	shl.b64 	%rd1200, %rd1199, 32;
	or.b64  	%rd1201, %rd1200, %rd1198;
	ld.u32 	%rd1202, [%rd1185+-8];
	ld.u32 	%rd1203, [%rd1185+-4];
	shl.b64 	%rd1204, %rd1203, 32;
	or.b64  	%rd1205, %rd1204, %rd1202;
	ld.u32 	%rd1206, [%rd1185+-16];
	ld.u32 	%rd1207, [%rd1185+-12];
	shl.b64 	%rd1208, %rd1207, 32;
	or.b64  	%rd1209, %rd1208, %rd1206;
	ld.u32 	%rd1210, [%rd1185+-32];
	ld.u32 	%rd1211, [%rd1185+-28];
	shl.b64 	%rd1212, %rd1211, 32;
	or.b64  	%rd1213, %rd1212, %rd1210;
	ld.u32 	%rd1214, [%rd1185+-24];
	ld.u32 	%rd1215, [%rd1185+-20];
	shl.b64 	%rd1216, %rd1215, 32;
	or.b64  	%rd1217, %rd1216, %rd1214;
	add.s64 	%rd122, %rd122, -2;
	ld.u32 	%rd1218, [%rd1185+-64];
	ld.u32 	%rd1219, [%rd1185+-60];
	shl.b64 	%rd1220, %rd1219, 32;
	or.b64  	%rd123, %rd1220, %rd1218;
	setp.eq.s64 	%p226, %rd1217, %rd1201;
	setp.lt.u64 	%p227, %rd1217, %rd1201;
	selp.u32 	%r318, -1, 0, %p227;
	setp.lt.u64 	%p228, %rd1213, %rd1197;
	selp.u32 	%r319, -1, 0, %p228;
	selp.b32 	%r320, %r319, %r318, %p226;
	cvt.u64.u32 	%rd1221, %r320;
	and.b64  	%rd1222, %rd1221, 1;
	sub.s64 	%rd1223, %rd1209, %rd1193;
	setp.lt.u64 	%p229, %rd1223, %rd1222;
	selp.s64 	%rd1224, -1, 0, %p229;
	sub.s64 	%rd1225, %rd1205, %rd1189;
	setp.lt.u64 	%p230, %rd1209, %rd1193;
	selp.s64 	%rd1226, -1, 0, %p230;
	add.s64 	%rd1227, %rd1225, %rd1226;
	add.s64 	%rd1228, %rd1227, %rd1224;
	and.b32  	%r321, %r320, 1;
	setp.eq.b32 	%p231, %r321, 1;
	selp.s64 	%rd1229, -1, 0, %p231;
	add.s64 	%rd1230, %rd1223, %rd1229;
	sub.s64 	%rd1231, %rd1217, %rd1201;
	selp.s64 	%rd1232, -1, 0, %p228;
	add.s64 	%rd1233, %rd1231, %rd1232;
	sub.s64 	%rd1234, %rd1213, %rd1197;
	add.u64 	%rd1235, %SP, 1568;
	add.u64 	%rd1236, %SPL, 1568;
	st.local.u32 	[%rd1236+24], %rd134;
	st.local.u32 	[%rd1236+28], %rd134;
	mov.u64 	%rd1238, 1;
	st.local.u32 	[%rd1236], %rd1238;
	st.local.u32 	[%rd1236+4], %rd134;
	st.local.u32 	[%rd1236+8], %rd134;
	st.local.u32 	[%rd1236+12], %rd134;
	st.local.u32 	[%rd1236+16], %rd134;
	st.local.u32 	[%rd1236+20], %rd134;
	add.u64 	%rd1239, %SP, 1600;
	add.u64 	%rd1240, %SPL, 1600;
	st.local.u32 	[%rd1240], %rd1234;
	shr.u64 	%rd1241, %rd1234, 32;
	st.local.u32 	[%rd1240+4], %rd1241;
	st.local.u32 	[%rd1240+8], %rd1233;
	shr.u64 	%rd1242, %rd1233, 32;
	st.local.u32 	[%rd1240+12], %rd1242;
	st.local.u32 	[%rd1240+16], %rd1230;
	shr.u64 	%rd1243, %rd1230, 32;
	st.local.u32 	[%rd1240+20], %rd1243;
	st.local.u32 	[%rd1240+24], %rd1228;
	shr.u64 	%rd1244, %rd1228, 32;
	st.local.u32 	[%rd1240+28], %rd1244;
	{ // callseq 61, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1235;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1239;
	call.uni 
	__device_sstore, 
	(
	param0, 
	param1
	);
	} // callseq 61
	{ // callseq 62, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1235;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r174, [retval0+0];
	} // callseq 62
	add.u64 	%rd1245, %SP, 1632;
	add.u64 	%rd1246, %SPL, 1632;
	st.local.u32 	[%rd1246+28], %rd134;
	st.local.u32 	[%rd1246+24], %rd134;
	st.local.u32 	[%rd1246+20], %rd134;
	st.local.u32 	[%rd1246+16], %rd134;
	st.local.u32 	[%rd1246+12], %rd134;
	st.local.u32 	[%rd1246+8], %rd134;
	st.local.u32 	[%rd1246+4], %rd134;
	st.local.u32 	[%rd1246], %rd1238;
	add.u64 	%rd1247, %SP, 1664;
	add.u64 	%rd1248, %SPL, 1664;
	{ // callseq 63, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1245;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1247;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 63
	{ // callseq 64, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1245;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r323, [retval0+0];
	} // callseq 64
	setp.eq.s32 	%p232, %r323, %r172;
	setp.eq.s32 	%p233, %r323, %r173;
	or.pred  	%p234, %p232, %p233;
	setp.eq.s32 	%p235, %r323, %r174;
	or.pred  	%p236, %p234, %p235;
	setp.eq.s32 	%p237, %r323, %r175;
	or.pred  	%p238, %p236, %p237;
	setp.eq.s32 	%p239, %r323, %r176;
	or.pred  	%p240, %p238, %p239;
	setp.eq.s32 	%p241, %r323, %r177;
	or.pred  	%p242, %p240, %p241;
	selp.u16 	%rs54, 1, 0, %p242;
	st.global.u8 	[%rd126+2], %rs54;
	ld.local.u32 	%rd1249, [%rd1248+12];
	ld.local.u32 	%rd1250, [%rd1248+8];
	ld.local.u32 	%rd1251, [%rd1248+4];
	ld.local.u32 	%rd1252, [%rd1248];
	ld.local.u32 	%rd1253, [%rd1248+28];
	ld.local.u32 	%rd1254, [%rd1248+24];
	ld.local.u32 	%rd1255, [%rd1248+20];
	ld.local.u32 	%rd1256, [%rd1248+16];
	st.u32 	[%rd1185+-48], %rd1256;
	st.u32 	[%rd1185+-44], %rd1255;
	st.u32 	[%rd1185+-40], %rd1254;
	st.u32 	[%rd1185+-36], %rd1253;
	st.u32 	[%rd1185+-64], %rd1252;
	st.u32 	[%rd1185+-60], %rd1251;
	st.u32 	[%rd1185+-56], %rd1250;
	st.u32 	[%rd1185+-52], %rd1249;
	mov.u32 	%r171, 1068;
	bra.uni 	LBB0_98;
LBB0_4:                                 // %.87
	st.global.u8 	[%rd126+2152], %rs1;
	xor.b64  	%rd167, %rd3, 1183395171;
	setp.eq.s64 	%p5, %rd167, 0;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd122, 1;
	mov.u64 	%rd121, 209384;
	mov.u32 	%r172, 0;
	mov.u32 	%r171, 1576;
	mov.u32 	%r173, %r172;
	mov.u32 	%r174, %r172;
	mov.u32 	%r176, %r172;
	mov.u32 	%r177, %r172;
	@%p5 bra 	LBB0_41;
// %bb.5:                               // %.98
	st.global.u8 	[%rd126+2775], %rs1;
	xor.b64  	%rd171, %rd3, 1698111815;
	setp.eq.s64 	%p6, %rd171, 0;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd122, 1;
	mov.u64 	%rd121, 209272;
	mov.u32 	%r172, 0;
	mov.u32 	%r171, 1663;
	mov.u32 	%r173, %r172;
	mov.u32 	%r174, %r172;
	mov.u32 	%r175, %r172;
	mov.u32 	%r176, %r172;
	mov.u32 	%r177, %r172;
	@%p6 bra 	LBB0_51;
// %bb.6:                               // %.109
	st.global.u8 	[%rd126+565], %rs1;
	xor.b64  	%rd175, %rd3, 2953925346;
	setp.eq.s64 	%p7, %rd175, 0;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd122, 1;
	mov.u64 	%rd121, 209160;
	mov.u32 	%r172, 0;
	mov.u32 	%r171, 549;
	mov.u32 	%r173, %r172;
	mov.u32 	%r174, %r172;
	mov.u32 	%r175, %r172;
	mov.u32 	%r177, %r172;
	@%p7 bra 	LBB0_61;
// %bb.7:                               // %.120
	st.global.u8 	[%rd126+2761], %rs1;
	xor.b64  	%rd179, %rd3, 3225657940;
	setp.eq.s64 	%p8, %rd179, 0;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd122, 1;
	mov.u64 	%rd121, 209048;
	mov.u32 	%r172, 0;
	mov.u32 	%r171, 1142;
	mov.u32 	%r173, %r172;
	mov.u32 	%r174, %r172;
	mov.u32 	%r175, %r172;
	mov.u32 	%r176, %r172;
	mov.u32 	%r177, %r172;
	@%p8 bra 	LBB0_71;
// %bb.8:                               // %.131
	st.global.u8 	[%rd126+2911], %rs1;
	xor.b64  	%rd183, %rd3, 4291659835;
	setp.eq.s64 	%p9, %rd183, 0;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd122, 1;
	mov.u64 	%rd121, 208936;
	mov.u32 	%r172, 0;
	mov.u32 	%r171, 1940;
	mov.u32 	%r173, %r172;
	mov.u32 	%r174, %r172;
	mov.u32 	%r175, %r172;
	mov.u32 	%r176, %r172;
	@%p9 bra 	LBB0_81;
	bra.uni 	LBB0_9;
LBB0_13:                                // %.155
	setp.lt.u64 	%p12, %rd121, 40;
	@%p12 bra 	LBB0_147;
// %bb.14:
	st.global.u8 	[%rd126+1014], %rs1;
	bra.uni 	LBB0_147;
LBB0_23:                                // %.230
	setp.lt.u64 	%p245, %rd121, 40;
	@%p245 bra 	LBB0_147;
// %bb.24:
	st.global.u8 	[%rd126+1463], %rs1;
	bra.uni 	LBB0_147;
LBB0_33:                                // %.305
	setp.lt.u64 	%p223, %rd121, 40;
	@%p223 bra 	LBB0_147;
// %bb.34:
	st.global.u8 	[%rd126+978], %rs1;
	bra.uni 	LBB0_147;
LBB0_19:                                // %.200
	setp.lt.u64 	%p193, %rd121, 184;
	@%p193 bra 	LBB0_147;
// %bb.20:
	xor.b32  	%r287, %r171, 3835;
	and.b32  	%r288, %r287, 4095;
	cvt.u64.u32 	%rd980, %r288;
	add.s64 	%rd981, %rd126, %rd980;
	st.global.u8 	[%rd981], %rs1;
	shl.b64 	%rd982, %rd122, 5;
	add.s64 	%rd983, %rd131, %rd982;
	ld.u32 	%rd984, [%rd983];
	ld.u32 	%rd985, [%rd983+4];
	ld.u32 	%rd986, [%rd983+8];
	ld.u32 	%rd987, [%rd983+12];
	ld.u32 	%rd988, [%rd983+16];
	ld.u32 	%rd989, [%rd983+20];
	ld.u32 	%rd990, [%rd983+24];
	ld.u32 	%rd991, [%rd983+28];
	add.u64 	%rd992, %SP, 224;
	add.u64 	%rd993, %SPL, 224;
	{ // callseq 48, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd992;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 48
	ld.local.u32 	%rd995, [%rd993];
	ld.local.u32 	%rd996, [%rd993+4];
	shl.b64 	%rd997, %rd996, 32;
	or.b64  	%rd998, %rd997, %rd995;
	add.u64 	%rd999, %SP, 256;
	add.u64 	%rd1000, %SPL, 256;
	st.local.u32 	[%rd1000+28], %rd991;
	st.local.u32 	[%rd1000+24], %rd990;
	st.local.u32 	[%rd1000+20], %rd989;
	st.local.u32 	[%rd1000+16], %rd988;
	st.local.u32 	[%rd1000+12], %rd987;
	st.local.u32 	[%rd1000+8], %rd986;
	st.local.u32 	[%rd1000+4], %rd985;
	st.local.u32 	[%rd1000], %rd984;
	{ // callseq 49, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd998;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd999;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 49
	add.u64 	%rd1002, %SP, 288;
	{ // callseq 50, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1002;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 50
	bra.uni 	LBB0_95;
LBB0_29:                                // %.275
	setp.lt.u64 	%p176, %rd121, 184;
	@%p176 bra 	LBB0_147;
// %bb.30:
	xor.b32  	%r274, %r171, 706;
	and.b32  	%r275, %r274, 4095;
	cvt.u64.u32 	%rd902, %r275;
	add.s64 	%rd903, %rd126, %rd902;
	st.global.u8 	[%rd903], %rs1;
	shl.b64 	%rd904, %rd122, 5;
	add.s64 	%rd905, %rd131, %rd904;
	ld.u32 	%rd906, [%rd905];
	ld.u32 	%rd907, [%rd905+4];
	ld.u32 	%rd908, [%rd905+8];
	ld.u32 	%rd909, [%rd905+12];
	ld.u32 	%rd910, [%rd905+16];
	ld.u32 	%rd911, [%rd905+20];
	ld.u32 	%rd912, [%rd905+24];
	ld.u32 	%rd913, [%rd905+28];
	add.u64 	%rd914, %SP, 384;
	add.u64 	%rd915, %SPL, 384;
	{ // callseq 43, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd914;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 43
	ld.local.u32 	%rd917, [%rd915];
	ld.local.u32 	%rd918, [%rd915+4];
	shl.b64 	%rd919, %rd918, 32;
	or.b64  	%rd920, %rd919, %rd917;
	add.u64 	%rd921, %SP, 416;
	add.u64 	%rd922, %SPL, 416;
	st.local.u32 	[%rd922+28], %rd913;
	st.local.u32 	[%rd922+24], %rd912;
	st.local.u32 	[%rd922+20], %rd911;
	st.local.u32 	[%rd922+16], %rd910;
	st.local.u32 	[%rd922+12], %rd909;
	st.local.u32 	[%rd922+8], %rd908;
	st.local.u32 	[%rd922+4], %rd907;
	st.local.u32 	[%rd922], %rd906;
	{ // callseq 44, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd920;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd921;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 44
	add.u64 	%rd924, %SP, 448;
	{ // callseq 45, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd924;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 45
	bra.uni 	LBB0_95;
LBB0_39:                                // %.350
	setp.lt.u64 	%p153, %rd121, 184;
	@%p153 bra 	LBB0_147;
// %bb.40:
	xor.b32  	%r256, %r171, 2536;
	and.b32  	%r257, %r256, 4095;
	cvt.u64.u32 	%rd754, %r257;
	add.s64 	%rd755, %rd126, %rd754;
	st.global.u8 	[%rd755], %rs1;
	shl.b64 	%rd756, %rd122, 5;
	add.s64 	%rd757, %rd131, %rd756;
	ld.u32 	%rd758, [%rd757];
	ld.u32 	%rd759, [%rd757+4];
	ld.u32 	%rd760, [%rd757+8];
	ld.u32 	%rd761, [%rd757+12];
	ld.u32 	%rd762, [%rd757+16];
	ld.u32 	%rd763, [%rd757+20];
	ld.u32 	%rd764, [%rd757+24];
	ld.u32 	%rd765, [%rd757+28];
	add.u64 	%rd766, %SP, 544;
	add.u64 	%rd767, %SPL, 544;
	{ // callseq 34, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd766;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 34
	ld.local.u32 	%rd769, [%rd767];
	ld.local.u32 	%rd770, [%rd767+4];
	shl.b64 	%rd771, %rd770, 32;
	or.b64  	%rd772, %rd771, %rd769;
	add.u64 	%rd773, %SP, 576;
	add.u64 	%rd774, %SPL, 576;
	st.local.u32 	[%rd774+28], %rd765;
	st.local.u32 	[%rd774+24], %rd764;
	st.local.u32 	[%rd774+20], %rd763;
	st.local.u32 	[%rd774+16], %rd762;
	st.local.u32 	[%rd774+12], %rd761;
	st.local.u32 	[%rd774+8], %rd760;
	st.local.u32 	[%rd774+4], %rd759;
	st.local.u32 	[%rd774], %rd758;
	{ // callseq 35, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd772;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd773;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 35
	add.u64 	%rd776, %SP, 608;
	{ // callseq 36, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd776;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 36
	bra.uni 	LBB0_95;
LBB0_41:                                // %.372
	setp.lt.u64 	%p194, %rd121, 96;
	@%p194 bra 	LBB0_147;
// %bb.42:
	xor.b32  	%r291, %r171, 3559;
	and.b32  	%r292, %r291, 4095;
	cvt.u64.u32 	%rd1003, %r292;
	add.s64 	%rd1004, %rd126, %rd1003;
	st.global.u8 	[%rd1004], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd1005, [%rd124+16];
	ld.u32 	%rd1006, [%rd124+20];
	shl.b64 	%rd1007, %rd1006, 32;
	or.b64  	%rd1008, %rd1007, %rd1005;
	ld.u32 	%rd1009, [%rd124];
	ld.u32 	%rd1010, [%rd124+4];
	shl.b64 	%rd1011, %rd1010, 32;
	or.b64  	%rd1012, %rd1011, %rd1009;
	ld.u32 	%rd1013, [%rd124+24];
	ld.u32 	%rd1014, [%rd124+28];
	shl.b64 	%rd1015, %rd1014, 32;
	or.b64  	%rd1016, %rd1015, %rd1013;
	ld.u32 	%rd1017, [%rd124+8];
	ld.u32 	%rd1018, [%rd124+12];
	shl.b64 	%rd1019, %rd1018, 32;
	or.b64  	%rd1020, %rd1019, %rd1017;
	or.b64  	%rd1021, %rd1020, %rd1016;
	or.b64  	%rd1022, %rd1012, %rd1008;
	or.b64  	%rd1023, %rd1022, %rd1021;
	setp.eq.s64 	%p195, %rd1023, 0;
	add.s64 	%rd1406, %rd122, 1;
	shl.b64 	%rd1024, %rd122, 5;
	add.s64 	%rd1025, %rd131, %rd1024;
	st.u32 	[%rd1025+48], %rd1005;
	st.u32 	[%rd1025+52], %rd1006;
	st.u32 	[%rd1025+56], %rd1013;
	st.u32 	[%rd1025+60], %rd1014;
	st.u32 	[%rd1025+32], %rd1009;
	st.u32 	[%rd1025+36], %rd1010;
	st.u32 	[%rd1025+40], %rd1017;
	st.u32 	[%rd1025+44], %rd1018;
	mov.u32 	%r171, 1779;
	@%p195 bra 	LBB0_45;
	bra.uni 	LBB0_43;
LBB0_45:                                // %.384
	setp.lt.u64 	%p197, %rd121, 336;
	@%p197 bra 	LBB0_147;
// %bb.46:
	xor.b32  	%r294, %r171, 3958;
	and.b32  	%r295, %r294, 4095;
	cvt.u64.u32 	%rd1026, %r295;
	add.s64 	%rd1027, %rd126, %rd1026;
	st.global.u8 	[%rd1027], %rs1;
	add.s64 	%rd121, %rd121, -336;
	shl.b64 	%rd1028, %rd1406, 5;
	add.s64 	%rd1029, %rd131, %rd1028;
	add.u64 	%rd1030, %SP, 640;
	add.u64 	%rd1031, %SPL, 640;
	{ // callseq 53, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1030;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1388;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 53
	ld.local.u32 	%rd1033, [%rd1031+12];
	ld.local.u32 	%rd1034, [%rd1031+8];
	ld.local.u32 	%rd1035, [%rd1031+4];
	ld.local.u32 	%rd1036, [%rd1031];
	ld.local.u32 	%rd1037, [%rd1031+28];
	ld.local.u32 	%rd1038, [%rd1031+24];
	ld.local.u32 	%rd1039, [%rd1031+20];
	ld.local.u32 	%rd1040, [%rd1031+16];
	add.u64 	%rd1041, %SP, 672;
	add.u64 	%rd1042, %SPL, 672;
	{ // callseq 54, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1041;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1389;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 54
	ld.local.u32 	%rd1044, [%rd1042+12];
	ld.local.u32 	%rd1045, [%rd1042+8];
	ld.local.u32 	%rd1046, [%rd1042+4];
	ld.local.u32 	%rd1047, [%rd1042];
	ld.local.u32 	%rd1048, [%rd1042+28];
	ld.local.u32 	%rd1049, [%rd1042+24];
	ld.local.u32 	%rd1050, [%rd1042+20];
	ld.local.u32 	%rd1051, [%rd1042+16];
	st.u32 	[%rd1029+16], %rd134;
	st.u32 	[%rd1029+20], %rd134;
	st.u32 	[%rd1029+24], %rd134;
	st.u32 	[%rd1029+28], %rd134;
	mov.u64 	%rd1053, 425;
	st.u32 	[%rd1029], %rd1053;
	st.u32 	[%rd1029+4], %rd134;
	st.u32 	[%rd1029+8], %rd134;
	st.u32 	[%rd1029+12], %rd134;
	add.s64 	%rd122, %rd1406, 2;
	st.u32 	[%rd1029+48], %rd1040;
	st.u32 	[%rd1029+52], %rd1039;
	st.u32 	[%rd1029+56], %rd1038;
	st.u32 	[%rd1029+60], %rd1037;
	st.u32 	[%rd1029+32], %rd1036;
	st.u32 	[%rd1029+36], %rd1035;
	st.u32 	[%rd1029+40], %rd1034;
	st.u32 	[%rd1029+44], %rd1033;
	st.u32 	[%rd1029+80], %rd1051;
	st.u32 	[%rd1029+84], %rd1050;
	st.u32 	[%rd1029+88], %rd1049;
	st.u32 	[%rd1029+92], %rd1048;
	st.u32 	[%rd1029+64], %rd1047;
	st.u32 	[%rd1029+68], %rd1046;
	st.u32 	[%rd1029+72], %rd1045;
	st.u32 	[%rd1029+76], %rd1044;
	mov.u32 	%r171, 1979;
LBB0_47:                                // %.749
	setp.lt.u64 	%p198, %rd121, 312;
	@%p198 bra 	LBB0_147;
// %bb.48:
	xor.b32  	%r297, %r171, 2793;
	and.b32  	%r298, %r297, 4095;
	cvt.u64.u32 	%rd1054, %r298;
	add.s64 	%rd1055, %rd126, %rd1054;
	st.global.u8 	[%rd1055], %rs1;
	add.s64 	%rd121, %rd121, -312;
	shl.b64 	%rd1056, %rd122, 5;
	add.s64 	%rd1057, %rd131, %rd1056;
	ld.u32 	%rd1058, [%rd1057+24];
	ld.u32 	%rd1059, [%rd1057+28];
	shl.b64 	%rd1060, %rd1059, 32;
	or.b64  	%rd1061, %rd1060, %rd1058;
	ld.u32 	%rd1062, [%rd1057+16];
	ld.u32 	%rd1063, [%rd1057+20];
	shl.b64 	%rd1064, %rd1063, 32;
	or.b64  	%rd1065, %rd1064, %rd1062;
	ld.u32 	%rd1066, [%rd1057+8];
	ld.u32 	%rd1067, [%rd1057+12];
	shl.b64 	%rd1068, %rd1067, 32;
	or.b64  	%rd1069, %rd1068, %rd1066;
	ld.u32 	%rd1070, [%rd1057];
	ld.u32 	%rd1071, [%rd1057+4];
	shl.b64 	%rd1072, %rd1071, 32;
	or.b64  	%rd1073, %rd1072, %rd1070;
	ld.u32 	%rd1074, [%rd1057+-8];
	ld.u32 	%rd1075, [%rd1057+-4];
	shl.b64 	%rd1076, %rd1075, 32;
	or.b64  	%rd1077, %rd1076, %rd1074;
	ld.u32 	%rd1078, [%rd1057+-16];
	ld.u32 	%rd1079, [%rd1057+-12];
	shl.b64 	%rd1080, %rd1079, 32;
	or.b64  	%rd1081, %rd1080, %rd1078;
	ld.u32 	%rd1082, [%rd1057+-24];
	ld.u32 	%rd1083, [%rd1057+-20];
	shl.b64 	%rd1084, %rd1083, 32;
	or.b64  	%rd1085, %rd1084, %rd1082;
	ld.u32 	%rd1086, [%rd1057+-32];
	ld.u32 	%rd1087, [%rd1057+-28];
	shl.b64 	%rd1088, %rd1087, 32;
	or.b64  	%rd1089, %rd1088, %rd1086;
	add.s64 	%rd122, %rd122, -2;
	ld.u32 	%rd1090, [%rd1057+-64];
	ld.u32 	%rd1091, [%rd1057+-60];
	shl.b64 	%rd1092, %rd1091, 32;
	or.b64  	%rd123, %rd1092, %rd1090;
	add.s64 	%rd1093, %rd1089, %rd1073;
	setp.lt.u64 	%p199, %rd1093, %rd1073;
	setp.lt.u64 	%p200, %rd1093, %rd1089;
	selp.u64 	%rd1094, 1, 0, %p200;
	selp.b64 	%rd1095, 1, %rd1094, %p199;
	add.s64 	%rd1096, %rd1085, %rd1069;
	add.s64 	%rd1097, %rd1096, %rd1095;
	setp.eq.s64 	%p201, %rd1097, %rd1069;
	setp.lt.u64 	%p202, %rd1097, %rd1069;
	selp.u32 	%r299, -1, 0, %p202;
	selp.u32 	%r300, -1, 0, %p199;
	selp.b32 	%r301, %r300, %r299, %p201;
	and.b32  	%r302, %r301, 1;
	setp.eq.b32 	%p203, %r302, 1;
	setp.eq.s64 	%p204, %rd1097, %rd1085;
	setp.lt.u64 	%p205, %rd1097, %rd1085;
	selp.u32 	%r303, -1, 0, %p205;
	selp.u32 	%r304, -1, 0, %p200;
	selp.b32 	%r305, %r304, %r303, %p204;
	cvt.u64.u32 	%rd1098, %r305;
	and.b64  	%rd1099, %rd1098, 1;
	selp.b64 	%rd1100, 1, %rd1099, %p203;
	add.s64 	%rd1101, %rd1081, %rd1065;
	add.s64 	%rd1102, %rd1101, %rd1100;
	setp.lt.u64 	%p206, %rd1102, %rd1100;
	setp.lt.u64 	%p207, %rd1102, %rd1101;
	selp.u64 	%rd1103, 1, 0, %p207;
	selp.b64 	%rd1104, 1, %rd1103, %p206;
	setp.lt.u64 	%p208, %rd1101, %rd1065;
	setp.lt.u64 	%p209, %rd1101, %rd1081;
	selp.u64 	%rd1105, 1, 0, %p209;
	selp.b64 	%rd1106, 1, %rd1105, %p208;
	add.s64 	%rd1107, %rd1077, %rd1061;
	add.s64 	%rd1108, %rd1107, %rd1106;
	add.s64 	%rd1109, %rd1108, %rd1104;
	add.u64 	%rd1110, %SP, 1696;
	add.u64 	%rd1111, %SPL, 1696;
	st.local.u32 	[%rd1111+24], %rd134;
	st.local.u32 	[%rd1111+28], %rd134;
	st.local.u32 	[%rd1111], %rd134;
	st.local.u32 	[%rd1111+4], %rd134;
	st.local.u32 	[%rd1111+8], %rd134;
	st.local.u32 	[%rd1111+12], %rd134;
	st.local.u32 	[%rd1111+16], %rd134;
	st.local.u32 	[%rd1111+20], %rd134;
	add.u64 	%rd1113, %SP, 1728;
	add.u64 	%rd1114, %SPL, 1728;
	st.local.u32 	[%rd1114], %rd1093;
	shr.u64 	%rd1115, %rd1093, 32;
	st.local.u32 	[%rd1114+4], %rd1115;
	st.local.u32 	[%rd1114+8], %rd1097;
	shr.u64 	%rd1116, %rd1097, 32;
	st.local.u32 	[%rd1114+12], %rd1116;
	st.local.u32 	[%rd1114+16], %rd1102;
	shr.u64 	%rd1117, %rd1102, 32;
	st.local.u32 	[%rd1114+20], %rd1117;
	st.local.u32 	[%rd1114+24], %rd1109;
	shr.u64 	%rd1118, %rd1109, 32;
	st.local.u32 	[%rd1114+28], %rd1118;
	{ // callseq 55, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1110;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1113;
	call.uni 
	__device_sstore, 
	(
	param0, 
	param1
	);
	} // callseq 55
	{ // callseq 56, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1110;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r175, [retval0+0];
	} // callseq 56
	add.u64 	%rd1119, %SP, 1760;
	add.u64 	%rd1120, %SPL, 1760;
	st.local.u32 	[%rd1120+28], %rd134;
	st.local.u32 	[%rd1120+24], %rd134;
	st.local.u32 	[%rd1120+20], %rd134;
	st.local.u32 	[%rd1120+16], %rd134;
	st.local.u32 	[%rd1120+12], %rd134;
	st.local.u32 	[%rd1120+8], %rd134;
	st.local.u32 	[%rd1120+4], %rd134;
	st.local.u32 	[%rd1120], %rd134;
	add.u64 	%rd1121, %SP, 1792;
	add.u64 	%rd1122, %SPL, 1792;
	{ // callseq 57, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1119;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1121;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 57
	{ // callseq 58, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1119;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r307, [retval0+0];
	} // callseq 58
	setp.eq.s32 	%p210, %r307, %r172;
	setp.eq.s32 	%p211, %r307, %r173;
	or.pred  	%p212, %p210, %p211;
	setp.eq.s32 	%p213, %r307, %r174;
	or.pred  	%p214, %p212, %p213;
	setp.eq.s32 	%p215, %r307, %r175;
	or.pred  	%p216, %p214, %p215;
	setp.eq.s32 	%p217, %r307, %r176;
	or.pred  	%p218, %p216, %p217;
	setp.eq.s32 	%p219, %r307, %r177;
	or.pred  	%p220, %p218, %p219;
	selp.u16 	%rs49, 1, 0, %p220;
	st.global.u8 	[%rd126+3], %rs49;
	ld.local.u32 	%rd1123, [%rd1122+12];
	ld.local.u32 	%rd1124, [%rd1122+8];
	ld.local.u32 	%rd1125, [%rd1122+4];
	ld.local.u32 	%rd1126, [%rd1122];
	ld.local.u32 	%rd1127, [%rd1122+28];
	ld.local.u32 	%rd1128, [%rd1122+24];
	ld.local.u32 	%rd1129, [%rd1122+20];
	ld.local.u32 	%rd1130, [%rd1122+16];
	st.u32 	[%rd1057+-48], %rd1130;
	st.u32 	[%rd1057+-44], %rd1129;
	st.u32 	[%rd1057+-40], %rd1128;
	st.u32 	[%rd1057+-36], %rd1127;
	st.u32 	[%rd1057+-64], %rd1126;
	st.u32 	[%rd1057+-60], %rd1125;
	st.u32 	[%rd1057+-56], %rd1124;
	st.u32 	[%rd1057+-52], %rd1123;
	mov.u32 	%r171, 1396;
	bra.uni 	LBB0_98;
LBB0_43:                                // %.380
	setp.lt.u64 	%p196, %rd121, 40;
	@%p196 bra 	LBB0_147;
// %bb.44:
	st.global.u8 	[%rd126+1406], %rs1;
	bra.uni 	LBB0_147;
LBB0_49:                                // %.425
	setp.lt.u64 	%p136, %rd121, 184;
	@%p136 bra 	LBB0_147;
// %bb.50:
	xor.b32  	%r243, %r171, 1370;
	and.b32  	%r244, %r243, 4095;
	cvt.u64.u32 	%rd675, %r244;
	add.s64 	%rd676, %rd126, %rd675;
	st.global.u8 	[%rd676], %rs1;
	shl.b64 	%rd677, %rd122, 5;
	add.s64 	%rd678, %rd131, %rd677;
	ld.u32 	%rd679, [%rd678];
	ld.u32 	%rd680, [%rd678+4];
	ld.u32 	%rd681, [%rd678+8];
	ld.u32 	%rd682, [%rd678+12];
	ld.u32 	%rd683, [%rd678+16];
	ld.u32 	%rd684, [%rd678+20];
	ld.u32 	%rd685, [%rd678+24];
	ld.u32 	%rd686, [%rd678+28];
	add.u64 	%rd687, %SP, 704;
	add.u64 	%rd688, %SPL, 704;
	{ // callseq 29, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd687;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 29
	ld.local.u32 	%rd690, [%rd688];
	ld.local.u32 	%rd691, [%rd688+4];
	shl.b64 	%rd692, %rd691, 32;
	or.b64  	%rd693, %rd692, %rd690;
	add.u64 	%rd694, %SP, 736;
	add.u64 	%rd695, %SPL, 736;
	st.local.u32 	[%rd695+28], %rd686;
	st.local.u32 	[%rd695+24], %rd685;
	st.local.u32 	[%rd695+20], %rd684;
	st.local.u32 	[%rd695+16], %rd683;
	st.local.u32 	[%rd695+12], %rd682;
	st.local.u32 	[%rd695+8], %rd681;
	st.local.u32 	[%rd695+4], %rd680;
	st.local.u32 	[%rd695], %rd679;
	{ // callseq 30, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd693;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd694;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 30
	add.u64 	%rd697, %SP, 768;
	{ // callseq 31, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd697;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 31
	bra.uni 	LBB0_95;
LBB0_51:                                // %.447
	setp.lt.u64 	%p177, %rd121, 96;
	@%p177 bra 	LBB0_147;
// %bb.52:
	xor.b32  	%r277, %r171, 2350;
	and.b32  	%r278, %r277, 4095;
	cvt.u64.u32 	%rd925, %r278;
	add.s64 	%rd926, %rd126, %rd925;
	st.global.u8 	[%rd926], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd927, [%rd124+16];
	ld.u32 	%rd928, [%rd124+20];
	shl.b64 	%rd929, %rd928, 32;
	or.b64  	%rd930, %rd929, %rd927;
	ld.u32 	%rd931, [%rd124];
	ld.u32 	%rd932, [%rd124+4];
	shl.b64 	%rd933, %rd932, 32;
	or.b64  	%rd934, %rd933, %rd931;
	ld.u32 	%rd935, [%rd124+24];
	ld.u32 	%rd936, [%rd124+28];
	shl.b64 	%rd937, %rd936, 32;
	or.b64  	%rd938, %rd937, %rd935;
	ld.u32 	%rd939, [%rd124+8];
	ld.u32 	%rd940, [%rd124+12];
	shl.b64 	%rd941, %rd940, 32;
	or.b64  	%rd942, %rd941, %rd939;
	or.b64  	%rd943, %rd942, %rd938;
	or.b64  	%rd944, %rd934, %rd930;
	or.b64  	%rd945, %rd944, %rd943;
	setp.eq.s64 	%p178, %rd945, 0;
	add.s64 	%rd1410, %rd122, 1;
	shl.b64 	%rd946, %rd122, 5;
	add.s64 	%rd947, %rd131, %rd946;
	st.u32 	[%rd947+48], %rd927;
	st.u32 	[%rd947+52], %rd928;
	st.u32 	[%rd947+56], %rd935;
	st.u32 	[%rd947+60], %rd936;
	st.u32 	[%rd947+32], %rd931;
	st.u32 	[%rd947+36], %rd932;
	st.u32 	[%rd947+40], %rd939;
	st.u32 	[%rd947+44], %rd940;
	mov.u32 	%r171, 1175;
	@%p178 bra 	LBB0_55;
	bra.uni 	LBB0_53;
LBB0_55:                                // %.459
	setp.lt.u64 	%p180, %rd121, 120;
	@%p180 bra 	LBB0_147;
// %bb.56:
	xor.b32  	%r280, %r171, 563;
	and.b32  	%r281, %r280, 4095;
	cvt.u64.u32 	%rd948, %r281;
	add.s64 	%rd949, %rd126, %rd948;
	st.global.u8 	[%rd949], %rs1;
	add.s64 	%rd121, %rd121, -120;
	shl.b64 	%rd950, %rd1410, 5;
	add.s64 	%rd951, %rd131, %rd950;
	st.u32 	[%rd951+28], %rd134;
	st.u32 	[%rd951+24], %rd134;
	st.u32 	[%rd951+20], %rd134;
	st.u32 	[%rd951+16], %rd134;
	st.u32 	[%rd951+12], %rd134;
	st.u32 	[%rd951+8], %rd134;
	st.u32 	[%rd951+4], %rd134;
	mov.u64 	%rd953, 468;
	st.u32 	[%rd951], %rd953;
	mov.u32 	%r171, 281;
	mov.u64 	%rd122, %rd1410;
LBB0_57:                                // %.771
	setp.lt.u64 	%p181, %rd121, 216;
	@%p181 bra 	LBB0_147;
// %bb.58:
	xor.b32  	%r283, %r171, 1118;
	and.b32  	%r284, %r283, 4095;
	cvt.u64.u32 	%rd954, %r284;
	add.s64 	%rd955, %rd126, %rd954;
	st.global.u8 	[%rd955], %rs1;
	add.s64 	%rd121, %rd121, -216;
	shl.b64 	%rd956, %rd122, 5;
	add.s64 	%rd957, %rd131, %rd956;
	ld.u32 	%rd958, [%rd957];
	ld.u32 	%rd959, [%rd957+4];
	shl.b64 	%rd960, %rd959, 32;
	or.b64  	%rd123, %rd960, %rd958;
	ld.u32 	%rd961, [%rd957+12];
	ld.u32 	%rd962, [%rd957+8];
	ld.u32 	%rd963, [%rd957+28];
	ld.u32 	%rd964, [%rd957+24];
	ld.u32 	%rd965, [%rd957+20];
	ld.u32 	%rd966, [%rd957+16];
	add.u64 	%rd967, %SP, 1824;
	add.u64 	%rd968, %SPL, 1824;
	st.local.u32 	[%rd968+16], %rd134;
	st.local.u32 	[%rd968+20], %rd134;
	st.local.u32 	[%rd968+24], %rd134;
	st.local.u32 	[%rd968+28], %rd134;
	st.local.u32 	[%rd968], %rd134;
	st.local.u32 	[%rd968+4], %rd134;
	st.local.u32 	[%rd968+8], %rd134;
	st.local.u32 	[%rd968+12], %rd134;
	add.u64 	%rd970, %SP, 1856;
	add.u64 	%rd971, %SPL, 1856;
	{ // callseq 46, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd967;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd970;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 46
	{ // callseq 47, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd967;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r285, [retval0+0];
	} // callseq 47
	setp.eq.s32 	%p182, %r285, %r172;
	setp.eq.s32 	%p183, %r285, %r173;
	or.pred  	%p184, %p182, %p183;
	setp.eq.s32 	%p185, %r285, %r174;
	or.pred  	%p186, %p184, %p185;
	setp.eq.s32 	%p187, %r285, %r175;
	or.pred  	%p188, %p186, %p187;
	setp.eq.s32 	%p189, %r285, %r176;
	or.pred  	%p190, %p188, %p189;
	setp.eq.s32 	%p191, %r285, %r177;
	or.pred  	%p192, %p190, %p191;
	selp.u16 	%rs43, 1, 0, %p192;
	st.global.u8 	[%rd126+4], %rs43;
	ld.local.u32 	%rd972, [%rd971+12];
	ld.local.u32 	%rd973, [%rd971+8];
	ld.local.u32 	%rd974, [%rd971+4];
	ld.local.u32 	%rd975, [%rd971];
	ld.local.u32 	%rd976, [%rd971+28];
	ld.local.u32 	%rd977, [%rd971+24];
	ld.local.u32 	%rd978, [%rd971+20];
	ld.local.u32 	%rd979, [%rd971+16];
	add.s64 	%rd122, %rd122, 1;
	st.u32 	[%rd957+16], %rd966;
	st.u32 	[%rd957+20], %rd965;
	st.u32 	[%rd957+24], %rd964;
	st.u32 	[%rd957+28], %rd963;
	st.u32 	[%rd957], %rd958;
	st.u32 	[%rd957+4], %rd959;
	st.u32 	[%rd957+8], %rd962;
	st.u32 	[%rd957+12], %rd961;
	st.u32 	[%rd957+48], %rd979;
	st.u32 	[%rd957+52], %rd978;
	st.u32 	[%rd957+56], %rd977;
	st.u32 	[%rd957+60], %rd976;
	st.u32 	[%rd957+32], %rd975;
	st.u32 	[%rd957+36], %rd974;
	st.u32 	[%rd957+40], %rd973;
	st.u32 	[%rd957+44], %rd972;
	mov.u32 	%r171, 559;
	bra.uni 	LBB0_98;
LBB0_53:                                // %.455
	setp.lt.u64 	%p179, %rd121, 40;
	@%p179 bra 	LBB0_147;
// %bb.54:
	st.global.u8 	[%rd126+1780], %rs1;
	bra.uni 	LBB0_147;
LBB0_59:                                // %.468
	setp.lt.u64 	%p90, %rd121, 184;
	@%p90 bra 	LBB0_147;
// %bb.60:
	xor.b32  	%r214, %r171, 1951;
	and.b32  	%r215, %r214, 4095;
	cvt.u64.u32 	%rd411, %r215;
	add.s64 	%rd412, %rd126, %rd411;
	st.global.u8 	[%rd412], %rs1;
	shl.b64 	%rd413, %rd122, 5;
	add.s64 	%rd414, %rd131, %rd413;
	ld.u32 	%rd415, [%rd414];
	ld.u32 	%rd416, [%rd414+4];
	ld.u32 	%rd417, [%rd414+8];
	ld.u32 	%rd418, [%rd414+12];
	ld.u32 	%rd419, [%rd414+16];
	ld.u32 	%rd420, [%rd414+20];
	ld.u32 	%rd421, [%rd414+24];
	ld.u32 	%rd422, [%rd414+28];
	add.u64 	%rd423, %SP, 800;
	add.u64 	%rd424, %SPL, 800;
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd423;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 20
	ld.local.u32 	%rd426, [%rd424];
	ld.local.u32 	%rd427, [%rd424+4];
	shl.b64 	%rd428, %rd427, 32;
	or.b64  	%rd429, %rd428, %rd426;
	add.u64 	%rd430, %SP, 832;
	add.u64 	%rd431, %SPL, 832;
	st.local.u32 	[%rd431+28], %rd422;
	st.local.u32 	[%rd431+24], %rd421;
	st.local.u32 	[%rd431+20], %rd420;
	st.local.u32 	[%rd431+16], %rd419;
	st.local.u32 	[%rd431+12], %rd418;
	st.local.u32 	[%rd431+8], %rd417;
	st.local.u32 	[%rd431+4], %rd416;
	st.local.u32 	[%rd431], %rd415;
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd429;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd430;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 21
	add.u64 	%rd433, %SP, 864;
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd433;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 22
	bra.uni 	LBB0_95;
LBB0_61:                                // %.490
	setp.lt.u64 	%p154, %rd121, 96;
	@%p154 bra 	LBB0_147;
// %bb.62:
	xor.b32  	%r259, %r171, 1225;
	and.b32  	%r260, %r259, 4095;
	cvt.u64.u32 	%rd777, %r260;
	add.s64 	%rd778, %rd126, %rd777;
	st.global.u8 	[%rd778], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd779, [%rd124+16];
	ld.u32 	%rd780, [%rd124+20];
	shl.b64 	%rd781, %rd780, 32;
	or.b64  	%rd782, %rd781, %rd779;
	ld.u32 	%rd783, [%rd124];
	ld.u32 	%rd784, [%rd124+4];
	shl.b64 	%rd785, %rd784, 32;
	or.b64  	%rd786, %rd785, %rd783;
	ld.u32 	%rd787, [%rd124+24];
	ld.u32 	%rd788, [%rd124+28];
	shl.b64 	%rd789, %rd788, 32;
	or.b64  	%rd790, %rd789, %rd787;
	ld.u32 	%rd791, [%rd124+8];
	ld.u32 	%rd792, [%rd124+12];
	shl.b64 	%rd793, %rd792, 32;
	or.b64  	%rd794, %rd793, %rd791;
	or.b64  	%rd795, %rd794, %rd790;
	or.b64  	%rd796, %rd786, %rd782;
	or.b64  	%rd797, %rd796, %rd795;
	setp.eq.s64 	%p155, %rd797, 0;
	add.s64 	%rd1414, %rd122, 1;
	shl.b64 	%rd798, %rd122, 5;
	add.s64 	%rd799, %rd131, %rd798;
	st.u32 	[%rd799+48], %rd779;
	st.u32 	[%rd799+52], %rd780;
	st.u32 	[%rd799+56], %rd787;
	st.u32 	[%rd799+60], %rd788;
	st.u32 	[%rd799+32], %rd783;
	st.u32 	[%rd799+36], %rd784;
	st.u32 	[%rd799+40], %rd791;
	st.u32 	[%rd799+44], %rd792;
	mov.u32 	%r171, 612;
	@%p155 bra 	LBB0_65;
	bra.uni 	LBB0_63;
LBB0_65:                                // %.502
	setp.lt.u64 	%p157, %rd121, 336;
	@%p157 bra 	LBB0_147;
// %bb.66:
	xor.b32  	%r262, %r171, 2918;
	and.b32  	%r263, %r262, 4095;
	cvt.u64.u32 	%rd800, %r263;
	add.s64 	%rd801, %rd126, %rd800;
	st.global.u8 	[%rd801], %rs1;
	add.s64 	%rd121, %rd121, -336;
	shl.b64 	%rd802, %rd1414, 5;
	add.s64 	%rd803, %rd131, %rd802;
	add.u64 	%rd804, %SP, 896;
	add.u64 	%rd805, %SPL, 896;
	{ // callseq 37, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd804;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1388;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 37
	ld.local.u32 	%rd807, [%rd805+12];
	ld.local.u32 	%rd808, [%rd805+8];
	ld.local.u32 	%rd809, [%rd805+4];
	ld.local.u32 	%rd810, [%rd805];
	ld.local.u32 	%rd811, [%rd805+28];
	ld.local.u32 	%rd812, [%rd805+24];
	ld.local.u32 	%rd813, [%rd805+20];
	ld.local.u32 	%rd814, [%rd805+16];
	add.u64 	%rd815, %SP, 928;
	add.u64 	%rd816, %SPL, 928;
	{ // callseq 38, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd815;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1389;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 38
	ld.local.u32 	%rd818, [%rd816+12];
	ld.local.u32 	%rd819, [%rd816+8];
	ld.local.u32 	%rd820, [%rd816+4];
	ld.local.u32 	%rd821, [%rd816];
	ld.local.u32 	%rd822, [%rd816+28];
	ld.local.u32 	%rd823, [%rd816+24];
	ld.local.u32 	%rd824, [%rd816+20];
	ld.local.u32 	%rd825, [%rd816+16];
	st.u32 	[%rd803+16], %rd134;
	st.u32 	[%rd803+20], %rd134;
	st.u32 	[%rd803+24], %rd134;
	st.u32 	[%rd803+28], %rd134;
	mov.u64 	%rd827, 543;
	st.u32 	[%rd803], %rd827;
	st.u32 	[%rd803+4], %rd134;
	st.u32 	[%rd803+8], %rd134;
	st.u32 	[%rd803+12], %rd134;
	add.s64 	%rd122, %rd1414, 2;
	st.u32 	[%rd803+48], %rd814;
	st.u32 	[%rd803+52], %rd813;
	st.u32 	[%rd803+56], %rd812;
	st.u32 	[%rd803+60], %rd811;
	st.u32 	[%rd803+32], %rd810;
	st.u32 	[%rd803+36], %rd809;
	st.u32 	[%rd803+40], %rd808;
	st.u32 	[%rd803+44], %rd807;
	st.u32 	[%rd803+80], %rd825;
	st.u32 	[%rd803+84], %rd824;
	st.u32 	[%rd803+88], %rd823;
	st.u32 	[%rd803+92], %rd822;
	st.u32 	[%rd803+64], %rd821;
	st.u32 	[%rd803+68], %rd820;
	st.u32 	[%rd803+72], %rd819;
	st.u32 	[%rd803+76], %rd818;
	mov.u32 	%r171, 1459;
LBB0_67:                                // %.777
	setp.lt.u64 	%p158, %rd121, 312;
	@%p158 bra 	LBB0_147;
// %bb.68:
	xor.b32  	%r265, %r171, 2260;
	and.b32  	%r266, %r265, 4095;
	cvt.u64.u32 	%rd828, %r266;
	add.s64 	%rd829, %rd126, %rd828;
	st.global.u8 	[%rd829], %rs1;
	add.s64 	%rd121, %rd121, -312;
	shl.b64 	%rd830, %rd122, 5;
	add.s64 	%rd831, %rd131, %rd830;
	ld.u32 	%rd832, [%rd831+24];
	ld.u32 	%rd833, [%rd831+28];
	shl.b64 	%rd834, %rd833, 32;
	or.b64  	%rd835, %rd834, %rd832;
	ld.u32 	%rd836, [%rd831+16];
	ld.u32 	%rd837, [%rd831+20];
	shl.b64 	%rd838, %rd837, 32;
	or.b64  	%rd839, %rd838, %rd836;
	ld.u32 	%rd840, [%rd831];
	ld.u32 	%rd841, [%rd831+4];
	shl.b64 	%rd842, %rd841, 32;
	or.b64  	%rd843, %rd842, %rd840;
	ld.u32 	%rd844, [%rd831+8];
	ld.u32 	%rd845, [%rd831+12];
	shl.b64 	%rd846, %rd845, 32;
	or.b64  	%rd847, %rd846, %rd844;
	ld.u32 	%rd848, [%rd831+-8];
	ld.u32 	%rd849, [%rd831+-4];
	shl.b64 	%rd850, %rd849, 32;
	or.b64  	%rd851, %rd850, %rd848;
	ld.u32 	%rd852, [%rd831+-16];
	ld.u32 	%rd853, [%rd831+-12];
	shl.b64 	%rd854, %rd853, 32;
	or.b64  	%rd855, %rd854, %rd852;
	ld.u32 	%rd856, [%rd831+-32];
	ld.u32 	%rd857, [%rd831+-28];
	shl.b64 	%rd858, %rd857, 32;
	or.b64  	%rd859, %rd858, %rd856;
	ld.u32 	%rd860, [%rd831+-24];
	ld.u32 	%rd861, [%rd831+-20];
	shl.b64 	%rd862, %rd861, 32;
	or.b64  	%rd863, %rd862, %rd860;
	add.s64 	%rd122, %rd122, -2;
	ld.u32 	%rd864, [%rd831+-64];
	ld.u32 	%rd865, [%rd831+-60];
	shl.b64 	%rd866, %rd865, 32;
	or.b64  	%rd123, %rd866, %rd864;
	setp.eq.s64 	%p159, %rd863, %rd847;
	setp.lt.u64 	%p160, %rd863, %rd847;
	selp.u32 	%r267, -1, 0, %p160;
	setp.lt.u64 	%p161, %rd859, %rd843;
	selp.u32 	%r268, -1, 0, %p161;
	selp.b32 	%r269, %r268, %r267, %p159;
	cvt.u64.u32 	%rd867, %r269;
	and.b64  	%rd868, %rd867, 1;
	sub.s64 	%rd869, %rd855, %rd839;
	setp.lt.u64 	%p162, %rd869, %rd868;
	selp.s64 	%rd870, -1, 0, %p162;
	sub.s64 	%rd871, %rd851, %rd835;
	setp.lt.u64 	%p163, %rd855, %rd839;
	selp.s64 	%rd872, -1, 0, %p163;
	add.s64 	%rd873, %rd871, %rd872;
	add.s64 	%rd874, %rd873, %rd870;
	and.b32  	%r270, %r269, 1;
	setp.eq.b32 	%p164, %r270, 1;
	selp.s64 	%rd875, -1, 0, %p164;
	add.s64 	%rd876, %rd869, %rd875;
	sub.s64 	%rd877, %rd863, %rd847;
	selp.s64 	%rd878, -1, 0, %p161;
	add.s64 	%rd879, %rd877, %rd878;
	sub.s64 	%rd880, %rd859, %rd843;
	add.u64 	%rd881, %SP, 1888;
	add.u64 	%rd882, %SPL, 1888;
	st.local.u32 	[%rd882+24], %rd134;
	st.local.u32 	[%rd882+28], %rd134;
	st.local.u32 	[%rd882], %rd134;
	st.local.u32 	[%rd882+4], %rd134;
	st.local.u32 	[%rd882+8], %rd134;
	st.local.u32 	[%rd882+12], %rd134;
	st.local.u32 	[%rd882+16], %rd134;
	st.local.u32 	[%rd882+20], %rd134;
	add.u64 	%rd884, %SP, 1920;
	add.u64 	%rd885, %SPL, 1920;
	st.local.u32 	[%rd885], %rd880;
	shr.u64 	%rd886, %rd880, 32;
	st.local.u32 	[%rd885+4], %rd886;
	st.local.u32 	[%rd885+8], %rd879;
	shr.u64 	%rd887, %rd879, 32;
	st.local.u32 	[%rd885+12], %rd887;
	st.local.u32 	[%rd885+16], %rd876;
	shr.u64 	%rd888, %rd876, 32;
	st.local.u32 	[%rd885+20], %rd888;
	st.local.u32 	[%rd885+24], %rd874;
	shr.u64 	%rd889, %rd874, 32;
	st.local.u32 	[%rd885+28], %rd889;
	{ // callseq 39, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd881;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd884;
	call.uni 
	__device_sstore, 
	(
	param0, 
	param1
	);
	} // callseq 39
	{ // callseq 40, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd881;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r176, [retval0+0];
	} // callseq 40
	add.u64 	%rd890, %SP, 1952;
	add.u64 	%rd891, %SPL, 1952;
	st.local.u32 	[%rd891+28], %rd134;
	st.local.u32 	[%rd891+24], %rd134;
	st.local.u32 	[%rd891+20], %rd134;
	st.local.u32 	[%rd891+16], %rd134;
	st.local.u32 	[%rd891+12], %rd134;
	st.local.u32 	[%rd891+8], %rd134;
	st.local.u32 	[%rd891+4], %rd134;
	st.local.u32 	[%rd891], %rd134;
	add.u64 	%rd892, %SP, 1984;
	add.u64 	%rd893, %SPL, 1984;
	{ // callseq 41, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd890;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd892;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 41
	{ // callseq 42, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd890;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r272, [retval0+0];
	} // callseq 42
	setp.eq.s32 	%p165, %r272, %r172;
	setp.eq.s32 	%p166, %r272, %r173;
	or.pred  	%p167, %p165, %p166;
	setp.eq.s32 	%p168, %r272, %r174;
	or.pred  	%p169, %p167, %p168;
	setp.eq.s32 	%p170, %r272, %r175;
	or.pred  	%p171, %p169, %p170;
	setp.eq.s32 	%p172, %r272, %r176;
	or.pred  	%p173, %p171, %p172;
	setp.eq.s32 	%p174, %r272, %r177;
	or.pred  	%p175, %p173, %p174;
	selp.u16 	%rs37, 1, 0, %p175;
	st.global.u8 	[%rd126+5], %rs37;
	ld.local.u32 	%rd894, [%rd893+12];
	ld.local.u32 	%rd895, [%rd893+8];
	ld.local.u32 	%rd896, [%rd893+4];
	ld.local.u32 	%rd897, [%rd893];
	ld.local.u32 	%rd898, [%rd893+28];
	ld.local.u32 	%rd899, [%rd893+24];
	ld.local.u32 	%rd900, [%rd893+20];
	ld.local.u32 	%rd901, [%rd893+16];
	st.u32 	[%rd831+-48], %rd901;
	st.u32 	[%rd831+-44], %rd900;
	st.u32 	[%rd831+-40], %rd899;
	st.u32 	[%rd831+-36], %rd898;
	st.u32 	[%rd831+-64], %rd897;
	st.u32 	[%rd831+-60], %rd896;
	st.u32 	[%rd831+-56], %rd895;
	st.u32 	[%rd831+-52], %rd894;
	mov.u32 	%r171, 1130;
	bra.uni 	LBB0_98;
LBB0_63:                                // %.498
	setp.lt.u64 	%p156, %rd121, 40;
	@%p156 bra 	LBB0_147;
// %bb.64:
	st.global.u8 	[%rd126+1534], %rs1;
	bra.uni 	LBB0_147;
LBB0_69:                                // %.543
	setp.lt.u64 	%p89, %rd121, 184;
	@%p89 bra 	LBB0_147;
// %bb.70:
	xor.b32  	%r212, %r171, 3378;
	and.b32  	%r213, %r212, 4095;
	cvt.u64.u32 	%rd388, %r213;
	add.s64 	%rd389, %rd126, %rd388;
	st.global.u8 	[%rd389], %rs1;
	shl.b64 	%rd390, %rd122, 5;
	add.s64 	%rd391, %rd131, %rd390;
	ld.u32 	%rd392, [%rd391];
	ld.u32 	%rd393, [%rd391+4];
	ld.u32 	%rd394, [%rd391+8];
	ld.u32 	%rd395, [%rd391+12];
	ld.u32 	%rd396, [%rd391+16];
	ld.u32 	%rd397, [%rd391+20];
	ld.u32 	%rd398, [%rd391+24];
	ld.u32 	%rd399, [%rd391+28];
	add.u64 	%rd400, %SP, 960;
	add.u64 	%rd401, %SPL, 960;
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd400;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 17
	ld.local.u32 	%rd403, [%rd401];
	ld.local.u32 	%rd404, [%rd401+4];
	shl.b64 	%rd405, %rd404, 32;
	or.b64  	%rd406, %rd405, %rd403;
	add.u64 	%rd407, %SP, 992;
	add.u64 	%rd408, %SPL, 992;
	st.local.u32 	[%rd408+28], %rd399;
	st.local.u32 	[%rd408+24], %rd398;
	st.local.u32 	[%rd408+20], %rd397;
	st.local.u32 	[%rd408+16], %rd396;
	st.local.u32 	[%rd408+12], %rd395;
	st.local.u32 	[%rd408+8], %rd394;
	st.local.u32 	[%rd408+4], %rd393;
	st.local.u32 	[%rd408], %rd392;
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd406;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd407;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 18
	add.u64 	%rd410, %SP, 1024;
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd410;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 19
	bra.uni 	LBB0_95;
LBB0_71:                                // %.565
	setp.lt.u64 	%p137, %rd121, 96;
	@%p137 bra 	LBB0_147;
// %bb.72:
	xor.b32  	%r246, %r171, 13;
	and.b32  	%r247, %r246, 4095;
	cvt.u64.u32 	%rd698, %r247;
	add.s64 	%rd699, %rd126, %rd698;
	st.global.u8 	[%rd699], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd700, [%rd124+16];
	ld.u32 	%rd701, [%rd124+20];
	shl.b64 	%rd702, %rd701, 32;
	or.b64  	%rd703, %rd702, %rd700;
	ld.u32 	%rd704, [%rd124];
	ld.u32 	%rd705, [%rd124+4];
	shl.b64 	%rd706, %rd705, 32;
	or.b64  	%rd707, %rd706, %rd704;
	ld.u32 	%rd708, [%rd124+24];
	ld.u32 	%rd709, [%rd124+28];
	shl.b64 	%rd710, %rd709, 32;
	or.b64  	%rd711, %rd710, %rd708;
	ld.u32 	%rd712, [%rd124+8];
	ld.u32 	%rd713, [%rd124+12];
	shl.b64 	%rd714, %rd713, 32;
	or.b64  	%rd715, %rd714, %rd712;
	or.b64  	%rd716, %rd715, %rd711;
	or.b64  	%rd717, %rd707, %rd703;
	or.b64  	%rd718, %rd717, %rd716;
	setp.eq.s64 	%p138, %rd718, 0;
	add.s64 	%rd1418, %rd122, 1;
	shl.b64 	%rd719, %rd122, 5;
	add.s64 	%rd720, %rd131, %rd719;
	st.u32 	[%rd720+48], %rd700;
	st.u32 	[%rd720+52], %rd701;
	st.u32 	[%rd720+56], %rd708;
	st.u32 	[%rd720+60], %rd709;
	st.u32 	[%rd720+32], %rd704;
	st.u32 	[%rd720+36], %rd705;
	st.u32 	[%rd720+40], %rd712;
	st.u32 	[%rd720+44], %rd713;
	mov.u32 	%r171, 6;
	@%p138 bra 	LBB0_75;
	bra.uni 	LBB0_73;
LBB0_75:                                // %.577
	setp.lt.u64 	%p140, %rd121, 120;
	@%p140 bra 	LBB0_147;
// %bb.76:
	xor.b32  	%r249, %r171, 2609;
	and.b32  	%r250, %r249, 4095;
	cvt.u64.u32 	%rd721, %r250;
	add.s64 	%rd722, %rd126, %rd721;
	st.global.u8 	[%rd722], %rs1;
	add.s64 	%rd121, %rd121, -120;
	shl.b64 	%rd723, %rd1418, 5;
	add.s64 	%rd724, %rd131, %rd723;
	st.u32 	[%rd724+28], %rd134;
	st.u32 	[%rd724+24], %rd134;
	st.u32 	[%rd724+20], %rd134;
	st.u32 	[%rd724+16], %rd134;
	st.u32 	[%rd724+12], %rd134;
	st.u32 	[%rd724+8], %rd134;
	st.u32 	[%rd724+4], %rd134;
	mov.u64 	%rd726, 586;
	st.u32 	[%rd724], %rd726;
	mov.u32 	%r171, 1304;
	mov.u64 	%rd122, %rd1418;
LBB0_77:                                // %.799
	setp.lt.u64 	%p141, %rd121, 216;
	@%p141 bra 	LBB0_147;
// %bb.78:
	xor.b32  	%r252, %r171, 3499;
	and.b32  	%r253, %r252, 4095;
	cvt.u64.u32 	%rd727, %r253;
	add.s64 	%rd728, %rd126, %rd727;
	st.global.u8 	[%rd728], %rs1;
	add.s64 	%rd121, %rd121, -216;
	shl.b64 	%rd729, %rd122, 5;
	add.s64 	%rd730, %rd131, %rd729;
	ld.u32 	%rd731, [%rd730];
	ld.u32 	%rd732, [%rd730+4];
	shl.b64 	%rd733, %rd732, 32;
	or.b64  	%rd123, %rd733, %rd731;
	ld.u32 	%rd734, [%rd730+12];
	ld.u32 	%rd735, [%rd730+8];
	ld.u32 	%rd736, [%rd730+28];
	ld.u32 	%rd737, [%rd730+24];
	ld.u32 	%rd738, [%rd730+20];
	ld.u32 	%rd739, [%rd730+16];
	add.u64 	%rd740, %SP, 2016;
	add.u64 	%rd741, %SPL, 2016;
	st.local.u32 	[%rd741+16], %rd134;
	st.local.u32 	[%rd741+20], %rd134;
	st.local.u32 	[%rd741+24], %rd134;
	st.local.u32 	[%rd741+28], %rd134;
	mov.u64 	%rd743, 1;
	st.local.u32 	[%rd741], %rd743;
	st.local.u32 	[%rd741+4], %rd134;
	st.local.u32 	[%rd741+8], %rd134;
	st.local.u32 	[%rd741+12], %rd134;
	add.u64 	%rd744, %SP, 2048;
	add.u64 	%rd745, %SPL, 2048;
	{ // callseq 32, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd740;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd744;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 32
	{ // callseq 33, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd740;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r254, [retval0+0];
	} // callseq 33
	setp.eq.s32 	%p142, %r254, %r172;
	setp.eq.s32 	%p143, %r254, %r173;
	or.pred  	%p144, %p142, %p143;
	setp.eq.s32 	%p145, %r254, %r174;
	or.pred  	%p146, %p144, %p145;
	setp.eq.s32 	%p147, %r254, %r175;
	or.pred  	%p148, %p146, %p147;
	setp.eq.s32 	%p149, %r254, %r176;
	or.pred  	%p150, %p148, %p149;
	setp.eq.s32 	%p151, %r254, %r177;
	or.pred  	%p152, %p150, %p151;
	selp.u16 	%rs31, 1, 0, %p152;
	st.global.u8 	[%rd126+6], %rs31;
	ld.local.u32 	%rd746, [%rd745+12];
	ld.local.u32 	%rd747, [%rd745+8];
	ld.local.u32 	%rd748, [%rd745+4];
	ld.local.u32 	%rd749, [%rd745];
	ld.local.u32 	%rd750, [%rd745+28];
	ld.local.u32 	%rd751, [%rd745+24];
	ld.local.u32 	%rd752, [%rd745+20];
	ld.local.u32 	%rd753, [%rd745+16];
	add.s64 	%rd122, %rd122, 1;
	st.u32 	[%rd730+16], %rd739;
	st.u32 	[%rd730+20], %rd738;
	st.u32 	[%rd730+24], %rd737;
	st.u32 	[%rd730+28], %rd736;
	st.u32 	[%rd730], %rd731;
	st.u32 	[%rd730+4], %rd732;
	st.u32 	[%rd730+8], %rd735;
	st.u32 	[%rd730+12], %rd734;
	st.u32 	[%rd730+48], %rd753;
	st.u32 	[%rd730+52], %rd752;
	st.u32 	[%rd730+56], %rd751;
	st.u32 	[%rd730+60], %rd750;
	st.u32 	[%rd730+32], %rd749;
	st.u32 	[%rd730+36], %rd748;
	st.u32 	[%rd730+40], %rd747;
	st.u32 	[%rd730+44], %rd746;
	mov.u32 	%r171, 1749;
	bra.uni 	LBB0_98;
LBB0_73:                                // %.573
	setp.lt.u64 	%p139, %rd121, 40;
	@%p139 bra 	LBB0_147;
// %bb.74:
	st.global.u8 	[%rd126+1969], %rs1;
	bra.uni 	LBB0_147;
LBB0_79:                                // %.586
	setp.lt.u64 	%p88, %rd121, 184;
	@%p88 bra 	LBB0_147;
// %bb.80:
	xor.b32  	%r210, %r171, 1112;
	and.b32  	%r211, %r210, 4095;
	cvt.u64.u32 	%rd365, %r211;
	add.s64 	%rd366, %rd126, %rd365;
	st.global.u8 	[%rd366], %rs1;
	shl.b64 	%rd367, %rd122, 5;
	add.s64 	%rd368, %rd131, %rd367;
	ld.u32 	%rd369, [%rd368];
	ld.u32 	%rd370, [%rd368+4];
	ld.u32 	%rd371, [%rd368+8];
	ld.u32 	%rd372, [%rd368+12];
	ld.u32 	%rd373, [%rd368+16];
	ld.u32 	%rd374, [%rd368+20];
	ld.u32 	%rd375, [%rd368+24];
	ld.u32 	%rd376, [%rd368+28];
	add.u64 	%rd377, %SP, 1056;
	add.u64 	%rd378, %SPL, 1056;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd377;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 14
	ld.local.u32 	%rd380, [%rd378];
	ld.local.u32 	%rd381, [%rd378+4];
	shl.b64 	%rd382, %rd381, 32;
	or.b64  	%rd383, %rd382, %rd380;
	add.u64 	%rd384, %SP, 1088;
	add.u64 	%rd385, %SPL, 1088;
	st.local.u32 	[%rd385+28], %rd376;
	st.local.u32 	[%rd385+24], %rd375;
	st.local.u32 	[%rd385+20], %rd374;
	st.local.u32 	[%rd385+16], %rd373;
	st.local.u32 	[%rd385+12], %rd372;
	st.local.u32 	[%rd385+8], %rd371;
	st.local.u32 	[%rd385+4], %rd370;
	st.local.u32 	[%rd385], %rd369;
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd383;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd384;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 15
	add.u64 	%rd387, %SP, 1120;
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd387;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 16
	bra.uni 	LBB0_95;
LBB0_81:                                // %.608
	setp.lt.u64 	%p91, %rd121, 96;
	@%p91 bra 	LBB0_147;
// %bb.82:
	xor.b32  	%r217, %r171, 163;
	and.b32  	%r218, %r217, 4095;
	cvt.u64.u32 	%rd434, %r218;
	add.s64 	%rd435, %rd126, %rd434;
	st.global.u8 	[%rd435], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd436, [%rd124+16];
	ld.u32 	%rd437, [%rd124+20];
	shl.b64 	%rd438, %rd437, 32;
	or.b64  	%rd439, %rd438, %rd436;
	ld.u32 	%rd440, [%rd124];
	ld.u32 	%rd441, [%rd124+4];
	shl.b64 	%rd442, %rd441, 32;
	or.b64  	%rd443, %rd442, %rd440;
	ld.u32 	%rd444, [%rd124+24];
	ld.u32 	%rd445, [%rd124+28];
	shl.b64 	%rd446, %rd445, 32;
	or.b64  	%rd447, %rd446, %rd444;
	ld.u32 	%rd448, [%rd124+8];
	ld.u32 	%rd449, [%rd124+12];
	shl.b64 	%rd450, %rd449, 32;
	or.b64  	%rd451, %rd450, %rd448;
	or.b64  	%rd452, %rd451, %rd447;
	or.b64  	%rd453, %rd443, %rd439;
	or.b64  	%rd454, %rd453, %rd452;
	setp.eq.s64 	%p92, %rd454, 0;
	add.s64 	%rd1422, %rd122, 1;
	shl.b64 	%rd455, %rd122, 5;
	add.s64 	%rd456, %rd131, %rd455;
	st.u32 	[%rd456+48], %rd436;
	st.u32 	[%rd456+52], %rd437;
	st.u32 	[%rd456+56], %rd444;
	st.u32 	[%rd456+60], %rd445;
	st.u32 	[%rd456+32], %rd440;
	st.u32 	[%rd456+36], %rd441;
	st.u32 	[%rd456+40], %rd448;
	st.u32 	[%rd456+44], %rd449;
	mov.u32 	%r171, 81;
	@%p92 bra 	LBB0_85;
	bra.uni 	LBB0_83;
LBB0_85:                                // %.620
	setp.lt.u64 	%p94, %rd121, 336;
	@%p94 bra 	LBB0_147;
// %bb.86:
	xor.b32  	%r220, %r171, 293;
	and.b32  	%r221, %r220, 4095;
	cvt.u64.u32 	%rd457, %r221;
	add.s64 	%rd458, %rd126, %rd457;
	st.global.u8 	[%rd458], %rs1;
	add.s64 	%rd121, %rd121, -336;
	shl.b64 	%rd459, %rd1422, 5;
	add.s64 	%rd460, %rd131, %rd459;
	add.u64 	%rd461, %SP, 1152;
	add.u64 	%rd462, %SPL, 1152;
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd461;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1388;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 23
	ld.local.u32 	%rd464, [%rd462+12];
	ld.local.u32 	%rd465, [%rd462+8];
	ld.local.u32 	%rd466, [%rd462+4];
	ld.local.u32 	%rd467, [%rd462];
	ld.local.u32 	%rd468, [%rd462+28];
	ld.local.u32 	%rd469, [%rd462+24];
	ld.local.u32 	%rd470, [%rd462+20];
	ld.local.u32 	%rd471, [%rd462+16];
	add.u64 	%rd472, %SP, 1184;
	add.u64 	%rd473, %SPL, 1184;
	{ // callseq 24, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd472;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1389;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 24
	ld.local.u32 	%rd475, [%rd473+12];
	ld.local.u32 	%rd476, [%rd473+8];
	ld.local.u32 	%rd477, [%rd473+4];
	ld.local.u32 	%rd478, [%rd473];
	ld.local.u32 	%rd479, [%rd473+28];
	ld.local.u32 	%rd480, [%rd473+24];
	ld.local.u32 	%rd481, [%rd473+20];
	ld.local.u32 	%rd482, [%rd473+16];
	st.u32 	[%rd460+16], %rd134;
	st.u32 	[%rd460+20], %rd134;
	st.u32 	[%rd460+24], %rd134;
	st.u32 	[%rd460+28], %rd134;
	mov.u64 	%rd484, 661;
	st.u32 	[%rd460], %rd484;
	st.u32 	[%rd460+4], %rd134;
	st.u32 	[%rd460+8], %rd134;
	st.u32 	[%rd460+12], %rd134;
	add.s64 	%rd122, %rd1422, 2;
	st.u32 	[%rd460+48], %rd471;
	st.u32 	[%rd460+52], %rd470;
	st.u32 	[%rd460+56], %rd469;
	st.u32 	[%rd460+60], %rd468;
	st.u32 	[%rd460+32], %rd467;
	st.u32 	[%rd460+36], %rd466;
	st.u32 	[%rd460+40], %rd465;
	st.u32 	[%rd460+44], %rd464;
	st.u32 	[%rd460+80], %rd482;
	st.u32 	[%rd460+84], %rd481;
	st.u32 	[%rd460+88], %rd480;
	st.u32 	[%rd460+92], %rd479;
	st.u32 	[%rd460+64], %rd478;
	st.u32 	[%rd460+68], %rd477;
	st.u32 	[%rd460+72], %rd476;
	st.u32 	[%rd460+76], %rd475;
	mov.u32 	%r171, 146;
LBB0_87:                                // %.805
	shl.b64 	%rd485, %rd122, 5;
	add.s64 	%rd486, %rd131, %rd485;
	st.u32 	[%rd486+60], %rd134;
	st.u32 	[%rd486+56], %rd134;
	st.u32 	[%rd486+52], %rd134;
	st.u32 	[%rd486+48], %rd134;
	st.u32 	[%rd486+44], %rd134;
	st.u32 	[%rd486+40], %rd134;
	st.u32 	[%rd486+36], %rd134;
	st.u32 	[%rd486+32], %rd134;
	st.u32 	[%rd486+92], %rd134;
	st.u32 	[%rd486+88], %rd134;
	st.u32 	[%rd486+84], %rd134;
	st.u32 	[%rd486+80], %rd134;
	st.u32 	[%rd486+76], %rd134;
	st.u32 	[%rd486+72], %rd134;
	st.u32 	[%rd486+68], %rd134;
	mov.u64 	%rd488, 1;
	st.u32 	[%rd486+64], %rd488;
	add.s64 	%rd122, %rd122, 3;
	st.u32 	[%rd486+124], %rd134;
	st.u32 	[%rd486+120], %rd134;
	st.u32 	[%rd486+116], %rd134;
	st.u32 	[%rd486+112], %rd134;
	st.u32 	[%rd486+108], %rd134;
	st.u32 	[%rd486+104], %rd134;
	st.u32 	[%rd486+100], %rd134;
	st.u32 	[%rd486+96], %rd134;
LBB0_88:                                // %.819.preheader
	shl.b64 	%rd491, %rd122, 5;
	add.s64 	%rd113, %rd131, %rd491;
LBB0_89:                                // %.819
                                        // =>This Inner Loop Header: Depth=1
	setp.lt.u64 	%p95, %rd121, 432;
	@%p95 bra 	LBB0_147;
// %bb.90:                              //   in Loop: Header=BB0_89 Depth=1
	xor.b32  	%r223, %r171, 3250;
	and.b32  	%r224, %r223, 4095;
	cvt.u64.u32 	%rd489, %r224;
	add.s64 	%rd490, %rd126, %rd489;
	st.global.u8 	[%rd490], %rs1;
	add.s64 	%rd121, %rd121, -432;
	ld.u32 	%rd492, [%rd113];
	ld.u32 	%rd493, [%rd113+4];
	shl.b64 	%rd494, %rd493, 32;
	or.b64  	%rd495, %rd494, %rd492;
	ld.u32 	%rd496, [%rd113+8];
	ld.u32 	%rd497, [%rd113+12];
	shl.b64 	%rd498, %rd497, 32;
	or.b64  	%rd499, %rd498, %rd496;
	ld.u32 	%rd500, [%rd113+16];
	ld.u32 	%rd501, [%rd113+20];
	shl.b64 	%rd502, %rd501, 32;
	or.b64  	%rd503, %rd502, %rd500;
	ld.u32 	%rd504, [%rd113+24];
	ld.u32 	%rd505, [%rd113+28];
	shl.b64 	%rd506, %rd505, 32;
	or.b64  	%rd507, %rd506, %rd504;
	ld.u32 	%rd508, [%rd113+-96];
	ld.u32 	%rd509, [%rd113+-92];
	shl.b64 	%rd510, %rd509, 32;
	or.b64  	%rd511, %rd510, %rd508;
	ld.u32 	%rd512, [%rd113+-88];
	ld.u32 	%rd513, [%rd113+-84];
	shl.b64 	%rd514, %rd513, 32;
	or.b64  	%rd515, %rd514, %rd512;
	ld.u32 	%rd516, [%rd113+-80];
	ld.u32 	%rd517, [%rd113+-76];
	shl.b64 	%rd518, %rd517, 32;
	or.b64  	%rd519, %rd518, %rd516;
	ld.u32 	%rd520, [%rd113+-72];
	ld.u32 	%rd521, [%rd113+-68];
	shl.b64 	%rd522, %rd521, 32;
	or.b64  	%rd523, %rd522, %rd520;
	setp.eq.s64 	%p96, %rd507, %rd523;
	setp.ge.u64 	%p97, %rd507, %rd523;
	selp.u32 	%r225, -1, 0, %p97;
	setp.ge.u64 	%p98, %rd503, %rd519;
	selp.u32 	%r226, -1, 0, %p98;
	selp.b32 	%r227, %r226, %r225, %p96;
	setp.eq.s64 	%p99, %rd499, %rd515;
	setp.ge.u64 	%p100, %rd499, %rd515;
	selp.u32 	%r228, -1, 0, %p100;
	setp.ge.u64 	%p101, %rd495, %rd511;
	selp.u32 	%r229, -1, 0, %p101;
	selp.b32 	%r230, %r229, %r228, %p99;
	xor.b64  	%rd524, %rd507, %rd523;
	xor.b64  	%rd525, %rd503, %rd519;
	or.b64  	%rd526, %rd525, %rd524;
	setp.eq.s64 	%p102, %rd526, 0;
	selp.b32 	%r231, %r230, %r227, %p102;
	and.b32  	%r232, %r231, 1;
	setp.eq.b32 	%p103, %r232, 1;
	mov.u32 	%r171, 1625;
	@%p103 bra 	LBB0_96;
// %bb.91:                              // %.828
                                        //   in Loop: Header=BB0_89 Depth=1
	setp.lt.u64 	%p104, %rd121, 520;
	@%p104 bra 	LBB0_147;
// %bb.92:                              //   in Loop: Header=BB0_89 Depth=1
	add.s64 	%rd114, %rd122, -3;
	st.global.u8 	[%rd126+1684], %rs1;
	add.s64 	%rd121, %rd121, -520;
	ld.u32 	%rd527, [%rd113+24];
	ld.u32 	%rd528, [%rd113+28];
	shl.b64 	%rd529, %rd528, 32;
	or.b64  	%rd530, %rd529, %rd527;
	ld.u32 	%rd531, [%rd113+16];
	ld.u32 	%rd532, [%rd113+20];
	shl.b64 	%rd533, %rd532, 32;
	or.b64  	%rd534, %rd533, %rd531;
	ld.u32 	%rd535, [%rd113+8];
	ld.u32 	%rd536, [%rd113+12];
	shl.b64 	%rd537, %rd536, 32;
	or.b64  	%rd538, %rd537, %rd535;
	ld.u32 	%rd539, [%rd113];
	ld.u32 	%rd540, [%rd113+4];
	shl.b64 	%rd541, %rd540, 32;
	or.b64  	%rd542, %rd541, %rd539;
	ld.u32 	%rd543, [%rd113+-16];
	ld.u32 	%rd544, [%rd113+-12];
	shl.b64 	%rd545, %rd544, 32;
	or.b64  	%rd546, %rd545, %rd543;
	ld.u32 	%rd547, [%rd113+-8];
	ld.u32 	%rd548, [%rd113+-4];
	shl.b64 	%rd549, %rd548, 32;
	or.b64  	%rd550, %rd549, %rd547;
	ld.u32 	%rd551, [%rd113+-24];
	ld.u32 	%rd552, [%rd113+-20];
	shl.b64 	%rd553, %rd552, 32;
	or.b64  	%rd554, %rd553, %rd551;
	ld.u32 	%rd555, [%rd113+-32];
	ld.u32 	%rd556, [%rd113+-28];
	shl.b64 	%rd557, %rd556, 32;
	or.b64  	%rd558, %rd557, %rd555;
	shl.b64 	%rd559, %rd114, 5;
	add.s64 	%rd560, %rd131, %rd559;
	ld.u32 	%rd561, [%rd560+-8];
	ld.u32 	%rd562, [%rd560+-4];
	shl.b64 	%rd563, %rd562, 32;
	or.b64  	%rd564, %rd563, %rd561;
	ld.u32 	%rd565, [%rd560+-16];
	ld.u32 	%rd566, [%rd560+-12];
	shl.b64 	%rd567, %rd566, 32;
	or.b64  	%rd568, %rd567, %rd565;
	ld.u32 	%rd569, [%rd560+-24];
	ld.u32 	%rd570, [%rd560+-20];
	shl.b64 	%rd571, %rd570, 32;
	or.b64  	%rd572, %rd571, %rd569;
	ld.u32 	%rd573, [%rd560+-32];
	ld.u32 	%rd574, [%rd560+-28];
	shl.b64 	%rd575, %rd574, 32;
	or.b64  	%rd576, %rd575, %rd573;
	mul.hi.u64 	%rd577, %rd558, %rd576;
	mul.lo.s64 	%rd578, %rd554, %rd576;
	add.s64 	%rd579, %rd578, %rd577;
	setp.lt.u64 	%p105, %rd579, %rd577;
	setp.lt.u64 	%p106, %rd579, %rd578;
	selp.u64 	%rd580, 1, 0, %p106;
	selp.b64 	%rd581, 1, %rd580, %p105;
	mul.hi.u64 	%rd582, %rd554, %rd576;
	add.s64 	%rd583, %rd582, %rd581;
	mul.lo.s64 	%rd584, %rd558, %rd572;
	add.s64 	%rd585, %rd584, %rd579;
	setp.lt.u64 	%p107, %rd585, %rd579;
	setp.lt.u64 	%p108, %rd585, %rd584;
	selp.u64 	%rd586, 1, 0, %p108;
	selp.b64 	%rd587, 1, %rd586, %p107;
	mul.hi.u64 	%rd588, %rd558, %rd572;
	add.s64 	%rd589, %rd588, %rd587;
	add.s64 	%rd590, %rd583, %rd589;
	mul.lo.s64 	%rd591, %rd554, %rd572;
	add.s64 	%rd592, %rd591, %rd590;
	setp.lt.u64 	%p109, %rd592, %rd590;
	setp.lt.u64 	%p110, %rd592, %rd591;
	selp.u64 	%rd593, 1, 0, %p110;
	selp.b64 	%rd594, 1, %rd593, %p109;
	setp.lt.u64 	%p111, %rd590, %rd589;
	setp.lt.u64 	%p112, %rd590, %rd583;
	selp.u64 	%rd595, 1, 0, %p112;
	selp.b64 	%rd596, 1, %rd595, %p111;
	mul.hi.u64 	%rd597, %rd554, %rd572;
	add.s64 	%rd598, %rd597, %rd596;
	add.s64 	%rd599, %rd598, %rd594;
	mul.lo.s64 	%rd600, %rd576, %rd550;
	mul.hi.u64 	%rd601, %rd576, %rd546;
	add.s64 	%rd602, %rd601, %rd600;
	mul.lo.s64 	%rd603, %rd572, %rd546;
	add.s64 	%rd604, %rd602, %rd603;
	mul.lo.s64 	%rd605, %rd568, %rd554;
	mul.hi.u64 	%rd606, %rd568, %rd558;
	add.s64 	%rd607, %rd606, %rd605;
	mul.lo.s64 	%rd608, %rd564, %rd558;
	add.s64 	%rd609, %rd607, %rd608;
	add.s64 	%rd610, %rd609, %rd604;
	mul.lo.s64 	%rd611, %rd576, %rd546;
	mul.lo.s64 	%rd612, %rd568, %rd558;
	add.s64 	%rd613, %rd612, %rd611;
	setp.lt.u64 	%p113, %rd613, %rd611;
	setp.lt.u64 	%p114, %rd613, %rd612;
	selp.u64 	%rd614, 1, 0, %p114;
	selp.b64 	%rd615, 1, %rd614, %p113;
	add.s64 	%rd616, %rd610, %rd615;
	add.s64 	%rd617, %rd599, %rd616;
	add.s64 	%rd618, %rd592, %rd613;
	setp.lt.u64 	%p115, %rd618, %rd592;
	selp.u64 	%rd619, 1, 0, %p115;
	setp.lt.u64 	%p116, %rd618, %rd613;
	selp.b64 	%rd620, 1, %rd619, %p116;
	add.s64 	%rd621, %rd617, %rd620;
	mul.lo.s64 	%rd622, %rd558, %rd576;
	add.s64 	%rd623, %rd542, 1;
	setp.lt.u64 	%p117, %rd623, %rd542;
	selp.u32 	%r234, -1, 0, %p117;
	selp.u64 	%rd624, 1, 0, %p117;
	setp.eq.s64 	%p118, %rd623, 0;
	selp.b64 	%rd625, 1, %rd624, %p118;
	setp.eq.s64 	%p119, %rd625, 0;
	add.s64 	%rd626, %rd538, %rd625;
	setp.lt.u64 	%p120, %rd626, %rd538;
	selp.u32 	%r235, -1, 0, %p120;
	selp.b32 	%r236, %r234, %r235, %p119;
	cvt.u64.u32 	%rd627, %r236;
	and.b64  	%rd628, %rd627, 1;
	or.b64  	%rd629, %rd626, %rd623;
	setp.eq.s64 	%p121, %rd629, 0;
	selp.b64 	%rd630, 1, %rd628, %p121;
	add.s64 	%rd631, %rd534, %rd630;
	setp.lt.u64 	%p122, %rd631, %rd630;
	setp.lt.u64 	%p123, %rd631, %rd534;
	selp.u64 	%rd632, 1, 0, %p123;
	selp.b64 	%rd633, 1, %rd632, %p122;
	add.s64 	%rd634, %rd530, %rd633;
	st.u32 	[%rd113+-32], %rd622;
	shr.u64 	%rd635, %rd622, 32;
	st.u32 	[%rd113+-28], %rd635;
	st.u32 	[%rd113+-24], %rd585;
	shr.u64 	%rd636, %rd585, 32;
	st.u32 	[%rd113+-20], %rd636;
	st.u32 	[%rd113+-16], %rd618;
	shr.u64 	%rd637, %rd618, 32;
	st.u32 	[%rd113+-12], %rd637;
	st.u32 	[%rd113+-8], %rd621;
	shr.u64 	%rd638, %rd621, 32;
	st.u32 	[%rd113+-4], %rd638;
	st.u32 	[%rd113], %rd623;
	shr.u64 	%rd639, %rd623, 32;
	st.u32 	[%rd113+4], %rd639;
	st.u32 	[%rd113+8], %rd626;
	shr.u64 	%rd640, %rd626, 32;
	st.u32 	[%rd113+12], %rd640;
	st.u32 	[%rd113+16], %rd631;
	shr.u64 	%rd641, %rd631, 32;
	st.u32 	[%rd113+20], %rd641;
	st.u32 	[%rd113+24], %rd634;
	shr.u64 	%rd642, %rd634, 32;
	st.u32 	[%rd113+28], %rd642;
	mov.u32 	%r171, 102;
	bra.uni 	LBB0_89;
LBB0_83:                                // %.616
	setp.lt.u64 	%p93, %rd121, 40;
	@%p93 bra 	LBB0_147;
// %bb.84:
	st.global.u8 	[%rd126+2315], %rs1;
	bra.uni 	LBB0_147;
LBB0_93:                                // %.661
	setp.lt.u64 	%p87, %rd121, 184;
	@%p87 bra 	LBB0_147;
// %bb.94:
	xor.b32  	%r208, %r171, 2397;
	and.b32  	%r209, %r208, 4095;
	cvt.u64.u32 	%rd342, %r209;
	add.s64 	%rd343, %rd126, %rd342;
	st.global.u8 	[%rd343], %rs1;
	shl.b64 	%rd344, %rd122, 5;
	add.s64 	%rd345, %rd131, %rd344;
	ld.u32 	%rd346, [%rd345];
	ld.u32 	%rd347, [%rd345+4];
	ld.u32 	%rd348, [%rd345+8];
	ld.u32 	%rd349, [%rd345+12];
	ld.u32 	%rd350, [%rd345+16];
	ld.u32 	%rd351, [%rd345+20];
	ld.u32 	%rd352, [%rd345+24];
	ld.u32 	%rd353, [%rd345+28];
	add.u64 	%rd354, %SP, 1216;
	add.u64 	%rd355, %SPL, 1216;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd354;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 11
	ld.local.u32 	%rd357, [%rd355];
	ld.local.u32 	%rd358, [%rd355+4];
	shl.b64 	%rd359, %rd358, 32;
	or.b64  	%rd360, %rd359, %rd357;
	add.u64 	%rd361, %SP, 1248;
	add.u64 	%rd362, %SPL, 1248;
	st.local.u32 	[%rd362+28], %rd353;
	st.local.u32 	[%rd362+24], %rd352;
	st.local.u32 	[%rd362+20], %rd351;
	st.local.u32 	[%rd362+16], %rd350;
	st.local.u32 	[%rd362+12], %rd349;
	st.local.u32 	[%rd362+8], %rd348;
	st.local.u32 	[%rd362+4], %rd347;
	st.local.u32 	[%rd362], %rd346;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd360;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd361;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 12
	add.u64 	%rd364, %SP, 1280;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd364;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 13
LBB0_95:                                // %Exit
	{ // callseq 51, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 51
	{ // callseq 52, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd131;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 52
	mov.u32 	%r289, 1;
	st.param.b32 	[func_retval0+0], %r289;
	ret;
LBB0_96:                                // %.845
	setp.lt.u64 	%p124, %rd121, 448;
	@%p124 bra 	LBB0_147;
// %bb.97:
	xor.b32  	%r238, %r171, 198;
	and.b32  	%r239, %r238, 4095;
	cvt.u64.u32 	%rd643, %r239;
	add.s64 	%rd644, %rd126, %rd643;
	st.global.u8 	[%rd644], %rs1;
	add.s64 	%rd121, %rd121, -448;
	shl.b64 	%rd645, %rd122, 5;
	add.s64 	%rd646, %rd131, %rd645;
	ld.u32 	%rd647, [%rd646+-20];
	ld.u32 	%rd648, [%rd646+-24];
	ld.u32 	%rd649, [%rd646+-28];
	ld.u32 	%rd650, [%rd646+-32];
	ld.u32 	%rd651, [%rd646+-4];
	ld.u32 	%rd652, [%rd646+-8];
	ld.u32 	%rd653, [%rd646+-12];
	ld.u32 	%rd654, [%rd646+-16];
	add.s64 	%rd122, %rd122, -5;
	ld.u32 	%rd655, [%rd646+-160];
	ld.u32 	%rd656, [%rd646+-156];
	shl.b64 	%rd657, %rd656, 32;
	or.b64  	%rd123, %rd657, %rd655;
	add.u64 	%rd658, %SP, 2080;
	add.u64 	%rd659, %SPL, 2080;
	st.local.u32 	[%rd659+24], %rd134;
	st.local.u32 	[%rd659+28], %rd134;
	st.local.u32 	[%rd659], %rd134;
	st.local.u32 	[%rd659+4], %rd134;
	st.local.u32 	[%rd659+8], %rd134;
	st.local.u32 	[%rd659+12], %rd134;
	st.local.u32 	[%rd659+16], %rd134;
	st.local.u32 	[%rd659+20], %rd134;
	add.u64 	%rd661, %SP, 2112;
	add.u64 	%rd662, %SPL, 2112;
	st.local.u32 	[%rd662+16], %rd654;
	st.local.u32 	[%rd662+20], %rd653;
	st.local.u32 	[%rd662+24], %rd652;
	st.local.u32 	[%rd662+28], %rd651;
	st.local.u32 	[%rd662], %rd650;
	st.local.u32 	[%rd662+4], %rd649;
	st.local.u32 	[%rd662+8], %rd648;
	st.local.u32 	[%rd662+12], %rd647;
	{ // callseq 25, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd658;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd661;
	call.uni 
	__device_sstore, 
	(
	param0, 
	param1
	);
	} // callseq 25
	{ // callseq 26, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd658;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r177, [retval0+0];
	} // callseq 26
	add.u64 	%rd663, %SP, 2144;
	add.u64 	%rd664, %SPL, 2144;
	st.local.u32 	[%rd664+28], %rd134;
	st.local.u32 	[%rd664+24], %rd134;
	st.local.u32 	[%rd664+20], %rd134;
	st.local.u32 	[%rd664+16], %rd134;
	st.local.u32 	[%rd664+12], %rd134;
	st.local.u32 	[%rd664+8], %rd134;
	st.local.u32 	[%rd664+4], %rd134;
	st.local.u32 	[%rd664], %rd134;
	add.u64 	%rd665, %SP, 2176;
	add.u64 	%rd666, %SPL, 2176;
	{ // callseq 27, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd663;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd665;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 27
	{ // callseq 28, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd663;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r241, [retval0+0];
	} // callseq 28
	setp.eq.s32 	%p125, %r241, %r172;
	setp.eq.s32 	%p126, %r241, %r173;
	or.pred  	%p127, %p125, %p126;
	setp.eq.s32 	%p128, %r241, %r174;
	or.pred  	%p129, %p127, %p128;
	setp.eq.s32 	%p130, %r241, %r175;
	or.pred  	%p131, %p129, %p130;
	setp.eq.s32 	%p132, %r241, %r176;
	or.pred  	%p133, %p131, %p132;
	setp.eq.s32 	%p134, %r241, %r177;
	or.pred  	%p135, %p133, %p134;
	selp.u16 	%rs25, 1, 0, %p135;
	st.global.u8 	[%rd126+7], %rs25;
	ld.local.u32 	%rd667, [%rd666+12];
	ld.local.u32 	%rd668, [%rd666+8];
	ld.local.u32 	%rd669, [%rd666+4];
	ld.local.u32 	%rd670, [%rd666];
	ld.local.u32 	%rd671, [%rd666+28];
	ld.local.u32 	%rd672, [%rd666+24];
	ld.local.u32 	%rd673, [%rd666+20];
	ld.local.u32 	%rd674, [%rd666+16];
	st.u32 	[%rd646+-144], %rd674;
	st.u32 	[%rd646+-140], %rd673;
	st.u32 	[%rd646+-136], %rd672;
	st.u32 	[%rd646+-132], %rd671;
	st.u32 	[%rd646+-160], %rd670;
	st.u32 	[%rd646+-156], %rd669;
	st.u32 	[%rd646+-152], %rd668;
	st.u32 	[%rd646+-148], %rd667;
	mov.u32 	%r171, 99;
LBB0_98:                                // %JumpTable
	setp.gt.s64 	%p38, %rd123, 576;
	@%p38 bra 	LBB0_126;
// %bb.99:                              // %JumpTable
	setp.gt.s64 	%p60, %rd123, 371;
	@%p60 bra 	LBB0_113;
	bra.uni 	LBB0_100;
LBB0_113:                               // %JumpTable
	setp.gt.s64 	%p61, %rd123, 467;
	@%p61 bra 	LBB0_120;
// %bb.114:                             // %JumpTable
	setp.gt.s64 	%p68, %rd123, 424;
	@%p68 bra 	LBB0_117;
	bra.uni 	LBB0_115;
LBB0_117:                               // %JumpTable
	setp.eq.s64 	%p69, %rd123, 447;
	@%p69 bra 	LBB0_51;
// %bb.118:                             // %JumpTable
	setp.eq.s64 	%p70, %rd123, 459;
	mov.u64 	%rd1410, %rd122;
	@%p70 bra 	LBB0_55;
// %bb.119:                             // %JumpTable
	setp.eq.s64 	%p71, %rd123, 425;
	@%p71 bra 	LBB0_49;
	bra.uni 	LBB0_147;
LBB0_126:                               // %JumpTable
	setp.gt.s64 	%p39, %rd123, 748;
	@%p39 bra 	LBB0_138;
	bra.uni 	LBB0_127;
LBB0_138:                               // %JumpTable
	setp.gt.s64 	%p40, %rd123, 798;
	@%p40 bra 	LBB0_142;
	bra.uni 	LBB0_139;
LBB0_142:                               // %JumpTable
	setp.gt.s64 	%p41, %rd123, 818;
	@%p41 bra 	LBB0_145;
// %bb.143:                             // %JumpTable
	setp.eq.s64 	%p44, %rd123, 799;
	@%p44 bra 	LBB0_77;
// %bb.144:                             // %JumpTable
	setp.eq.s64 	%p45, %rd123, 805;
	@%p45 bra 	LBB0_87;
	bra.uni 	LBB0_147;
LBB0_100:                               // %JumpTable
	setp.gt.s64 	%p74, %rd123, 233;
	@%p74 bra 	LBB0_107;
// %bb.101:                             // %JumpTable
	setp.gt.s64 	%p81, %rd123, 158;
	@%p81 bra 	LBB0_104;
	bra.uni 	LBB0_102;
LBB0_104:                               // %JumpTable
	setp.eq.s64 	%p82, %rd123, 159;
	mov.u64 	%rd1394, %rd122;
	@%p82 bra 	LBB0_15;
// %bb.105:                             // %JumpTable
	setp.eq.s64 	%p83, %rd123, 222;
	@%p83 bra 	LBB0_21;
// %bb.106:                             // %JumpTable
	setp.eq.s64 	%p84, %rd123, 200;
	@%p84 bra 	LBB0_19;
	bra.uni 	LBB0_147;
LBB0_127:                               // %JumpTable
	setp.gt.s64 	%p49, %rd123, 660;
	@%p49 bra 	LBB0_133;
// %bb.128:                             // %JumpTable
	setp.gt.s64 	%p55, %rd123, 607;
	@%p55 bra 	LBB0_131;
	bra.uni 	LBB0_129;
LBB0_131:                               // %JumpTable
	setp.eq.s64 	%p56, %rd123, 608;
	@%p56 bra 	LBB0_81;
// %bb.132:                             // %JumpTable
	setp.eq.s64 	%p57, %rd123, 620;
	mov.u64 	%rd1422, %rd122;
	@%p57 bra 	LBB0_85;
	bra.uni 	LBB0_147;
LBB0_120:                               // %JumpTable
	setp.gt.s64 	%p62, %rd123, 501;
	@%p62 bra 	LBB0_123;
	bra.uni 	LBB0_121;
LBB0_123:                               // %JumpTable
	setp.eq.s64 	%p63, %rd123, 502;
	mov.u64 	%rd1414, %rd122;
	@%p63 bra 	LBB0_65;
// %bb.124:                             // %JumpTable
	setp.eq.s64 	%p64, %rd123, 565;
	@%p64 bra 	LBB0_71;
// %bb.125:                             // %JumpTable
	setp.eq.s64 	%p65, %rd123, 543;
	@%p65 bra 	LBB0_69;
	bra.uni 	LBB0_147;
LBB0_107:                               // %JumpTable
	setp.gt.s64 	%p75, %rd123, 296;
	@%p75 bra 	LBB0_110;
	bra.uni 	LBB0_108;
LBB0_110:                               // %JumpTable
	setp.eq.s64 	%p76, %rd123, 297;
	@%p76 bra 	LBB0_31;
// %bb.111:                             // %JumpTable
	setp.eq.s64 	%p77, %rd123, 309;
	mov.u64 	%rd1402, %rd122;
	@%p77 bra 	LBB0_35;
// %bb.112:                             // %JumpTable
	setp.eq.s64 	%p78, %rd123, 350;
	@%p78 bra 	LBB0_39;
	bra.uni 	LBB0_147;
LBB0_133:                               // %JumpTable
	setp.gt.s64 	%p50, %rd123, 704;
	@%p50 bra 	LBB0_136;
	bra.uni 	LBB0_134;
LBB0_136:                               // %JumpTable
	setp.eq.s64 	%p51, %rd123, 705;
	@%p51 bra 	LBB0_27;
// %bb.137:                             // %JumpTable
	setp.eq.s64 	%p52, %rd123, 727;
	@%p52 bra 	LBB0_37;
	bra.uni 	LBB0_147;
LBB0_139:                               // %JumpTable
	setp.eq.s64 	%p46, %rd123, 749;
	@%p46 bra 	LBB0_47;
// %bb.140:                             // %JumpTable
	setp.eq.s64 	%p47, %rd123, 771;
	@%p47 bra 	LBB0_57;
// %bb.141:                             // %JumpTable
	setp.eq.s64 	%p48, %rd123, 777;
	@%p48 bra 	LBB0_67;
	bra.uni 	LBB0_147;
LBB0_115:                               // %JumpTable
	setp.eq.s64 	%p72, %rd123, 372;
	@%p72 bra 	LBB0_41;
// %bb.116:                             // %JumpTable
	setp.eq.s64 	%p73, %rd123, 384;
	mov.u64 	%rd1406, %rd122;
	@%p73 bra 	LBB0_45;
	bra.uni 	LBB0_147;
LBB0_145:                               // %JumpTable
	setp.eq.s64 	%p42, %rd123, 819;
	@%p42 bra 	LBB0_88;
// %bb.146:                             // %JumpTable
	setp.eq.s64 	%p43, %rd123, 845;
	@%p43 bra 	LBB0_96;
	bra.uni 	LBB0_147;
LBB0_102:                               // %JumpTable
	setp.eq.s64 	%p85, %rd123, 147;
	@%p85 bra 	LBB0_11;
// %bb.103:                             // %JumpTable
	setp.eq.s64 	%p86, %rd123, 142;
	@%p86 bra 	LBB0_9;
	bra.uni 	LBB0_147;
LBB0_129:                               // %JumpTable
	setp.eq.s64 	%p58, %rd123, 577;
	mov.u64 	%rd1418, %rd122;
	@%p58 bra 	LBB0_75;
// %bb.130:                             // %JumpTable
	setp.eq.s64 	%p59, %rd123, 586;
	@%p59 bra 	LBB0_79;
	bra.uni 	LBB0_147;
LBB0_121:                               // %JumpTable
	setp.eq.s64 	%p66, %rd123, 490;
	@%p66 bra 	LBB0_61;
// %bb.122:                             // %JumpTable
	setp.eq.s64 	%p67, %rd123, 468;
	@%p67 bra 	LBB0_59;
	bra.uni 	LBB0_147;
LBB0_108:                               // %JumpTable
	setp.eq.s64 	%p79, %rd123, 234;
	mov.u64 	%rd1398, %rd122;
	@%p79 bra 	LBB0_25;
// %bb.109:                             // %JumpTable
	setp.eq.s64 	%p80, %rd123, 275;
	@%p80 bra 	LBB0_29;
	bra.uni 	LBB0_147;
LBB0_134:                               // %JumpTable
	setp.eq.s64 	%p53, %rd123, 683;
	@%p53 bra 	LBB0_17;
// %bb.135:                             // %JumpTable
	setp.eq.s64 	%p54, %rd123, 661;
	@%p54 bra 	LBB0_93;
	bra.uni 	LBB0_147;
                                        // -- End function
}
.func evm_$_udiv_$_i256(
	.param .b64 evm_$_udiv_$_i256_param_0,
	.param .b64 evm_$_udiv_$_i256_param_1,
	.param .b64 evm_$_udiv_$_i256_param_2
)                                       // -- Begin function evm_$_udiv_$_i256
                                        // @"evm_$_udiv_$_i256"
{
	.local .align 8 .b8 	__local_depot1[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b64 	%rd<5>;

// %bb.0:
	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [evm_$_udiv_$_i256_param_0];
	ld.param.u64 	%rd2, [evm_$_udiv_$_i256_param_1];
	ld.param.u64 	%rd3, [evm_$_udiv_$_i256_param_2];
	add.u64 	%rd4, %SP, 0;
	{ // callseq 73, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd2;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd3;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd4;
	call.uni 
	evm_$_udivrem_$_i256, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 73
	ret;
                                        // -- End function
}
.func evm_$_udivrem_$_i256(
	.param .b64 evm_$_udivrem_$_i256_param_0,
	.param .b64 evm_$_udivrem_$_i256_param_1,
	.param .b64 evm_$_udivrem_$_i256_param_2,
	.param .b64 evm_$_udivrem_$_i256_param_3
)                                       // -- Begin function evm_$_udivrem_$_i256
                                        // @"evm_$_udivrem_$_i256"
{
	.reg .pred 	%p<60>;
	.reg .b32 	%r<47>;
	.reg .b64 	%rd<250>;

// %bb.0:                               // %Entry
	ld.param.u64 	%rd74, [evm_$_udivrem_$_i256_param_3];
	ld.param.u64 	%rd73, [evm_$_udivrem_$_i256_param_2];
	ld.param.u64 	%rd79, [evm_$_udivrem_$_i256_param_0];
	ld.u32 	%rd80, [%rd79];
	ld.u32 	%rd81, [%rd79+4];
	shl.b64 	%rd82, %rd81, 32;
	or.b64  	%rd230, %rd82, %rd80;
	ld.u32 	%rd83, [%rd79+8];
	ld.u32 	%rd84, [%rd79+12];
	shl.b64 	%rd85, %rd84, 32;
	or.b64  	%rd231, %rd85, %rd83;
	ld.u32 	%rd86, [%rd79+16];
	ld.u32 	%rd87, [%rd79+20];
	shl.b64 	%rd88, %rd87, 32;
	or.b64  	%rd232, %rd88, %rd86;
	ld.u32 	%rd89, [%rd79+24];
	ld.u32 	%rd90, [%rd79+28];
	shl.b64 	%rd91, %rd90, 32;
	or.b64  	%rd233, %rd91, %rd89;
	ld.param.u64 	%rd92, [evm_$_udivrem_$_i256_param_1];
	ld.u32 	%rd93, [%rd92];
	ld.u32 	%rd94, [%rd92+4];
	shl.b64 	%rd95, %rd94, 32;
	or.b64  	%rd222, %rd95, %rd93;
	ld.u32 	%rd96, [%rd92+8];
	ld.u32 	%rd97, [%rd92+12];
	shl.b64 	%rd98, %rd97, 32;
	or.b64  	%rd223, %rd98, %rd96;
	ld.u32 	%rd99, [%rd92+16];
	ld.u32 	%rd100, [%rd92+20];
	shl.b64 	%rd101, %rd100, 32;
	or.b64  	%rd224, %rd101, %rd99;
	ld.u32 	%rd102, [%rd92+24];
	ld.u32 	%rd103, [%rd92+28];
	shl.b64 	%rd104, %rd103, 32;
	or.b64  	%rd225, %rd104, %rd102;
	setp.eq.s64 	%p1, %rd225, %rd233;
	setp.gt.u64 	%p2, %rd225, %rd233;
	selp.u32 	%r1, -1, 0, %p2;
	setp.gt.u64 	%p3, %rd224, %rd232;
	selp.u32 	%r2, -1, 0, %p3;
	selp.b32 	%r3, %r2, %r1, %p1;
	setp.eq.s64 	%p4, %rd223, %rd231;
	setp.gt.u64 	%p5, %rd223, %rd231;
	selp.u32 	%r4, -1, 0, %p5;
	setp.gt.u64 	%p6, %rd222, %rd230;
	selp.u32 	%r5, -1, 0, %p6;
	selp.b32 	%r6, %r5, %r4, %p4;
	xor.b64  	%rd105, %rd225, %rd233;
	xor.b64  	%rd106, %rd224, %rd232;
	or.b64  	%rd107, %rd106, %rd105;
	setp.eq.s64 	%p7, %rd107, 0;
	selp.b32 	%r7, %r6, %r3, %p7;
	and.b32  	%r8, %r7, 1;
	setp.eq.b32 	%p8, %r8, 1;
	mov.u64 	%rd242, 0;
	mov.u64 	%rd243, %rd242;
	mov.u64 	%rd244, %rd242;
	mov.u64 	%rd245, %rd242;
	@%p8 bra 	LBB2_6;
// %bb.1:                               // %Main
	setp.ne.s64 	%p9, %rd225, 0;
	clz.b64 	%r9, %rd224;
	cvt.u64.u32 	%rd108, %r9;
	add.s64 	%rd109, %rd108, 64;
	clz.b64 	%r10, %rd225;
	cvt.u64.u32 	%rd110, %r10;
	selp.b64 	%rd111, %rd110, %rd109, %p9;
	setp.ne.s64 	%p10, %rd223, 0;
	clz.b64 	%r11, %rd222;
	cvt.u64.u32 	%rd112, %r11;
	add.s64 	%rd113, %rd112, 64;
	clz.b64 	%r12, %rd223;
	cvt.u64.u32 	%rd114, %r12;
	selp.b64 	%rd115, %rd114, %rd113, %p10;
	add.s64 	%rd116, %rd115, 128;
	or.b64  	%rd117, %rd224, %rd225;
	setp.ne.s64 	%p11, %rd117, 0;
	selp.b64 	%rd118, %rd111, %rd116, %p11;
	setp.lt.u64 	%p12, %rd116, %rd115;
	selp.u64 	%rd119, 1, 0, %p12;
	setp.lt.u64 	%p13, %rd116, 128;
	selp.b64 	%rd120, 1, %rd119, %p13;
	selp.b64 	%rd121, 0, %rd120, %p11;
	setp.ne.s64 	%p14, %rd233, 0;
	clz.b64 	%r13, %rd232;
	cvt.u64.u32 	%rd122, %r13;
	add.s64 	%rd123, %rd122, 64;
	clz.b64 	%r14, %rd233;
	cvt.u64.u32 	%rd124, %r14;
	selp.b64 	%rd125, %rd124, %rd123, %p14;
	setp.ne.s64 	%p15, %rd231, 0;
	clz.b64 	%r15, %rd230;
	cvt.u64.u32 	%rd126, %r15;
	add.s64 	%rd127, %rd126, 64;
	clz.b64 	%r16, %rd231;
	cvt.u64.u32 	%rd128, %r16;
	selp.b64 	%rd129, %rd128, %rd127, %p15;
	add.s64 	%rd130, %rd129, 128;
	or.b64  	%rd131, %rd232, %rd233;
	setp.ne.s64 	%p16, %rd131, 0;
	selp.b64 	%rd132, %rd125, %rd130, %p16;
	setp.lt.u64 	%p17, %rd130, %rd129;
	selp.u64 	%rd133, 1, 0, %p17;
	setp.lt.u64 	%p18, %rd130, 128;
	selp.b64 	%rd134, 1, %rd133, %p18;
	selp.b64 	%rd135, 0, %rd134, %p16;
	setp.eq.s64 	%p19, %rd121, %rd135;
	setp.lt.u64 	%p20, %rd118, %rd132;
	selp.u32 	%r17, -1, 0, %p20;
	setp.lt.u64 	%p21, %rd121, %rd135;
	selp.u32 	%r18, -1, 0, %p21;
	selp.b32 	%r19, %r17, %r18, %p19;
	and.b32  	%r20, %r19, 1;
	setp.eq.b32 	%p22, %r20, 1;
	selp.s64 	%rd236, -1, 0, %p22;
	sub.s64 	%rd136, %rd121, %rd135;
	selp.s64 	%rd137, -1, 0, %p20;
	add.s64 	%rd235, %rd136, %rd137;
	sub.s64 	%rd234, %rd118, %rd132;
	mov.u64 	%rd218, %rd234;
	mov.u64 	%rd219, %rd235;
	mov.u64 	%rd220, %rd236;
	mov.u64 	%rd221, %rd236;
LBB2_2:                                 // %beforeloopY
                                        // =>This Inner Loop Header: Depth=1
	or.b64  	%rd138, %rd218, %rd220;
	or.b64  	%rd139, %rd219, %rd221;
	or.b64  	%rd140, %rd138, %rd139;
	setp.ne.s64 	%p23, %rd140, 0;
	@%p23 bra 	LBB2_7;
	bra.uni 	LBB2_3;
LBB2_7:                                 // %LoopY
                                        //   in Loop: Header=BB2_2 Depth=1
	shr.u64 	%rd199, %rd222, 63;
	shl.b64 	%rd200, %rd223, 1;
	or.b64  	%rd22, %rd200, %rd199;
	shr.u64 	%rd201, %rd223, 63;
	shl.b64 	%rd202, %rd224, 1;
	or.b64  	%rd23, %rd202, %rd201;
	shr.u64 	%rd203, %rd224, 63;
	shl.b64 	%rd204, %rd225, 1;
	or.b64  	%rd225, %rd204, %rd203;
	shl.b64 	%rd222, %rd222, 1;
	add.s64 	%rd25, %rd218, -1;
	setp.lt.u64 	%p49, %rd25, %rd218;
	selp.u64 	%rd205, 1, 0, %p49;
	setp.ne.s64 	%p50, %rd25, -1;
	selp.b64 	%rd206, 1, %rd205, %p50;
	add.s64 	%rd207, %rd219, %rd206;
	add.s64 	%rd26, %rd207, -1;
	setp.eq.s64 	%p51, %rd26, %rd219;
	selp.u32 	%r40, -1, 0, %p49;
	setp.lt.u64 	%p52, %rd26, %rd219;
	selp.u32 	%r41, -1, 0, %p52;
	selp.b32 	%r42, %r40, %r41, %p51;
	cvt.u64.u32 	%rd208, %r42;
	and.b64  	%rd209, %rd208, 1;
	setp.eq.s64 	%p53, %rd26, -1;
	setp.ne.s64 	%p54, %rd26, -1;
	selp.u32 	%r43, -1, 0, %p54;
	selp.u32 	%r44, -1, 0, %p50;
	selp.b32 	%r45, %r44, %r43, %p53;
	and.b32  	%r46, %r45, 1;
	setp.eq.b32 	%p55, %r46, 1;
	selp.b64 	%rd210, 1, %rd209, %p55;
	add.s64 	%rd211, %rd220, -1;
	add.s64 	%rd27, %rd211, %rd210;
	setp.lt.u64 	%p56, %rd27, %rd210;
	setp.lt.u64 	%p57, %rd27, %rd211;
	selp.u64 	%rd212, 1, 0, %p57;
	selp.b64 	%rd213, 1, %rd212, %p56;
	setp.lt.u64 	%p58, %rd211, %rd220;
	selp.u64 	%rd214, 1, 0, %p58;
	setp.ne.s64 	%p59, %rd211, -1;
	selp.b64 	%rd215, 1, %rd214, %p59;
	add.s64 	%rd216, %rd221, %rd215;
	add.s64 	%rd217, %rd216, %rd213;
	add.s64 	%rd221, %rd217, -1;
	mov.u64 	%rd218, %rd25;
	mov.u64 	%rd219, %rd26;
	mov.u64 	%rd220, %rd27;
	mov.u64 	%rd223, %rd22;
	mov.u64 	%rd224, %rd23;
	bra.uni 	LBB2_2;
LBB2_3:                                 // %Loop.preheader
	mov.u64 	%rd238, 0;
	mov.u64 	%rd237, %rd236;
	mov.u64 	%rd243, %rd238;
	mov.u64 	%rd244, %rd238;
	mov.u64 	%rd245, %rd238;
LBB2_4:                                 // %Loop
                                        // =>This Inner Loop Header: Depth=1
	setp.eq.s64 	%p24, %rd231, %rd223;
	setp.lt.u64 	%p25, %rd230, %rd222;
	selp.u32 	%r21, -1, 0, %p25;
	setp.lt.u64 	%p26, %rd231, %rd223;
	selp.u32 	%r22, -1, 0, %p26;
	selp.b32 	%r23, %r21, %r22, %p24;
	and.b32  	%r24, %r23, 1;
	setp.eq.b32 	%p27, %r24, 1;
	selp.s64 	%rd145, -1, 0, %p27;
	sub.s64 	%rd146, %rd232, %rd224;
	add.s64 	%rd147, %rd146, %rd145;
	cvt.u64.u32 	%rd148, %r23;
	and.b64  	%rd149, %rd148, 1;
	setp.lt.u64 	%p28, %rd146, %rd149;
	selp.s64 	%rd150, -1, 0, %p28;
	sub.s64 	%rd151, %rd233, %rd225;
	setp.lt.u64 	%p29, %rd232, %rd224;
	selp.s64 	%rd152, -1, 0, %p29;
	add.s64 	%rd153, %rd151, %rd152;
	add.s64 	%rd154, %rd153, %rd150;
	sub.s64 	%rd155, %rd231, %rd223;
	selp.s64 	%rd156, -1, 0, %p25;
	add.s64 	%rd157, %rd155, %rd156;
	sub.s64 	%rd158, %rd230, %rd222;
	or.b64  	%rd159, %rd238, 1;
	setp.ge.u64 	%p30, %rd230, %rd222;
	selp.u32 	%r25, -1, 0, %p30;
	setp.ge.u64 	%p31, %rd231, %rd223;
	selp.u32 	%r26, -1, 0, %p31;
	selp.b32 	%r27, %r25, %r26, %p24;
	setp.eq.s64 	%p32, %rd233, %rd225;
	setp.ge.u64 	%p33, %rd232, %rd224;
	selp.u32 	%r28, -1, 0, %p33;
	setp.ge.u64 	%p34, %rd233, %rd225;
	selp.u32 	%r29, -1, 0, %p34;
	selp.b32 	%r30, %r28, %r29, %p32;
	xor.b64  	%rd160, %rd232, %rd224;
	xor.b64  	%rd161, %rd233, %rd225;
	or.b64  	%rd162, %rd160, %rd161;
	setp.eq.s64 	%p35, %rd162, 0;
	selp.b32 	%r31, %r27, %r30, %p35;
	and.b32  	%r32, %r31, 1;
	setp.eq.b32 	%p36, %r32, 1;
	selp.b64 	%rd233, %rd154, %rd233, %p36;
	selp.b64 	%rd232, %rd147, %rd232, %p36;
	selp.b64 	%rd231, %rd157, %rd231, %p36;
	selp.b64 	%rd230, %rd158, %rd230, %p36;
	selp.b64 	%rd242, %rd159, %rd238, %p36;
	or.b64  	%rd163, %rd234, %rd236;
	or.b64  	%rd164, %rd235, %rd237;
	or.b64  	%rd165, %rd163, %rd164;
	setp.eq.s64 	%p37, %rd165, 0;
	@%p37 bra 	LBB2_6;
// %bb.5:                               // %Continue
                                        //   in Loop: Header=BB2_4 Depth=1
	add.s64 	%rd53, %rd234, -1;
	setp.lt.u64 	%p38, %rd53, %rd234;
	selp.u64 	%rd166, 1, 0, %p38;
	setp.ne.s64 	%p39, %rd53, -1;
	selp.b64 	%rd167, 1, %rd166, %p39;
	add.s64 	%rd168, %rd235, %rd167;
	add.s64 	%rd54, %rd168, -1;
	setp.eq.s64 	%p40, %rd54, %rd235;
	selp.u32 	%r33, -1, 0, %p38;
	setp.lt.u64 	%p41, %rd54, %rd235;
	selp.u32 	%r34, -1, 0, %p41;
	selp.b32 	%r35, %r33, %r34, %p40;
	cvt.u64.u32 	%rd169, %r35;
	and.b64  	%rd170, %rd169, 1;
	setp.eq.s64 	%p42, %rd54, -1;
	setp.ne.s64 	%p43, %rd54, -1;
	selp.u32 	%r36, -1, 0, %p43;
	selp.u32 	%r37, -1, 0, %p39;
	selp.b32 	%r38, %r37, %r36, %p42;
	and.b32  	%r39, %r38, 1;
	setp.eq.b32 	%p44, %r39, 1;
	selp.b64 	%rd171, 1, %rd170, %p44;
	add.s64 	%rd172, %rd236, -1;
	add.s64 	%rd55, %rd172, %rd171;
	setp.lt.u64 	%p45, %rd55, %rd171;
	setp.lt.u64 	%p46, %rd55, %rd172;
	selp.u64 	%rd173, 1, 0, %p46;
	selp.b64 	%rd174, 1, %rd173, %p45;
	setp.lt.u64 	%p47, %rd172, %rd236;
	selp.u64 	%rd175, 1, 0, %p47;
	setp.ne.s64 	%p48, %rd172, -1;
	selp.b64 	%rd176, 1, %rd175, %p48;
	add.s64 	%rd177, %rd237, %rd176;
	add.s64 	%rd178, %rd177, %rd174;
	add.s64 	%rd237, %rd178, -1;
	shr.u64 	%rd179, %rd242, 63;
	shl.b64 	%rd180, %rd243, 1;
	or.b64  	%rd58, %rd180, %rd179;
	shr.u64 	%rd181, %rd243, 63;
	shl.b64 	%rd182, %rd244, 1;
	or.b64  	%rd59, %rd182, %rd181;
	shr.u64 	%rd183, %rd244, 63;
	shl.b64 	%rd184, %rd245, 1;
	or.b64  	%rd245, %rd184, %rd183;
	shl.b64 	%rd238, %rd242, 1;
	shr.u64 	%rd185, %rd222, 1;
	shl.b64 	%rd186, %rd223, 63;
	or.b64  	%rd222, %rd185, %rd186;
	shr.u64 	%rd187, %rd223, 1;
	shl.b64 	%rd188, %rd224, 63;
	or.b64  	%rd223, %rd187, %rd188;
	shr.u64 	%rd189, %rd224, 1;
	shl.b64 	%rd190, %rd225, 63;
	or.b64  	%rd224, %rd189, %rd190;
	shr.u64 	%rd225, %rd225, 1;
	mov.u64 	%rd234, %rd53;
	mov.u64 	%rd235, %rd54;
	mov.u64 	%rd236, %rd55;
	mov.u64 	%rd243, %rd58;
	mov.u64 	%rd244, %rd59;
	bra.uni 	LBB2_4;
LBB2_6:                                 // %Return
	st.u32 	[%rd73], %rd242;
	st.u32 	[%rd73+8], %rd243;
	shr.u64 	%rd191, %rd242, 32;
	st.u32 	[%rd73+4], %rd191;
	st.u32 	[%rd73+16], %rd244;
	shr.u64 	%rd192, %rd243, 32;
	st.u32 	[%rd73+12], %rd192;
	st.u32 	[%rd73+24], %rd245;
	shr.u64 	%rd193, %rd244, 32;
	st.u32 	[%rd73+20], %rd193;
	shr.u64 	%rd194, %rd245, 32;
	st.u32 	[%rd73+28], %rd194;
	st.u32 	[%rd74+16], %rd232;
	shr.u64 	%rd195, %rd232, 32;
	st.u32 	[%rd74+20], %rd195;
	st.u32 	[%rd74+24], %rd233;
	shr.u64 	%rd196, %rd233, 32;
	st.u32 	[%rd74+28], %rd196;
	st.u32 	[%rd74], %rd230;
	shr.u64 	%rd197, %rd230, 32;
	st.u32 	[%rd74+4], %rd197;
	st.u32 	[%rd74+8], %rd231;
	shr.u64 	%rd198, %rd231, 32;
	st.u32 	[%rd74+12], %rd198;
	ret;
                                        // -- End function
}
	// .globl	rand                    // -- Begin function rand
.visible .func  (.param .b32 func_retval0) rand() // @rand
{
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<4>;

// %bb.0:
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mul.wide.u32 	%rd1, %r4, 4;
	mov.u64 	%rd2, cuda_states;
	add.s64 	%rd3, %rd2, %rd1;
	ld.global.u32 	%r5, [%rd3];
	mad.lo.s32 	%r6, %r5, 1103515245, 12345;
	mad.lo.s32 	%r7, %r6, 1103515245, 12345;
	shr.u32 	%r8, %r6, 6;
	and.b32  	%r9, %r8, 2096128;
	bfe.u32 	%r10, %r7, 16, 10;
	or.b32  	%r11, %r10, %r9;
	mad.lo.s32 	%r12, %r7, 1103515245, 12345;
	shl.b32 	%r13, %r11, 10;
	bfe.u32 	%r14, %r12, 16, 10;
	or.b32  	%r15, %r13, %r14;
	st.global.u32 	[%rd3], %r12;
	st.param.b32 	[func_retval0+0], %r15;
	ret;
                                        // -- End function
}
	// .globl	bytesToString           // -- Begin function bytesToString
.visible .func bytesToString(
	.param .b64 bytesToString_param_0,
	.param .b64 bytesToString_param_1,
	.param .b32 bytesToString_param_2
)                                       // @bytesToString
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<23>;
	.reg .b32 	%r<15>;
	.reg .b64 	%rd<35>;

// %bb.0:
	ld.param.u32 	%r6, [bytesToString_param_2];
	ld.param.u64 	%rd4, [bytesToString_param_0];
	setp.eq.s32 	%p1, %r6, 0;
	@%p1 bra 	LBB4_6;
// %bb.1:
	ld.param.u64 	%rd5, [bytesToString_param_1];
	and.b32  	%r1, %r6, 1;
	setp.eq.s32 	%p2, %r6, 1;
	mov.u32 	%r13, 0;
	mov.u64 	%rd33, __const_$_printbytes_$_hexmap;
	@%p2 bra 	LBB4_4;
// %bb.2:
	cvt.u64.u32 	%rd7, %r6;
	and.b64  	%rd1, %rd7, 4294967294;
	mov.u32 	%r14, 2;
	mov.u64 	%rd34, 0;
LBB4_3:                                 // =>This Inner Loop Header: Depth=1
	add.s64 	%rd8, %rd5, %rd34;
	ld.u8 	%rs1, [%rd8];
	and.b16  	%rs2, %rs1, 15;
	cvt.u64.u16 	%rd9, %rs2;
	add.s64 	%rd11, %rd33, %rd9;
	ld.global.nc.u8 	%rs3, [%rd11];
	cvt.u16.u8 	%rs4, %rs3;
	add.s32 	%r9, %r14, -2;
	cvt.u64.u32 	%rd12, %r9;
	add.s64 	%rd13, %rd4, %rd12;
	st.u8 	[%rd13+1], %rs4;
	shr.u16 	%rs5, %rs1, 4;
	cvt.u64.u16 	%rd14, %rs5;
	add.s64 	%rd15, %rd33, %rd14;
	ld.global.nc.u8 	%rs6, [%rd15];
	cvt.u16.u8 	%rs7, %rs6;
	st.u8 	[%rd13], %rs7;
	ld.u8 	%rs8, [%rd8+1];
	and.b16  	%rs9, %rs8, 15;
	cvt.u64.u16 	%rd16, %rs9;
	add.s64 	%rd17, %rd33, %rd16;
	ld.global.nc.u8 	%rs10, [%rd17];
	cvt.u16.u8 	%rs11, %rs10;
	cvt.u64.u32 	%rd18, %r14;
	add.s64 	%rd19, %rd4, %rd18;
	st.u8 	[%rd19+1], %rs11;
	shr.u16 	%rs12, %rs8, 4;
	cvt.u64.u16 	%rd20, %rs12;
	add.s64 	%rd21, %rd33, %rd20;
	ld.global.nc.u8 	%rs13, [%rd21];
	cvt.u16.u8 	%rs14, %rs13;
	st.u8 	[%rd19], %rs14;
	add.s32 	%r14, %r14, 4;
	add.s64 	%rd34, %rd34, 2;
	cvt.u32.u64 	%r13, %rd34;
	cvt.u32.u64 	%r10, %rd1;
	setp.eq.s32 	%p3, %r10, %r13;
	@%p3 bra 	LBB4_4;
	bra.uni 	LBB4_3;
LBB4_4:
	setp.eq.s32 	%p4, %r1, 0;
	@%p4 bra 	LBB4_6;
// %bb.5:
	cvt.u64.u32 	%rd22, %r13;
	add.s64 	%rd23, %rd5, %rd22;
	ld.u8 	%rs15, [%rd23];
	and.b16  	%rs16, %rs15, 15;
	cvt.u64.u16 	%rd24, %rs16;
	add.s64 	%rd26, %rd33, %rd24;
	ld.global.nc.u8 	%rs17, [%rd26];
	cvt.u16.u8 	%rs18, %rs17;
	shl.b32 	%r11, %r13, 1;
	cvt.u64.u32 	%rd27, %r11;
	add.s64 	%rd28, %rd4, %rd27;
	st.u8 	[%rd28+1], %rs18;
	shr.u16 	%rs19, %rs15, 4;
	cvt.u64.u16 	%rd29, %rs19;
	add.s64 	%rd30, %rd33, %rd29;
	ld.global.nc.u8 	%rs20, [%rd30];
	cvt.u16.u8 	%rs21, %rs20;
	st.u8 	[%rd28], %rs21;
LBB4_6:
	shl.b32 	%r12, %r6, 1;
	cvt.u64.u32 	%rd31, %r12;
	add.s64 	%rd32, %rd4, %rd31;
	mov.u16 	%rs22, 0;
	st.u8 	[%rd32], %rs22;
	ret;
                                        // -- End function
}
	// .globl	printbytes              // -- Begin function printbytes
.visible .func printbytes(
	.param .b64 printbytes_param_0,
	.param .b64 printbytes_param_1,
	.param .b32 printbytes_param_2
)                                       // @printbytes
{
	.local .align 8 .b8 	__local_depot5[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<23>;
	.reg .b32 	%r<18>;
	.reg .b64 	%rd<41>;

// %bb.0:
	mov.u64 	%SPL, __local_depot5;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r7, [printbytes_param_2];
	ld.param.u64 	%rd6, [printbytes_param_0];
	add.u64 	%rd8, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	shl.b32 	%r1, %r7, 1;
	or.b32  	%r8, %r1, 1;
	cvt.u64.u32 	%rd9, %r8;
	{ // callseq 74, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd10, [retval0+0];
	} // callseq 74
	setp.eq.s32 	%p1, %r7, 0;
	@%p1 bra 	LBB5_6;
// %bb.1:
	ld.param.u64 	%rd7, [printbytes_param_1];
	and.b32  	%r2, %r7, 1;
	setp.eq.s32 	%p2, %r7, 1;
	mov.u32 	%r16, 0;
	mov.u64 	%rd39, __const_$_printbytes_$_hexmap;
	@%p2 bra 	LBB5_4;
// %bb.2:
	cvt.u64.u32 	%rd12, %r7;
	and.b64  	%rd3, %rd12, 4294967294;
	mov.u32 	%r17, 2;
	mov.u64 	%rd40, 0;
LBB5_3:                                 // =>This Inner Loop Header: Depth=1
	add.s64 	%rd13, %rd7, %rd40;
	ld.u8 	%rs1, [%rd13];
	and.b16  	%rs2, %rs1, 15;
	cvt.u64.u16 	%rd14, %rs2;
	add.s64 	%rd16, %rd39, %rd14;
	ld.global.nc.u8 	%rs3, [%rd16];
	cvt.u16.u8 	%rs4, %rs3;
	add.s32 	%r11, %r17, -2;
	cvt.u64.u32 	%rd17, %r11;
	add.s64 	%rd18, %rd10, %rd17;
	shr.u16 	%rs5, %rs1, 4;
	cvt.u64.u16 	%rd19, %rs5;
	add.s64 	%rd20, %rd39, %rd19;
	ld.global.nc.u8 	%rs6, [%rd20];
	cvt.u16.u8 	%rs7, %rs6;
	ld.u8 	%rs8, [%rd13+1];
	and.b16  	%rs9, %rs8, 15;
	cvt.u64.u16 	%rd21, %rs9;
	add.s64 	%rd22, %rd39, %rd21;
	ld.global.nc.u8 	%rs10, [%rd22];
	cvt.u16.u8 	%rs11, %rs10;
	shr.u16 	%rs12, %rs8, 4;
	cvt.u64.u16 	%rd23, %rs12;
	add.s64 	%rd24, %rd39, %rd23;
	ld.global.nc.u8 	%rs13, [%rd24];
	cvt.u16.u8 	%rs14, %rs13;
	st.v4.u8 	[%rd18], {%rs7, %rs4, %rs14, %rs11};
	add.s32 	%r17, %r17, 4;
	add.s64 	%rd40, %rd40, 2;
	cvt.u32.u64 	%r16, %rd40;
	cvt.u32.u64 	%r12, %rd3;
	setp.eq.s32 	%p3, %r12, %r16;
	@%p3 bra 	LBB5_4;
	bra.uni 	LBB5_3;
LBB5_4:
	setp.eq.s32 	%p4, %r2, 0;
	@%p4 bra 	LBB5_6;
// %bb.5:
	cvt.u64.u32 	%rd25, %r16;
	add.s64 	%rd26, %rd7, %rd25;
	ld.u8 	%rs15, [%rd26];
	and.b16  	%rs16, %rs15, 15;
	cvt.u64.u16 	%rd27, %rs16;
	add.s64 	%rd29, %rd39, %rd27;
	ld.global.nc.u8 	%rs17, [%rd29];
	cvt.u16.u8 	%rs18, %rs17;
	shl.b32 	%r13, %r16, 1;
	cvt.u64.u32 	%rd30, %r13;
	add.s64 	%rd31, %rd10, %rd30;
	shr.u16 	%rs19, %rs15, 4;
	cvt.u64.u16 	%rd32, %rs19;
	add.s64 	%rd33, %rd39, %rd32;
	ld.global.nc.u8 	%rs20, [%rd33];
	cvt.u16.u8 	%rs21, %rs20;
	st.v2.u8 	[%rd31], {%rs21, %rs18};
LBB5_6:
	cvt.u64.u32 	%rd34, %r1;
	add.s64 	%rd35, %rd10, %rd34;
	mov.u16 	%rs22, 0;
	st.u8 	[%rd35], %rs22;
	st.local.u64 	[%rd1], %rd6;
	st.local.u64 	[%rd1+8], %rd10;
	mov.u64 	%rd36, _$_str;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 75, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd37;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd8;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r14, [retval0+0];
	} // callseq 75
	{ // callseq 76, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd10;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 76
	ret;
                                        // -- End function
}
	// .globl	__clear_bitmap          // -- Begin function __clear_bitmap
.visible .func __clear_bitmap(
	.param .b64 __clear_bitmap_param_0
)                                       // @__clear_bitmap
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<8>;

// %bb.0:
	mov.u64 	%rd4, 0;
	ld.param.u64 	%rd3, [__clear_bitmap_param_0];
	mov.u64 	%rd7, %rd4;
LBB6_1:                                 // =>This Inner Loop Header: Depth=1
	add.s64 	%rd5, %rd3, %rd7;
	st.global.u64 	[%rd5], %rd4;
	st.global.u64 	[%rd5+8], %rd4;
	st.global.u64 	[%rd5+16], %rd4;
	st.global.u64 	[%rd5+24], %rd4;
	st.global.u64 	[%rd5+32], %rd4;
	st.global.u64 	[%rd5+40], %rd4;
	st.global.u64 	[%rd5+48], %rd4;
	st.global.u64 	[%rd5+56], %rd4;
	st.global.u64 	[%rd5+64], %rd4;
	st.global.u64 	[%rd5+72], %rd4;
	st.global.u64 	[%rd5+80], %rd4;
	st.global.u64 	[%rd5+88], %rd4;
	st.global.u64 	[%rd5+96], %rd4;
	st.global.u64 	[%rd5+104], %rd4;
	st.global.u64 	[%rd5+112], %rd4;
	st.global.u64 	[%rd5+120], %rd4;
	add.s64 	%rd7, %rd7, 128;
	cvt.u32.u64 	%r1, %rd7;
	setp.ne.s32 	%p1, %r1, 4096;
	@%p1 bra 	LBB6_1;
// %bb.2:
	ret;
                                        // -- End function
}
	// .globl	__device_sha3           // -- Begin function __device_sha3
.visible .func __device_sha3(
	.param .b64 __device_sha3_param_0,
	.param .b32 __device_sha3_param_1,
	.param .b64 __device_sha3_param_2
)                                       // @__device_sha3
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<3>;

// %bb.0:
	ld.param.u64 	%rd1, [__device_sha3_param_0];
	ld.param.u32 	%r1, [__device_sha3_param_1];
	ld.param.u64 	%rd2, [__device_sha3_param_2];
	{ // callseq 77, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r1;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd2;
	call.uni 
	keccak256, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 77
	ret;
                                        // -- End function
}
	// .globl	keccak256               // -- Begin function keccak256
.visible .func keccak256(
	.param .b64 keccak256_param_0,
	.param .b32 keccak256_param_1,
	.param .b64 keccak256_param_2
)                                       // @keccak256
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<6>;

// %bb.0:
	ld.param.u64 	%rd1, [keccak256_param_0];
	ld.param.u32 	%rd2, [keccak256_param_1];
	ld.param.u64 	%rd3, [keccak256_param_2];
	mov.u64 	%rd4, 32;
	mov.u64 	%rd5, 136;
	mov.u32 	%r1, 1;
	{ // callseq 78, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd3;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd2;
	.param .b64 param4;
	st.param.b64 	[param4+0], %rd5;
	.param .b32 param5;
	st.param.b32 	[param5+0], %r1;
	call.uni 
	hash, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4, 
	param5
	);
	} // callseq 78
	ret;
                                        // -- End function
}
	// .globl	hash                    // -- Begin function hash
.visible .func hash(
	.param .b64 hash_param_0,
	.param .b64 hash_param_1,
	.param .b64 hash_param_2,
	.param .b64 hash_param_3,
	.param .b64 hash_param_4,
	.param .b32 hash_param_5
)                                       // @hash
{
	.local .align 8 .b8 	__local_depot9[200];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<36>;
	.reg .b16 	%rs<97>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<1003>;

// %bb.0:
	mov.u64 	%SPL, __local_depot9;
	ld.param.u64 	%rd375, [hash_param_4];
	ld.param.u64 	%rd901, [hash_param_3];
	add.u64 	%rd1, %SPL, 0;
	mov.u64 	%rd817, 0;
	mov.pred 	%p1, 0;
	mov.u16 	%rs94, 0;
	@%p1 bra 	LBB9_2;
LBB9_1:                                 // %loadstoreloop
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd378, %rd1, %rd817;
	st.local.u8 	[%rd378], %rs94;
	add.s64 	%rd817, %rd817, 1;
	setp.lt.u64 	%p2, %rd817, 200;
	@%p2 bra 	LBB9_1;
LBB9_2:                                 // %split
	ld.param.u8 	%rs7, [hash_param_5];
	ld.param.u64 	%rd900, [hash_param_2];
	setp.lt.u64 	%p3, %rd901, %rd375;
	add.s64 	%rd813, %rd375, -1;
	mov.u64 	%rd814, RC;
	@%p3 bra 	LBB9_17;
// %bb.3:
	mov.u64 	%rd815, 1;
	add.s64 	%rd6, %rd375, -2;
	and.b64  	%rd7, %rd813, 7;
	and.b64  	%rd8, %rd813, -8;
	add.s64 	%rd9, %rd1, 4;
	mov.u64 	%rd873, 0;
	setp.eq.s64 	%p4, %rd375, 0;
	setp.eq.s64 	%p5, %rd375, 1;
	setp.lt.u64 	%p6, %rd6, 7;
	setp.eq.s64 	%p8, %rd7, 0;
	mov.u64 	%rd872, %rd873;
	mov.u64 	%rd871, %rd873;
	mov.u64 	%rd870, %rd873;
	mov.u64 	%rd869, %rd873;
	mov.u64 	%rd868, %rd873;
	mov.u64 	%rd867, %rd873;
	mov.u64 	%rd866, %rd873;
	mov.u64 	%rd865, %rd873;
	mov.u64 	%rd864, %rd873;
	mov.u64 	%rd863, %rd873;
	mov.u64 	%rd862, %rd873;
	mov.u64 	%rd861, %rd873;
	mov.u64 	%rd860, %rd873;
	mov.u64 	%rd859, %rd873;
	mov.u64 	%rd858, %rd873;
	mov.u64 	%rd857, %rd873;
	mov.u64 	%rd856, %rd873;
	mov.u64 	%rd855, %rd873;
	mov.u64 	%rd854, %rd873;
	mov.u64 	%rd853, %rd873;
	mov.u64 	%rd852, %rd873;
	mov.u64 	%rd851, %rd873;
	mov.u64 	%rd850, %rd873;
	mov.u64 	%rd849, %rd873;
LBB9_4:                                 // =>This Loop Header: Depth=1
                                        //     Child Loop BB9_8 Depth 2
                                        //     Child Loop BB9_12 Depth 2
                                        //     Child Loop BB9_15 Depth 2
	@%p4 bra 	LBB9_14;
// %bb.5:                               //   in Loop: Header=BB9_4 Depth=1
	ld.u8 	%rs10, [%rd900];
	xor.b16  	%rs11, %rs94, %rs10;
	st.local.u8 	[%rd1], %rs11;
	@%p5 bra 	LBB9_13;
// %bb.6:                               //   in Loop: Header=BB9_4 Depth=1
	mov.u64 	%rd847, %rd815;
	@%p6 bra 	LBB9_10;
// %bb.7:                               // %.preheader15
                                        //   in Loop: Header=BB9_4 Depth=1
	mov.u64 	%rd845, 0;
LBB9_8:                                 //   Parent Loop BB9_4 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add.s64 	%rd383, %rd9, %rd845;
	ld.local.u8 	%rs12, [%rd383+-3];
	add.s64 	%rd384, %rd900, %rd845;
	ld.u8 	%rs13, [%rd384+1];
	xor.b16  	%rs14, %rs12, %rs13;
	st.local.u8 	[%rd383+-3], %rs14;
	ld.local.u8 	%rs15, [%rd383+-2];
	ld.u8 	%rs16, [%rd384+2];
	xor.b16  	%rs17, %rs15, %rs16;
	st.local.u8 	[%rd383+-2], %rs17;
	ld.local.u8 	%rs18, [%rd383+-1];
	ld.u8 	%rs19, [%rd384+3];
	xor.b16  	%rs20, %rs18, %rs19;
	st.local.u8 	[%rd383+-1], %rs20;
	ld.local.u8 	%rs21, [%rd383];
	ld.u8 	%rs22, [%rd384+4];
	xor.b16  	%rs23, %rs21, %rs22;
	st.local.u8 	[%rd383], %rs23;
	ld.local.u8 	%rs24, [%rd383+1];
	ld.u8 	%rs25, [%rd384+5];
	xor.b16  	%rs26, %rs24, %rs25;
	st.local.u8 	[%rd383+1], %rs26;
	ld.local.u8 	%rs27, [%rd383+2];
	ld.u8 	%rs28, [%rd384+6];
	xor.b16  	%rs29, %rs27, %rs28;
	st.local.u8 	[%rd383+2], %rs29;
	ld.local.u8 	%rs30, [%rd383+3];
	ld.u8 	%rs31, [%rd384+7];
	xor.b16  	%rs32, %rs30, %rs31;
	st.local.u8 	[%rd383+3], %rs32;
	ld.local.u8 	%rs33, [%rd383+4];
	ld.u8 	%rs34, [%rd384+8];
	xor.b16  	%rs35, %rs33, %rs34;
	st.local.u8 	[%rd383+4], %rs35;
	add.s64 	%rd845, %rd845, 8;
	setp.ne.s64 	%p7, %rd8, %rd845;
	@%p7 bra 	LBB9_8;
// %bb.9:                               // %.loopexit16
                                        //   in Loop: Header=BB9_4 Depth=1
	add.s64 	%rd847, %rd845, 1;
LBB9_10:                                //   in Loop: Header=BB9_4 Depth=1
	@%p8 bra 	LBB9_13;
// %bb.11:                              // %.preheader13
                                        //   in Loop: Header=BB9_4 Depth=1
	mov.u64 	%rd848, %rd7;
LBB9_12:                                //   Parent Loop BB9_4 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	.pragma "nounroll";
	add.s64 	%rd385, %rd1, %rd847;
	ld.local.u8 	%rs36, [%rd385];
	add.s64 	%rd386, %rd900, %rd847;
	ld.u8 	%rs37, [%rd386];
	xor.b16  	%rs38, %rs36, %rs37;
	st.local.u8 	[%rd385], %rs38;
	add.s64 	%rd847, %rd847, 1;
	add.s64 	%rd848, %rd848, -1;
	setp.ne.s64 	%p9, %rd848, 0;
	@%p9 bra 	LBB9_12;
LBB9_13:                                //   in Loop: Header=BB9_4 Depth=1
	ld.local.u64 	%rd849, [%rd1];
	ld.local.u64 	%rd850, [%rd1+40];
	ld.local.u64 	%rd851, [%rd1+80];
	ld.local.u64 	%rd852, [%rd1+120];
	ld.local.u64 	%rd853, [%rd1+160];
	ld.local.u64 	%rd854, [%rd1+8];
	ld.local.u64 	%rd855, [%rd1+48];
	ld.local.u64 	%rd856, [%rd1+88];
	ld.local.u64 	%rd857, [%rd1+128];
	ld.local.u64 	%rd858, [%rd1+168];
	ld.local.u64 	%rd859, [%rd1+16];
	ld.local.u64 	%rd860, [%rd1+56];
	ld.local.u64 	%rd861, [%rd1+96];
	ld.local.u64 	%rd862, [%rd1+136];
	ld.local.u64 	%rd863, [%rd1+176];
	ld.local.u64 	%rd864, [%rd1+24];
	ld.local.u64 	%rd865, [%rd1+64];
	ld.local.u64 	%rd866, [%rd1+104];
	ld.local.u64 	%rd867, [%rd1+144];
	ld.local.u64 	%rd868, [%rd1+184];
	ld.local.u64 	%rd869, [%rd1+32];
	ld.local.u64 	%rd870, [%rd1+72];
	ld.local.u64 	%rd871, [%rd1+112];
	ld.local.u64 	%rd872, [%rd1+152];
	ld.local.u64 	%rd873, [%rd1+192];
LBB9_14:                                //   in Loop: Header=BB9_4 Depth=1
	mov.u64 	%rd874, 0;
LBB9_15:                                //   Parent Loop BB9_4 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	xor.b64  	%rd388, %rd850, %rd849;
	xor.b64  	%rd389, %rd388, %rd851;
	xor.b64  	%rd390, %rd389, %rd852;
	xor.b64  	%rd391, %rd390, %rd853;
	xor.b64  	%rd392, %rd855, %rd854;
	xor.b64  	%rd393, %rd392, %rd856;
	xor.b64  	%rd394, %rd393, %rd857;
	xor.b64  	%rd395, %rd394, %rd858;
	xor.b64  	%rd396, %rd860, %rd859;
	xor.b64  	%rd397, %rd396, %rd861;
	xor.b64  	%rd398, %rd397, %rd862;
	xor.b64  	%rd399, %rd398, %rd863;
	xor.b64  	%rd400, %rd865, %rd864;
	xor.b64  	%rd401, %rd400, %rd866;
	xor.b64  	%rd402, %rd401, %rd867;
	xor.b64  	%rd403, %rd402, %rd868;
	xor.b64  	%rd404, %rd870, %rd869;
	xor.b64  	%rd405, %rd404, %rd871;
	xor.b64  	%rd406, %rd405, %rd872;
	xor.b64  	%rd407, %rd406, %rd873;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd395, 1;
	shr.b64 	%rhs, %rd395, 63;
	add.u64 	%rd408, %lhs, %rhs;
	}
	xor.b64  	%rd409, %rd407, %rd408;
	xor.b64  	%rd410, %rd409, %rd849;
	xor.b64  	%rd411, %rd409, %rd850;
	xor.b64  	%rd412, %rd409, %rd851;
	xor.b64  	%rd413, %rd409, %rd852;
	xor.b64  	%rd414, %rd409, %rd853;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd399, 1;
	shr.b64 	%rhs, %rd399, 63;
	add.u64 	%rd415, %lhs, %rhs;
	}
	xor.b64  	%rd416, %rd415, %rd391;
	xor.b64  	%rd417, %rd416, %rd854;
	xor.b64  	%rd418, %rd416, %rd855;
	xor.b64  	%rd419, %rd416, %rd856;
	xor.b64  	%rd420, %rd416, %rd857;
	xor.b64  	%rd421, %rd416, %rd858;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd403, 1;
	shr.b64 	%rhs, %rd403, 63;
	add.u64 	%rd422, %lhs, %rhs;
	}
	xor.b64  	%rd423, %rd422, %rd395;
	xor.b64  	%rd424, %rd423, %rd859;
	xor.b64  	%rd425, %rd423, %rd860;
	xor.b64  	%rd426, %rd423, %rd861;
	xor.b64  	%rd427, %rd423, %rd862;
	xor.b64  	%rd428, %rd423, %rd863;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd407, 1;
	shr.b64 	%rhs, %rd407, 63;
	add.u64 	%rd429, %lhs, %rhs;
	}
	xor.b64  	%rd430, %rd429, %rd399;
	xor.b64  	%rd431, %rd430, %rd864;
	xor.b64  	%rd432, %rd430, %rd865;
	xor.b64  	%rd433, %rd430, %rd866;
	xor.b64  	%rd434, %rd430, %rd867;
	xor.b64  	%rd435, %rd430, %rd868;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd391, 1;
	shr.b64 	%rhs, %rd391, 63;
	add.u64 	%rd436, %lhs, %rhs;
	}
	xor.b64  	%rd437, %rd403, %rd436;
	xor.b64  	%rd438, %rd437, %rd869;
	xor.b64  	%rd439, %rd870, %rd437;
	xor.b64  	%rd440, %rd871, %rd437;
	xor.b64  	%rd441, %rd872, %rd437;
	xor.b64  	%rd442, %rd873, %rd437;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd417, 1;
	shr.b64 	%rhs, %rd417, 63;
	add.u64 	%rd443, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd412, 3;
	shr.b64 	%rhs, %rd412, 61;
	add.u64 	%rd444, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd425, 6;
	shr.b64 	%rhs, %rd425, 58;
	add.u64 	%rd445, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd419, 10;
	shr.b64 	%rhs, %rd419, 54;
	add.u64 	%rd446, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd427, 15;
	shr.b64 	%rhs, %rd427, 49;
	add.u64 	%rd447, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd434, 21;
	shr.b64 	%rhs, %rd434, 43;
	add.u64 	%rd448, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd431, 28;
	shr.b64 	%rhs, %rd431, 36;
	add.u64 	%rd449, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd411, 36;
	shr.b64 	%rhs, %rd411, 28;
	add.u64 	%rd450, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd420, 45;
	shr.b64 	%rhs, %rd420, 19;
	add.u64 	%rd451, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd432, 55;
	shr.b64 	%rhs, %rd432, 9;
	add.u64 	%rd452, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd421, 2;
	shr.b64 	%rhs, %rd421, 62;
	add.u64 	%rd453, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd442, 14;
	shr.b64 	%rhs, %rd442, 50;
	add.u64 	%rd454, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd438, 27;
	shr.b64 	%rhs, %rd438, 37;
	add.u64 	%rd455, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd413, 41;
	shr.b64 	%rhs, %rd413, 23;
	add.u64 	%rd456, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd435, 56;
	shr.b64 	%rhs, %rd435, 8;
	add.u64 	%rd457, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd441, 8;
	shr.b64 	%rhs, %rd441, 56;
	add.u64 	%rd458, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd433, 25;
	shr.b64 	%rhs, %rd433, 39;
	add.u64 	%rd459, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd426, 43;
	shr.b64 	%rhs, %rd426, 21;
	add.u64 	%rd460, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd424, 62;
	shr.b64 	%rhs, %rd424, 2;
	add.u64 	%rd461, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd414, 18;
	shr.b64 	%rhs, %rd414, 46;
	add.u64 	%rd462, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd440, 39;
	shr.b64 	%rhs, %rd440, 25;
	add.u64 	%rd463, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd428, 61;
	shr.b64 	%rhs, %rd428, 3;
	add.u64 	%rd464, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd439, 20;
	shr.b64 	%rhs, %rd439, 44;
	add.u64 	%rd465, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd418, 44;
	shr.b64 	%rhs, %rd418, 20;
	add.u64 	%rd466, %lhs, %rhs;
	}
	not.b64 	%rd467, %rd466;
	and.b64  	%rd468, %rd460, %rd467;
	not.b64 	%rd469, %rd460;
	and.b64  	%rd470, %rd448, %rd469;
	xor.b64  	%rd854, %rd470, %rd466;
	not.b64 	%rd471, %rd448;
	and.b64  	%rd472, %rd454, %rd471;
	xor.b64  	%rd859, %rd472, %rd460;
	not.b64 	%rd473, %rd454;
	and.b64  	%rd474, %rd410, %rd473;
	xor.b64  	%rd864, %rd448, %rd474;
	not.b64 	%rd475, %rd410;
	and.b64  	%rd476, %rd466, %rd475;
	xor.b64  	%rd869, %rd476, %rd454;
	not.b64 	%rd477, %rd465;
	and.b64  	%rd478, %rd444, %rd477;
	xor.b64  	%rd850, %rd449, %rd478;
	not.b64 	%rd479, %rd444;
	and.b64  	%rd480, %rd451, %rd479;
	xor.b64  	%rd855, %rd480, %rd465;
	not.b64 	%rd481, %rd451;
	and.b64  	%rd482, %rd464, %rd481;
	xor.b64  	%rd860, %rd444, %rd482;
	not.b64 	%rd483, %rd464;
	and.b64  	%rd484, %rd449, %rd483;
	xor.b64  	%rd865, %rd484, %rd451;
	not.b64 	%rd485, %rd449;
	and.b64  	%rd486, %rd465, %rd485;
	xor.b64  	%rd870, %rd486, %rd464;
	not.b64 	%rd487, %rd445;
	and.b64  	%rd488, %rd459, %rd487;
	xor.b64  	%rd851, %rd488, %rd443;
	not.b64 	%rd489, %rd459;
	and.b64  	%rd490, %rd458, %rd489;
	xor.b64  	%rd856, %rd490, %rd445;
	not.b64 	%rd491, %rd458;
	and.b64  	%rd492, %rd462, %rd491;
	xor.b64  	%rd861, %rd459, %rd492;
	not.b64 	%rd493, %rd462;
	and.b64  	%rd494, %rd443, %rd493;
	xor.b64  	%rd866, %rd494, %rd458;
	not.b64 	%rd495, %rd443;
	and.b64  	%rd496, %rd445, %rd495;
	xor.b64  	%rd871, %rd462, %rd496;
	not.b64 	%rd497, %rd450;
	and.b64  	%rd498, %rd446, %rd497;
	xor.b64  	%rd852, %rd498, %rd455;
	not.b64 	%rd499, %rd446;
	and.b64  	%rd500, %rd447, %rd499;
	xor.b64  	%rd857, %rd450, %rd500;
	not.b64 	%rd501, %rd447;
	and.b64  	%rd502, %rd457, %rd501;
	xor.b64  	%rd862, %rd502, %rd446;
	not.b64 	%rd503, %rd457;
	and.b64  	%rd504, %rd455, %rd503;
	xor.b64  	%rd867, %rd504, %rd447;
	not.b64 	%rd505, %rd455;
	and.b64  	%rd506, %rd450, %rd505;
	xor.b64  	%rd872, %rd457, %rd506;
	not.b64 	%rd507, %rd452;
	and.b64  	%rd508, %rd463, %rd507;
	xor.b64  	%rd853, %rd508, %rd461;
	not.b64 	%rd509, %rd463;
	and.b64  	%rd510, %rd456, %rd509;
	xor.b64  	%rd858, %rd452, %rd510;
	not.b64 	%rd511, %rd456;
	and.b64  	%rd512, %rd453, %rd511;
	xor.b64  	%rd863, %rd512, %rd463;
	not.b64 	%rd513, %rd453;
	and.b64  	%rd514, %rd461, %rd513;
	xor.b64  	%rd868, %rd456, %rd514;
	not.b64 	%rd515, %rd461;
	and.b64  	%rd516, %rd452, %rd515;
	xor.b64  	%rd873, %rd516, %rd453;
	add.s64 	%rd518, %rd814, %rd874;
	ld.global.nc.u64 	%rd519, [%rd518];
	xor.b64  	%rd520, %rd519, %rd468;
	xor.b64  	%rd849, %rd520, %rd410;
	add.s64 	%rd874, %rd874, 8;
	cvt.u32.u64 	%r1, %rd874;
	setp.ne.s32 	%p10, %r1, 192;
	@%p10 bra 	LBB9_15;
// %bb.16:                              //   in Loop: Header=BB9_4 Depth=1
	st.local.u64 	[%rd1], %rd849;
	st.local.u64 	[%rd1+40], %rd850;
	st.local.u64 	[%rd1+80], %rd851;
	st.local.u64 	[%rd1+120], %rd852;
	st.local.u64 	[%rd1+160], %rd853;
	st.local.u64 	[%rd1+8], %rd854;
	st.local.u64 	[%rd1+48], %rd855;
	st.local.u64 	[%rd1+88], %rd856;
	st.local.u64 	[%rd1+128], %rd857;
	st.local.u64 	[%rd1+168], %rd858;
	st.local.u64 	[%rd1+16], %rd859;
	st.local.u64 	[%rd1+56], %rd860;
	st.local.u64 	[%rd1+96], %rd861;
	st.local.u64 	[%rd1+136], %rd862;
	st.local.u64 	[%rd1+176], %rd863;
	st.local.u64 	[%rd1+24], %rd864;
	st.local.u64 	[%rd1+64], %rd865;
	st.local.u64 	[%rd1+104], %rd866;
	st.local.u64 	[%rd1+144], %rd867;
	st.local.u64 	[%rd1+184], %rd868;
	st.local.u64 	[%rd1+32], %rd869;
	st.local.u64 	[%rd1+72], %rd870;
	st.local.u64 	[%rd1+112], %rd871;
	st.local.u64 	[%rd1+152], %rd872;
	st.local.u64 	[%rd1+192], %rd873;
	add.s64 	%rd900, %rd900, %rd375;
	sub.s64 	%rd901, %rd901, %rd375;
	cvt.u16.u64 	%rs94, %rd849;
	setp.ge.u64 	%p11, %rd901, %rd375;
	@%p11 bra 	LBB9_4;
LBB9_17:
	add.s64 	%rd521, %rd1, %rd901;
	ld.local.u8 	%rs39, [%rd521];
	xor.b16  	%rs40, %rs39, %rs7;
	st.local.u8 	[%rd521], %rs40;
	add.s64 	%rd522, %rd1, %rd375;
	ld.local.u8 	%rs41, [%rd522+-1];
	xor.b16  	%rs42, %rs41, 128;
	st.local.u8 	[%rd522+-1], %rs42;
	setp.eq.s64 	%p12, %rd901, 0;
	@%p12 bra 	LBB9_24;
// %bb.18:
	add.s64 	%rd524, %rd901, -1;
	and.b64  	%rd906, %rd901, 7;
	setp.lt.u64 	%p13, %rd524, 7;
	mov.u64 	%rd903, 0;
	@%p13 bra 	LBB9_21;
// %bb.19:
	and.b64  	%rd153, %rd901, -8;
	mov.u64 	%rd903, 0;
LBB9_20:                                // =>This Inner Loop Header: Depth=1
	add.s64 	%rd526, %rd900, %rd903;
	ld.u8 	%rs43, [%rd526];
	add.s64 	%rd527, %rd1, %rd903;
	ld.local.v4.u8 	{%rs44, %rs45, %rs46, %rs47}, [%rd527+4];
	ld.local.v4.u8 	{%rs48, %rs49, %rs50, %rs51}, [%rd527];
	xor.b16  	%rs52, %rs48, %rs43;
	st.local.u8 	[%rd527], %rs52;
	ld.u8 	%rs53, [%rd526+1];
	xor.b16  	%rs54, %rs49, %rs53;
	st.local.u8 	[%rd527+1], %rs54;
	ld.u8 	%rs55, [%rd526+2];
	xor.b16  	%rs56, %rs50, %rs55;
	st.local.u8 	[%rd527+2], %rs56;
	ld.u8 	%rs57, [%rd526+3];
	xor.b16  	%rs58, %rs51, %rs57;
	st.local.u8 	[%rd527+3], %rs58;
	ld.u8 	%rs59, [%rd526+4];
	xor.b16  	%rs60, %rs44, %rs59;
	st.local.u8 	[%rd527+4], %rs60;
	ld.u8 	%rs61, [%rd526+5];
	xor.b16  	%rs62, %rs45, %rs61;
	st.local.u8 	[%rd527+5], %rs62;
	ld.u8 	%rs63, [%rd526+6];
	xor.b16  	%rs64, %rs46, %rs63;
	st.local.u8 	[%rd527+6], %rs64;
	ld.u8 	%rs65, [%rd526+7];
	xor.b16  	%rs66, %rs47, %rs65;
	st.local.u8 	[%rd527+7], %rs66;
	add.s64 	%rd903, %rd903, 8;
	setp.ne.s64 	%p14, %rd153, %rd903;
	@%p14 bra 	LBB9_20;
LBB9_21:
	setp.eq.s64 	%p15, %rd906, 0;
	@%p15 bra 	LBB9_24;
// %bb.22:                              // %.preheader10
	add.s64 	%rd905, %rd1, %rd903;
	add.s64 	%rd904, %rd900, %rd903;
LBB9_23:                                // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	ld.u8 	%rs67, [%rd904];
	ld.local.u8 	%rs68, [%rd905];
	xor.b16  	%rs69, %rs68, %rs67;
	st.local.u8 	[%rd905], %rs69;
	add.s64 	%rd906, %rd906, -1;
	add.s64 	%rd905, %rd905, 1;
	add.s64 	%rd904, %rd904, 1;
	setp.ne.s64 	%p16, %rd906, 0;
	@%p16 bra 	LBB9_23;
LBB9_24:
	ld.param.u64 	%rd990, [hash_param_1];
	ld.param.u64 	%rd991, [hash_param_0];
	ld.local.u64 	%rd965, [%rd1];
	ld.local.u64 	%rd966, [%rd1+40];
	ld.local.u64 	%rd967, [%rd1+80];
	ld.local.u64 	%rd968, [%rd1+120];
	ld.local.u64 	%rd969, [%rd1+160];
	ld.local.u64 	%rd970, [%rd1+8];
	ld.local.u64 	%rd971, [%rd1+48];
	ld.local.u64 	%rd972, [%rd1+88];
	ld.local.u64 	%rd973, [%rd1+128];
	ld.local.u64 	%rd974, [%rd1+168];
	ld.local.u64 	%rd975, [%rd1+16];
	ld.local.u64 	%rd976, [%rd1+56];
	ld.local.u64 	%rd977, [%rd1+96];
	ld.local.u64 	%rd978, [%rd1+136];
	ld.local.u64 	%rd979, [%rd1+176];
	ld.local.u64 	%rd980, [%rd1+24];
	ld.local.u64 	%rd981, [%rd1+64];
	ld.local.u64 	%rd982, [%rd1+104];
	ld.local.u64 	%rd983, [%rd1+144];
	ld.local.u64 	%rd984, [%rd1+184];
	ld.local.u64 	%rd985, [%rd1+32];
	ld.local.u64 	%rd986, [%rd1+72];
	ld.local.u64 	%rd987, [%rd1+112];
	ld.local.u64 	%rd988, [%rd1+152];
	ld.local.u64 	%rd989, [%rd1+192];
	mov.u64 	%rd907, 0;
LBB9_25:                                // =>This Inner Loop Header: Depth=1
	xor.b64  	%rd529, %rd966, %rd965;
	xor.b64  	%rd530, %rd529, %rd967;
	xor.b64  	%rd531, %rd530, %rd968;
	xor.b64  	%rd532, %rd531, %rd969;
	xor.b64  	%rd533, %rd971, %rd970;
	xor.b64  	%rd534, %rd533, %rd972;
	xor.b64  	%rd535, %rd534, %rd973;
	xor.b64  	%rd536, %rd535, %rd974;
	xor.b64  	%rd537, %rd976, %rd975;
	xor.b64  	%rd538, %rd537, %rd977;
	xor.b64  	%rd539, %rd538, %rd978;
	xor.b64  	%rd540, %rd539, %rd979;
	xor.b64  	%rd541, %rd981, %rd980;
	xor.b64  	%rd542, %rd541, %rd982;
	xor.b64  	%rd543, %rd542, %rd983;
	xor.b64  	%rd544, %rd543, %rd984;
	xor.b64  	%rd545, %rd986, %rd985;
	xor.b64  	%rd546, %rd545, %rd987;
	xor.b64  	%rd547, %rd546, %rd988;
	xor.b64  	%rd548, %rd547, %rd989;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd536, 1;
	shr.b64 	%rhs, %rd536, 63;
	add.u64 	%rd549, %lhs, %rhs;
	}
	xor.b64  	%rd550, %rd548, %rd549;
	xor.b64  	%rd551, %rd550, %rd965;
	xor.b64  	%rd552, %rd550, %rd966;
	xor.b64  	%rd553, %rd550, %rd967;
	xor.b64  	%rd554, %rd550, %rd968;
	xor.b64  	%rd555, %rd550, %rd969;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd540, 1;
	shr.b64 	%rhs, %rd540, 63;
	add.u64 	%rd556, %lhs, %rhs;
	}
	xor.b64  	%rd557, %rd556, %rd532;
	xor.b64  	%rd558, %rd557, %rd970;
	xor.b64  	%rd559, %rd557, %rd971;
	xor.b64  	%rd560, %rd557, %rd972;
	xor.b64  	%rd561, %rd557, %rd973;
	xor.b64  	%rd562, %rd557, %rd974;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd544, 1;
	shr.b64 	%rhs, %rd544, 63;
	add.u64 	%rd563, %lhs, %rhs;
	}
	xor.b64  	%rd564, %rd563, %rd536;
	xor.b64  	%rd565, %rd564, %rd975;
	xor.b64  	%rd566, %rd564, %rd976;
	xor.b64  	%rd567, %rd564, %rd977;
	xor.b64  	%rd568, %rd564, %rd978;
	xor.b64  	%rd569, %rd564, %rd979;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd548, 1;
	shr.b64 	%rhs, %rd548, 63;
	add.u64 	%rd570, %lhs, %rhs;
	}
	xor.b64  	%rd571, %rd570, %rd540;
	xor.b64  	%rd572, %rd571, %rd980;
	xor.b64  	%rd573, %rd571, %rd981;
	xor.b64  	%rd574, %rd571, %rd982;
	xor.b64  	%rd575, %rd571, %rd983;
	xor.b64  	%rd576, %rd571, %rd984;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd532, 1;
	shr.b64 	%rhs, %rd532, 63;
	add.u64 	%rd577, %lhs, %rhs;
	}
	xor.b64  	%rd578, %rd544, %rd577;
	xor.b64  	%rd579, %rd578, %rd985;
	xor.b64  	%rd580, %rd986, %rd578;
	xor.b64  	%rd581, %rd987, %rd578;
	xor.b64  	%rd582, %rd988, %rd578;
	xor.b64  	%rd583, %rd989, %rd578;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd558, 1;
	shr.b64 	%rhs, %rd558, 63;
	add.u64 	%rd584, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd553, 3;
	shr.b64 	%rhs, %rd553, 61;
	add.u64 	%rd585, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd566, 6;
	shr.b64 	%rhs, %rd566, 58;
	add.u64 	%rd586, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd560, 10;
	shr.b64 	%rhs, %rd560, 54;
	add.u64 	%rd587, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd568, 15;
	shr.b64 	%rhs, %rd568, 49;
	add.u64 	%rd588, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd575, 21;
	shr.b64 	%rhs, %rd575, 43;
	add.u64 	%rd589, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd572, 28;
	shr.b64 	%rhs, %rd572, 36;
	add.u64 	%rd590, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd552, 36;
	shr.b64 	%rhs, %rd552, 28;
	add.u64 	%rd591, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd561, 45;
	shr.b64 	%rhs, %rd561, 19;
	add.u64 	%rd592, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd573, 55;
	shr.b64 	%rhs, %rd573, 9;
	add.u64 	%rd593, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd562, 2;
	shr.b64 	%rhs, %rd562, 62;
	add.u64 	%rd594, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd583, 14;
	shr.b64 	%rhs, %rd583, 50;
	add.u64 	%rd595, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd579, 27;
	shr.b64 	%rhs, %rd579, 37;
	add.u64 	%rd596, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd554, 41;
	shr.b64 	%rhs, %rd554, 23;
	add.u64 	%rd597, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd576, 56;
	shr.b64 	%rhs, %rd576, 8;
	add.u64 	%rd598, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd582, 8;
	shr.b64 	%rhs, %rd582, 56;
	add.u64 	%rd599, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd574, 25;
	shr.b64 	%rhs, %rd574, 39;
	add.u64 	%rd600, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd567, 43;
	shr.b64 	%rhs, %rd567, 21;
	add.u64 	%rd601, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd565, 62;
	shr.b64 	%rhs, %rd565, 2;
	add.u64 	%rd602, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd555, 18;
	shr.b64 	%rhs, %rd555, 46;
	add.u64 	%rd603, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd581, 39;
	shr.b64 	%rhs, %rd581, 25;
	add.u64 	%rd604, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd569, 61;
	shr.b64 	%rhs, %rd569, 3;
	add.u64 	%rd605, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd580, 20;
	shr.b64 	%rhs, %rd580, 44;
	add.u64 	%rd606, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd559, 44;
	shr.b64 	%rhs, %rd559, 20;
	add.u64 	%rd607, %lhs, %rhs;
	}
	not.b64 	%rd608, %rd607;
	and.b64  	%rd609, %rd601, %rd608;
	not.b64 	%rd610, %rd601;
	and.b64  	%rd611, %rd589, %rd610;
	xor.b64  	%rd970, %rd611, %rd607;
	not.b64 	%rd612, %rd589;
	and.b64  	%rd613, %rd595, %rd612;
	xor.b64  	%rd975, %rd613, %rd601;
	not.b64 	%rd614, %rd595;
	and.b64  	%rd615, %rd551, %rd614;
	xor.b64  	%rd980, %rd589, %rd615;
	not.b64 	%rd616, %rd551;
	and.b64  	%rd617, %rd607, %rd616;
	xor.b64  	%rd985, %rd617, %rd595;
	not.b64 	%rd618, %rd606;
	and.b64  	%rd619, %rd585, %rd618;
	xor.b64  	%rd966, %rd590, %rd619;
	not.b64 	%rd620, %rd585;
	and.b64  	%rd621, %rd592, %rd620;
	xor.b64  	%rd971, %rd621, %rd606;
	not.b64 	%rd622, %rd592;
	and.b64  	%rd623, %rd605, %rd622;
	xor.b64  	%rd976, %rd585, %rd623;
	not.b64 	%rd624, %rd605;
	and.b64  	%rd625, %rd590, %rd624;
	xor.b64  	%rd981, %rd625, %rd592;
	not.b64 	%rd626, %rd590;
	and.b64  	%rd627, %rd606, %rd626;
	xor.b64  	%rd986, %rd627, %rd605;
	not.b64 	%rd628, %rd586;
	and.b64  	%rd629, %rd600, %rd628;
	xor.b64  	%rd967, %rd629, %rd584;
	not.b64 	%rd630, %rd600;
	and.b64  	%rd631, %rd599, %rd630;
	xor.b64  	%rd972, %rd631, %rd586;
	not.b64 	%rd632, %rd599;
	and.b64  	%rd633, %rd603, %rd632;
	xor.b64  	%rd977, %rd600, %rd633;
	not.b64 	%rd634, %rd603;
	and.b64  	%rd635, %rd584, %rd634;
	xor.b64  	%rd982, %rd635, %rd599;
	not.b64 	%rd636, %rd584;
	and.b64  	%rd637, %rd586, %rd636;
	xor.b64  	%rd987, %rd603, %rd637;
	not.b64 	%rd638, %rd591;
	and.b64  	%rd639, %rd587, %rd638;
	xor.b64  	%rd968, %rd639, %rd596;
	not.b64 	%rd640, %rd587;
	and.b64  	%rd641, %rd588, %rd640;
	xor.b64  	%rd973, %rd591, %rd641;
	not.b64 	%rd642, %rd588;
	and.b64  	%rd643, %rd598, %rd642;
	xor.b64  	%rd978, %rd643, %rd587;
	not.b64 	%rd644, %rd598;
	and.b64  	%rd645, %rd596, %rd644;
	xor.b64  	%rd983, %rd645, %rd588;
	not.b64 	%rd646, %rd596;
	and.b64  	%rd647, %rd591, %rd646;
	xor.b64  	%rd988, %rd598, %rd647;
	not.b64 	%rd648, %rd593;
	and.b64  	%rd649, %rd604, %rd648;
	xor.b64  	%rd969, %rd649, %rd602;
	not.b64 	%rd650, %rd604;
	and.b64  	%rd651, %rd597, %rd650;
	xor.b64  	%rd974, %rd593, %rd651;
	not.b64 	%rd652, %rd597;
	and.b64  	%rd653, %rd594, %rd652;
	xor.b64  	%rd979, %rd653, %rd604;
	not.b64 	%rd654, %rd594;
	and.b64  	%rd655, %rd602, %rd654;
	xor.b64  	%rd984, %rd597, %rd655;
	not.b64 	%rd656, %rd602;
	and.b64  	%rd657, %rd593, %rd656;
	xor.b64  	%rd989, %rd657, %rd594;
	add.s64 	%rd659, %rd814, %rd907;
	ld.global.nc.u64 	%rd660, [%rd659];
	xor.b64  	%rd661, %rd660, %rd609;
	xor.b64  	%rd965, %rd661, %rd551;
	add.s64 	%rd907, %rd907, 8;
	cvt.u32.u64 	%r2, %rd907;
	setp.ne.s32 	%p17, %r2, 192;
	@%p17 bra 	LBB9_25;
// %bb.26:
	st.local.u64 	[%rd1], %rd965;
	st.local.u64 	[%rd1+40], %rd966;
	st.local.u64 	[%rd1+80], %rd967;
	st.local.u64 	[%rd1+120], %rd968;
	st.local.u64 	[%rd1+160], %rd969;
	st.local.u64 	[%rd1+8], %rd970;
	st.local.u64 	[%rd1+48], %rd971;
	st.local.u64 	[%rd1+88], %rd972;
	st.local.u64 	[%rd1+128], %rd973;
	st.local.u64 	[%rd1+168], %rd974;
	st.local.u64 	[%rd1+16], %rd975;
	st.local.u64 	[%rd1+56], %rd976;
	st.local.u64 	[%rd1+96], %rd977;
	st.local.u64 	[%rd1+136], %rd978;
	st.local.u64 	[%rd1+176], %rd979;
	st.local.u64 	[%rd1+24], %rd980;
	st.local.u64 	[%rd1+64], %rd981;
	st.local.u64 	[%rd1+104], %rd982;
	st.local.u64 	[%rd1+144], %rd983;
	st.local.u64 	[%rd1+184], %rd984;
	st.local.u64 	[%rd1+32], %rd985;
	st.local.u64 	[%rd1+72], %rd986;
	st.local.u64 	[%rd1+112], %rd987;
	st.local.u64 	[%rd1+152], %rd988;
	st.local.u64 	[%rd1+192], %rd989;
	setp.lt.u64 	%p18, %rd990, %rd375;
	cvt.u16.u64 	%rs96, %rd965;
	@%p18 bra 	LBB9_39;
// %bb.27:
	add.s64 	%rd242, %rd375, -2;
	and.b64  	%rd243, %rd813, 7;
	and.b64  	%rd244, %rd813, -8;
	add.s64 	%rd245, %rd1, 4;
	setp.eq.s64 	%p19, %rd375, 1;
	setp.lt.u64 	%p20, %rd242, 7;
	setp.eq.s64 	%p22, %rd243, 0;
LBB9_28:                                // =>This Loop Header: Depth=1
                                        //     Child Loop BB9_31 Depth 2
                                        //     Child Loop BB9_35 Depth 2
                                        //     Child Loop BB9_37 Depth 2
	st.u8 	[%rd991], %rs96;
	@%p19 bra 	LBB9_36;
// %bb.29:                              //   in Loop: Header=BB9_28 Depth=1
	mov.u64 	%rd962, 1;
	@%p20 bra 	LBB9_33;
// %bb.30:                              // %.preheader7
                                        //   in Loop: Header=BB9_28 Depth=1
	mov.u64 	%rd960, 0;
LBB9_31:                                //   Parent Loop BB9_28 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add.s64 	%rd664, %rd245, %rd960;
	ld.local.u8 	%rs70, [%rd664+-3];
	add.s64 	%rd665, %rd991, %rd960;
	st.u8 	[%rd665+1], %rs70;
	ld.local.u8 	%rs71, [%rd664+-2];
	st.u8 	[%rd665+2], %rs71;
	ld.local.u8 	%rs72, [%rd664+-1];
	st.u8 	[%rd665+3], %rs72;
	ld.local.u8 	%rs73, [%rd664];
	st.u8 	[%rd665+4], %rs73;
	ld.local.u8 	%rs74, [%rd664+1];
	st.u8 	[%rd665+5], %rs74;
	ld.local.u8 	%rs75, [%rd664+2];
	st.u8 	[%rd665+6], %rs75;
	ld.local.u8 	%rs76, [%rd664+3];
	st.u8 	[%rd665+7], %rs76;
	ld.local.u8 	%rs77, [%rd664+4];
	st.u8 	[%rd665+8], %rs77;
	add.s64 	%rd960, %rd960, 8;
	setp.ne.s64 	%p21, %rd244, %rd960;
	@%p21 bra 	LBB9_31;
// %bb.32:                              // %.loopexit8
                                        //   in Loop: Header=BB9_28 Depth=1
	add.s64 	%rd962, %rd960, 1;
LBB9_33:                                //   in Loop: Header=BB9_28 Depth=1
	@%p22 bra 	LBB9_36;
// %bb.34:                              // %.preheader5
                                        //   in Loop: Header=BB9_28 Depth=1
	mov.u64 	%rd963, %rd243;
LBB9_35:                                //   Parent Loop BB9_28 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	.pragma "nounroll";
	add.s64 	%rd666, %rd1, %rd962;
	ld.local.u8 	%rs78, [%rd666];
	add.s64 	%rd667, %rd991, %rd962;
	st.u8 	[%rd667], %rs78;
	add.s64 	%rd962, %rd962, 1;
	add.s64 	%rd963, %rd963, -1;
	setp.ne.s64 	%p23, %rd963, 0;
	@%p23 bra 	LBB9_35;
LBB9_36:                                //   in Loop: Header=BB9_28 Depth=1
	mov.u64 	%rd964, 0;
LBB9_37:                                //   Parent Loop BB9_28 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	xor.b64  	%rd669, %rd966, %rd965;
	xor.b64  	%rd670, %rd669, %rd967;
	xor.b64  	%rd671, %rd670, %rd968;
	xor.b64  	%rd672, %rd671, %rd969;
	xor.b64  	%rd673, %rd971, %rd970;
	xor.b64  	%rd674, %rd673, %rd972;
	xor.b64  	%rd675, %rd674, %rd973;
	xor.b64  	%rd676, %rd675, %rd974;
	xor.b64  	%rd677, %rd976, %rd975;
	xor.b64  	%rd678, %rd677, %rd977;
	xor.b64  	%rd679, %rd678, %rd978;
	xor.b64  	%rd680, %rd679, %rd979;
	xor.b64  	%rd681, %rd981, %rd980;
	xor.b64  	%rd682, %rd681, %rd982;
	xor.b64  	%rd683, %rd682, %rd983;
	xor.b64  	%rd684, %rd683, %rd984;
	xor.b64  	%rd685, %rd986, %rd985;
	xor.b64  	%rd686, %rd685, %rd987;
	xor.b64  	%rd687, %rd686, %rd988;
	xor.b64  	%rd688, %rd687, %rd989;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd676, 1;
	shr.b64 	%rhs, %rd676, 63;
	add.u64 	%rd689, %lhs, %rhs;
	}
	xor.b64  	%rd690, %rd688, %rd689;
	xor.b64  	%rd691, %rd690, %rd965;
	xor.b64  	%rd692, %rd690, %rd966;
	xor.b64  	%rd693, %rd690, %rd967;
	xor.b64  	%rd694, %rd690, %rd968;
	xor.b64  	%rd695, %rd690, %rd969;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd680, 1;
	shr.b64 	%rhs, %rd680, 63;
	add.u64 	%rd696, %lhs, %rhs;
	}
	xor.b64  	%rd697, %rd696, %rd672;
	xor.b64  	%rd698, %rd697, %rd970;
	xor.b64  	%rd699, %rd697, %rd971;
	xor.b64  	%rd700, %rd697, %rd972;
	xor.b64  	%rd701, %rd697, %rd973;
	xor.b64  	%rd702, %rd697, %rd974;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd684, 1;
	shr.b64 	%rhs, %rd684, 63;
	add.u64 	%rd703, %lhs, %rhs;
	}
	xor.b64  	%rd704, %rd703, %rd676;
	xor.b64  	%rd705, %rd704, %rd975;
	xor.b64  	%rd706, %rd704, %rd976;
	xor.b64  	%rd707, %rd704, %rd977;
	xor.b64  	%rd708, %rd704, %rd978;
	xor.b64  	%rd709, %rd704, %rd979;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd688, 1;
	shr.b64 	%rhs, %rd688, 63;
	add.u64 	%rd710, %lhs, %rhs;
	}
	xor.b64  	%rd711, %rd710, %rd680;
	xor.b64  	%rd712, %rd711, %rd980;
	xor.b64  	%rd713, %rd711, %rd981;
	xor.b64  	%rd714, %rd711, %rd982;
	xor.b64  	%rd715, %rd711, %rd983;
	xor.b64  	%rd716, %rd711, %rd984;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd672, 1;
	shr.b64 	%rhs, %rd672, 63;
	add.u64 	%rd717, %lhs, %rhs;
	}
	xor.b64  	%rd718, %rd684, %rd717;
	xor.b64  	%rd719, %rd718, %rd985;
	xor.b64  	%rd720, %rd986, %rd718;
	xor.b64  	%rd721, %rd987, %rd718;
	xor.b64  	%rd722, %rd988, %rd718;
	xor.b64  	%rd723, %rd989, %rd718;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd698, 1;
	shr.b64 	%rhs, %rd698, 63;
	add.u64 	%rd724, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd693, 3;
	shr.b64 	%rhs, %rd693, 61;
	add.u64 	%rd725, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd706, 6;
	shr.b64 	%rhs, %rd706, 58;
	add.u64 	%rd726, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd700, 10;
	shr.b64 	%rhs, %rd700, 54;
	add.u64 	%rd727, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd708, 15;
	shr.b64 	%rhs, %rd708, 49;
	add.u64 	%rd728, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd715, 21;
	shr.b64 	%rhs, %rd715, 43;
	add.u64 	%rd729, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd712, 28;
	shr.b64 	%rhs, %rd712, 36;
	add.u64 	%rd730, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd692, 36;
	shr.b64 	%rhs, %rd692, 28;
	add.u64 	%rd731, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd701, 45;
	shr.b64 	%rhs, %rd701, 19;
	add.u64 	%rd732, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd713, 55;
	shr.b64 	%rhs, %rd713, 9;
	add.u64 	%rd733, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd702, 2;
	shr.b64 	%rhs, %rd702, 62;
	add.u64 	%rd734, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd723, 14;
	shr.b64 	%rhs, %rd723, 50;
	add.u64 	%rd735, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd719, 27;
	shr.b64 	%rhs, %rd719, 37;
	add.u64 	%rd736, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd694, 41;
	shr.b64 	%rhs, %rd694, 23;
	add.u64 	%rd737, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd716, 56;
	shr.b64 	%rhs, %rd716, 8;
	add.u64 	%rd738, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd722, 8;
	shr.b64 	%rhs, %rd722, 56;
	add.u64 	%rd739, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd714, 25;
	shr.b64 	%rhs, %rd714, 39;
	add.u64 	%rd740, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd707, 43;
	shr.b64 	%rhs, %rd707, 21;
	add.u64 	%rd741, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd705, 62;
	shr.b64 	%rhs, %rd705, 2;
	add.u64 	%rd742, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd695, 18;
	shr.b64 	%rhs, %rd695, 46;
	add.u64 	%rd743, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd721, 39;
	shr.b64 	%rhs, %rd721, 25;
	add.u64 	%rd744, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd709, 61;
	shr.b64 	%rhs, %rd709, 3;
	add.u64 	%rd745, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd720, 20;
	shr.b64 	%rhs, %rd720, 44;
	add.u64 	%rd746, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd699, 44;
	shr.b64 	%rhs, %rd699, 20;
	add.u64 	%rd747, %lhs, %rhs;
	}
	not.b64 	%rd748, %rd747;
	and.b64  	%rd749, %rd741, %rd748;
	not.b64 	%rd750, %rd741;
	and.b64  	%rd751, %rd729, %rd750;
	xor.b64  	%rd970, %rd751, %rd747;
	not.b64 	%rd752, %rd729;
	and.b64  	%rd753, %rd735, %rd752;
	xor.b64  	%rd975, %rd753, %rd741;
	not.b64 	%rd754, %rd735;
	and.b64  	%rd755, %rd691, %rd754;
	xor.b64  	%rd980, %rd729, %rd755;
	not.b64 	%rd756, %rd691;
	and.b64  	%rd757, %rd747, %rd756;
	xor.b64  	%rd985, %rd757, %rd735;
	not.b64 	%rd758, %rd746;
	and.b64  	%rd759, %rd725, %rd758;
	xor.b64  	%rd966, %rd730, %rd759;
	not.b64 	%rd760, %rd725;
	and.b64  	%rd761, %rd732, %rd760;
	xor.b64  	%rd971, %rd761, %rd746;
	not.b64 	%rd762, %rd732;
	and.b64  	%rd763, %rd745, %rd762;
	xor.b64  	%rd976, %rd725, %rd763;
	not.b64 	%rd764, %rd745;
	and.b64  	%rd765, %rd730, %rd764;
	xor.b64  	%rd981, %rd765, %rd732;
	not.b64 	%rd766, %rd730;
	and.b64  	%rd767, %rd746, %rd766;
	xor.b64  	%rd986, %rd767, %rd745;
	not.b64 	%rd768, %rd726;
	and.b64  	%rd769, %rd740, %rd768;
	xor.b64  	%rd967, %rd769, %rd724;
	not.b64 	%rd770, %rd740;
	and.b64  	%rd771, %rd739, %rd770;
	xor.b64  	%rd972, %rd771, %rd726;
	not.b64 	%rd772, %rd739;
	and.b64  	%rd773, %rd743, %rd772;
	xor.b64  	%rd977, %rd740, %rd773;
	not.b64 	%rd774, %rd743;
	and.b64  	%rd775, %rd724, %rd774;
	xor.b64  	%rd982, %rd775, %rd739;
	not.b64 	%rd776, %rd724;
	and.b64  	%rd777, %rd726, %rd776;
	xor.b64  	%rd987, %rd743, %rd777;
	not.b64 	%rd778, %rd731;
	and.b64  	%rd779, %rd727, %rd778;
	xor.b64  	%rd968, %rd779, %rd736;
	not.b64 	%rd780, %rd727;
	and.b64  	%rd781, %rd728, %rd780;
	xor.b64  	%rd973, %rd731, %rd781;
	not.b64 	%rd782, %rd728;
	and.b64  	%rd783, %rd738, %rd782;
	xor.b64  	%rd978, %rd783, %rd727;
	not.b64 	%rd784, %rd738;
	and.b64  	%rd785, %rd736, %rd784;
	xor.b64  	%rd983, %rd785, %rd728;
	not.b64 	%rd786, %rd736;
	and.b64  	%rd787, %rd731, %rd786;
	xor.b64  	%rd988, %rd738, %rd787;
	not.b64 	%rd788, %rd733;
	and.b64  	%rd789, %rd744, %rd788;
	xor.b64  	%rd969, %rd789, %rd742;
	not.b64 	%rd790, %rd744;
	and.b64  	%rd791, %rd737, %rd790;
	xor.b64  	%rd974, %rd733, %rd791;
	not.b64 	%rd792, %rd737;
	and.b64  	%rd793, %rd734, %rd792;
	xor.b64  	%rd979, %rd793, %rd744;
	not.b64 	%rd794, %rd734;
	and.b64  	%rd795, %rd742, %rd794;
	xor.b64  	%rd984, %rd737, %rd795;
	not.b64 	%rd796, %rd742;
	and.b64  	%rd797, %rd733, %rd796;
	xor.b64  	%rd989, %rd797, %rd734;
	add.s64 	%rd799, %rd814, %rd964;
	ld.global.nc.u64 	%rd800, [%rd799];
	xor.b64  	%rd801, %rd800, %rd749;
	xor.b64  	%rd965, %rd801, %rd691;
	add.s64 	%rd964, %rd964, 8;
	cvt.u32.u64 	%r3, %rd964;
	setp.ne.s32 	%p24, %r3, 192;
	@%p24 bra 	LBB9_37;
// %bb.38:                              //   in Loop: Header=BB9_28 Depth=1
	st.local.u64 	[%rd1], %rd965;
	st.local.u64 	[%rd1+40], %rd966;
	st.local.u64 	[%rd1+80], %rd967;
	st.local.u64 	[%rd1+120], %rd968;
	st.local.u64 	[%rd1+160], %rd969;
	st.local.u64 	[%rd1+8], %rd970;
	st.local.u64 	[%rd1+48], %rd971;
	st.local.u64 	[%rd1+88], %rd972;
	st.local.u64 	[%rd1+128], %rd973;
	st.local.u64 	[%rd1+168], %rd974;
	st.local.u64 	[%rd1+16], %rd975;
	st.local.u64 	[%rd1+56], %rd976;
	st.local.u64 	[%rd1+96], %rd977;
	st.local.u64 	[%rd1+136], %rd978;
	st.local.u64 	[%rd1+176], %rd979;
	st.local.u64 	[%rd1+24], %rd980;
	st.local.u64 	[%rd1+64], %rd981;
	st.local.u64 	[%rd1+104], %rd982;
	st.local.u64 	[%rd1+144], %rd983;
	st.local.u64 	[%rd1+184], %rd984;
	st.local.u64 	[%rd1+32], %rd985;
	st.local.u64 	[%rd1+72], %rd986;
	st.local.u64 	[%rd1+112], %rd987;
	st.local.u64 	[%rd1+152], %rd988;
	st.local.u64 	[%rd1+192], %rd989;
	add.s64 	%rd991, %rd991, %rd375;
	sub.s64 	%rd990, %rd990, %rd375;
	cvt.u16.u64 	%rs96, %rd965;
	setp.ge.u64 	%p25, %rd990, %rd375;
	@%p25 bra 	LBB9_28;
LBB9_39:
	setp.eq.s64 	%p26, %rd990, 0;
	@%p26 bra 	LBB9_55;
// %bb.40:
	st.u8 	[%rd991], %rs96;
	setp.eq.s64 	%p27, %rd990, 1;
	add.s64 	%rd816, %rd990, -1;
	@%p27 bra 	LBB9_48;
// %bb.41:
	add.s64 	%rd803, %rd990, -2;
	and.b64  	%rd996, %rd816, 7;
	setp.lt.u64 	%p28, %rd803, 7;
	mov.u64 	%rd993, 1;
	@%p28 bra 	LBB9_45;
// %bb.42:
	and.b64  	%rd339, %rd816, -8;
	add.s64 	%rd340, %rd1, 4;
	mov.u64 	%rd992, 0;
LBB9_43:                                // =>This Inner Loop Header: Depth=1
	add.s64 	%rd805, %rd340, %rd992;
	ld.local.u8 	%rs79, [%rd805+-3];
	add.s64 	%rd806, %rd991, %rd992;
	st.u8 	[%rd806+1], %rs79;
	ld.local.u8 	%rs80, [%rd805+-2];
	st.u8 	[%rd806+2], %rs80;
	ld.local.u8 	%rs81, [%rd805+-1];
	st.u8 	[%rd806+3], %rs81;
	ld.local.u8 	%rs82, [%rd805];
	st.u8 	[%rd806+4], %rs82;
	ld.local.u8 	%rs83, [%rd805+1];
	st.u8 	[%rd806+5], %rs83;
	ld.local.u8 	%rs84, [%rd805+2];
	st.u8 	[%rd806+6], %rs84;
	ld.local.u8 	%rs85, [%rd805+3];
	st.u8 	[%rd806+7], %rs85;
	ld.local.u8 	%rs86, [%rd805+4];
	st.u8 	[%rd806+8], %rs86;
	add.s64 	%rd992, %rd992, 8;
	setp.ne.s64 	%p29, %rd339, %rd992;
	@%p29 bra 	LBB9_43;
// %bb.44:                              // %.loopexit4
	add.s64 	%rd993, %rd992, 1;
LBB9_45:
	setp.eq.s64 	%p30, %rd996, 0;
	@%p30 bra 	LBB9_48;
// %bb.46:                              // %.preheader2
	add.s64 	%rd995, %rd1, %rd993;
	add.s64 	%rd994, %rd991, %rd993;
LBB9_47:                                // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	ld.local.u8 	%rs87, [%rd995];
	st.u8 	[%rd994], %rs87;
	add.s64 	%rd996, %rd996, -1;
	add.s64 	%rd995, %rd995, 1;
	add.s64 	%rd994, %rd994, 1;
	setp.ne.s64 	%p31, %rd996, 0;
	@%p31 bra 	LBB9_47;
LBB9_48:
	and.b64  	%rd1000, %rd990, 3;
	setp.lt.u64 	%p32, %rd816, 3;
	mov.u64 	%rd997, 0;
	@%p32 bra 	LBB9_52;
// %bb.49:
	and.b64  	%rd809, %rd990, -4;
	neg.s64 	%rd355, %rd809;
	add.s64 	%rd810, %rd990, %rd1;
	add.s64 	%rd356, %rd810, -2;
	mov.u64 	%rd1002, 0;
	mov.u64 	%rd1001, %rd991;
LBB9_50:                                // =>This Inner Loop Header: Depth=1
	add.s64 	%rd811, %rd356, %rd1002;
	ld.local.u8 	%rs88, [%rd811+1];
	st.u8 	[%rd1001], %rs88;
	ld.local.u8 	%rs89, [%rd811];
	st.u8 	[%rd1001+1], %rs89;
	ld.local.u8 	%rs90, [%rd811+-1];
	st.u8 	[%rd1001+2], %rs90;
	ld.local.u8 	%rs91, [%rd811+-2];
	st.u8 	[%rd1001+3], %rs91;
	add.s64 	%rd1002, %rd1002, -4;
	add.s64 	%rd1001, %rd1001, 4;
	setp.eq.s64 	%p33, %rd355, %rd1002;
	@%p33 bra 	LBB9_51;
	bra.uni 	LBB9_50;
LBB9_51:                                // %.loopexit1
	neg.s64 	%rd997, %rd1002;
LBB9_52:
	setp.eq.s64 	%p34, %rd1000, 0;
	@%p34 bra 	LBB9_55;
// %bb.53:                              // %.preheader
	add.s64 	%rd999, %rd991, %rd997;
	sub.s64 	%rd812, %rd816, %rd997;
	add.s64 	%rd998, %rd1, %rd812;
LBB9_54:                                // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	ld.local.u8 	%rs92, [%rd998];
	st.u8 	[%rd999], %rs92;
	add.s64 	%rd1000, %rd1000, -1;
	add.s64 	%rd999, %rd999, 1;
	add.s64 	%rd998, %rd998, -1;
	setp.ne.s64 	%p35, %rd1000, 0;
	@%p35 bra 	LBB9_54;
LBB9_55:
	ret;
                                        // -- End function
}
	// .globl	__power_word            // -- Begin function __power_word
.visible .func __power_word(
	.param .b64 __power_word_param_0,
	.param .b64 __power_word_param_1,
	.param .b64 __power_word_param_2
)                                       // @__power_word
{
	.reg .pred 	%p<34>;
	.reg .b32 	%r<9>;
	.reg .b64 	%rd<157>;

// %bb.0:
	ld.param.u64 	%rd38, [__power_word_param_2];
	ld.param.u64 	%rd43, [__power_word_param_1];
	ld.u64 	%rd143, [%rd43+16];
	ld.u64 	%rd141, [%rd43];
	ld.u64 	%rd144, [%rd43+24];
	ld.u64 	%rd142, [%rd43+8];
	or.b64  	%rd44, %rd142, %rd144;
	or.b64  	%rd45, %rd141, %rd143;
	or.b64  	%rd46, %rd45, %rd44;
	setp.eq.s64 	%p1, %rd46, 0;
	mov.u64 	%rd154, 0;
	mov.u64 	%rd153, 1;
	mov.u64 	%rd155, %rd154;
	mov.u64 	%rd156, %rd154;
	@%p1 bra 	LBB10_3;
// %bb.1:
	ld.param.u64 	%rd37, [__power_word_param_0];
	ld.u64 	%rd148, [%rd37+24];
	ld.u64 	%rd147, [%rd37+16];
	ld.u64 	%rd146, [%rd37+8];
	ld.u64 	%rd145, [%rd37];
	mov.u64 	%rd150, 0;
	mov.u64 	%rd153, 1;
	mov.u64 	%rd155, %rd150;
	mov.u64 	%rd156, %rd150;
LBB10_2:                                // =>This Inner Loop Header: Depth=1
	and.b64  	%rd51, %rd141, 1;
	setp.eq.b64 	%p2, %rd51, 1;
	selp.b64 	%rd52, %rd148, 0, %p2;
	selp.b64 	%rd53, %rd147, 0, %p2;
	selp.b64 	%rd54, %rd146, 0, %p2;
	selp.b64 	%rd55, %rd145, 1, %p2;
	mul.hi.u64 	%rd56, %rd55, %rd153;
	mul.lo.s64 	%rd57, %rd54, %rd153;
	add.s64 	%rd58, %rd57, %rd56;
	setp.lt.u64 	%p3, %rd58, %rd56;
	setp.lt.u64 	%p4, %rd58, %rd57;
	selp.u64 	%rd59, 1, 0, %p4;
	selp.b64 	%rd60, 1, %rd59, %p3;
	mul.hi.u64 	%rd61, %rd54, %rd153;
	add.s64 	%rd62, %rd61, %rd60;
	mul.lo.s64 	%rd63, %rd55, %rd150;
	add.s64 	%rd154, %rd63, %rd58;
	setp.lt.u64 	%p5, %rd154, %rd58;
	setp.lt.u64 	%p6, %rd154, %rd63;
	selp.u64 	%rd64, 1, 0, %p6;
	selp.b64 	%rd65, 1, %rd64, %p5;
	mul.hi.u64 	%rd66, %rd55, %rd150;
	add.s64 	%rd67, %rd66, %rd65;
	add.s64 	%rd68, %rd62, %rd67;
	mul.lo.s64 	%rd69, %rd54, %rd150;
	add.s64 	%rd70, %rd69, %rd68;
	setp.lt.u64 	%p7, %rd70, %rd68;
	setp.lt.u64 	%p8, %rd70, %rd69;
	selp.u64 	%rd71, 1, 0, %p8;
	selp.b64 	%rd72, 1, %rd71, %p7;
	setp.lt.u64 	%p9, %rd68, %rd67;
	setp.lt.u64 	%p10, %rd68, %rd62;
	selp.u64 	%rd73, 1, 0, %p10;
	selp.b64 	%rd74, 1, %rd73, %p9;
	mul.hi.u64 	%rd75, %rd54, %rd150;
	add.s64 	%rd76, %rd75, %rd74;
	add.s64 	%rd77, %rd76, %rd72;
	mul.lo.s64 	%rd78, %rd153, %rd53;
	mul.lo.s64 	%rd79, %rd155, %rd55;
	add.s64 	%rd80, %rd79, %rd78;
	setp.lt.u64 	%p11, %rd80, %rd78;
	setp.lt.u64 	%p12, %rd80, %rd79;
	selp.u64 	%rd81, 1, 0, %p12;
	selp.b64 	%rd82, 1, %rd81, %p11;
	mul.lo.s64 	%rd83, %rd155, %rd54;
	mul.hi.u64 	%rd84, %rd155, %rd55;
	add.s64 	%rd85, %rd84, %rd83;
	mul.lo.s64 	%rd86, %rd156, %rd55;
	add.s64 	%rd87, %rd85, %rd86;
	mul.hi.u64 	%rd88, %rd153, %rd53;
	mul.lo.s64 	%rd89, %rd153, %rd52;
	add.s64 	%rd90, %rd88, %rd89;
	mul.lo.s64 	%rd91, %rd150, %rd53;
	add.s64 	%rd92, %rd90, %rd91;
	add.s64 	%rd93, %rd87, %rd92;
	add.s64 	%rd94, %rd93, %rd82;
	add.s64 	%rd95, %rd77, %rd94;
	add.s64 	%rd155, %rd70, %rd80;
	setp.lt.u64 	%p13, %rd155, %rd70;
	selp.u64 	%rd96, 1, 0, %p13;
	setp.lt.u64 	%p14, %rd155, %rd80;
	selp.b64 	%rd97, 1, %rd96, %p14;
	add.s64 	%rd156, %rd95, %rd97;
	mul.lo.s64 	%rd153, %rd55, %rd153;
	mul.lo.s64 	%rd98, %rd146, %rd145;
	mul.hi.u64 	%rd99, %rd145, %rd145;
	add.s64 	%rd100, %rd98, %rd99;
	add.s64 	%rd26, %rd98, %rd100;
	setp.lt.u64 	%p15, %rd26, %rd100;
	setp.lt.u64 	%p16, %rd26, %rd98;
	selp.u64 	%rd101, 1, 0, %p16;
	selp.b64 	%rd102, 1, %rd101, %p15;
	mul.hi.u64 	%rd103, %rd146, %rd145;
	add.s64 	%rd104, %rd103, %rd102;
	setp.lt.u64 	%p17, %rd100, %rd98;
	selp.u64 	%rd105, 1, 0, %p17;
	setp.lt.u64 	%p18, %rd100, %rd99;
	selp.b64 	%rd106, 1, %rd105, %p18;
	add.s64 	%rd107, %rd103, %rd106;
	add.s64 	%rd108, %rd107, %rd104;
	mul.lo.s64 	%rd109, %rd146, %rd146;
	add.s64 	%rd110, %rd109, %rd108;
	setp.lt.u64 	%p19, %rd110, %rd108;
	setp.lt.u64 	%p20, %rd110, %rd109;
	selp.u64 	%rd111, 1, 0, %p20;
	selp.b64 	%rd112, 1, %rd111, %p19;
	setp.lt.u64 	%p21, %rd108, %rd104;
	setp.lt.u64 	%p22, %rd108, %rd107;
	selp.u64 	%rd113, 1, 0, %p22;
	selp.b64 	%rd114, 1, %rd113, %p21;
	mul.hi.u64 	%rd115, %rd146, %rd146;
	add.s64 	%rd116, %rd115, %rd114;
	add.s64 	%rd117, %rd116, %rd112;
	mul.lo.s64 	%rd118, %rd145, %rd147;
	add.s64 	%rd119, %rd118, %rd118;
	setp.lt.u64 	%p23, %rd119, %rd118;
	selp.u64 	%rd120, 1, 0, %p23;
	selp.b64 	%rd121, 1, %rd120, %p23;
	mul.lo.s64 	%rd122, %rd146, %rd147;
	mul.hi.u64 	%rd123, %rd145, %rd147;
	add.s64 	%rd124, %rd123, %rd122;
	mul.lo.s64 	%rd125, %rd145, %rd148;
	add.s64 	%rd126, %rd124, %rd125;
	add.s64 	%rd127, %rd123, %rd125;
	add.s64 	%rd128, %rd127, %rd122;
	add.s64 	%rd129, %rd126, %rd128;
	add.s64 	%rd130, %rd129, %rd121;
	add.s64 	%rd131, %rd117, %rd130;
	add.s64 	%rd147, %rd110, %rd119;
	setp.lt.u64 	%p24, %rd147, %rd110;
	selp.u64 	%rd132, 1, 0, %p24;
	setp.lt.u64 	%p25, %rd147, %rd119;
	selp.b64 	%rd133, 1, %rd132, %p25;
	add.s64 	%rd148, %rd131, %rd133;
	mul.lo.s64 	%rd145, %rd145, %rd145;
	shr.u64 	%rd134, %rd141, 1;
	shl.b64 	%rd135, %rd142, 63;
	or.b64  	%rd29, %rd134, %rd135;
	shr.u64 	%rd136, %rd142, 1;
	shl.b64 	%rd137, %rd143, 63;
	or.b64  	%rd30, %rd136, %rd137;
	shr.u64 	%rd138, %rd143, 1;
	shl.b64 	%rd139, %rd144, 63;
	or.b64  	%rd31, %rd138, %rd139;
	shr.u64 	%rd32, %rd144, 1;
	setp.eq.s64 	%p26, %rd142, 0;
	setp.gt.u64 	%p27, %rd141, 1;
	selp.u32 	%r1, -1, 0, %p27;
	setp.ne.s64 	%p28, %rd142, 0;
	selp.u32 	%r2, -1, 0, %p28;
	selp.b32 	%r3, %r1, %r2, %p26;
	setp.eq.s64 	%p29, %rd144, 0;
	setp.ne.s64 	%p30, %rd143, 0;
	selp.u32 	%r4, -1, 0, %p30;
	setp.ne.s64 	%p31, %rd144, 0;
	selp.u32 	%r5, -1, 0, %p31;
	selp.b32 	%r6, %r4, %r5, %p29;
	or.b64  	%rd140, %rd143, %rd144;
	setp.eq.s64 	%p32, %rd140, 0;
	selp.b32 	%r7, %r3, %r6, %p32;
	and.b32  	%r8, %r7, 1;
	setp.eq.b32 	%p33, %r8, 1;
	mov.u64 	%rd141, %rd29;
	mov.u64 	%rd142, %rd30;
	mov.u64 	%rd143, %rd31;
	mov.u64 	%rd144, %rd32;
	mov.u64 	%rd146, %rd26;
	mov.u64 	%rd150, %rd154;
	@%p33 bra 	LBB10_2;
LBB10_3:
	st.u64 	[%rd38], %rd153;
	st.u64 	[%rd38+8], %rd154;
	st.u64 	[%rd38+16], %rd155;
	st.u64 	[%rd38+24], %rd156;
	ret;
                                        // -- End function
}
	// .globl	__device_calldatacpy    // -- Begin function __device_calldatacpy
.visible .func __device_calldatacpy(
	.param .b64 __device_calldatacpy_param_0,
	.param .b64 __device_calldatacpy_param_1,
	.param .b64 __device_calldatacpy_param_2,
	.param .b64 __device_calldatacpy_param_3,
	.param .b64 __device_calldatacpy_param_4
)                                       // @__device_calldatacpy
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<6>;
	.reg .b64 	%rd<41>;

// %bb.0:
	ld.param.u64 	%rd24, [__device_calldatacpy_param_4];
	setp.eq.s64 	%p1, %rd24, 0;
	@%p1 bra 	LBB11_10;
// %bb.1:
	ld.param.u64 	%rd21, [__device_calldatacpy_param_1];
	add.s64 	%rd25, %rd24, %rd21;
	setp.lt.u64 	%p2, %rd25, %rd24;
	setp.gt.u64 	%p3, %rd25, 727;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	LBB11_10;
// %bb.2:
	ld.param.u64 	%rd23, [__device_calldatacpy_param_3];
	add.s64 	%rd26, %rd24, %rd23;
	setp.lt.u64 	%p5, %rd26, %rd24;
	setp.gt.u64 	%p6, %rd26, 2035;
	or.pred  	%p7, %p5, %p6;
	@%p7 bra 	LBB11_10;
// %bb.3:
	min.u64 	%rd1, %rd23, 2036;
	add.s64 	%rd27, %rd1, %rd24;
	min.u64 	%rd2, %rd27, 2036;
	setp.eq.s64 	%p8, %rd2, %rd1;
	@%p8 bra 	LBB11_10;
// %bb.4:
	ld.param.u64 	%rd22, [__device_calldatacpy_param_2];
	ld.param.u64 	%rd20, [__device_calldatacpy_param_0];
	sub.s64 	%rd3, %rd2, %rd1;
	not.b64 	%rd29, %rd1;
	add.s64 	%rd30, %rd2, %rd29;
	and.b64  	%rd4, %rd3, 3;
	setp.lt.u64 	%p9, %rd30, 3;
	mov.u64 	%rd37, 0;
	@%p9 bra 	LBB11_7;
// %bb.5:
	and.b64  	%rd5, %rd3, -4;
	add.s64 	%rd6, %rd20, %rd21;
	add.s64 	%rd7, %rd22, %rd1;
	mov.u64 	%rd37, 0;
LBB11_6:                                // =>This Inner Loop Header: Depth=1
	add.s64 	%rd32, %rd7, %rd37;
	ld.u8 	%rs1, [%rd32];
	add.s64 	%rd33, %rd6, %rd37;
	st.u8 	[%rd33], %rs1;
	ld.u8 	%rs2, [%rd32+1];
	st.u8 	[%rd33+1], %rs2;
	ld.u8 	%rs3, [%rd32+2];
	st.u8 	[%rd33+2], %rs3;
	ld.u8 	%rs4, [%rd32+3];
	st.u8 	[%rd33+3], %rs4;
	add.s64 	%rd37, %rd37, 4;
	setp.ne.s64 	%p10, %rd5, %rd37;
	@%p10 bra 	LBB11_6;
LBB11_7:
	setp.eq.s64 	%p11, %rd4, 0;
	@%p11 bra 	LBB11_10;
// %bb.8:                               // %.preheader
	add.s64 	%rd34, %rd37, %rd21;
	add.s64 	%rd40, %rd20, %rd34;
	add.s64 	%rd35, %rd37, %rd1;
	add.s64 	%rd39, %rd22, %rd35;
	neg.s64 	%rd38, %rd4;
LBB11_9:                                // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	ld.u8 	%rs5, [%rd39];
	st.u8 	[%rd40], %rs5;
	add.s64 	%rd40, %rd40, 1;
	add.s64 	%rd39, %rd39, 1;
	add.s64 	%rd19, %rd38, 1;
	setp.ge.u64 	%p12, %rd19, %rd38;
	mov.u64 	%rd38, %rd19;
	@%p12 bra 	LBB11_9;
LBB11_10:
	ret;
                                        // -- End function
}
	// .globl	__device_calldataload   // -- Begin function __device_calldataload
.visible .func __device_calldataload(
	.param .b64 __device_calldataload_param_0,
	.param .b64 __device_calldataload_param_1,
	.param .b64 __device_calldataload_param_2
)                                       // @__device_calldataload
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<33>;
	.reg .b64 	%rd<7>;

// %bb.0:
	ld.param.u64 	%rd3, [__device_calldataload_param_2];
	ld.param.u64 	%rd1, [__device_calldataload_param_0];
	setp.gt.u64 	%p1, %rd3, -33;
	add.s64 	%rd4, %rd3, 32;
	setp.gt.u64 	%p2, %rd4, 2035;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	LBB12_2;
	bra.uni 	LBB12_1;
LBB12_2:
	mov.u64 	%rd6, 0;
	st.u64 	[%rd1+24], %rd6;
	st.u64 	[%rd1+16], %rd6;
	st.u64 	[%rd1+8], %rd6;
	st.u64 	[%rd1], %rd6;
	bra.uni 	LBB12_3;
LBB12_1:
	ld.param.u64 	%rd2, [__device_calldataload_param_1];
	add.s64 	%rd5, %rd2, %rd3;
	ld.u8 	%rs1, [%rd5+31];
	st.u8 	[%rd1], %rs1;
	ld.u8 	%rs2, [%rd5+30];
	st.u8 	[%rd1+1], %rs2;
	ld.u8 	%rs3, [%rd5+29];
	st.u8 	[%rd1+2], %rs3;
	ld.u8 	%rs4, [%rd5+28];
	st.u8 	[%rd1+3], %rs4;
	ld.u8 	%rs5, [%rd5+27];
	st.u8 	[%rd1+4], %rs5;
	ld.u8 	%rs6, [%rd5+26];
	st.u8 	[%rd1+5], %rs6;
	ld.u8 	%rs7, [%rd5+25];
	st.u8 	[%rd1+6], %rs7;
	ld.u8 	%rs8, [%rd5+24];
	st.u8 	[%rd1+7], %rs8;
	ld.u8 	%rs9, [%rd5+23];
	st.u8 	[%rd1+8], %rs9;
	ld.u8 	%rs10, [%rd5+22];
	st.u8 	[%rd1+9], %rs10;
	ld.u8 	%rs11, [%rd5+21];
	st.u8 	[%rd1+10], %rs11;
	ld.u8 	%rs12, [%rd5+20];
	st.u8 	[%rd1+11], %rs12;
	ld.u8 	%rs13, [%rd5+19];
	st.u8 	[%rd1+12], %rs13;
	ld.u8 	%rs14, [%rd5+18];
	st.u8 	[%rd1+13], %rs14;
	ld.u8 	%rs15, [%rd5+17];
	st.u8 	[%rd1+14], %rs15;
	ld.u8 	%rs16, [%rd5+16];
	st.u8 	[%rd1+15], %rs16;
	ld.u8 	%rs17, [%rd5+15];
	st.u8 	[%rd1+16], %rs17;
	ld.u8 	%rs18, [%rd5+14];
	st.u8 	[%rd1+17], %rs18;
	ld.u8 	%rs19, [%rd5+13];
	st.u8 	[%rd1+18], %rs19;
	ld.u8 	%rs20, [%rd5+12];
	st.u8 	[%rd1+19], %rs20;
	ld.u8 	%rs21, [%rd5+11];
	st.u8 	[%rd1+20], %rs21;
	ld.u8 	%rs22, [%rd5+10];
	st.u8 	[%rd1+21], %rs22;
	ld.u8 	%rs23, [%rd5+9];
	st.u8 	[%rd1+22], %rs23;
	ld.u8 	%rs24, [%rd5+8];
	st.u8 	[%rd1+23], %rs24;
	ld.u8 	%rs25, [%rd5+7];
	st.u8 	[%rd1+24], %rs25;
	ld.u8 	%rs26, [%rd5+6];
	st.u8 	[%rd1+25], %rs26;
	ld.u8 	%rs27, [%rd5+5];
	st.u8 	[%rd1+26], %rs27;
	ld.u8 	%rs28, [%rd5+4];
	st.u8 	[%rd1+27], %rs28;
	ld.u8 	%rs29, [%rd5+3];
	st.u8 	[%rd1+28], %rs29;
	ld.u8 	%rs30, [%rd5+2];
	st.u8 	[%rd1+29], %rs30;
	ld.u8 	%rs31, [%rd5+1];
	st.u8 	[%rd1+30], %rs31;
	ld.u8 	%rs32, [%rd5];
	st.u8 	[%rd1+31], %rs32;
LBB12_3:
	ret;
                                        // -- End function
}
	// .globl	__device_mstore         // -- Begin function __device_mstore
.visible .func __device_mstore(
	.param .b64 __device_mstore_param_0,
	.param .b64 __device_mstore_param_1,
	.param .b64 __device_mstore_param_2,
	.param .b64 __device_mstore_param_3
)                                       // @__device_mstore
{
	.reg .pred 	%p<11>;
	.reg .b16 	%rs<6>;
	.reg .b64 	%rd<40>;

// %bb.0:
	ld.param.u64 	%rd23, [__device_mstore_param_3];
	ld.param.u64 	%rd21, [__device_mstore_param_1];
	setp.ne.s64 	%p1, %rd23, 0;
	not.b64 	%rd24, %rd21;
	setp.ge.u64 	%p2, %rd24, %rd23;
	and.pred  	%p3, %p1, %p2;
	mov.u64 	%rd25, 728;
	sub.s64 	%rd26, %rd25, %rd23;
	setp.gt.u64 	%p4, %rd26, %rd21;
	and.pred  	%p5, %p3, %p4;
	and.pred  	%p6, %p5, %p1;
	@!%p6 bra 	LBB13_8;
	bra.uni 	LBB13_1;
LBB13_1:
	ld.param.u64 	%rd22, [__device_mstore_param_2];
	ld.param.u64 	%rd20, [__device_mstore_param_0];
	add.s64 	%rd1, %rd23, -1;
	and.b64  	%rd39, %rd23, 3;
	setp.lt.u64 	%p7, %rd1, 3;
	mov.u64 	%rd36, 0;
	@%p7 bra 	LBB13_5;
// %bb.2:
	and.b64  	%rd29, %rd23, -4;
	neg.s64 	%rd3, %rd29;
	add.s64 	%rd34, %rd20, %rd21;
	add.s64 	%rd30, %rd23, %rd22;
	add.s64 	%rd5, %rd30, -2;
	mov.u64 	%rd35, 0;
LBB13_3:                                // =>This Inner Loop Header: Depth=1
	add.s64 	%rd31, %rd5, %rd35;
	ld.u8 	%rs1, [%rd31+1];
	st.u8 	[%rd34], %rs1;
	ld.u8 	%rs2, [%rd31];
	st.u8 	[%rd34+1], %rs2;
	ld.u8 	%rs3, [%rd31+-1];
	st.u8 	[%rd34+2], %rs3;
	ld.u8 	%rs4, [%rd31+-2];
	st.u8 	[%rd34+3], %rs4;
	add.s64 	%rd35, %rd35, -4;
	add.s64 	%rd34, %rd34, 4;
	setp.ne.s64 	%p8, %rd3, %rd35;
	@%p8 bra 	LBB13_3;
// %bb.4:                               // %.loopexit1
	neg.s64 	%rd36, %rd35;
LBB13_5:
	setp.eq.s64 	%p9, %rd39, 0;
	@%p9 bra 	LBB13_8;
// %bb.6:                               // %.preheader
	add.s64 	%rd32, %rd36, %rd21;
	add.s64 	%rd38, %rd20, %rd32;
	sub.s64 	%rd33, %rd1, %rd36;
	add.s64 	%rd37, %rd22, %rd33;
LBB13_7:                                // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	ld.u8 	%rs5, [%rd37];
	st.u8 	[%rd38], %rs5;
	add.s64 	%rd39, %rd39, -1;
	add.s64 	%rd38, %rd38, 1;
	add.s64 	%rd37, %rd37, -1;
	setp.ne.s64 	%p10, %rd39, 0;
	@%p10 bra 	LBB13_7;
LBB13_8:
	ret;
                                        // -- End function
}
	// .globl	__device_mload          // -- Begin function __device_mload
.visible .func __device_mload(
	.param .b64 __device_mload_param_0,
	.param .b64 __device_mload_param_1,
	.param .b64 __device_mload_param_2
)                                       // @__device_mload
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<33>;
	.reg .b64 	%rd<6>;

// %bb.0:
	ld.param.u64 	%rd3, [__device_mload_param_2];
	ld.param.u64 	%rd2, [__device_mload_param_1];
	setp.lt.u64 	%p1, %rd2, 696;
	@%p1 bra 	LBB14_2;
// %bb.1:
	mov.u64 	%rd5, 0;
	st.u64 	[%rd3+24], %rd5;
	st.u64 	[%rd3+16], %rd5;
	st.u64 	[%rd3+8], %rd5;
	st.u64 	[%rd3], %rd5;
	bra.uni 	LBB14_3;
LBB14_2:
	ld.param.u64 	%rd1, [__device_mload_param_0];
	add.s64 	%rd4, %rd1, %rd2;
	ld.u8 	%rs1, [%rd4+31];
	st.u8 	[%rd3], %rs1;
	ld.u8 	%rs2, [%rd4+30];
	st.u8 	[%rd3+1], %rs2;
	ld.u8 	%rs3, [%rd4+29];
	st.u8 	[%rd3+2], %rs3;
	ld.u8 	%rs4, [%rd4+28];
	st.u8 	[%rd3+3], %rs4;
	ld.u8 	%rs5, [%rd4+27];
	st.u8 	[%rd3+4], %rs5;
	ld.u8 	%rs6, [%rd4+26];
	st.u8 	[%rd3+5], %rs6;
	ld.u8 	%rs7, [%rd4+25];
	st.u8 	[%rd3+6], %rs7;
	ld.u8 	%rs8, [%rd4+24];
	st.u8 	[%rd3+7], %rs8;
	ld.u8 	%rs9, [%rd4+23];
	st.u8 	[%rd3+8], %rs9;
	ld.u8 	%rs10, [%rd4+22];
	st.u8 	[%rd3+9], %rs10;
	ld.u8 	%rs11, [%rd4+21];
	st.u8 	[%rd3+10], %rs11;
	ld.u8 	%rs12, [%rd4+20];
	st.u8 	[%rd3+11], %rs12;
	ld.u8 	%rs13, [%rd4+19];
	st.u8 	[%rd3+12], %rs13;
	ld.u8 	%rs14, [%rd4+18];
	st.u8 	[%rd3+13], %rs14;
	ld.u8 	%rs15, [%rd4+17];
	st.u8 	[%rd3+14], %rs15;
	ld.u8 	%rs16, [%rd4+16];
	st.u8 	[%rd3+15], %rs16;
	ld.u8 	%rs17, [%rd4+15];
	st.u8 	[%rd3+16], %rs17;
	ld.u8 	%rs18, [%rd4+14];
	st.u8 	[%rd3+17], %rs18;
	ld.u8 	%rs19, [%rd4+13];
	st.u8 	[%rd3+18], %rs19;
	ld.u8 	%rs20, [%rd4+12];
	st.u8 	[%rd3+19], %rs20;
	ld.u8 	%rs21, [%rd4+11];
	st.u8 	[%rd3+20], %rs21;
	ld.u8 	%rs22, [%rd4+10];
	st.u8 	[%rd3+21], %rs22;
	ld.u8 	%rs23, [%rd4+9];
	st.u8 	[%rd3+22], %rs23;
	ld.u8 	%rs24, [%rd4+8];
	st.u8 	[%rd3+23], %rs24;
	ld.u8 	%rs25, [%rd4+7];
	st.u8 	[%rd3+24], %rs25;
	ld.u8 	%rs26, [%rd4+6];
	st.u8 	[%rd3+25], %rs26;
	ld.u8 	%rs27, [%rd4+5];
	st.u8 	[%rd3+26], %rs27;
	ld.u8 	%rs28, [%rd4+4];
	st.u8 	[%rd3+27], %rs28;
	ld.u8 	%rs29, [%rd4+3];
	st.u8 	[%rd3+28], %rs29;
	ld.u8 	%rs30, [%rd4+2];
	st.u8 	[%rd3+29], %rs30;
	ld.u8 	%rs31, [%rd4+1];
	st.u8 	[%rd3+30], %rs31;
	ld.u8 	%rs32, [%rd4];
	st.u8 	[%rd3+31], %rs32;
LBB14_3:
	ret;
                                        // -- End function
}
	// .globl	__device_sstore         // -- Begin function __device_sstore
.visible .func __device_sstore(
	.param .b64 __device_sstore_param_0,
	.param .b64 __device_sstore_param_1
)                                       // @__device_sstore
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<52>;

// %bb.0:
	ld.param.u64 	%rd10, [__device_sstore_param_1];
	ld.param.u64 	%rd12, [__device_sstore_param_0];
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	cvt.u64.u32 	%rd1, %r4;
	mov.u64 	%rd13, l1snap_lens;
	add.s64 	%rd2, %rd13, %rd1;
	ld.global.u8 	%rs1, [%rd2];
	setp.eq.s16 	%p1, %rs1, 0;
	ld.u64 	%rd7, [%rd12+24];
	ld.u64 	%rd6, [%rd12+16];
	ld.u64 	%rd5, [%rd12+8];
	ld.u64 	%rd4, [%rd12];
	mov.u64 	%rd51, 0;
	shl.b64 	%rd49, %rd1, 13;
	mov.u64 	%rd50, l1snaps;
	@%p1 bra 	LBB15_5;
// %bb.1:                               // %.preheader
	cvt.u64.u16 	%rd51, %rs1;
	mov.u16 	%rs7, 0;
LBB15_2:                                // =>This Inner Loop Header: Depth=1
	add.s64 	%rd17, %rd50, %rd49;
	cvt.u32.u16 	%r5, %rs7;
	and.b32  	%r6, %r5, 255;
	mul.wide.u32 	%rd18, %r6, 64;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.u64 	%rd20, [%rd19];
	ld.global.u64 	%rd21, [%rd19+16];
	ld.global.u64 	%rd22, [%rd19+8];
	ld.global.u64 	%rd23, [%rd19+24];
	xor.b64  	%rd24, %rd23, %rd7;
	xor.b64  	%rd25, %rd22, %rd5;
	or.b64  	%rd26, %rd25, %rd24;
	xor.b64  	%rd27, %rd21, %rd6;
	xor.b64  	%rd28, %rd20, %rd4;
	or.b64  	%rd29, %rd28, %rd27;
	or.b64  	%rd30, %rd29, %rd26;
	setp.ne.s64 	%p2, %rd30, 0;
	@%p2 bra 	LBB15_4;
	bra.uni 	LBB15_3;
LBB15_4:                                //   in Loop: Header=BB15_2 Depth=1
	add.s16 	%rs7, %rs7, 1;
	and.b16  	%rs5, %rs7, 255;
	setp.lt.u16 	%p3, %rs5, %rs1;
	@%p3 bra 	LBB15_2;
LBB15_5:
	add.s64 	%rd42, %rd50, %rd49;
	shl.b64 	%rd43, %rd51, 6;
	add.s64 	%rd44, %rd42, %rd43;
	st.global.u64 	[%rd44+24], %rd7;
	st.global.u64 	[%rd44+16], %rd6;
	st.global.u64 	[%rd44+8], %rd5;
	st.global.u64 	[%rd44], %rd4;
	ld.u64 	%rd45, [%rd10+16];
	ld.u64 	%rd46, [%rd10+8];
	ld.u64 	%rd47, [%rd10];
	ld.u64 	%rd48, [%rd10+24];
	st.global.u64 	[%rd44+56], %rd48;
	st.global.u64 	[%rd44+32], %rd47;
	st.global.u64 	[%rd44+40], %rd46;
	st.global.u64 	[%rd44+48], %rd45;
	add.s16 	%rs6, %rs1, 1;
	st.global.u8 	[%rd2], %rs6;
	bra.uni 	LBB15_6;
LBB15_3:
	cvt.u64.u16 	%rd14, %rs7;
	and.b64  	%rd8, %rd14, 255;
	ld.u64 	%rd31, [%rd10+8];
	ld.u64 	%rd32, [%rd10];
	ld.u64 	%rd33, [%rd10+24];
	ld.u64 	%rd34, [%rd10+16];
	shl.b64 	%rd38, %rd8, 6;
	add.s64 	%rd39, %rd17, %rd38;
	st.global.u64 	[%rd39+48], %rd34;
	st.global.u64 	[%rd39+56], %rd33;
	st.global.u64 	[%rd39+32], %rd32;
	st.global.u64 	[%rd39+40], %rd31;
LBB15_6:
	ret;
                                        // -- End function
}
	// .globl	__device_sload          // -- Begin function __device_sload
.visible .func __device_sload(
	.param .b64 __device_sload_param_0,
	.param .b64 __device_sload_param_1
)                                       // @__device_sload
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<76>;

// %bb.0:
	ld.param.u64 	%rd24, [__device_sload_param_1];
	ld.param.u64 	%rd25, [__device_sload_param_0];
	mov.u32 	%r7, %tid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %ntid.x;
	mad.lo.s32 	%r10, %r9, %r8, %r7;
	cvt.u64.u32 	%rd1, %r10;
	ld.u64 	%rd5, [%rd25+24];
	ld.u64 	%rd4, [%rd25+16];
	ld.u64 	%rd3, [%rd25+8];
	ld.u64 	%rd2, [%rd25];
	mov.u64 	%rd26, l1snap_lens;
	add.s64 	%rd27, %rd26, %rd1;
	ld.global.u8 	%r11, [%rd27];
	setp.eq.s32 	%p1, %r11, 0;
	@%p1 bra 	LBB16_4;
// %bb.1:                               // %.preheader1
	shl.b64 	%rd28, %rd1, 13;
	mov.u64 	%rd29, l1snaps;
	add.s64 	%rd30, %rd29, %rd28;
	add.s64 	%rd69, %rd30, 32;
LBB16_3:                                // =>This Inner Loop Header: Depth=1
	ld.global.u64 	%rd31, [%rd69+-8];
	ld.global.u64 	%rd32, [%rd69+-24];
	ld.global.u64 	%rd33, [%rd69+-16];
	ld.global.u64 	%rd34, [%rd69+-32];
	xor.b64  	%rd35, %rd34, %rd2;
	xor.b64  	%rd36, %rd33, %rd4;
	or.b64  	%rd37, %rd35, %rd36;
	xor.b64  	%rd38, %rd32, %rd3;
	xor.b64  	%rd39, %rd31, %rd5;
	or.b64  	%rd40, %rd38, %rd39;
	or.b64  	%rd41, %rd37, %rd40;
	setp.eq.s64 	%p2, %rd41, 0;
	@%p2 bra 	LBB16_8;
// %bb.2:                               //   in Loop: Header=BB16_3 Depth=1
	add.s32 	%r11, %r11, -1;
	add.s64 	%rd69, %rd69, 64;
	setp.eq.s32 	%p3, %r11, 0;
	@%p3 bra 	LBB16_4;
	bra.uni 	LBB16_3;
LBB16_4:
	shl.b64 	%rd46, %rd1, 2;
	mov.u64 	%rd47, __snap_map;
	add.s64 	%rd48, %rd47, %rd46;
	ld.global.u32 	%rd10, [%rd48];
	mov.u64 	%rd49, l2snap_lens;
	add.s64 	%rd50, %rd49, %rd10;
	ld.global.u8 	%r12, [%rd50];
	setp.eq.s32 	%p4, %r12, 0;
	mov.u64 	%rd72, 0;
	mov.u64 	%rd73, %rd72;
	mov.u64 	%rd74, %rd72;
	mov.u64 	%rd75, %rd72;
	@%p4 bra 	LBB16_9;
// %bb.5:                               // %.preheader
	shl.b64 	%rd51, %rd10, 13;
	mov.u64 	%rd52, l2snaps;
	add.s64 	%rd53, %rd52, %rd51;
	add.s64 	%rd69, %rd53, 32;
LBB16_7:                                // =>This Inner Loop Header: Depth=1
	ld.global.u64 	%rd54, [%rd69+-8];
	ld.global.u64 	%rd55, [%rd69+-24];
	ld.global.u64 	%rd56, [%rd69+-16];
	ld.global.u64 	%rd57, [%rd69+-32];
	xor.b64  	%rd58, %rd57, %rd2;
	xor.b64  	%rd59, %rd56, %rd4;
	or.b64  	%rd60, %rd58, %rd59;
	xor.b64  	%rd61, %rd55, %rd3;
	xor.b64  	%rd62, %rd54, %rd5;
	or.b64  	%rd63, %rd61, %rd62;
	or.b64  	%rd64, %rd60, %rd63;
	setp.ne.s64 	%p5, %rd64, 0;
	@%p5 bra 	LBB16_6;
	bra.uni 	LBB16_8;
LBB16_6:                                //   in Loop: Header=BB16_7 Depth=1
	add.s32 	%r12, %r12, -1;
	add.s64 	%rd69, %rd69, 64;
	setp.eq.s32 	%p6, %r12, 0;
	mov.u64 	%rd72, 0;
	mov.u64 	%rd73, %rd72;
	mov.u64 	%rd74, %rd72;
	mov.u64 	%rd75, %rd72;
	@%p6 bra 	LBB16_9;
	bra.uni 	LBB16_7;
LBB16_8:
	ld.global.u64 	%rd75, [%rd69+24];
	ld.global.u64 	%rd74, [%rd69+16];
	ld.global.u64 	%rd73, [%rd69+8];
	ld.global.u64 	%rd72, [%rd69];
LBB16_9:
	st.u64 	[%rd24], %rd72;
	st.u64 	[%rd24+8], %rd73;
	st.u64 	[%rd24+16], %rd74;
	st.u64 	[%rd24+24], %rd75;
	ret;
                                        // -- End function
}
	// .globl	__simple_hash           // -- Begin function __simple_hash
.visible .func  (.param .b64 func_retval0) __simple_hash(
	.param .b64 __simple_hash_param_0
)                                       // @__simple_hash
{
	.reg .b64 	%rd<10>;

// %bb.0:
	ld.param.u64 	%rd1, [__simple_hash_param_0];
	shr.u64 	%rd2, %rd1, 30;
	xor.b64  	%rd3, %rd2, %rd1;
	mul.lo.s64 	%rd4, %rd3, -4658895280553007687;
	shr.u64 	%rd5, %rd4, 27;
	xor.b64  	%rd6, %rd5, %rd4;
	mul.lo.s64 	%rd7, %rd6, -7723592293110705685;
	shr.u64 	%rd8, %rd7, 31;
	xor.b64  	%rd9, %rd8, %rd7;
	st.param.b64 	[func_retval0+0], %rd9;
	ret;
                                        // -- End function
}
	// .globl	__hashint               // -- Begin function __hashint
.visible .func  (.param .b32 func_retval0) __hashint(
	.param .b32 __hashint_param_0,
	.param .b32 __hashint_param_1
)                                       // @__hashint
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<13>;

// %bb.0:
	ld.param.u32 	%rd1, [__hashint_param_1];
	ld.param.u32 	%rd2, [__hashint_param_0];
	shl.b64 	%rd3, %rd2, 32;
	or.b64  	%rd4, %rd3, %rd1;
	shr.u64 	%rd5, %rd4, 30;
	xor.b64  	%rd6, %rd5, %rd4;
	mul.lo.s64 	%rd7, %rd6, -4658895280553007687;
	shr.u64 	%rd8, %rd7, 27;
	xor.b64  	%rd9, %rd8, %rd7;
	mul.lo.s64 	%rd10, %rd9, -7723592293110705685;
	shr.u64 	%rd11, %rd10, 31;
	xor.b64  	%rd12, %rd11, %rd10;
	cvt.u32.u64 	%r1, %rd12;
	st.param.b32 	[func_retval0+0], %r1;
	ret;
                                        // -- End function
}
	// .globl	__hashword              // -- Begin function __hashword
.visible .func  (.param .b32 func_retval0) __hashword(
	.param .b64 __hashword_param_0
)                                       // @__hashword
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<43>;

// %bb.0:
	ld.param.u64 	%rd1, [__hashword_param_0];
	ld.u64 	%rd2, [%rd1];
	ld.u64 	%rd3, [%rd1+8];
	ld.u64 	%rd4, [%rd1+16];
	ld.u64 	%rd5, [%rd1+24];
	shr.u64 	%rd6, %rd2, 30;
	xor.b64  	%rd7, %rd6, %rd2;
	mul.lo.s64 	%rd8, %rd7, -4658895280553007687;
	shr.u64 	%rd9, %rd8, 27;
	xor.b64  	%rd10, %rd9, %rd8;
	mul.lo.s64 	%rd11, %rd10, -7723592293110705685;
	shr.u64 	%rd12, %rd11, 31;
	shr.u64 	%rd13, %rd3, 30;
	xor.b64  	%rd14, %rd13, %rd3;
	mul.lo.s64 	%rd15, %rd14, -4658895280553007687;
	shr.u64 	%rd16, %rd15, 27;
	xor.b64  	%rd17, %rd16, %rd15;
	mul.lo.s64 	%rd18, %rd17, -7723592293110705685;
	shr.u64 	%rd19, %rd18, 31;
	shr.u64 	%rd20, %rd4, 30;
	xor.b64  	%rd21, %rd20, %rd4;
	mul.lo.s64 	%rd22, %rd21, -4658895280553007687;
	shr.u64 	%rd23, %rd22, 27;
	xor.b64  	%rd24, %rd23, %rd22;
	mul.lo.s64 	%rd25, %rd24, -7723592293110705685;
	shr.u64 	%rd26, %rd25, 31;
	shr.u64 	%rd27, %rd5, 30;
	xor.b64  	%rd28, %rd27, %rd5;
	mul.lo.s64 	%rd29, %rd28, -4658895280553007687;
	shr.u64 	%rd30, %rd29, 27;
	xor.b64  	%rd31, %rd30, %rd29;
	mul.lo.s64 	%rd32, %rd31, -7723592293110705685;
	shr.u64 	%rd33, %rd32, 31;
	xor.b64  	%rd34, %rd12, %rd11;
	xor.b64  	%rd35, %rd34, %rd18;
	xor.b64  	%rd36, %rd35, %rd19;
	xor.b64  	%rd37, %rd36, %rd25;
	xor.b64  	%rd38, %rd37, %rd26;
	xor.b64  	%rd39, %rd38, %rd32;
	xor.b64  	%rd40, %rd39, %rd33;
	shr.u64 	%rd41, %rd40, 32;
	xor.b64  	%rd42, %rd41, %rd40;
	cvt.u32.u64 	%r1, %rd42;
	st.param.b32 	[func_retval0+0], %r1;
	ret;
                                        // -- End function
}
	// .globl	__classify_counts       // -- Begin function __classify_counts
.visible .func __classify_counts(
	.param .b64 __classify_counts_param_0
)                                       // @__classify_counts
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<26>;
	// demoted variable
	.shared .align 1 .b8 count_class_lookup8[256];
// %bb.0:
	mov.u64 	%rd25, 0;
	ld.param.u64 	%rd5, [__classify_counts_param_0];
LBB20_1:                                // =>This Inner Loop Header: Depth=1
	add.s64 	%rd2, %rd5, %rd25;
	ld.global.u64 	%rd3, [%rd2];
	setp.eq.s64 	%p1, %rd3, 0;
	@%p1 bra 	LBB20_3;
	bra.uni 	LBB20_2;
LBB20_3:                                //   in Loop: Header=BB20_1 Depth=1
	add.s64 	%rd25, %rd25, 8;
	cvt.u32.u64 	%r1, %rd25;
	setp.ne.s32 	%p2, %r1, 4096;
	@%p2 bra 	LBB20_1;
	bra.uni 	LBB20_4;
LBB20_2:                                //   in Loop: Header=BB20_1 Depth=1
	shr.u64 	%rd7, %rd3, 56;
	shr.u64 	%rd8, %rd3, 32;
	and.b64  	%rd9, %rd3, 255;
	mov.u64 	%rd10, count_class_lookup8;
	add.s64 	%rd11, %rd10, %rd9;
	ld.shared.u8 	%rs1, [%rd11];
	st.global.u8 	[%rd2], %rs1;
	bfe.u64 	%rd12, %rd3, 8, 8;
	add.s64 	%rd13, %rd10, %rd12;
	ld.shared.u8 	%rs2, [%rd13];
	st.global.u8 	[%rd2+1], %rs2;
	bfe.u64 	%rd14, %rd3, 16, 8;
	add.s64 	%rd15, %rd10, %rd14;
	ld.shared.u8 	%rs3, [%rd15];
	st.global.u8 	[%rd2+2], %rs3;
	bfe.u64 	%rd16, %rd3, 24, 8;
	add.s64 	%rd17, %rd10, %rd16;
	ld.shared.u8 	%rs4, [%rd17];
	st.global.u8 	[%rd2+3], %rs4;
	and.b64  	%rd18, %rd8, 255;
	add.s64 	%rd19, %rd10, %rd18;
	ld.shared.u8 	%rs5, [%rd19];
	st.global.u8 	[%rd2+4], %rs5;
	bfe.u64 	%rd20, %rd3, 40, 8;
	add.s64 	%rd21, %rd10, %rd20;
	ld.shared.u8 	%rs6, [%rd21];
	st.global.u8 	[%rd2+5], %rs6;
	bfe.u64 	%rd22, %rd3, 48, 8;
	add.s64 	%rd23, %rd10, %rd22;
	ld.shared.u8 	%rs7, [%rd23];
	st.global.u8 	[%rd2+6], %rs7;
	add.s64 	%rd24, %rd10, %rd7;
	ld.shared.u8 	%rs8, [%rd24];
	st.global.u8 	[%rd2+7], %rs8;
	bra.uni 	LBB20_3;
LBB20_4:
	ret;
                                        // -- End function
}
	// .globl	updateBits              // -- Begin function updateBits
.visible .func updateBits(
	.param .b64 updateBits_param_0
)                                       // @updateBits
{
	.reg .pred 	%p<8>;
	.reg .b16 	%rs<5>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<44>;

// %bb.0:
	ld.param.u64 	%rd19, [updateBits_param_0];
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	cvt.u64.u32 	%rd1, %r4;
	mul.wide.u32 	%rd22, %r4, 8;
	mov.u64 	%rd23, __virgin_bits;
	add.s64 	%rd2, %rd23, %rd22;
	mov.u64 	%rd24, __bitmaps;
	add.s64 	%rd40, %rd24, 8;
	mov.u64 	%rd41, 0;
	mov.u16 	%rs4, 2;
LBB21_1:                                // =>This Inner Loop Header: Depth=1
	ld.global.u64 	%rd25, [%rd40+-8];
	shl.b64 	%rd26, %rd1, 3;
	add.s64 	%rd5, %rd25, %rd26;
	ld.global.u64 	%rd42, [%rd5];
	setp.eq.s64 	%p1, %rd42, 0;
	@%p1 bra 	LBB21_6;
	bra.uni 	LBB21_2;
LBB21_6:                                //   in Loop: Header=BB21_1 Depth=1
	mov.u64 	%rd31, 0;
	st.global.u64 	[%rd5], %rd31;
	bar.sync 	0;
	ld.global.u64 	%rd32, [%rd40];
	add.s64 	%rd11, %rd32, %rd26;
	ld.global.u64 	%rd43, [%rd11];
	setp.eq.s64 	%p4, %rd43, 0;
	@%p4 bra 	LBB21_11;
	bra.uni 	LBB21_7;
LBB21_11:                               //   in Loop: Header=BB21_1 Depth=1
	st.global.u64 	[%rd11], %rd31;
	bar.sync 	0;
	add.s64 	%rd41, %rd41, 2;
	cvt.u32.u64 	%r5, %rd41;
	add.s64 	%rd40, %rd40, 16;
	setp.eq.s32 	%p7, %r5, 1024;
	@%p7 bra 	LBB21_12;
	bra.uni 	LBB21_1;
LBB21_2:                                //   in Loop: Header=BB21_1 Depth=1
	ld.global.u64 	%rd7, [%rd2];
	and.b64  	%rd27, %rd7, %rd42;
	setp.eq.s64 	%p2, %rd27, 0;
	@%p2 bra 	LBB21_6;
// %bb.3:                               //   in Loop: Header=BB21_1 Depth=1
	mov.u64 	%rd28, __hnbs;
	add.s64 	%rd8, %rd28, %rd41;
	ld.global.u8 	%rs1, [%rd8];
	setp.eq.s16 	%p3, %rs1, 3;
	@%p3 bra 	LBB21_5;
// %bb.4:                               //   in Loop: Header=BB21_1 Depth=1
	st.global.u8 	[%rd8], %rs4;
	ld.global.u64 	%rd42, [%rd5];
LBB21_5:                                //   in Loop: Header=BB21_1 Depth=1
	not.b64 	%rd29, %rd42;
	and.b64  	%rd30, %rd7, %rd29;
	st.global.u64 	[%rd2], %rd30;
	bra.uni 	LBB21_6;
LBB21_7:                                //   in Loop: Header=BB21_1 Depth=1
	ld.global.u64 	%rd13, [%rd2];
	and.b64  	%rd34, %rd13, %rd43;
	setp.eq.s64 	%p5, %rd34, 0;
	@%p5 bra 	LBB21_11;
// %bb.8:                               //   in Loop: Header=BB21_1 Depth=1
	mov.u64 	%rd35, __hnbs;
	add.s64 	%rd14, %rd35, %rd41;
	ld.global.u8 	%rs3, [%rd14+1];
	setp.eq.s16 	%p6, %rs3, 3;
	@%p6 bra 	LBB21_10;
// %bb.9:                               //   in Loop: Header=BB21_1 Depth=1
	st.global.u8 	[%rd14+1], %rs4;
	ld.global.u64 	%rd43, [%rd11];
LBB21_10:                               //   in Loop: Header=BB21_1 Depth=1
	not.b64 	%rd36, %rd43;
	and.b64  	%rd37, %rd13, %rd36;
	st.global.u64 	[%rd2], %rd37;
	bra.uni 	LBB21_11;
LBB21_12:
	bar.sync 	0;
	ld.global.u64 	%rd39, [__signals];
	st.global.u64 	[%rd19], %rd39;
	ret;
                                        // -- End function
}
	// .globl	addBugSet               // -- Begin function addBugSet
.visible .func addBugSet(
	.param .b64 addBugSet_param_0
)                                       // @addBugSet
{
	.local .align 8 .b8 	__local_depot22[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<11>;

// %bb.0:
	mov.u64 	%SPL, __local_depot22;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd2, [addBugSet_param_0];
	setp.ne.s64 	%p1, %rd2, 1258295;
	@%p1 bra 	LBB22_2;
// %bb.1:
	add.u64 	%rd3, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r2, %tid.x;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r2;
	cvt.u64.u32 	%rd4, %r1;
	mov.u64 	%rd5, __hnbs;
	add.s64 	%rd6, %rd5, %rd4;
	mov.u16 	%rs1, 3;
	st.global.u8 	[%rd6], %rs1;
	or.b64  	%rd7, %rd4, -2401018191707897856;
	st.global.u64 	[__signals], %rd7;
	mov.u32 	%r5, 3;
	st.local.v2.u32 	[%rd1], {%r1, %r5};
	mov.u64 	%rd8, _$_str1;
	cvta.global.u64 	%rd9, %rd8;
	{ // callseq 79, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r6, [retval0+0];
	} // callseq 79
LBB22_2:
	ret;
                                        // -- End function
}
	// .globl	parallel_mutate         // -- Begin function parallel_mutate
.visible .func parallel_mutate(
	.param .b64 parallel_mutate_param_0,
	.param .b32 parallel_mutate_param_1
)                                       // @parallel_mutate
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<28>;
	.reg .b64 	%rd<12>;

// %bb.0:
	ld.param.u64 	%rd5, [parallel_mutate_param_0];
	mov.u32 	%r5, %tid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %ntid.x;
	mad.lo.s32 	%r8, %r7, %r6, %r5;
	shl.b32 	%r9, %r8, 11;
	cvt.u64.u32 	%rd6, %r9;
	add.s64 	%rd1, %rd5, %rd6;
	ld.global.u32 	%r1, [%rd1+64];
	setp.lt.u32 	%p1, %r1, 5;
	mul.wide.u32 	%rd8, %r8, 4;
	mov.u64 	%rd9, cuda_states;
	add.s64 	%rd4, %rd9, %rd8;
	ld.global.u32 	%r27, [%rd4];
	@%p1 bra 	LBB23_2;
// %bb.1:
	mad.lo.s32 	%r10, %r27, 1103515245, 12345;
	mad.lo.s32 	%r11, %r10, 1103515245, 12345;
	shr.u32 	%r12, %r10, 6;
	and.b32  	%r13, %r12, 2096128;
	bfe.u32 	%r14, %r11, 16, 10;
	or.b32  	%r15, %r14, %r13;
	mad.lo.s32 	%r27, %r11, 1103515245, 12345;
	shl.b32 	%r16, %r15, 10;
	bfe.u32 	%r17, %r27, 16, 10;
	or.b32  	%r18, %r16, %r17;
	st.global.u32 	[%rd4], %r27;
	mul.hi.u32 	%r19, %r18, 1374389535;
	shr.u32 	%r20, %r19, 5;
	mul.lo.s32 	%r21, %r20, 100;
	sub.s32 	%r22, %r18, %r21;
	setp.lt.u32 	%p2, %r22, 91;
	@%p2 bra 	LBB23_5;
LBB23_2:
	mad.lo.s32 	%r25, %r27, -2139243339, -1492899873;
	st.global.u32 	[%rd4], %r25;
	and.b32  	%r26, %r25, 65536;
	setp.ne.s32 	%p3, %r26, 0;
	@%p3 bra 	LBB23_4;
// %bb.3:
	cvta.global.u64 	%rd2, %rd1;
	{ // callseq 82, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd2;
	call.uni 
	mutateCaller, 
	(
	param0
	);
	} // callseq 82
	bra.uni 	LBB23_6;
LBB23_4:
	add.s64 	%rd7, %rd1, 32;
	cvta.global.u64 	%rd3, %rd7;
	{ // callseq 81, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd3;
	call.uni 
	mutateCallvalue, 
	(
	param0
	);
	} // callseq 81
	bra.uni 	LBB23_6;
LBB23_5:
	add.s64 	%rd10, %rd1, 72;
	cvta.global.u64 	%rd11, %rd10;
	add.s32 	%r23, %r1, -4;
	shr.u32 	%r24, %r23, 5;
	{ // callseq 80, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd11;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r24;
	call.uni 
	mutateCalldata, 
	(
	param0, 
	param1
	);
	} // callseq 80
LBB23_6:
	bar.sync 	0;
	ret;
                                        // -- End function
}
	// .globl	mutateCaller            // -- Begin function mutateCaller
.visible .func mutateCaller(
	.param .b64 mutateCaller_param_0
)                                       // @mutateCaller
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<33>;
	.reg .b32 	%r<32>;
	.reg .b64 	%rd<12>;

// %bb.0:
	ld.param.u64 	%rd4, [mutateCaller_param_0];
	mov.u32 	%r2, %tid.x;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mad.lo.s32 	%r5, %r4, %r3, %r2;
	mul.wide.u32 	%rd6, %r5, 4;
	mov.u64 	%rd7, cuda_states;
	add.s64 	%rd1, %rd7, %rd6;
	ld.global.u32 	%r6, [%rd1];
	mad.lo.s32 	%r7, %r6, 1103515245, 12345;
	mad.lo.s32 	%r8, %r7, 1103515245, 12345;
	shr.u32 	%r9, %r7, 6;
	and.b32  	%r10, %r9, 2096128;
	bfe.u32 	%r11, %r8, 16, 10;
	or.b32  	%r12, %r11, %r10;
	mad.lo.s32 	%r1, %r8, 1103515245, 12345;
	shl.b32 	%r13, %r12, 10;
	bfe.u32 	%r14, %r1, 16, 10;
	or.b32  	%r15, %r13, %r14;
	st.global.u32 	[%rd1], %r1;
	mul.hi.u32 	%r16, %r15, 1374389535;
	shr.u32 	%r17, %r16, 5;
	mul.lo.s32 	%r18, %r17, 100;
	sub.s32 	%r19, %r15, %r18;
	setp.lt.u32 	%p1, %r19, 80;
	mov.u64 	%rd11, 0;
	@%p1 bra 	LBB24_2;
// %bb.1:
	ld.volatile.global.u32 	%r20, [callers_pool_len];
	mad.lo.s32 	%r21, %r1, 1103515245, 12345;
	mad.lo.s32 	%r22, %r21, 1103515245, 12345;
	shr.u32 	%r23, %r21, 6;
	and.b32  	%r24, %r23, 2096128;
	bfe.u32 	%r25, %r22, 16, 10;
	or.b32  	%r26, %r25, %r24;
	mad.lo.s32 	%r27, %r22, 1103515245, 12345;
	shl.b32 	%r28, %r26, 10;
	bfe.u32 	%r29, %r27, 16, 10;
	or.b32  	%r30, %r28, %r29;
	st.global.u32 	[%rd1], %r27;
	rem.u32 	%r31, %r30, %r20;
	cvt.u64.u32 	%rd11, %r31;
LBB24_2:
	shl.b64 	%rd8, %rd11, 5;
	mov.u64 	%rd9, callers_pool;
	add.s64 	%rd10, %rd9, %rd8;
	ld.global.u8 	%rs1, [%rd10+31];
	st.u8 	[%rd4+31], %rs1;
	ld.global.u8 	%rs2, [%rd10+30];
	st.u8 	[%rd4+30], %rs2;
	ld.global.u8 	%rs3, [%rd10+29];
	st.u8 	[%rd4+29], %rs3;
	ld.global.u8 	%rs4, [%rd10+28];
	st.u8 	[%rd4+28], %rs4;
	ld.global.u8 	%rs5, [%rd10+27];
	st.u8 	[%rd4+27], %rs5;
	ld.global.u8 	%rs6, [%rd10+26];
	st.u8 	[%rd4+26], %rs6;
	ld.global.u8 	%rs7, [%rd10+25];
	st.u8 	[%rd4+25], %rs7;
	ld.global.u8 	%rs8, [%rd10+24];
	st.u8 	[%rd4+24], %rs8;
	ld.global.u8 	%rs9, [%rd10+23];
	st.u8 	[%rd4+23], %rs9;
	ld.global.u8 	%rs10, [%rd10+22];
	st.u8 	[%rd4+22], %rs10;
	ld.global.u8 	%rs11, [%rd10+21];
	st.u8 	[%rd4+21], %rs11;
	ld.global.u8 	%rs12, [%rd10+20];
	st.u8 	[%rd4+20], %rs12;
	ld.global.u8 	%rs13, [%rd10+19];
	st.u8 	[%rd4+19], %rs13;
	ld.global.u8 	%rs14, [%rd10+18];
	st.u8 	[%rd4+18], %rs14;
	ld.global.u8 	%rs15, [%rd10+17];
	st.u8 	[%rd4+17], %rs15;
	ld.global.u8 	%rs16, [%rd10+16];
	st.u8 	[%rd4+16], %rs16;
	ld.global.u8 	%rs17, [%rd10+15];
	st.u8 	[%rd4+15], %rs17;
	ld.global.u8 	%rs18, [%rd10+14];
	st.u8 	[%rd4+14], %rs18;
	ld.global.u8 	%rs19, [%rd10+13];
	st.u8 	[%rd4+13], %rs19;
	ld.global.u8 	%rs20, [%rd10+12];
	st.u8 	[%rd4+12], %rs20;
	ld.global.u8 	%rs21, [%rd10+11];
	st.u8 	[%rd4+11], %rs21;
	ld.global.u8 	%rs22, [%rd10+10];
	st.u8 	[%rd4+10], %rs22;
	ld.global.u8 	%rs23, [%rd10+9];
	st.u8 	[%rd4+9], %rs23;
	ld.global.u8 	%rs24, [%rd10+8];
	st.u8 	[%rd4+8], %rs24;
	ld.global.u8 	%rs25, [%rd10+7];
	st.u8 	[%rd4+7], %rs25;
	ld.global.u8 	%rs26, [%rd10+6];
	st.u8 	[%rd4+6], %rs26;
	ld.global.u8 	%rs27, [%rd10+5];
	st.u8 	[%rd4+5], %rs27;
	ld.global.u8 	%rs28, [%rd10+4];
	st.u8 	[%rd4+4], %rs28;
	ld.global.u8 	%rs29, [%rd10+3];
	st.u8 	[%rd4+3], %rs29;
	ld.global.u8 	%rs30, [%rd10+2];
	st.u8 	[%rd4+2], %rs30;
	ld.global.u8 	%rs31, [%rd10+1];
	st.u8 	[%rd4+1], %rs31;
	ld.global.u8 	%rs32, [%rd10];
	st.u8 	[%rd4], %rs32;
	ret;
                                        // -- End function
}
	// .globl	mutateCallvalue         // -- Begin function mutateCallvalue
.visible .func mutateCallvalue(
	.param .b64 mutateCallvalue_param_0
)                                       // @mutateCallvalue
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<30>;
	.reg .b64 	%rd<6>;

// %bb.0:
	ld.param.u64 	%rd2, [mutateCallvalue_param_0];
	mov.u32 	%r5, %tid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %ntid.x;
	mad.lo.s32 	%r8, %r7, %r6, %r5;
	mul.wide.u32 	%rd3, %r8, 4;
	mov.u64 	%rd4, cuda_states;
	add.s64 	%rd5, %rd4, %rd3;
	ld.global.u32 	%r9, [%rd5];
	mad.lo.s32 	%r10, %r9, 1103515245, 12345;
	mad.lo.s32 	%r11, %r10, 1103515245, 12345;
	shr.u32 	%r12, %r10, 6;
	and.b32  	%r13, %r12, 2096128;
	bfe.u32 	%r14, %r11, 16, 10;
	or.b32  	%r15, %r14, %r13;
	mad.lo.s32 	%r16, %r11, 1103515245, 12345;
	shl.b32 	%r17, %r15, 10;
	bfe.u32 	%r18, %r16, 16, 10;
	or.b32  	%r19, %r17, %r18;
	st.global.u32 	[%rd5], %r16;
	mul.hi.u32 	%r20, %r19, 613566757;
	sub.s32 	%r21, %r19, %r20;
	shr.u32 	%r22, %r21, 1;
	add.s32 	%r23, %r22, %r20;
	shr.u32 	%r24, %r23, 2;
	mul.lo.s32 	%r25, %r24, 7;
	sub.s32 	%r26, %r19, %r25;
	add.s32 	%r1, %r26, 1;
	add.s64 	%rd1, %rd2, 16;
	mov.u32 	%r29, 1;
LBB25_1:                                // =>This Inner Loop Header: Depth=1
	mov.u32 	%r27, 16;
	{ // callseq 83, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r27;
	call.uni 
	cuhavoc, 
	(
	param0, 
	param1
	);
	} // callseq 83
	shr.u32 	%r28, %r29, %r1;
	setp.eq.s32 	%p1, %r28, 0;
	add.s32 	%r29, %r29, 1;
	@%p1 bra 	LBB25_1;
// %bb.2:
	ret;
                                        // -- End function
}
	// .globl	mutateCalldata          // -- Begin function mutateCalldata
.visible .func mutateCalldata(
	.param .b64 mutateCalldata_param_0,
	.param .b32 mutateCalldata_param_1
)                                       // @mutateCalldata
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<27>;
	.reg .b32 	%r<102>;
	.reg .b64 	%rd<21>;

// %bb.0:
	ld.param.u32 	%r15, [mutateCalldata_param_1];
	ld.param.u64 	%rd8, [mutateCalldata_param_0];
	mov.u32 	%r16, %tid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %ntid.x;
	mad.lo.s32 	%r19, %r18, %r17, %r16;
	mul.wide.u32 	%rd9, %r19, 4;
	mov.u64 	%rd10, cuda_states;
	add.s64 	%rd1, %rd10, %rd9;
	ld.global.u32 	%r20, [%rd1];
	mad.lo.s32 	%r21, %r20, 1103515245, 12345;
	mad.lo.s32 	%r22, %r21, 1103515245, 12345;
	shr.u32 	%r23, %r21, 6;
	and.b32  	%r24, %r23, 2096128;
	bfe.u32 	%r25, %r22, 16, 10;
	or.b32  	%r26, %r25, %r24;
	mad.lo.s32 	%r27, %r22, 1103515245, 12345;
	shl.b32 	%r28, %r26, 10;
	bfe.u32 	%r29, %r27, 16, 10;
	or.b32  	%r30, %r28, %r29;
	st.global.u32 	[%rd1], %r27;
	rem.u32 	%r101, %r30, %r15;
	mov.u64 	%rd12, argTypeMap;
	mov.u16 	%rs4, 0;
	mov.u32 	%r98, %r15;
	bra.uni 	LBB26_1;
LBB26_20:                               //   in Loop: Header=BB26_1 Depth=1
	add.s32 	%r31, %r101, 1;
	rem.u32 	%r101, %r31, %r15;
LBB26_21:                               //   in Loop: Header=BB26_1 Depth=1
	add.s32 	%r98, %r98, -1;
	@%p2 bra 	LBB26_1;
	bra.uni 	LBB26_22;
LBB26_1:                                // =>This Loop Header: Depth=1
                                        //     Child Loop BB26_4 Depth 2
	setp.eq.s32 	%p1, %r98, 0;
	@%p1 bra 	LBB26_22;
// %bb.2:                               //   in Loop: Header=BB26_1 Depth=1
	cvt.u64.u32 	%rd11, %r101;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.u8 	%rs1, [%rd13];
	cvt.u32.u16 	%r5, %rs1;
	add.s32 	%r6, %r5, -1;
	setp.gt.u32 	%p2, %r6, 65;
	@%p2 bra 	LBB26_20;
// %bb.3:                               //   in Loop: Header=BB26_1 Depth=1
	cvt.u64.u16 	%rd2, %rs1;
	ld.global.u32 	%r33, [%rd1];
	mad.lo.s32 	%r34, %r33, 1103515245, 12345;
	mad.lo.s32 	%r35, %r34, 1103515245, 12345;
	shr.u32 	%r36, %r34, 6;
	and.b32  	%r37, %r36, 2096128;
	bfe.u32 	%r38, %r35, 16, 10;
	or.b32  	%r39, %r38, %r37;
	mad.lo.s32 	%r40, %r35, 1103515245, 12345;
	shl.b32 	%r41, %r39, 10;
	bfe.u32 	%r42, %r40, 16, 10;
	or.b32  	%r43, %r41, %r42;
	st.global.u32 	[%rd1], %r40;
	mul.hi.u32 	%r44, %r43, 613566757;
	sub.s32 	%r45, %r43, %r44;
	shr.u32 	%r46, %r45, 1;
	add.s32 	%r47, %r46, %r44;
	shr.u32 	%r48, %r47, 2;
	mul.lo.s32 	%r49, %r48, 7;
	sub.s32 	%r50, %r43, %r49;
	add.s32 	%r7, %r50, 1;
	shl.b32 	%r51, %r101, 5;
	cvt.u64.u32 	%rd14, %r51;
	add.s64 	%rd3, %rd8, %rd14;
	sub.s64 	%rd15, %rd3, %rd2;
	add.s64 	%rd4, %rd15, 32;
	add.s64 	%rd5, %rd3, 12;
	add.s32 	%r8, %r5, -34;
	mov.u32 	%r100, 1;
	bra.uni 	LBB26_4;
LBB26_5:                                //   in Loop: Header=BB26_4 Depth=2
	add.s16 	%rs3, %rs1, -2;
	setp.lt.u16 	%p6, %rs3, 31;
	@%p6 bra 	LBB26_16;
	bra.uni 	LBB26_6;
LBB26_16:                               //   in Loop: Header=BB26_4 Depth=2
	{ // callseq 84, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r5;
	call.uni 
	cuhavoc, 
	(
	param0, 
	param1
	);
	} // callseq 84
LBB26_19:                               //   in Loop: Header=BB26_4 Depth=2
	shr.u32 	%r97, %r100, %r7;
	setp.eq.s32 	%p11, %r97, 0;
	add.s32 	%r100, %r100, 1;
	@%p11 bra 	LBB26_4;
	bra.uni 	LBB26_21;
LBB26_4:                                //   Parent Loop BB26_1 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	setp.gt.s16 	%p3, %rs1, 33;
	@%p3 bra 	LBB26_12;
	bra.uni 	LBB26_5;
LBB26_12:                               //   in Loop: Header=BB26_4 Depth=2
	add.s16 	%rs2, %rs1, -35;
	setp.lt.u16 	%p4, %rs2, 32;
	@%p4 bra 	LBB26_18;
	bra.uni 	LBB26_13;
LBB26_18:                               //   in Loop: Header=BB26_4 Depth=2
	{ // callseq 85, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd3;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r8;
	call.uni 
	cuhavoc, 
	(
	param0, 
	param1
	);
	} // callseq 85
	bra.uni 	LBB26_19;
LBB26_6:                                //   in Loop: Header=BB26_4 Depth=2
	setp.eq.s16 	%p7, %rs1, 1;
	@%p7 bra 	LBB26_15;
// %bb.7:                               //   in Loop: Header=BB26_4 Depth=2
	setp.eq.s16 	%p8, %rs1, 33;
	@%p8 bra 	LBB26_8;
	bra.uni 	LBB26_19;
LBB26_8:                                //   in Loop: Header=BB26_4 Depth=2
	ld.global.u32 	%r55, [%rd1];
	mad.lo.s32 	%r56, %r55, 1103515245, 12345;
	mad.lo.s32 	%r57, %r56, 1103515245, 12345;
	shr.u32 	%r58, %r56, 6;
	and.b32  	%r59, %r58, 2096128;
	bfe.u32 	%r60, %r57, 16, 10;
	or.b32  	%r61, %r60, %r59;
	mad.lo.s32 	%r10, %r57, 1103515245, 12345;
	shl.b32 	%r62, %r61, 10;
	bfe.u32 	%r63, %r10, 16, 10;
	or.b32  	%r64, %r62, %r63;
	st.global.u32 	[%rd1], %r10;
	mul.hi.u32 	%r65, %r64, 1374389535;
	shr.u32 	%r66, %r65, 5;
	mul.lo.s32 	%r67, %r66, 100;
	sub.s32 	%r68, %r64, %r67;
	setp.gt.u32 	%p9, %r68, 89;
	@%p9 bra 	LBB26_17;
// %bb.9:                               //   in Loop: Header=BB26_4 Depth=2
	mad.lo.s32 	%r69, %r10, 1103515245, 12345;
	mad.lo.s32 	%r70, %r69, 1103515245, 12345;
	shr.u32 	%r71, %r69, 6;
	and.b32  	%r72, %r71, 2096128;
	bfe.u32 	%r73, %r70, 16, 10;
	or.b32  	%r74, %r73, %r72;
	mad.lo.s32 	%r11, %r70, 1103515245, 12345;
	shl.b32 	%r75, %r74, 10;
	bfe.u32 	%r76, %r11, 16, 10;
	or.b32  	%r77, %r75, %r76;
	st.global.u32 	[%rd1], %r11;
	mul.hi.u32 	%r78, %r77, 1374389535;
	shr.u32 	%r79, %r78, 5;
	mul.lo.s32 	%r80, %r79, 100;
	sub.s32 	%r81, %r77, %r80;
	setp.lt.u32 	%p10, %r81, 80;
	mov.u64 	%rd20, 0;
	@%p10 bra 	LBB26_11;
// %bb.10:                              //   in Loop: Header=BB26_4 Depth=2
	ld.volatile.global.u32 	%r82, [addresses_pool_len];
	mad.lo.s32 	%r83, %r11, 1103515245, 12345;
	mad.lo.s32 	%r84, %r83, 1103515245, 12345;
	shr.u32 	%r85, %r83, 6;
	and.b32  	%r86, %r85, 2096128;
	bfe.u32 	%r87, %r84, 16, 10;
	or.b32  	%r88, %r87, %r86;
	mad.lo.s32 	%r89, %r84, 1103515245, 12345;
	shl.b32 	%r90, %r88, 10;
	bfe.u32 	%r91, %r89, 16, 10;
	or.b32  	%r92, %r90, %r91;
	st.global.u32 	[%rd1], %r89;
	rem.u32 	%r93, %r92, %r82;
	cvt.u64.u32 	%rd20, %r93;
LBB26_11:                               //   in Loop: Header=BB26_4 Depth=2
	shl.b64 	%rd17, %rd20, 5;
	mov.u64 	%rd18, addresses_pool;
	add.s64 	%rd19, %rd18, %rd17;
	ld.global.u8 	%rs5, [%rd19+19];
	st.u8 	[%rd5+19], %rs5;
	ld.global.u8 	%rs6, [%rd19+18];
	st.u8 	[%rd5+18], %rs6;
	ld.global.u8 	%rs7, [%rd19+17];
	st.u8 	[%rd5+17], %rs7;
	ld.global.u8 	%rs8, [%rd19+16];
	st.u8 	[%rd5+16], %rs8;
	ld.global.u8 	%rs9, [%rd19+15];
	st.u8 	[%rd5+15], %rs9;
	ld.global.u8 	%rs10, [%rd19+14];
	st.u8 	[%rd5+14], %rs10;
	ld.global.u8 	%rs11, [%rd19+13];
	st.u8 	[%rd5+13], %rs11;
	ld.global.u8 	%rs12, [%rd19+12];
	st.u8 	[%rd5+12], %rs12;
	ld.global.u8 	%rs13, [%rd19+11];
	st.u8 	[%rd5+11], %rs13;
	ld.global.u8 	%rs14, [%rd19+10];
	st.u8 	[%rd5+10], %rs14;
	ld.global.u8 	%rs15, [%rd19+9];
	st.u8 	[%rd5+9], %rs15;
	ld.global.u8 	%rs16, [%rd19+8];
	st.u8 	[%rd5+8], %rs16;
	ld.global.u8 	%rs17, [%rd19+7];
	st.u8 	[%rd5+7], %rs17;
	ld.global.u8 	%rs18, [%rd19+6];
	st.u8 	[%rd5+6], %rs18;
	ld.global.u8 	%rs19, [%rd19+5];
	st.u8 	[%rd5+5], %rs19;
	ld.global.u8 	%rs20, [%rd19+4];
	st.u8 	[%rd5+4], %rs20;
	ld.global.u8 	%rs21, [%rd19+3];
	st.u8 	[%rd5+3], %rs21;
	ld.global.u8 	%rs22, [%rd19+2];
	st.u8 	[%rd5+2], %rs22;
	ld.global.u8 	%rs23, [%rd19+1];
	st.u8 	[%rd5+1], %rs23;
	ld.global.u8 	%rs24, [%rd19];
	st.u8 	[%rd5], %rs24;
	bra.uni 	LBB26_19;
LBB26_13:                               //   in Loop: Header=BB26_4 Depth=2
	setp.eq.s16 	%p5, %rs1, 34;
	@%p5 bra 	LBB26_14;
	bra.uni 	LBB26_19;
LBB26_14:                               //   in Loop: Header=BB26_4 Depth=2
	ld.global.u32 	%r94, [%rd1];
	mad.lo.s32 	%r95, %r94, -2139243339, -1492899873;
	shr.u32 	%r96, %r95, 16;
	st.global.u32 	[%rd1], %r95;
	cvt.u16.u32 	%rs25, %r96;
	and.b16  	%rs26, %rs25, 1;
	st.u8 	[%rd3+31], %rs26;
	bra.uni 	LBB26_19;
LBB26_15:                               //   in Loop: Header=BB26_4 Depth=2
	ld.global.u32 	%r52, [%rd1];
	mad.lo.s32 	%r53, %r52, -2139243339, -1492899873;
	shr.u32 	%r54, %r53, 16;
	st.global.u32 	[%rd1], %r53;
	st.u8 	[%rd3+31], %r54;
	bra.uni 	LBB26_19;
LBB26_17:                               //   in Loop: Header=BB26_4 Depth=2
	st.u8 	[%rd3+31], %rs4;
	st.u8 	[%rd3+30], %rs4;
	st.u8 	[%rd3+29], %rs4;
	st.u8 	[%rd3+28], %rs4;
	st.u8 	[%rd3+27], %rs4;
	st.u8 	[%rd3+26], %rs4;
	st.u8 	[%rd3+25], %rs4;
	st.u8 	[%rd3+24], %rs4;
	st.u8 	[%rd3+23], %rs4;
	st.u8 	[%rd3+22], %rs4;
	st.u8 	[%rd3+21], %rs4;
	st.u8 	[%rd3+20], %rs4;
	st.u8 	[%rd3+19], %rs4;
	st.u8 	[%rd3+18], %rs4;
	st.u8 	[%rd3+17], %rs4;
	st.u8 	[%rd3+16], %rs4;
	st.u8 	[%rd3+15], %rs4;
	st.u8 	[%rd3+14], %rs4;
	st.u8 	[%rd3+13], %rs4;
	st.u8 	[%rd3+12], %rs4;
	st.u8 	[%rd3+11], %rs4;
	st.u8 	[%rd3+10], %rs4;
	st.u8 	[%rd3+9], %rs4;
	st.u8 	[%rd3+8], %rs4;
	st.u8 	[%rd3+7], %rs4;
	st.u8 	[%rd3+6], %rs4;
	st.u8 	[%rd3+5], %rs4;
	st.u8 	[%rd3+4], %rs4;
	st.u8 	[%rd3+3], %rs4;
	st.u8 	[%rd3+2], %rs4;
	st.u8 	[%rd3+1], %rs4;
	st.u8 	[%rd3], %rs4;
	bra.uni 	LBB26_19;
LBB26_22:
	ret;
                                        // -- End function
}
	// .globl	cuhavoc                 // -- Begin function cuhavoc
.visible .func cuhavoc(
	.param .b64 cuhavoc_param_0,
	.param .b32 cuhavoc_param_1
)                                       // @cuhavoc
{
	.local .align 1 .b8 	__local_depot27[2048];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<64>;
	.reg .b16 	%rs<46>;
	.reg .b32 	%r<502>;
	.reg .b64 	%rd<208>;

// %bb.0:
	mov.u64 	%SPL, __local_depot27;
	ld.param.u32 	%r10, [cuhavoc_param_1];
	ld.param.u64 	%rd44, [cuhavoc_param_0];
	mov.u32 	%r12, %tid.x;
	mov.u32 	%r13, %ctaid.x;
	mov.u32 	%r14, %ntid.x;
	mad.lo.s32 	%r1, %r14, %r13, %r12;
	mul.wide.u32 	%rd46, %r1, 4;
	mov.u64 	%rd47, cuda_states;
	add.s64 	%rd2, %rd47, %rd46;
	ld.global.u32 	%r15, [%rd2];
	mad.lo.s32 	%r16, %r15, 1103515245, 12345;
	mad.lo.s32 	%r17, %r16, 1103515245, 12345;
	shr.u32 	%r18, %r16, 6;
	and.b32  	%r19, %r18, 2096128;
	bfe.u32 	%r20, %r17, 16, 10;
	or.b32  	%r21, %r20, %r19;
	mad.lo.s32 	%r2, %r17, 1103515245, 12345;
	shl.b32 	%r22, %r21, 10;
	bfe.u32 	%r23, %r2, 16, 10;
	or.b32  	%r24, %r22, %r23;
	st.global.u32 	[%rd2], %r2;
	mul.hi.u32 	%r25, %r24, 954437177;
	shr.u32 	%r26, %r25, 2;
	mul.lo.s32 	%r27, %r26, 18;
	sub.s32 	%r11, %r24, %r27;
	setp.gt.s32 	%p1, %r11, 8;
	@%p1 bra 	LBB27_18;
// %bb.1:
	setp.gt.s32 	%p14, %r11, 3;
	@%p14 bra 	LBB27_9;
	bra.uni 	LBB27_2;
LBB27_9:
	setp.gt.s32 	%p15, %r11, 5;
	@%p15 bra 	LBB27_13;
	bra.uni 	LBB27_10;
LBB27_13:
	setp.eq.s32 	%p16, %r11, 6;
	@%p16 bra 	LBB27_44;
// %bb.14:
	setp.eq.s32 	%p17, %r11, 7;
	@%p17 bra 	LBB27_47;
// %bb.15:
	setp.eq.s32 	%p18, %r11, 8;
	@%p18 bra 	LBB27_16;
	bra.uni 	LBB27_76;
LBB27_16:
	setp.lt.u32 	%p59, %r10, 4;
	@%p59 bra 	LBB27_76;
// %bb.17:
	add.s32 	%r311, %r10, -3;
	mad.lo.s32 	%r312, %r2, 1103515245, 12345;
	mad.lo.s32 	%r313, %r312, 1103515245, 12345;
	shr.u32 	%r314, %r312, 6;
	and.b32  	%r315, %r314, 2096128;
	bfe.u32 	%r316, %r313, 16, 10;
	or.b32  	%r317, %r316, %r315;
	mad.lo.s32 	%r318, %r313, 1103515245, 12345;
	shl.b32 	%r319, %r317, 10;
	bfe.u32 	%r320, %r318, 16, 10;
	or.b32  	%r321, %r319, %r320;
	rem.u32 	%r322, %r321, %r311;
	mad.lo.s32 	%r323, %r318, 1103515245, 12345;
	mad.lo.s32 	%r324, %r323, 1103515245, 12345;
	shr.u32 	%r325, %r323, 6;
	and.b32  	%r326, %r325, 2096128;
	bfe.u32 	%r327, %r324, 16, 10;
	or.b32  	%r328, %r327, %r326;
	mad.lo.s32 	%r329, %r324, 1103515245, 12345;
	shl.b32 	%r330, %r328, 10;
	bfe.u32 	%r331, %r329, 16, 10;
	or.b32  	%r332, %r330, %r331;
	st.global.u32 	[%rd2], %r329;
	mul.hi.u32 	%r333, %r332, -736280107;
	sub.s32 	%r334, %r332, %r333;
	shr.u32 	%r335, %r334, 1;
	add.s32 	%r336, %r335, %r333;
	shr.u32 	%r337, %r336, 5;
	mul.lo.s32 	%r338, %r337, 35;
	sub.s32 	%r339, %r332, %r338;
	add.s32 	%r340, %r339, 1;
	cvt.u64.u32 	%rd181, %r322;
	add.s64 	%rd182, %rd44, %rd181;
	ld.u8 	%r341, [%rd182];
	ld.u8 	%r342, [%rd182+1];
	shl.b32 	%r343, %r342, 8;
	or.b32  	%r344, %r343, %r341;
	ld.u8 	%r345, [%rd182+2];
	ld.u8 	%r346, [%rd182+3];
	shl.b32 	%r347, %r346, 8;
	or.b32  	%r348, %r347, %r345;
	shl.b32 	%r349, %r348, 16;
	or.b32  	%r350, %r349, %r344;
	mad.lo.s32 	%r351, %r329, -2139243339, -1492899873;
	st.global.u32 	[%rd2], %r351;
	and.b32  	%r352, %r351, 65536;
	setp.eq.s32 	%p60, %r352, 0;
	shr.u32 	%r353, %r350, 24;
	shr.u32 	%r354, %r350, 8;
	and.b32  	%r355, %r354, 65280;
	or.b32  	%r356, %r355, %r353;
	shl.b32 	%r357, %r350, 24;
	shl.b32 	%r358, %r350, 8;
	and.b32  	%r359, %r358, 16711680;
	or.b32  	%r360, %r357, %r359;
	or.b32  	%r361, %r360, %r356;
	not.b32 	%r362, %r339;
	selp.b32 	%r363, %r362, %r340, %p60;
	add.s32 	%r364, %r361, %r363;
	shr.u32 	%r365, %r364, 24;
	st.u8 	[%rd182+3], %r364;
	shr.u32 	%r366, %r364, 8;
	st.u8 	[%rd182+2], %r366;
	shr.u32 	%r367, %r364, 16;
	st.u8 	[%rd182+1], %r367;
	st.u8 	[%rd182], %r365;
	bra.uni 	LBB27_76;
LBB27_18:
	setp.gt.s32 	%p2, %r11, 12;
	@%p2 bra 	LBB27_28;
	bra.uni 	LBB27_19;
LBB27_28:
	setp.gt.s32 	%p3, %r11, 14;
	@%p3 bra 	LBB27_34;
	bra.uni 	LBB27_29;
LBB27_34:
	setp.eq.s32 	%p4, %r11, 15;
	@%p4 bra 	LBB27_59;
// %bb.35:
	setp.eq.s32 	%p5, %r11, 16;
	@%p5 bra 	LBB27_66;
// %bb.36:
	setp.eq.s32 	%p6, %r11, 17;
	@%p6 bra 	LBB27_37;
	bra.uni 	LBB27_76;
LBB27_37:
	mul.wide.s32 	%rd48, %r1, 4;
	mov.u64 	%rd49, __snap_map;
	add.s64 	%rd50, %rd49, %rd48;
	ld.global.u32 	%rd34, [%rd50];
	mov.u64 	%rd51, l2snap_lens;
	add.s64 	%rd52, %rd51, %rd34;
	ld.global.u8 	%r9, [%rd52];
	setp.eq.s32 	%p26, %r9, 0;
	@%p26 bra 	LBB27_76;
// %bb.38:
	mad.lo.s32 	%r28, %r2, 1103515245, 12345;
	mad.lo.s32 	%r29, %r28, 1103515245, 12345;
	shr.u32 	%r30, %r28, 6;
	and.b32  	%r31, %r30, 2096128;
	bfe.u32 	%r32, %r29, 16, 10;
	or.b32  	%r33, %r32, %r31;
	mad.lo.s32 	%r34, %r29, 1103515245, 12345;
	shl.b32 	%r35, %r33, 10;
	bfe.u32 	%r36, %r34, 16, 10;
	or.b32  	%r37, %r35, %r36;
	rem.u32 	%r38, %r37, %r9;
	mad.lo.s32 	%r39, %r34, 1103515245, 12345;
	mad.lo.s32 	%r40, %r39, 1103515245, 12345;
	shr.u32 	%r41, %r39, 6;
	and.b32  	%r42, %r41, 2096128;
	bfe.u32 	%r43, %r40, 16, 10;
	or.b32  	%r44, %r43, %r42;
	mad.lo.s32 	%r45, %r40, 1103515245, 12345;
	shl.b32 	%r46, %r44, 10;
	bfe.u32 	%r47, %r45, 16, 10;
	or.b32  	%r48, %r46, %r47;
	st.global.u32 	[%rd2], %r45;
	mul.hi.u32 	%r49, %r48, 1374389535;
	shr.u32 	%r50, %r49, 5;
	mul.lo.s32 	%r51, %r50, 100;
	sub.s32 	%r52, %r48, %r51;
	setp.gt.u32 	%p27, %r52, 89;
	cvt.u64.u32 	%rd35, %r38;
	@%p27 bra 	LBB27_74;
// %bb.39:
	shl.b64 	%rd63, %rd34, 13;
	mov.u64 	%rd64, l2snaps;
	add.s64 	%rd65, %rd64, %rd63;
	shl.b64 	%rd66, %rd35, 6;
	add.s64 	%rd67, %rd65, %rd66;
	cvt.u64.u32 	%rd36, %r10;
	sub.s64 	%rd68, %rd67, %rd36;
	add.s64 	%rd37, %rd68, 64;
	setp.eq.s32 	%p30, %r10, 0;
	mov.u64 	%rd206, 0;
	@%p30 bra 	LBB27_76;
LBB27_40:                               // %loop-memcpy-expansion23
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd69, %rd37, %rd206;
	ld.global.u8 	%rs7, [%rd69];
	add.s64 	%rd70, %rd44, %rd206;
	st.u8 	[%rd70], %rs7;
	add.s64 	%rd206, %rd206, 1;
	setp.lt.u64 	%p31, %rd206, %rd36;
	@%p31 bra 	LBB27_40;
	bra.uni 	LBB27_76;
LBB27_2:
	setp.gt.s32 	%p21, %r11, 1;
	@%p21 bra 	LBB27_6;
// %bb.3:
	setp.eq.s32 	%p24, %r11, 0;
	@%p24 bra 	LBB27_41;
// %bb.4:
	setp.eq.s32 	%p25, %r11, 1;
	@%p25 bra 	LBB27_5;
	bra.uni 	LBB27_76;
LBB27_5:
	mad.lo.s32 	%r475, %r2, 1103515245, 12345;
	mad.lo.s32 	%r476, %r475, 1103515245, 12345;
	shr.u32 	%r477, %r475, 6;
	and.b32  	%r478, %r477, 2096128;
	bfe.u32 	%r479, %r476, 16, 10;
	or.b32  	%r480, %r479, %r478;
	mad.lo.s32 	%r481, %r476, 1103515245, 12345;
	shl.b32 	%r482, %r480, 10;
	bfe.u32 	%r483, %r481, 16, 10;
	or.b32  	%r484, %r482, %r483;
	st.global.u32 	[%rd2], %r481;
	rem.u32 	%r485, %r484, %r10;
	cvt.u64.u32 	%rd194, %r485;
	add.s64 	%rd195, %rd44, %rd194;
	ld.u8 	%rs41, [%rd195];
	not.b16 	%rs42, %rs41;
	st.u8 	[%rd195], %rs42;
	bra.uni 	LBB27_76;
LBB27_19:
	setp.gt.s32 	%p9, %r11, 10;
	@%p9 bra 	LBB27_23;
// %bb.20:
	setp.eq.s32 	%p12, %r11, 9;
	@%p12 bra 	LBB27_49;
// %bb.21:
	setp.eq.s32 	%p13, %r11, 10;
	@%p13 bra 	LBB27_22;
	bra.uni 	LBB27_76;
LBB27_22:
	mad.lo.s32 	%r254, %r2, 1103515245, 12345;
	mad.lo.s32 	%r255, %r254, 1103515245, 12345;
	shr.u32 	%r256, %r254, 6;
	and.b32  	%r257, %r256, 2096128;
	bfe.u32 	%r258, %r255, 16, 10;
	or.b32  	%r259, %r258, %r257;
	mad.lo.s32 	%r260, %r255, 1103515245, 12345;
	shl.b32 	%r261, %r259, 10;
	bfe.u32 	%r262, %r260, 16, 10;
	or.b32  	%r263, %r261, %r262;
	mul.hi.u32 	%r264, %r263, 954437177;
	shr.u32 	%r265, %r264, 1;
	mul.lo.s32 	%r266, %r265, 9;
	sub.s32 	%r267, %r263, %r266;
	cvt.u64.u32 	%rd120, %r267;
	mov.u64 	%rd121, interesting_8;
	add.s64 	%rd122, %rd121, %rd120;
	ld.const.u8 	%rs17, [%rd122];
	mad.lo.s32 	%r268, %r260, 1103515245, 12345;
	mad.lo.s32 	%r269, %r268, 1103515245, 12345;
	shr.u32 	%r270, %r268, 6;
	and.b32  	%r271, %r270, 2096128;
	bfe.u32 	%r272, %r269, 16, 10;
	or.b32  	%r273, %r272, %r271;
	mad.lo.s32 	%r274, %r269, 1103515245, 12345;
	shl.b32 	%r275, %r273, 10;
	bfe.u32 	%r276, %r274, 16, 10;
	or.b32  	%r277, %r275, %r276;
	st.global.u32 	[%rd2], %r274;
	rem.u32 	%r278, %r277, %r10;
	cvt.u64.u32 	%rd123, %r278;
	add.s64 	%rd124, %rd44, %rd123;
	st.u8 	[%rd124], %rs17;
	bra.uni 	LBB27_76;
LBB27_10:
	setp.eq.s32 	%p19, %r11, 4;
	@%p19 bra 	LBB27_43;
// %bb.11:
	setp.eq.s32 	%p20, %r11, 5;
	@%p20 bra 	LBB27_12;
	bra.uni 	LBB27_76;
LBB27_12:
	mad.lo.s32 	%r429, %r2, -2139243339, -1492899873;
	shr.u32 	%r430, %r429, 16;
	mad.lo.s32 	%r431, %r429, 1103515245, 12345;
	mad.lo.s32 	%r432, %r431, 1103515245, 12345;
	shr.u32 	%r433, %r431, 6;
	and.b32  	%r434, %r433, 2096128;
	bfe.u32 	%r435, %r432, 16, 10;
	or.b32  	%r436, %r435, %r434;
	mad.lo.s32 	%r437, %r432, 1103515245, 12345;
	shl.b32 	%r438, %r436, 10;
	bfe.u32 	%r439, %r437, 16, 10;
	or.b32  	%r440, %r438, %r439;
	st.global.u32 	[%rd2], %r437;
	rem.u32 	%r441, %r440, %r10;
	cvt.u64.u32 	%rd186, %r441;
	add.s64 	%rd187, %rd44, %rd186;
	st.u8 	[%rd187], %r430;
	bra.uni 	LBB27_76;
LBB27_29:
	setp.eq.s32 	%p7, %r11, 13;
	@%p7 bra 	LBB27_56;
// %bb.30:
	setp.eq.s32 	%p8, %r11, 14;
	@%p8 bra 	LBB27_31;
	bra.uni 	LBB27_76;
LBB27_31:
	setp.eq.s32 	%p47, %r10, 0;
	@%p47 bra 	LBB27_76;
// %bb.32:
	mad.lo.s32 	%r101, %r2, 1103515245, 12345;
	mad.lo.s32 	%r102, %r101, 1103515245, 12345;
	shr.u32 	%r103, %r101, 6;
	and.b32  	%r104, %r103, 2096128;
	bfe.u32 	%r105, %r102, 16, 10;
	or.b32  	%r106, %r105, %r104;
	mad.lo.s32 	%r107, %r102, 1103515245, 12345;
	shl.b32 	%r108, %r106, 10;
	bfe.u32 	%r109, %r107, 16, 10;
	or.b32  	%r110, %r108, %r109;
	rem.u32 	%r111, %r110, %r10;
	sub.s32 	%r112, %r10, %r111;
	min.u32 	%r113, %r112, 16;
	mad.lo.s32 	%r114, %r107, 1103515245, 12345;
	mad.lo.s32 	%r115, %r114, 1103515245, 12345;
	shr.u32 	%r116, %r114, 6;
	and.b32  	%r117, %r116, 2096128;
	bfe.u32 	%r118, %r115, 16, 10;
	or.b32  	%r119, %r118, %r117;
	mad.lo.s32 	%r120, %r115, 1103515245, 12345;
	shl.b32 	%r121, %r119, 10;
	bfe.u32 	%r122, %r120, 16, 10;
	or.b32  	%r123, %r121, %r122;
	rem.u32 	%r124, %r123, %r113;
	add.s32 	%r125, %r124, 1;
	cvt.u64.u32 	%rd8, %r125;
	mad.lo.s32 	%r126, %r120, -2139243339, -1492899873;
	shr.u32 	%r127, %r126, 16;
	st.global.u32 	[%rd2], %r126;
	cvt.u16.u32 	%rs5, %r127;
	cvt.u64.u32 	%rd99, %r111;
	add.s64 	%rd9, %rd44, %rd99;
	setp.eq.s32 	%p48, %r125, 0;
	mov.u64 	%rd199, 0;
	@%p48 bra 	LBB27_76;
LBB27_33:                               // %loadstoreloop7
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd100, %rd9, %rd199;
	st.u8 	[%rd100], %rs5;
	add.s64 	%rd199, %rd199, 1;
	setp.lt.u64 	%p49, %rd199, %rd8;
	@%p49 bra 	LBB27_33;
	bra.uni 	LBB27_76;
LBB27_6:
	setp.eq.s32 	%p22, %r11, 2;
	@%p22 bra 	LBB27_42;
// %bb.7:
	setp.eq.s32 	%p23, %r11, 3;
	@%p23 bra 	LBB27_8;
	bra.uni 	LBB27_76;
LBB27_8:
	mad.lo.s32 	%r453, %r2, 1103515245, 12345;
	mad.lo.s32 	%r454, %r453, 1103515245, 12345;
	shr.u32 	%r455, %r453, 6;
	and.b32  	%r456, %r455, 2096128;
	bfe.u32 	%r457, %r454, 16, 10;
	or.b32  	%r458, %r457, %r456;
	mad.lo.s32 	%r459, %r454, 1103515245, 12345;
	shl.b32 	%r460, %r458, 10;
	bfe.u32 	%r461, %r459, 16, 10;
	or.b32  	%r462, %r460, %r461;
	st.global.u32 	[%rd2], %r459;
	rem.u32 	%r463, %r462, %r10;
	cvt.u64.u32 	%rd190, %r463;
	add.s64 	%rd191, %rd44, %rd190;
	ld.u8 	%rs37, [%rd191];
	add.s16 	%rs38, %rs37, -1;
	st.u8 	[%rd191], %rs38;
	bra.uni 	LBB27_76;
LBB27_23:
	setp.eq.s32 	%p10, %r11, 11;
	@%p10 bra 	LBB27_51;
// %bb.24:
	setp.eq.s32 	%p11, %r11, 12;
	@%p11 bra 	LBB27_25;
	bra.uni 	LBB27_76;
LBB27_25:
	setp.lt.u32 	%p53, %r10, 4;
	@%p53 bra 	LBB27_76;
// %bb.26:
	mad.lo.s32 	%r164, %r2, 1103515245, 12345;
	mad.lo.s32 	%r165, %r164, 1103515245, 12345;
	shr.u32 	%r166, %r164, 6;
	and.b32  	%r167, %r166, 2096128;
	bfe.u32 	%r168, %r165, 16, 10;
	or.b32  	%r169, %r168, %r167;
	mad.lo.s32 	%r170, %r165, 1103515245, 12345;
	shl.b32 	%r171, %r169, 10;
	bfe.u32 	%r172, %r170, 16, 10;
	or.b32  	%r173, %r171, %r172;
	mul.hi.u32 	%r174, %r173, 795364315;
	sub.s32 	%r175, %r173, %r174;
	shr.u32 	%r176, %r175, 1;
	add.s32 	%r177, %r176, %r174;
	shr.u32 	%r178, %r177, 4;
	mul.lo.s32 	%r179, %r178, 27;
	sub.s32 	%r180, %r173, %r179;
	mul.wide.u32 	%rd106, %r180, 4;
	mov.u64 	%rd107, interesting_32;
	add.s64 	%rd108, %rd107, %rd106;
	ld.const.u32 	%r4, [%rd108];
	mad.lo.s32 	%r5, %r170, -2139243339, -1492899873;
	and.b32  	%r181, %r5, 65536;
	setp.eq.s32 	%p54, %r181, 0;
	@%p54 bra 	LBB27_55;
	bra.uni 	LBB27_27;
LBB27_55:
	shr.u32 	%r197, %r4, 24;
	add.s32 	%r198, %r10, -3;
	mad.lo.s32 	%r199, %r5, 1103515245, 12345;
	mad.lo.s32 	%r200, %r199, 1103515245, 12345;
	shr.u32 	%r201, %r199, 6;
	and.b32  	%r202, %r201, 2096128;
	bfe.u32 	%r203, %r200, 16, 10;
	or.b32  	%r204, %r203, %r202;
	mad.lo.s32 	%r205, %r200, 1103515245, 12345;
	shl.b32 	%r206, %r204, 10;
	bfe.u32 	%r207, %r205, 16, 10;
	or.b32  	%r208, %r206, %r207;
	st.global.u32 	[%rd2], %r205;
	rem.u32 	%r209, %r208, %r198;
	cvt.u64.u32 	%rd111, %r209;
	add.s64 	%rd112, %rd44, %rd111;
	st.u8 	[%rd112+3], %r4;
	shr.u32 	%r210, %r4, 8;
	st.u8 	[%rd112+2], %r210;
	shr.u32 	%r211, %r4, 16;
	st.u8 	[%rd112+1], %r211;
	st.u8 	[%rd112], %r197;
	bra.uni 	LBB27_76;
LBB27_41:
	shl.b32 	%r486, %r10, 3;
	mad.lo.s32 	%r487, %r2, 1103515245, 12345;
	mad.lo.s32 	%r488, %r487, 1103515245, 12345;
	shr.u32 	%r489, %r487, 6;
	and.b32  	%r490, %r489, 2096128;
	bfe.u32 	%r491, %r488, 16, 10;
	or.b32  	%r492, %r491, %r490;
	mad.lo.s32 	%r493, %r488, 1103515245, 12345;
	shl.b32 	%r494, %r492, 10;
	bfe.u32 	%r495, %r493, 16, 10;
	or.b32  	%r496, %r494, %r495;
	st.global.u32 	[%rd2], %r493;
	rem.u32 	%r497, %r496, %r486;
	and.b32  	%r498, %r497, 7;
	mov.u32 	%r499, 128;
	shr.u32 	%r500, %r499, %r498;
	shr.u32 	%r501, %r497, 3;
	cvt.u64.u32 	%rd196, %r501;
	add.s64 	%rd197, %rd44, %rd196;
	ld.u8 	%rs43, [%rd197];
	cvt.u16.u32 	%rs44, %r500;
	xor.b16  	%rs45, %rs43, %rs44;
	st.u8 	[%rd197], %rs45;
	bra.uni 	LBB27_76;
LBB27_49:
	setp.lt.u32 	%p57, %r10, 8;
	@%p57 bra 	LBB27_76;
// %bb.50:
	add.s32 	%r279, %r10, -7;
	mad.lo.s32 	%r280, %r2, 1103515245, 12345;
	mad.lo.s32 	%r281, %r280, 1103515245, 12345;
	shr.u32 	%r282, %r280, 6;
	and.b32  	%r283, %r282, 2096128;
	bfe.u32 	%r284, %r281, 16, 10;
	or.b32  	%r285, %r284, %r283;
	mad.lo.s32 	%r286, %r281, 1103515245, 12345;
	shl.b32 	%r287, %r285, 10;
	bfe.u32 	%r288, %r286, 16, 10;
	or.b32  	%r289, %r287, %r288;
	rem.u32 	%r290, %r289, %r279;
	mad.lo.s32 	%r291, %r286, 1103515245, 12345;
	mad.lo.s32 	%r292, %r291, 1103515245, 12345;
	shr.u32 	%r293, %r291, 6;
	and.b32  	%r294, %r293, 2096128;
	bfe.u32 	%r295, %r292, 16, 10;
	or.b32  	%r296, %r295, %r294;
	mad.lo.s32 	%r297, %r292, 1103515245, 12345;
	shl.b32 	%r298, %r296, 10;
	bfe.u32 	%r299, %r297, 16, 10;
	or.b32  	%r300, %r298, %r299;
	st.global.u32 	[%rd2], %r297;
	mul.hi.u32 	%r301, %r300, -736280107;
	sub.s32 	%r302, %r300, %r301;
	shr.u32 	%r303, %r302, 1;
	add.s32 	%r304, %r303, %r301;
	shr.u32 	%r305, %r304, 5;
	mul.lo.s32 	%r306, %r305, 35;
	sub.s32 	%r307, %r300, %r306;
	add.s32 	%r308, %r307, 1;
	cvt.u64.u32 	%rd125, %r308;
	cvt.u64.u32 	%rd126, %r290;
	add.s64 	%rd127, %rd44, %rd126;
	ld.u8 	%rd128, [%rd127];
	ld.u8 	%rd129, [%rd127+1];
	shl.b64 	%rd130, %rd129, 8;
	or.b64  	%rd131, %rd130, %rd128;
	ld.u8 	%rd132, [%rd127+2];
	ld.u8 	%rd133, [%rd127+3];
	shl.b64 	%rd134, %rd133, 8;
	or.b64  	%rd135, %rd134, %rd132;
	shl.b64 	%rd136, %rd135, 16;
	or.b64  	%rd137, %rd136, %rd131;
	ld.u8 	%rd138, [%rd127+4];
	ld.u8 	%rd139, [%rd127+5];
	shl.b64 	%rd140, %rd139, 8;
	or.b64  	%rd141, %rd140, %rd138;
	ld.u8 	%rd142, [%rd127+6];
	ld.u8 	%rd143, [%rd127+7];
	shl.b64 	%rd144, %rd143, 8;
	or.b64  	%rd145, %rd144, %rd142;
	shl.b64 	%rd146, %rd145, 16;
	or.b64  	%rd147, %rd146, %rd141;
	shl.b64 	%rd148, %rd147, 32;
	or.b64  	%rd149, %rd148, %rd137;
	mad.lo.s32 	%r309, %r297, -2139243339, -1492899873;
	st.global.u32 	[%rd2], %r309;
	and.b32  	%r310, %r309, 65536;
	setp.eq.s32 	%p58, %r310, 0;
	shr.u64 	%rd150, %rd149, 56;
	shr.u64 	%rd151, %rd149, 40;
	and.b64  	%rd152, %rd151, 65280;
	or.b64  	%rd153, %rd152, %rd150;
	shr.u64 	%rd154, %rd149, 24;
	and.b64  	%rd155, %rd154, 16711680;
	shr.u64 	%rd156, %rd149, 8;
	and.b64  	%rd157, %rd156, 4278190080;
	or.b64  	%rd158, %rd157, %rd155;
	or.b64  	%rd159, %rd158, %rd153;
	shl.b64 	%rd160, %rd149, 8;
	and.b64  	%rd161, %rd160, 1095216660480;
	shl.b64 	%rd162, %rd149, 24;
	and.b64  	%rd163, %rd162, 280375465082880;
	or.b64  	%rd164, %rd163, %rd161;
	shl.b64 	%rd165, %rd149, 56;
	shl.b64 	%rd166, %rd149, 40;
	and.b64  	%rd167, %rd166, 71776119061217280;
	or.b64  	%rd168, %rd165, %rd167;
	or.b64  	%rd169, %rd168, %rd164;
	or.b64  	%rd170, %rd169, %rd159;
	neg.s64 	%rd171, %rd125;
	selp.b64 	%rd172, %rd171, %rd125, %p58;
	add.s64 	%rd173, %rd170, %rd172;
	shr.u64 	%rd174, %rd173, 56;
	shr.u64 	%rd175, %rd173, 40;
	st.u8 	[%rd127+7], %rd173;
	shr.u64 	%rd176, %rd173, 8;
	st.u8 	[%rd127+6], %rd176;
	shr.u64 	%rd177, %rd173, 16;
	st.u8 	[%rd127+5], %rd177;
	shr.u64 	%rd178, %rd173, 24;
	st.u8 	[%rd127+4], %rd178;
	shr.u64 	%rd179, %rd173, 32;
	st.u8 	[%rd127+3], %rd179;
	st.u8 	[%rd127+2], %rd175;
	shr.u64 	%rd180, %rd173, 48;
	st.u8 	[%rd127+1], %rd180;
	st.u8 	[%rd127], %rd174;
	bra.uni 	LBB27_76;
LBB27_42:
	mad.lo.s32 	%r464, %r2, 1103515245, 12345;
	mad.lo.s32 	%r465, %r464, 1103515245, 12345;
	shr.u32 	%r466, %r464, 6;
	and.b32  	%r467, %r466, 2096128;
	bfe.u32 	%r468, %r465, 16, 10;
	or.b32  	%r469, %r468, %r467;
	mad.lo.s32 	%r470, %r465, 1103515245, 12345;
	shl.b32 	%r471, %r469, 10;
	bfe.u32 	%r472, %r470, 16, 10;
	or.b32  	%r473, %r471, %r472;
	st.global.u32 	[%rd2], %r470;
	rem.u32 	%r474, %r473, %r10;
	cvt.u64.u32 	%rd192, %r474;
	add.s64 	%rd193, %rd44, %rd192;
	ld.u8 	%rs39, [%rd193];
	add.s16 	%rs40, %rs39, 1;
	st.u8 	[%rd193], %rs40;
	bra.uni 	LBB27_76;
LBB27_51:
	setp.lt.u32 	%p55, %r10, 2;
	@%p55 bra 	LBB27_76;
// %bb.52:
	mad.lo.s32 	%r212, %r2, 1103515245, 12345;
	mad.lo.s32 	%r213, %r212, 1103515245, 12345;
	shr.u32 	%r214, %r212, 6;
	and.b32  	%r215, %r214, 2096128;
	bfe.u32 	%r216, %r213, 16, 10;
	or.b32  	%r217, %r216, %r215;
	mad.lo.s32 	%r218, %r213, 1103515245, 12345;
	shl.b32 	%r219, %r217, 10;
	bfe.u32 	%r220, %r218, 16, 10;
	or.b32  	%r221, %r219, %r220;
	mul.hi.u32 	%r222, %r221, -1356305461;
	sub.s32 	%r223, %r221, %r222;
	shr.u32 	%r224, %r223, 1;
	add.s32 	%r225, %r224, %r222;
	shr.u32 	%r226, %r225, 4;
	mul.lo.s32 	%r227, %r226, 19;
	sub.s32 	%r228, %r221, %r227;
	mul.wide.u32 	%rd113, %r228, 2;
	mov.u64 	%rd114, interesting_16;
	add.s64 	%rd115, %rd114, %rd113;
	ld.const.u16 	%rs3, [%rd115];
	mad.lo.s32 	%r3, %r218, -2139243339, -1492899873;
	and.b32  	%r229, %r3, 65536;
	setp.eq.s32 	%p56, %r229, 0;
	@%p56 bra 	LBB27_54;
	bra.uni 	LBB27_53;
LBB27_54:
	shr.u16 	%rs16, %rs3, 8;
	add.s32 	%r242, %r10, -1;
	mad.lo.s32 	%r243, %r3, 1103515245, 12345;
	mad.lo.s32 	%r244, %r243, 1103515245, 12345;
	shr.u32 	%r245, %r243, 6;
	and.b32  	%r246, %r245, 2096128;
	bfe.u32 	%r247, %r244, 16, 10;
	or.b32  	%r248, %r247, %r246;
	mad.lo.s32 	%r249, %r244, 1103515245, 12345;
	shl.b32 	%r250, %r248, 10;
	bfe.u32 	%r251, %r249, 16, 10;
	or.b32  	%r252, %r250, %r251;
	st.global.u32 	[%rd2], %r249;
	rem.u32 	%r253, %r252, %r242;
	cvt.u64.u32 	%rd118, %r253;
	add.s64 	%rd119, %rd44, %rd118;
	st.u8 	[%rd119+1], %rs3;
	st.u8 	[%rd119], %rs16;
	bra.uni 	LBB27_76;
LBB27_44:
	mad.lo.s32 	%r399, %r2, -2139243339, -1492899873;
	and.b32  	%r400, %r399, 65536;
	setp.eq.s32 	%p63, %r400, 0;
	mad.lo.s32 	%r401, %r399, 1103515245, 12345;
	mad.lo.s32 	%r402, %r401, 1103515245, 12345;
	shr.u32 	%r403, %r401, 6;
	and.b32  	%r404, %r403, 2096128;
	bfe.u32 	%r405, %r402, 16, 10;
	or.b32  	%r406, %r405, %r404;
	mad.lo.s32 	%r407, %r402, 1103515245, 12345;
	shl.b32 	%r408, %r406, 10;
	bfe.u32 	%r409, %r407, 16, 10;
	or.b32  	%r410, %r408, %r409;
	mul.hi.u32 	%r411, %r410, -736280107;
	sub.s32 	%r412, %r410, %r411;
	shr.u32 	%r413, %r412, 1;
	add.s32 	%r414, %r413, %r411;
	shr.u32 	%r415, %r414, 5;
	mul.lo.s32 	%r416, %r415, 35;
	sub.s32 	%r417, %r410, %r416;
	mad.lo.s32 	%r418, %r407, 1103515245, 12345;
	mad.lo.s32 	%r419, %r418, 1103515245, 12345;
	shr.u32 	%r420, %r418, 6;
	and.b32  	%r421, %r420, 2096128;
	bfe.u32 	%r422, %r419, 16, 10;
	or.b32  	%r423, %r422, %r421;
	mad.lo.s32 	%r424, %r419, 1103515245, 12345;
	shl.b32 	%r425, %r423, 10;
	bfe.u32 	%r426, %r424, 16, 10;
	or.b32  	%r427, %r425, %r426;
	st.global.u32 	[%rd2], %r424;
	rem.u32 	%r428, %r427, %r10;
	cvt.u64.u32 	%rd185, %r428;
	add.s64 	%rd3, %rd44, %rd185;
	ld.u8 	%rs1, [%rd3];
	cvt.u16.u32 	%rs2, %r417;
	@%p63 bra 	LBB27_46;
	bra.uni 	LBB27_45;
LBB27_46:
	not.b16 	%rs33, %rs2;
	add.s16 	%rs34, %rs1, %rs33;
	st.u8 	[%rd3], %rs34;
	bra.uni 	LBB27_76;
LBB27_47:
	setp.lt.u32 	%p61, %r10, 2;
	@%p61 bra 	LBB27_76;
// %bb.48:
	add.s32 	%r368, %r10, -1;
	mad.lo.s32 	%r369, %r2, 1103515245, 12345;
	mad.lo.s32 	%r370, %r369, 1103515245, 12345;
	shr.u32 	%r371, %r369, 6;
	and.b32  	%r372, %r371, 2096128;
	bfe.u32 	%r373, %r370, 16, 10;
	or.b32  	%r374, %r373, %r372;
	mad.lo.s32 	%r375, %r370, 1103515245, 12345;
	shl.b32 	%r376, %r374, 10;
	bfe.u32 	%r377, %r375, 16, 10;
	or.b32  	%r378, %r376, %r377;
	rem.u32 	%r379, %r378, %r368;
	mad.lo.s32 	%r380, %r375, 1103515245, 12345;
	mad.lo.s32 	%r381, %r380, 1103515245, 12345;
	shr.u32 	%r382, %r380, 6;
	and.b32  	%r383, %r382, 2096128;
	bfe.u32 	%r384, %r381, 16, 10;
	or.b32  	%r385, %r384, %r383;
	mad.lo.s32 	%r386, %r381, 1103515245, 12345;
	shl.b32 	%r387, %r385, 10;
	bfe.u32 	%r388, %r386, 16, 10;
	or.b32  	%r389, %r387, %r388;
	st.global.u32 	[%rd2], %r386;
	mul.hi.u32 	%r390, %r389, -736280107;
	sub.s32 	%r391, %r389, %r390;
	shr.u32 	%r392, %r391, 1;
	add.s32 	%r393, %r392, %r390;
	shr.u32 	%r394, %r393, 5;
	mul.lo.s32 	%r395, %r394, 35;
	sub.s32 	%r396, %r389, %r395;
	cvt.u16.u32 	%rs18, %r396;
	add.s16 	%rs19, %rs18, 1;
	cvt.u64.u32 	%rd183, %r379;
	add.s64 	%rd184, %rd44, %rd183;
	ld.u8 	%rs20, [%rd184];
	ld.u8 	%rs21, [%rd184+1];
	shl.b16 	%rs22, %rs21, 8;
	or.b16  	%rs23, %rs22, %rs20;
	mad.lo.s32 	%r397, %r386, -2139243339, -1492899873;
	st.global.u32 	[%rd2], %r397;
	and.b32  	%r398, %r397, 65536;
	setp.eq.s32 	%p62, %r398, 0;
	shr.u16 	%rs24, %rs23, 8;
	shl.b16 	%rs25, %rs23, 8;
	or.b16  	%rs26, %rs25, %rs24;
	not.b16 	%rs27, %rs18;
	selp.b16 	%rs28, %rs27, %rs19, %p62;
	add.s16 	%rs29, %rs26, %rs28;
	shr.u16 	%rs30, %rs29, 8;
	st.u8 	[%rd184+1], %rs29;
	st.u8 	[%rd184], %rs30;
	bra.uni 	LBB27_76;
LBB27_59:
	setp.lt.u32 	%p40, %r10, 2;
	@%p40 bra 	LBB27_76;
// %bb.60:
	add.u64 	%rd1, %SPL, 0;
	mad.lo.s32 	%r66, %r2, 1103515245, 12345;
	mad.lo.s32 	%r67, %r66, 1103515245, 12345;
	shr.u32 	%r68, %r66, 6;
	and.b32  	%r69, %r68, 2096128;
	bfe.u32 	%r70, %r67, 16, 10;
	or.b32  	%r71, %r70, %r69;
	mad.lo.s32 	%r72, %r67, 1103515245, 12345;
	shl.b32 	%r73, %r71, 10;
	bfe.u32 	%r74, %r72, 16, 10;
	or.b32  	%r75, %r73, %r74;
	rem.u32 	%r76, %r75, %r10;
	mad.lo.s32 	%r77, %r72, 1103515245, 12345;
	mad.lo.s32 	%r78, %r77, 1103515245, 12345;
	shr.u32 	%r79, %r77, 6;
	and.b32  	%r80, %r79, 2096128;
	bfe.u32 	%r81, %r78, 16, 10;
	or.b32  	%r82, %r81, %r80;
	mad.lo.s32 	%r83, %r78, 1103515245, 12345;
	shl.b32 	%r84, %r82, 10;
	bfe.u32 	%r85, %r83, 16, 10;
	or.b32  	%r86, %r84, %r85;
	rem.u32 	%r6, %r86, %r10;
	max.u32 	%r87, %r76, %r6;
	sub.s32 	%r88, %r10, %r87;
	mad.lo.s32 	%r89, %r83, 1103515245, 12345;
	mad.lo.s32 	%r90, %r89, 1103515245, 12345;
	shr.u32 	%r91, %r89, 6;
	and.b32  	%r92, %r91, 2096128;
	bfe.u32 	%r93, %r90, 16, 10;
	or.b32  	%r94, %r93, %r92;
	mad.lo.s32 	%r95, %r90, 1103515245, 12345;
	shl.b32 	%r96, %r94, 10;
	bfe.u32 	%r97, %r95, 16, 10;
	or.b32  	%r98, %r96, %r97;
	st.global.u32 	[%rd2], %r95;
	rem.u32 	%r99, %r98, %r88;
	add.s32 	%r100, %r99, 1;
	cvt.u64.u32 	%rd12, %r100;
	cvt.u64.u32 	%rd88, %r76;
	add.s64 	%rd14, %rd44, %rd88;
	setp.eq.s32 	%p41, %r100, 0;
	mov.u64 	%rd200, 0;
	@%p41 bra 	LBB27_62;
LBB27_61:                               // %loop-memcpy-expansion
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd89, %rd14, %rd200;
	ld.u8 	%rs12, [%rd89];
	add.s64 	%rd90, %rd1, %rd200;
	st.local.u8 	[%rd90], %rs12;
	add.s64 	%rd200, %rd200, 1;
	setp.lt.u64 	%p42, %rd200, %rd12;
	@%p42 bra 	LBB27_61;
LBB27_62:                               // %post-loop-memcpy-expansion
	cvt.u64.u32 	%rd92, %r6;
	add.s64 	%rd18, %rd44, %rd92;
	setp.eq.s64 	%p43, %rd12, 0;
	mov.u64 	%rd201, 0;
	@%p43 bra 	LBB27_64;
LBB27_63:                               // %loop-memcpy-expansion9
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd93, %rd18, %rd201;
	ld.u8 	%rs13, [%rd93];
	add.s64 	%rd94, %rd14, %rd201;
	st.u8 	[%rd94], %rs13;
	add.s64 	%rd201, %rd201, 1;
	setp.lt.u64 	%p44, %rd201, %rd12;
	@%p44 bra 	LBB27_63;
LBB27_64:                               // %post-loop-memcpy-expansion8
	mov.u64 	%rd202, 0;
	@%p43 bra 	LBB27_76;
LBB27_65:                               // %loop-memcpy-expansion12
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd96, %rd1, %rd202;
	ld.local.u8 	%rs14, [%rd96];
	add.s64 	%rd97, %rd18, %rd202;
	st.u8 	[%rd97], %rs14;
	add.s64 	%rd202, %rd202, 1;
	setp.lt.u64 	%p46, %rd202, %rd12;
	@%p46 bra 	LBB27_65;
	bra.uni 	LBB27_76;
LBB27_66:
	ld.global.u32 	%r7, [cbconstants_length];
	setp.eq.s32 	%p32, %r7, 0;
	@%p32 bra 	LBB27_76;
// %bb.67:
	mad.lo.s32 	%r53, %r2, 1103515245, 12345;
	mad.lo.s32 	%r54, %r53, 1103515245, 12345;
	shr.u32 	%r55, %r53, 6;
	and.b32  	%r56, %r55, 2096128;
	bfe.u32 	%r57, %r54, 16, 10;
	or.b32  	%r58, %r57, %r56;
	mad.lo.s32 	%r59, %r54, 1103515245, 12345;
	shl.b32 	%r60, %r58, 10;
	bfe.u32 	%r61, %r59, 16, 10;
	or.b32  	%r62, %r60, %r61;
	st.global.u32 	[%rd2], %r59;
	rem.u32 	%r63, %r62, %r7;
	cvt.u64.u32 	%rd71, %r63;
	mul.wide.u32 	%rd72, %r63, 32;
	mov.u64 	%rd73, cbconstants;
	add.s64 	%rd23, %rd73, %rd72;
	mov.u64 	%rd74, cbconstant_sizes;
	add.s64 	%rd75, %rd74, %rd71;
	ld.global.u8 	%rs8, [%rd75];
	cvt.u32.u16 	%r64, %rs8;
	and.b32  	%r8, %r64, 255;
	setp.lt.u32 	%p33, %r8, %r10;
	@%p33 bra 	LBB27_70;
	bra.uni 	LBB27_68;
LBB27_70:
	cvt.u64.u16 	%rd76, %rs8;
	and.b64  	%rd24, %rd76, 255;
	sub.s32 	%r65, %r10, %r8;
	cvt.u64.u32 	%rd28, %r65;
	setp.eq.s32 	%p36, %r65, 0;
	mov.u64 	%rd204, 0;
	@%p36 bra 	LBB27_72;
LBB27_71:                               // %loadstoreloop18
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd81, %rd44, %rd204;
	mov.u16 	%rs10, 0;
	st.u8 	[%rd81], %rs10;
	add.s64 	%rd204, %rd204, 1;
	setp.lt.u64 	%p37, %rd204, %rd28;
	@%p37 bra 	LBB27_71;
LBB27_72:                               // %split17
	cvt.u64.u32 	%rd83, %r10;
	sub.s64 	%rd84, %rd83, %rd24;
	add.s64 	%rd31, %rd44, %rd84;
	setp.eq.s64 	%p38, %rd24, 0;
	mov.u64 	%rd205, 0;
	@%p38 bra 	LBB27_76;
LBB27_73:                               // %loop-memcpy-expansion20
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd85, %rd23, %rd205;
	ld.global.u8 	%rs11, [%rd85];
	add.s64 	%rd86, %rd31, %rd205;
	st.u8 	[%rd86], %rs11;
	add.s64 	%rd205, %rd205, 1;
	setp.lt.u64 	%p39, %rd205, %rd24;
	@%p39 bra 	LBB27_73;
	bra.uni 	LBB27_76;
LBB27_43:
	mad.lo.s32 	%r442, %r2, 1103515245, 12345;
	mad.lo.s32 	%r443, %r442, 1103515245, 12345;
	shr.u32 	%r444, %r442, 6;
	and.b32  	%r445, %r444, 2096128;
	bfe.u32 	%r446, %r443, 16, 10;
	or.b32  	%r447, %r446, %r445;
	mad.lo.s32 	%r448, %r443, 1103515245, 12345;
	shl.b32 	%r449, %r447, 10;
	bfe.u32 	%r450, %r448, 16, 10;
	or.b32  	%r451, %r449, %r450;
	st.global.u32 	[%rd2], %r448;
	rem.u32 	%r452, %r451, %r10;
	cvt.u64.u32 	%rd188, %r452;
	add.s64 	%rd189, %rd44, %rd188;
	ld.u8 	%rs35, [%rd189];
	neg.s16 	%rs36, %rs35;
	st.u8 	[%rd189], %rs36;
	bra.uni 	LBB27_76;
LBB27_56:
	setp.eq.s32 	%p50, %r10, 0;
	@%p50 bra 	LBB27_76;
// %bb.57:
	mad.lo.s32 	%r128, %r2, 1103515245, 12345;
	mad.lo.s32 	%r129, %r128, 1103515245, 12345;
	shr.u32 	%r130, %r128, 6;
	and.b32  	%r131, %r130, 2096128;
	bfe.u32 	%r132, %r129, 16, 10;
	or.b32  	%r133, %r132, %r131;
	mad.lo.s32 	%r134, %r129, 1103515245, 12345;
	shl.b32 	%r135, %r133, 10;
	bfe.u32 	%r136, %r134, 16, 10;
	or.b32  	%r137, %r135, %r136;
	rem.u32 	%r138, %r137, %r10;
	sub.s32 	%r139, %r10, %r138;
	min.u32 	%r140, %r139, 16;
	mad.lo.s32 	%r141, %r134, 1103515245, 12345;
	mad.lo.s32 	%r142, %r141, 1103515245, 12345;
	shr.u32 	%r143, %r141, 6;
	and.b32  	%r144, %r143, 2096128;
	bfe.u32 	%r145, %r142, 16, 10;
	or.b32  	%r146, %r145, %r144;
	mad.lo.s32 	%r147, %r142, 1103515245, 12345;
	shl.b32 	%r148, %r146, 10;
	bfe.u32 	%r149, %r147, 16, 10;
	or.b32  	%r150, %r148, %r149;
	rem.u32 	%r151, %r150, %r140;
	add.s32 	%r152, %r151, 1;
	cvt.u64.u32 	%rd4, %r152;
	mad.lo.s32 	%r153, %r147, 1103515245, 12345;
	mad.lo.s32 	%r154, %r153, 1103515245, 12345;
	shr.u32 	%r155, %r153, 6;
	and.b32  	%r156, %r155, 2096128;
	bfe.u32 	%r157, %r154, 16, 10;
	or.b32  	%r158, %r157, %r156;
	mad.lo.s32 	%r159, %r154, 1103515245, 12345;
	shl.b32 	%r160, %r158, 10;
	bfe.u32 	%r161, %r159, 16, 10;
	or.b32  	%r162, %r160, %r161;
	st.global.u32 	[%rd2], %r159;
	rem.u32 	%r163, %r162, %r10;
	cvt.u64.u32 	%rd102, %r163;
	add.s64 	%rd103, %rd44, %rd102;
	ld.u8 	%rs4, [%rd103];
	cvt.u64.u32 	%rd104, %r138;
	add.s64 	%rd5, %rd44, %rd104;
	setp.eq.s32 	%p51, %r152, 0;
	mov.u64 	%rd198, 0;
	@%p51 bra 	LBB27_76;
LBB27_58:                               // %loadstoreloop
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd105, %rd5, %rd198;
	st.u8 	[%rd105], %rs4;
	add.s64 	%rd198, %rd198, 1;
	setp.lt.u64 	%p52, %rd198, %rd4;
	@%p52 bra 	LBB27_58;
	bra.uni 	LBB27_76;
LBB27_45:
	add.s16 	%rs31, %rs2, %rs1;
	add.s16 	%rs32, %rs31, 1;
	st.u8 	[%rd3], %rs32;
	bra.uni 	LBB27_76;
LBB27_74:
	shl.b64 	%rd54, %rd34, 13;
	mov.u64 	%rd55, l2snaps;
	add.s64 	%rd56, %rd55, %rd54;
	shl.b64 	%rd57, %rd35, 6;
	add.s64 	%rd58, %rd56, %rd57;
	cvt.u64.u32 	%rd40, %r10;
	sub.s64 	%rd59, %rd58, %rd40;
	add.s64 	%rd41, %rd59, 32;
	setp.eq.s32 	%p28, %r10, 0;
	mov.u64 	%rd207, 0;
	@%p28 bra 	LBB27_76;
LBB27_75:                               // %loop-memcpy-expansion26
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd60, %rd41, %rd207;
	ld.global.u8 	%rs6, [%rd60];
	add.s64 	%rd61, %rd44, %rd207;
	st.u8 	[%rd61], %rs6;
	add.s64 	%rd207, %rd207, 1;
	setp.lt.u64 	%p29, %rd207, %rd40;
	@%p29 bra 	LBB27_75;
	bra.uni 	LBB27_76;
LBB27_68:
	cvt.u64.u32 	%rd25, %r10;
	setp.eq.s32 	%p34, %r10, 0;
	mov.u64 	%rd203, 0;
	@%p34 bra 	LBB27_76;
LBB27_69:                               // %loop-memcpy-expansion15
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd78, %rd23, %rd203;
	ld.global.u8 	%rs9, [%rd78];
	add.s64 	%rd79, %rd44, %rd203;
	st.u8 	[%rd79], %rs9;
	add.s64 	%rd203, %rd203, 1;
	setp.lt.u64 	%p35, %rd203, %rd25;
	@%p35 bra 	LBB27_69;
	bra.uni 	LBB27_76;
LBB27_27:
	add.s32 	%r182, %r10, -3;
	mad.lo.s32 	%r183, %r5, 1103515245, 12345;
	mad.lo.s32 	%r184, %r183, 1103515245, 12345;
	shr.u32 	%r185, %r183, 6;
	and.b32  	%r186, %r185, 2096128;
	bfe.u32 	%r187, %r184, 16, 10;
	or.b32  	%r188, %r187, %r186;
	mad.lo.s32 	%r189, %r184, 1103515245, 12345;
	shl.b32 	%r190, %r188, 10;
	bfe.u32 	%r191, %r189, 16, 10;
	or.b32  	%r192, %r190, %r191;
	st.global.u32 	[%rd2], %r189;
	rem.u32 	%r193, %r192, %r182;
	cvt.u64.u32 	%rd109, %r193;
	add.s64 	%rd110, %rd44, %rd109;
	shr.u32 	%r194, %r4, 24;
	st.u8 	[%rd110+3], %r194;
	shr.u32 	%r195, %r4, 16;
	st.u8 	[%rd110+2], %r195;
	shr.u32 	%r196, %r4, 8;
	st.u8 	[%rd110+1], %r196;
	st.u8 	[%rd110], %r4;
	bra.uni 	LBB27_76;
LBB27_53:
	add.s32 	%r230, %r10, -1;
	mad.lo.s32 	%r231, %r3, 1103515245, 12345;
	mad.lo.s32 	%r232, %r231, 1103515245, 12345;
	shr.u32 	%r233, %r231, 6;
	and.b32  	%r234, %r233, 2096128;
	bfe.u32 	%r235, %r232, 16, 10;
	or.b32  	%r236, %r235, %r234;
	mad.lo.s32 	%r237, %r232, 1103515245, 12345;
	shl.b32 	%r238, %r236, 10;
	bfe.u32 	%r239, %r237, 16, 10;
	or.b32  	%r240, %r238, %r239;
	st.global.u32 	[%rd2], %r237;
	rem.u32 	%r241, %r240, %r230;
	cvt.u64.u32 	%rd116, %r241;
	add.s64 	%rd117, %rd44, %rd116;
	shr.u16 	%rs15, %rs3, 8;
	st.u8 	[%rd117+1], %rs15;
	st.u8 	[%rd117], %rs3;
LBB27_76:
	ret;
                                        // -- End function
}
	// .globl	main_contract           // -- Begin function main_contract
.visible .func main_contract(
	.param .b64 main_contract_param_0,
	.param .b32 main_contract_param_1
)                                       // @main_contract
{
	.local .align 16 .b8 	__local_depot28[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<9>;
	.reg .b64 	%rd<27>;

// %bb.0:
	mov.u64 	%SPL, __local_depot28;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [main_contract_param_0];
	add.u64 	%rd2, %SP, 0;
	add.u64 	%rd3, %SPL, 0;
	add.u64 	%rd4, %SP, 32;
	add.u64 	%rd5, %SPL, 32;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	cvt.u64.u32 	%rd6, %r4;
	mov.u64 	%rd7, __hnbs;
	add.s64 	%rd8, %rd7, %rd6;
	mov.u16 	%rs1, 0;
	st.global.u8 	[%rd8], %rs1;
	shl.b32 	%r5, %r4, 11;
	cvt.u64.u32 	%rd9, %r5;
	add.s64 	%rd10, %rd1, %rd9;
	ld.global.u64 	%rd11, [%rd10+8];
	ld.global.u64 	%rd12, [%rd10];
	ld.global.u64 	%rd13, [%rd10+24];
	ld.global.u64 	%rd14, [%rd10+16];
	st.local.u64 	[%rd3+16], %rd14;
	st.local.u64 	[%rd3+24], %rd13;
	st.local.u64 	[%rd3], %rd12;
	st.local.u64 	[%rd3+8], %rd11;
	ld.global.u64 	%rd15, [%rd10+40];
	ld.global.u64 	%rd16, [%rd10+32];
	ld.global.u64 	%rd17, [%rd10+56];
	ld.global.u64 	%rd18, [%rd10+48];
	st.local.u64 	[%rd5+16], %rd18;
	st.local.u64 	[%rd5+24], %rd17;
	st.local.u64 	[%rd5], %rd16;
	st.local.u64 	[%rd5+8], %rd15;
	ld.global.u32 	%r6, [%rd10+64];
	add.s64 	%rd19, %rd10, 68;
	cvta.global.u64 	%rd20, %rd19;
	mov.u64 	%rd21, l1snap_lens;
	add.s64 	%rd22, %rd21, %rd6;
	st.global.u8 	[%rd22], %rs1;
	mul.wide.u32 	%rd23, %r4, 8;
	mov.u64 	%rd24, __bitmaps;
	add.s64 	%rd25, %rd24, %rd23;
	ld.global.u64 	%rd26, [%rd25];
	{ // callseq 86, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd2;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd20;
	.param .b32 param3;
	st.param.b32 	[param3+0], %r6;
	.param .b64 param4;
	st.param.b64 	[param4+0], %rd26;
	.param .b32 retval0;
	call.uni (retval0), 
	contract, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	ld.param.b32 	%r7, [retval0+0];
	} // callseq 86
	ret;
                                        // -- End function
}
