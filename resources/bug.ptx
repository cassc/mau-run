//
// Generated by LLVM NVPTX Back-End
//

.version 7.1
.target sm_86
.address_size 64

	// .globl	contract                // -- Begin function contract
.extern .func  (.param .b64 func_retval0) malloc
(
	.param .b64 malloc_param_0
)
;
.func evm_$_udiv_$_i256
(
	.param .b64 evm_$_udiv_$_i256_param_0,
	.param .b64 evm_$_udiv_$_i256_param_1,
	.param .b64 evm_$_udiv_$_i256_param_2
)
;
.extern .func free
(
	.param .b64 free_param_0
)
;
.func evm_$_udivrem_$_i256
(
	.param .b64 evm_$_udivrem_$_i256_param_0,
	.param .b64 evm_$_udivrem_$_i256_param_1,
	.param .b64 evm_$_udivrem_$_i256_param_2,
	.param .b64 evm_$_udivrem_$_i256_param_3
)
;
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.visible .func keccak256
(
	.param .b64 keccak256_param_0,
	.param .b32 keccak256_param_1,
	.param .b64 keccak256_param_2
)
;
.visible .func hash
(
	.param .b64 hash_param_0,
	.param .b64 hash_param_1,
	.param .b64 hash_param_2,
	.param .b64 hash_param_3,
	.param .b64 hash_param_4,
	.param .b32 hash_param_5
)
;
.visible .func __device_calldataload
(
	.param .b64 __device_calldataload_param_0,
	.param .b64 __device_calldataload_param_1,
	.param .b64 __device_calldataload_param_2
)
;
.visible .func __device_mstore
(
	.param .b64 __device_mstore_param_0,
	.param .b64 __device_mstore_param_1,
	.param .b64 __device_mstore_param_2,
	.param .b64 __device_mstore_param_3
)
;
.visible .func __device_mload
(
	.param .b64 __device_mload_param_0,
	.param .b64 __device_mload_param_1,
	.param .b64 __device_mload_param_2
)
;
.visible .func __device_sstore
(
	.param .b64 __device_sstore_param_0,
	.param .b64 __device_sstore_param_1
)
;
.visible .func __device_sload
(
	.param .b64 __device_sload_param_0,
	.param .b64 __device_sload_param_1
)
;
.visible .func  (.param .b32 func_retval0) __hashword
(
	.param .b64 __hashword_param_0
)
;
.visible .func mutateCaller
(
	.param .b64 mutateCaller_param_0
)
;
.visible .func mutateCallvalue
(
	.param .b64 mutateCallvalue_param_0
)
;
.visible .func mutateCalldata
(
	.param .b64 mutateCalldata_param_0,
	.param .b32 mutateCalldata_param_1
)
;
.visible .func cuhavoc
(
	.param .b64 cuhavoc_param_0,
	.param .b32 cuhavoc_param_1
)
;
.visible .const .align 1 .b8 __evmCode[32769] = {96, 128, 96, 64, 82, 52, 128, 21, 97, 0, 16, 87, 96, 0, 128, 253, 91, 80, 97, 3, 141, 128, 97, 0, 32, 96, 0, 57, 96, 0, 243, 0, 96, 128, 96, 64, 82, 96, 4, 54, 16, 97, 0, 142, 87, 96, 0, 53, 124, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 144, 4, 99, 255, 255, 255, 255, 22, 128, 99, 38, 74, 251, 125, 20, 97, 0, 147, 87, 128, 99, 55, 92, 88, 176, 20, 97, 0, 222, 87, 128, 99, 60, 131, 7, 19, 20, 97, 1, 41, 87, 128, 99, 70, 137, 45, 99, 20, 97, 1, 116, 87, 128, 99, 101, 55, 33, 71, 20, 97, 1, 191, 87, 128, 99, 176, 17, 82, 226, 20, 97, 1, 234, 87, 128, 99, 192, 67, 162, 84, 20, 97, 2, 53, 87, 128, 99, 255, 205, 136, 59, 20, 97, 2, 96, 87, 91, 96, 0, 128, 253, 91, 52, 128, 21, 97, 0, 159, 87, 96, 0, 128, 253, 91, 80, 97, 0, 200, 96, 4, 128, 54, 3, 129, 1, 144, 128, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 80, 80, 80, 97, 2, 171, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 52, 128, 21, 97, 0, 234, 87, 96, 0, 128, 253, 91, 80, 97, 1, 19, 96, 4, 128, 54, 3, 129, 1, 144, 128, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 80, 80, 80, 97, 2, 193, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 52, 128, 21, 97, 1, 53, 87, 96, 0, 128, 253, 91, 80, 97, 1, 94, 96, 4, 128, 54, 3, 129, 1, 144, 128, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 80, 80, 80, 97, 2, 215, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 52, 128, 21, 97, 1, 128, 87, 96, 0, 128, 253, 91, 80, 97, 1, 169, 96, 4, 128, 54, 3, 129, 1, 144, 128, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 80, 80, 80, 97, 2, 237, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 52, 128, 21, 97, 1, 203, 87, 96, 0, 128, 253, 91, 80, 97, 1, 212, 97, 3, 3, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 52, 128, 21, 97, 1, 246, 87, 96, 0, 128, 253, 91, 80, 97, 2, 31, 96, 4, 128, 54, 3, 129, 1, 144, 128, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 80, 80, 80, 97, 3, 9, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 52, 128, 21, 97, 2, 65, 87, 96, 0, 128, 253, 91, 80, 97, 2, 74, 97, 3, 31, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 52, 128, 21, 97, 2, 108, 87, 96, 0, 128, 253, 91, 80, 97, 2, 149, 96, 4, 128, 54, 3, 129, 1, 144, 128, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 128, 53, 144, 96, 32, 1, 144, 146, 145, 144, 80, 80, 80, 97, 3, 37, 86, 91, 96, 64, 81, 128, 130, 129, 82, 96, 32, 1, 145, 80, 80, 96, 64, 81, 128, 145, 3, 144, 243, 91, 96, 0, 129, 131, 2, 96, 0, 129, 144, 85, 80, 96, 0, 84, 144, 80, 146, 145, 80, 80, 86, 91, 96, 0, 129, 131, 1, 96, 1, 129, 144, 85, 80, 96, 1, 84, 144, 80, 146, 145, 80, 80, 86, 91, 96, 0, 129, 131, 3, 96, 1, 129, 144, 85, 80, 96, 1, 84, 144, 80, 146, 145, 80, 80, 86, 91, 96, 0, 129, 131, 1, 96, 0, 129, 144, 85, 80, 96, 0, 84, 144, 80, 146, 145, 80, 80, 86, 91, 96, 0, 84, 129, 86, 91, 96, 0, 129, 131, 3, 96, 0, 129, 144, 85, 80, 96, 0, 84, 144, 80, 146, 145, 80, 80, 86, 91, 96, 1, 84, 129, 86, 91, 96, 0, 128, 96, 0, 96, 1, 145, 80, 96, 0, 144, 80, 91, 131, 129, 16, 21, 97, 3, 77, 87, 132, 130, 2, 145, 80, 128, 128, 96, 1, 1, 145, 80, 80, 97, 3, 51, 86, 91, 129, 96, 0, 129, 144, 85, 80, 96, 0, 84, 146, 80, 80, 80, 146, 145, 80, 80, 86, 0, 161, 101, 98, 122, 122, 114, 48, 88, 32, 130, 29, 120, 182, 84, 23, 206, 112, 126, 35, 40, 11, 74, 157, 174, 222, 197, 242, 111, 82, 199, 31, 211, 109, 208, 231, 224, 22, 84, 84, 237, 176, 0, 41, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
.visible .const .align 4 .u32 __evmCodeSize = 941;
.global .align 1 .b8 __const_$_printbytes_$_hexmap[16] = {48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 97, 98, 99, 100, 101, 102};
.global .align 1 .b8 _$_str[19] = {37, 115, 46, 32, 104, 101, 120, 32, 98, 121, 116, 101, 115, 58, 32, 37, 115, 10, 0};
.visible .const .align 8 .u64 cuTimestamp;
.visible .global .align 8 .u64 __signals;
.visible .global .align 1 .b8 __hnbs[1024];
.extern .global .align 8 .b8 l1snaps[8388608];
.extern .global .align 1 .b8 l1snap_lens[1024];
// count_class_lookup8 has been demoted
.visible .global .align 1 .b8 __virgin_bits[4096];
.visible .global .align 8 .b8 __bitmaps[8192];
.global .align 1 .b8 _$_str1[48] = {98, 117, 103, 59, 32, 116, 97, 114, 103, 101, 116, 32, 104, 105, 116, 32, 97, 116, 32, 116, 104, 114, 101, 97, 100, 35, 37, 100, 46, 32, 95, 95, 104, 110, 98, 115, 91, 116, 105, 100, 93, 32, 61, 32, 37, 100, 10, 0};
.visible .global .align 1 .b8 __cov_bits[4096];
.global .align 8 .b8 RC[192] = {1, 0, 0, 0, 0, 0, 0, 0, 130, 128, 0, 0, 0, 0, 0, 0, 138, 128, 0, 0, 0, 0, 0, 128, 0, 128, 0, 128, 0, 0, 0, 128, 139, 128, 0, 0, 0, 0, 0, 0, 1, 0, 0, 128, 0, 0, 0, 0, 129, 128, 0, 128, 0, 0, 0, 128, 9, 128, 0, 0, 0, 0, 0, 128, 138, 0, 0, 0, 0, 0, 0, 0, 136, 0, 0, 0, 0, 0, 0, 0, 9, 128, 0, 128, 0, 0, 0, 0, 10, 0, 0, 128, 0, 0, 0, 0, 139, 128, 0, 128, 0, 0, 0, 0, 139, 0, 0, 0, 0, 0, 0, 128, 137, 128, 0, 0, 0, 0, 0, 128, 3, 128, 0, 0, 0, 0, 0, 128, 2, 128, 0, 0, 0, 0, 0, 128, 128, 0, 0, 0, 0, 0, 0, 128, 10, 128, 0, 0, 0, 0, 0, 0, 10, 0, 0, 128, 0, 0, 0, 128, 129, 128, 0, 128, 0, 0, 0, 128, 128, 128, 0, 0, 0, 0, 0, 128, 1, 0, 0, 128, 0, 0, 0, 0, 8, 128, 0, 128, 0, 0, 0, 128};
.visible .global .align 4 .b8 cuda_states[4096];
.visible .global .align 4 .u32 cbconstants_length;
.visible .global .align 4 .u32 callers_pool_len;
.visible .global .align 4 .u32 addresses_pool_len;
.visible .global .align 1 .b8 addresses_pool[2048];
.visible .global .align 1 .b8 callers_pool[2048];
.visible .global .align 1 .b8 argTypeMap[64];
.const .align 1 .b8 interesting_8[9] = {128, 255, 0, 1, 16, 32, 64, 100, 127};
.const .align 2 .b8 interesting_16[38] = {128, 255, 255, 255, 0, 0, 1, 0, 16, 0, 32, 0, 64, 0, 100, 0, 127, 0, 0, 128, 127, 255, 128, 0, 255, 0, 0, 1, 0, 2, 232, 3, 0, 4, 0, 16, 255, 127};
.const .align 4 .b8 interesting_32[108] = {128, 255, 255, 255, 255, 255, 255, 255, 0, 0, 0, 0, 1, 0, 0, 0, 16, 0, 0, 0, 32, 0, 0, 0, 64, 0, 0, 0, 100, 0, 0, 0, 127, 0, 0, 0, 0, 128, 255, 255, 127, 255, 255, 255, 128, 0, 0, 0, 255, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 232, 3, 0, 0, 0, 4, 0, 0, 0, 16, 0, 0, 255, 127, 0, 0, 0, 0, 0, 128, 250, 0, 0, 250, 255, 127, 255, 255, 0, 128, 0, 0, 255, 255, 0, 0, 0, 0, 1, 0, 5, 255, 255, 5, 255, 255, 255, 127};
.visible .global .align 1 .b8 cbconstants[65536];
.visible .global .align 1 .b8 cbconstant_sizes[2048];
.extern .global .align 4 .b8 __snap_map[4096];
.extern .global .align 1 .b8 l2snap_lens[32768];
.extern .global .align 8 .b8 l2snaps[268435456];
                                        // @contract
.visible .func  (.param .b32 func_retval0) contract(
	.param .b64 contract_param_0,
	.param .b64 contract_param_1,
	.param .b64 contract_param_2,
	.param .b32 contract_param_3,
	.param .b64 contract_param_4
)
{
	.local .align 8 .b8 	__local_depot0[2208];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<206>;
	.reg .b16 	%rs<61>;
	.reg .b32 	%r<486>;
	.reg .b64 	%rd<1342>;

// %bb.0:                               // %Entry
	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd126, [contract_param_4];
	mov.u64 	%rd128, 728;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd128;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd129, [retval0+0];
	} // callseq 0
	mov.u64 	%rd130, 8192;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd130;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd131, [retval0+0];
	} // callseq 1
	ld.param.u32 	%r179, [contract_param_3];
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd126+1383], %rs1;
	add.u64 	%rd132, %SP, 0;
	add.u64 	%rd133, %SPL, 0;
	mov.u64 	%rd134, 0;
	st.local.u32 	[%rd133+28], %rd134;
	st.local.u32 	[%rd133+24], %rd134;
	st.local.u32 	[%rd133+20], %rd134;
	st.local.u32 	[%rd133+16], %rd134;
	st.local.u32 	[%rd133+12], %rd134;
	st.local.u32 	[%rd133+8], %rd134;
	st.local.u32 	[%rd133+4], %rd134;
	mov.u64 	%rd135, 128;
	st.local.u32 	[%rd133], %rd135;
	mov.u64 	%rd136, 64;
	mov.u64 	%rd137, 32;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd132;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 2
	setp.lt.u32 	%p1, %r179, 4;
	mov.u64 	%rd121, 209912;
	mov.u32 	%r171, 691;
	@%p1 bra 	$L__BB0_9;
	bra.uni 	$L__BB0_1;
$L__BB0_9:                              // %.142
	setp.lt.u64 	%p205, %rd121, 16;
	@%p205 bra 	$L__BB0_147;
// %bb.10:
	xor.b32  	%r311, %r171, 3277;
	and.b32  	%r312, %r311, 4095;
	cvt.u64.u32 	%rd1281, %r312;
	add.s64 	%rd1282, %rd126, %rd1281;
	st.global.u8 	[%rd1282], %rs1;
$L__BB0_147:                            // %Abort
	{ // callseq 71, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 71
	{ // callseq 72, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd131;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 72
	mov.u32 	%r313, 0;
	st.param.b32 	[func_retval0+0], %r313;
	ret;
$L__BB0_1:                              // %.13
	ld.param.u64 	%rd125, [contract_param_2];
	ld.param.u64 	%rd124, [contract_param_1];
	mov.u32 	%r173, 0;
	st.global.u8 	[%rd126+373], %rs1;
	add.u64 	%rd140, %SP, 32;
	add.u64 	%rd141, %SPL, 32;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd140;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd134;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 3
	ld.local.u32 	%rd142, [%rd141+20];
	ld.local.u32 	%rd143, [%rd141+16];
	ld.local.u32 	%rd144, [%rd141+12];
	ld.local.u32 	%rd145, [%rd141+8];
	ld.local.u32 	%rd146, [%rd141+4];
	ld.local.u32 	%rd147, [%rd141];
	ld.local.u32 	%rd148, [%rd141+28];
	ld.local.u32 	%rd149, [%rd141+24];
	add.u64 	%rd150, %SP, 64;
	add.u64 	%rd151, %SPL, 64;
	st.local.u32 	[%rd151+24], %rd149;
	st.local.u32 	[%rd151+28], %rd148;
	st.local.u32 	[%rd151], %rd147;
	st.local.u32 	[%rd151+4], %rd146;
	st.local.u32 	[%rd151+8], %rd145;
	st.local.u32 	[%rd151+12], %rd144;
	st.local.u32 	[%rd151+16], %rd143;
	st.local.u32 	[%rd151+20], %rd142;
	add.u64 	%rd152, %SP, 96;
	add.u64 	%rd153, %SPL, 96;
	st.local.u32 	[%rd153+16], %rd134;
	st.local.u32 	[%rd153+20], %rd134;
	st.local.u32 	[%rd153+24], %rd134;
	mov.u64 	%rd122, 1;
	st.local.u32 	[%rd153+28], %rd122;
	st.local.u32 	[%rd153], %rd134;
	st.local.u32 	[%rd153+4], %rd134;
	st.local.u32 	[%rd153+8], %rd134;
	st.local.u32 	[%rd153+12], %rd134;
	add.u64 	%rd154, %SP, 128;
	add.u64 	%rd155, %SPL, 128;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd150;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd152;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd154;
	call.uni 
	evm_$_udiv_$_i256, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 4
	ld.local.u32 	%rd3, [%rd155];
	setp.eq.s64 	%p2, %rd3, 642448253;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd121, 209720;
	mov.u32 	%r171, 483;
	mov.u64 	%rd1283, 4;
	mov.u64 	%rd1284, 36;
	mov.u32 	%r174, %r173;
	mov.u32 	%r175, %r173;
	mov.u32 	%r176, %r173;
	mov.u32 	%r177, %r173;
	@%p2 bra 	$L__BB0_11;
	bra.uni 	$L__BB0_2;
$L__BB0_11:                             // %.147
	setp.lt.u64 	%p10, %rd121, 96;
	@%p10 bra 	$L__BB0_147;
// %bb.12:
	xor.b32  	%r197, %r171, 2234;
	and.b32  	%r198, %r197, 4095;
	cvt.u64.u32 	%rd177, %r198;
	add.s64 	%rd178, %rd126, %rd177;
	st.global.u8 	[%rd178], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd179, [%rd124+16];
	ld.u32 	%rd180, [%rd124];
	ld.u32 	%rd181, [%rd124+20];
	ld.u32 	%rd182, [%rd124+4];
	ld.u32 	%rd183, [%rd124+24];
	ld.u32 	%rd184, [%rd124+8];
	ld.u32 	%rd185, [%rd124+28];
	ld.u32 	%rd186, [%rd124+12];
	or.b64  	%rd187, %rd186, %rd185;
	shl.b64 	%rd188, %rd187, 32;
	or.b64  	%rd189, %rd188, %rd184;
	or.b64  	%rd190, %rd189, %rd183;
	or.b64  	%rd191, %rd182, %rd181;
	shl.b64 	%rd192, %rd191, 32;
	or.b64  	%rd193, %rd192, %rd180;
	or.b64  	%rd194, %rd193, %rd179;
	or.b64  	%rd195, %rd194, %rd190;
	setp.eq.s64 	%p11, %rd195, 0;
	add.s64 	%rd1289, %rd122, 1;
	shl.b64 	%rd196, %rd122, 5;
	add.s64 	%rd197, %rd131, %rd196;
	st.u32 	[%rd197+48], %rd179;
	st.u32 	[%rd197+52], %rd181;
	st.u32 	[%rd197+56], %rd183;
	st.u32 	[%rd197+60], %rd185;
	st.u32 	[%rd197+32], %rd180;
	st.u32 	[%rd197+36], %rd182;
	st.u32 	[%rd197+40], %rd184;
	st.u32 	[%rd197+44], %rd186;
	mov.u32 	%r171, 1117;
	@%p11 bra 	$L__BB0_15;
	bra.uni 	$L__BB0_13;
$L__BB0_15:                             // %.159
	setp.lt.u64 	%p13, %rd121, 336;
	@%p13 bra 	$L__BB0_147;
// %bb.16:
	xor.b32  	%r200, %r171, 498;
	and.b32  	%r201, %r200, 4095;
	cvt.u64.u32 	%rd198, %r201;
	add.s64 	%rd199, %rd126, %rd198;
	st.global.u8 	[%rd199], %rs1;
	add.s64 	%rd121, %rd121, -336;
	shl.b64 	%rd200, %rd1289, 5;
	add.s64 	%rd201, %rd131, %rd200;
	add.u64 	%rd202, %SP, 160;
	add.u64 	%rd203, %SPL, 160;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd202;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1283;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 5
	ld.local.u32 	%rd205, [%rd203+12];
	ld.local.u32 	%rd206, [%rd203+8];
	ld.local.u32 	%rd207, [%rd203+4];
	ld.local.u32 	%rd208, [%rd203];
	ld.local.u32 	%rd209, [%rd203+28];
	ld.local.u32 	%rd210, [%rd203+24];
	ld.local.u32 	%rd211, [%rd203+20];
	ld.local.u32 	%rd212, [%rd203+16];
	add.u64 	%rd213, %SP, 192;
	add.u64 	%rd214, %SPL, 192;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd213;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1284;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 6
	ld.local.u32 	%rd216, [%rd214+12];
	ld.local.u32 	%rd217, [%rd214+8];
	ld.local.u32 	%rd218, [%rd214+4];
	ld.local.u32 	%rd219, [%rd214];
	ld.local.u32 	%rd220, [%rd214+28];
	ld.local.u32 	%rd221, [%rd214+24];
	ld.local.u32 	%rd222, [%rd214+20];
	ld.local.u32 	%rd223, [%rd214+16];
	st.u32 	[%rd201+16], %rd134;
	st.u32 	[%rd201+20], %rd134;
	st.u32 	[%rd201+24], %rd134;
	st.u32 	[%rd201+28], %rd134;
	mov.u64 	%rd225, 200;
	st.u32 	[%rd201], %rd225;
	st.u32 	[%rd201+4], %rd134;
	st.u32 	[%rd201+8], %rd134;
	st.u32 	[%rd201+12], %rd134;
	add.s64 	%rd122, %rd1289, 2;
	st.u32 	[%rd201+48], %rd212;
	st.u32 	[%rd201+52], %rd211;
	st.u32 	[%rd201+56], %rd210;
	st.u32 	[%rd201+60], %rd209;
	st.u32 	[%rd201+32], %rd208;
	st.u32 	[%rd201+36], %rd207;
	st.u32 	[%rd201+40], %rd206;
	st.u32 	[%rd201+44], %rd205;
	st.u32 	[%rd201+80], %rd223;
	st.u32 	[%rd201+84], %rd222;
	st.u32 	[%rd201+88], %rd221;
	st.u32 	[%rd201+92], %rd220;
	st.u32 	[%rd201+64], %rd219;
	st.u32 	[%rd201+68], %rd218;
	st.u32 	[%rd201+72], %rd217;
	st.u32 	[%rd201+76], %rd216;
	mov.u32 	%r171, 249;
$L__BB0_17:                             // %.683
	setp.lt.u64 	%p14, %rd121, 312;
	@%p14 bra 	$L__BB0_147;
// %bb.18:
	xor.b32  	%r203, %r171, 261;
	and.b32  	%r204, %r203, 4095;
	cvt.u64.u32 	%rd226, %r204;
	add.s64 	%rd227, %rd126, %rd226;
	st.global.u8 	[%rd227], %rs1;
	add.s64 	%rd121, %rd121, -312;
	shl.b64 	%rd228, %rd122, 5;
	add.s64 	%rd229, %rd131, %rd228;
	ld.u32 	%rd230, [%rd229+24];
	ld.u32 	%rd231, [%rd229+28];
	shl.b64 	%rd232, %rd231, 32;
	or.b64  	%rd233, %rd232, %rd230;
	ld.u32 	%rd234, [%rd229+16];
	ld.u32 	%rd235, [%rd229+20];
	shl.b64 	%rd236, %rd235, 32;
	or.b64  	%rd237, %rd236, %rd234;
	ld.u32 	%rd238, [%rd229+8];
	ld.u32 	%rd239, [%rd229+12];
	shl.b64 	%rd240, %rd239, 32;
	or.b64  	%rd241, %rd240, %rd238;
	ld.u32 	%rd242, [%rd229];
	ld.u32 	%rd243, [%rd229+4];
	shl.b64 	%rd244, %rd243, 32;
	or.b64  	%rd245, %rd244, %rd242;
	ld.u32 	%rd246, [%rd229+-16];
	ld.u32 	%rd247, [%rd229+-12];
	shl.b64 	%rd248, %rd247, 32;
	or.b64  	%rd249, %rd248, %rd246;
	ld.u32 	%rd250, [%rd229+-8];
	ld.u32 	%rd251, [%rd229+-4];
	shl.b64 	%rd252, %rd251, 32;
	or.b64  	%rd253, %rd252, %rd250;
	ld.u32 	%rd254, [%rd229+-24];
	ld.u32 	%rd255, [%rd229+-20];
	shl.b64 	%rd256, %rd255, 32;
	or.b64  	%rd257, %rd256, %rd254;
	ld.u32 	%rd258, [%rd229+-32];
	ld.u32 	%rd259, [%rd229+-28];
	shl.b64 	%rd260, %rd259, 32;
	or.b64  	%rd261, %rd260, %rd258;
	add.s64 	%rd122, %rd122, -2;
	ld.u32 	%rd262, [%rd229+-64];
	ld.u32 	%rd263, [%rd229+-60];
	shl.b64 	%rd264, %rd263, 32;
	or.b64  	%rd123, %rd264, %rd262;
	mul.hi.u64 	%rd265, %rd261, %rd245;
	mul.lo.s64 	%rd266, %rd257, %rd245;
	mul.hi.u64 	%rd267, %rd257, %rd245;
	add.cc.s64 	%rd268, %rd266, %rd265;
	addc.cc.s64 	%rd269, %rd267, 0;
	mul.lo.s64 	%rd270, %rd261, %rd241;
	mul.hi.u64 	%rd271, %rd261, %rd241;
	add.cc.s64 	%rd272, %rd270, %rd268;
	addc.cc.s64 	%rd273, %rd271, 0;
	add.cc.s64 	%rd275, %rd269, %rd273;
	addc.cc.s64 	%rd276, %rd134, 0;
	mul.lo.s64 	%rd277, %rd257, %rd241;
	mul.hi.u64 	%rd278, %rd257, %rd241;
	add.cc.s64 	%rd279, %rd277, %rd275;
	addc.cc.s64 	%rd280, %rd278, %rd276;
	mul.lo.s64 	%rd281, %rd245, %rd253;
	mul.hi.u64 	%rd282, %rd245, %rd249;
	add.s64 	%rd283, %rd282, %rd281;
	mul.lo.s64 	%rd284, %rd241, %rd249;
	add.s64 	%rd285, %rd283, %rd284;
	mul.lo.s64 	%rd286, %rd237, %rd257;
	mul.hi.u64 	%rd287, %rd237, %rd261;
	add.s64 	%rd288, %rd287, %rd286;
	mul.lo.s64 	%rd289, %rd233, %rd261;
	add.s64 	%rd290, %rd288, %rd289;
	mul.lo.s64 	%rd291, %rd245, %rd249;
	mul.lo.s64 	%rd292, %rd237, %rd261;
	add.cc.s64 	%rd293, %rd292, %rd291;
	addc.cc.s64 	%rd294, %rd290, %rd285;
	add.cc.s64 	%rd295, %rd279, %rd293;
	addc.cc.s64 	%rd296, %rd280, %rd294;
	mul.lo.s64 	%rd297, %rd261, %rd245;
	add.u64 	%rd298, %SP, 1312;
	add.u64 	%rd299, %SPL, 1312;
	st.local.u32 	[%rd299+24], %rd134;
	st.local.u32 	[%rd299+28], %rd134;
	st.local.u32 	[%rd299], %rd134;
	st.local.u32 	[%rd299+4], %rd134;
	st.local.u32 	[%rd299+8], %rd134;
	st.local.u32 	[%rd299+12], %rd134;
	st.local.u32 	[%rd299+16], %rd134;
	st.local.u32 	[%rd299+20], %rd134;
	add.u64 	%rd300, %SP, 1344;
	add.u64 	%rd301, %SPL, 1344;
	st.local.u32 	[%rd301], %rd297;
	shr.u64 	%rd302, %rd297, 32;
	st.local.u32 	[%rd301+4], %rd302;
	st.local.u32 	[%rd301+8], %rd272;
	shr.u64 	%rd303, %rd272, 32;
	st.local.u32 	[%rd301+12], %rd303;
	st.local.u32 	[%rd301+16], %rd295;
	st.local.u32 	[%rd301+24], %rd296;
	shr.u64 	%rd304, %rd295, 32;
	st.local.u32 	[%rd301+20], %rd304;
	shr.u64 	%rd305, %rd296, 32;
	st.local.u32 	[%rd301+28], %rd305;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd298;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd300;
	call.uni 
	__device_sstore, 
	(
	param0, 
	param1
	);
	} // callseq 7
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd298;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r172, [retval0+0];
	} // callseq 8
	add.u64 	%rd306, %SP, 1376;
	add.u64 	%rd307, %SPL, 1376;
	st.local.u32 	[%rd307+28], %rd134;
	st.local.u32 	[%rd307+24], %rd134;
	st.local.u32 	[%rd307+20], %rd134;
	st.local.u32 	[%rd307+16], %rd134;
	st.local.u32 	[%rd307+12], %rd134;
	st.local.u32 	[%rd307+8], %rd134;
	st.local.u32 	[%rd307+4], %rd134;
	st.local.u32 	[%rd307], %rd134;
	add.u64 	%rd308, %SP, 1408;
	add.u64 	%rd309, %SPL, 1408;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd306;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd308;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 9
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd306;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r206, [retval0+0];
	} // callseq 10
	setp.eq.s32 	%p15, %r206, %r172;
	setp.eq.s32 	%p16, %r206, %r173;
	or.pred  	%p17, %p15, %p16;
	setp.eq.s32 	%p18, %r206, %r174;
	or.pred  	%p19, %p17, %p18;
	setp.eq.s32 	%p20, %r206, %r175;
	or.pred  	%p21, %p19, %p20;
	setp.eq.s32 	%p22, %r206, %r176;
	or.pred  	%p23, %p21, %p22;
	setp.eq.s32 	%p24, %r206, %r177;
	or.pred  	%p25, %p23, %p24;
	selp.u16 	%rs14, 1, 0, %p25;
	st.global.u8 	[%rd126], %rs14;
	ld.local.u32 	%rd310, [%rd309+12];
	ld.local.u32 	%rd311, [%rd309+8];
	ld.local.u32 	%rd312, [%rd309+4];
	ld.local.u32 	%rd313, [%rd309];
	ld.local.u32 	%rd314, [%rd309+28];
	ld.local.u32 	%rd315, [%rd309+24];
	ld.local.u32 	%rd316, [%rd309+20];
	ld.local.u32 	%rd317, [%rd309+16];
	st.u32 	[%rd229+-48], %rd317;
	st.u32 	[%rd229+-44], %rd316;
	st.u32 	[%rd229+-40], %rd315;
	st.u32 	[%rd229+-36], %rd314;
	st.u32 	[%rd229+-64], %rd313;
	st.u32 	[%rd229+-60], %rd312;
	st.u32 	[%rd229+-56], %rd311;
	st.u32 	[%rd229+-52], %rd310;
	mov.u32 	%r171, 130;
	bra.uni 	$L__BB0_98;
$L__BB0_2:                              // %.65
	st.global.u8 	[%rd126+2442], %rs1;
	setp.eq.s64 	%p3, %rd3, 928798896;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd122, 1;
	mov.u64 	%rd121, 209608;
	mov.u32 	%r172, 0;
	mov.u32 	%r171, 1076;
	mov.u32 	%r174, %r172;
	mov.u32 	%r175, %r172;
	mov.u32 	%r176, %r172;
	mov.u32 	%r177, %r172;
	@%p3 bra 	$L__BB0_21;
	bra.uni 	$L__BB0_3;
$L__BB0_21:                             // %.222
	setp.lt.u64 	%p189, %rd121, 96;
	@%p189 bra 	$L__BB0_147;
// %bb.22:
	xor.b32  	%r300, %r171, 2531;
	and.b32  	%r301, %r300, 4095;
	cvt.u64.u32 	%rd1167, %r301;
	add.s64 	%rd1168, %rd126, %rd1167;
	st.global.u8 	[%rd1168], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd1169, [%rd124+16];
	ld.u32 	%rd1170, [%rd124];
	ld.u32 	%rd1171, [%rd124+20];
	ld.u32 	%rd1172, [%rd124+4];
	ld.u32 	%rd1173, [%rd124+24];
	ld.u32 	%rd1174, [%rd124+8];
	ld.u32 	%rd1175, [%rd124+28];
	ld.u32 	%rd1176, [%rd124+12];
	or.b64  	%rd1177, %rd1176, %rd1175;
	shl.b64 	%rd1178, %rd1177, 32;
	or.b64  	%rd1179, %rd1178, %rd1174;
	or.b64  	%rd1180, %rd1179, %rd1173;
	or.b64  	%rd1181, %rd1172, %rd1171;
	shl.b64 	%rd1182, %rd1181, 32;
	or.b64  	%rd1183, %rd1182, %rd1170;
	or.b64  	%rd1184, %rd1183, %rd1169;
	or.b64  	%rd1185, %rd1184, %rd1180;
	setp.eq.s64 	%p190, %rd1185, 0;
	add.s64 	%rd1293, %rd122, 1;
	shl.b64 	%rd1186, %rd122, 5;
	add.s64 	%rd1187, %rd131, %rd1186;
	st.u32 	[%rd1187+48], %rd1169;
	st.u32 	[%rd1187+52], %rd1171;
	st.u32 	[%rd1187+56], %rd1173;
	st.u32 	[%rd1187+60], %rd1175;
	st.u32 	[%rd1187+32], %rd1170;
	st.u32 	[%rd1187+36], %rd1172;
	st.u32 	[%rd1187+40], %rd1174;
	st.u32 	[%rd1187+44], %rd1176;
	mov.u32 	%r171, 1265;
	@%p190 bra 	$L__BB0_25;
	bra.uni 	$L__BB0_23;
$L__BB0_25:                             // %.234
	setp.lt.u64 	%p192, %rd121, 336;
	@%p192 bra 	$L__BB0_147;
// %bb.26:
	xor.b32  	%r303, %r171, 124;
	and.b32  	%r304, %r303, 4095;
	cvt.u64.u32 	%rd1188, %r304;
	add.s64 	%rd1189, %rd126, %rd1188;
	st.global.u8 	[%rd1189], %rs1;
	add.s64 	%rd121, %rd121, -336;
	shl.b64 	%rd1190, %rd1293, 5;
	add.s64 	%rd1191, %rd131, %rd1190;
	add.u64 	%rd1192, %SP, 320;
	add.u64 	%rd1193, %SPL, 320;
	{ // callseq 65, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1192;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1283;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 65
	ld.local.u32 	%rd1195, [%rd1193+12];
	ld.local.u32 	%rd1196, [%rd1193+8];
	ld.local.u32 	%rd1197, [%rd1193+4];
	ld.local.u32 	%rd1198, [%rd1193];
	ld.local.u32 	%rd1199, [%rd1193+28];
	ld.local.u32 	%rd1200, [%rd1193+24];
	ld.local.u32 	%rd1201, [%rd1193+20];
	ld.local.u32 	%rd1202, [%rd1193+16];
	add.u64 	%rd1203, %SP, 352;
	add.u64 	%rd1204, %SPL, 352;
	{ // callseq 66, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1203;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1284;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 66
	ld.local.u32 	%rd1206, [%rd1204+12];
	ld.local.u32 	%rd1207, [%rd1204+8];
	ld.local.u32 	%rd1208, [%rd1204+4];
	ld.local.u32 	%rd1209, [%rd1204];
	ld.local.u32 	%rd1210, [%rd1204+28];
	ld.local.u32 	%rd1211, [%rd1204+24];
	ld.local.u32 	%rd1212, [%rd1204+20];
	ld.local.u32 	%rd1213, [%rd1204+16];
	st.u32 	[%rd1191+16], %rd134;
	st.u32 	[%rd1191+20], %rd134;
	st.u32 	[%rd1191+24], %rd134;
	st.u32 	[%rd1191+28], %rd134;
	mov.u64 	%rd1215, 275;
	st.u32 	[%rd1191], %rd1215;
	st.u32 	[%rd1191+4], %rd134;
	st.u32 	[%rd1191+8], %rd134;
	st.u32 	[%rd1191+12], %rd134;
	add.s64 	%rd122, %rd1293, 2;
	st.u32 	[%rd1191+48], %rd1202;
	st.u32 	[%rd1191+52], %rd1201;
	st.u32 	[%rd1191+56], %rd1200;
	st.u32 	[%rd1191+60], %rd1199;
	st.u32 	[%rd1191+32], %rd1198;
	st.u32 	[%rd1191+36], %rd1197;
	st.u32 	[%rd1191+40], %rd1196;
	st.u32 	[%rd1191+44], %rd1195;
	st.u32 	[%rd1191+80], %rd1213;
	st.u32 	[%rd1191+84], %rd1212;
	st.u32 	[%rd1191+88], %rd1211;
	st.u32 	[%rd1191+92], %rd1210;
	st.u32 	[%rd1191+64], %rd1209;
	st.u32 	[%rd1191+68], %rd1208;
	st.u32 	[%rd1191+72], %rd1207;
	st.u32 	[%rd1191+76], %rd1206;
	mov.u32 	%r171, 62;
$L__BB0_27:                             // %.705
	setp.lt.u64 	%p193, %rd121, 312;
	@%p193 bra 	$L__BB0_147;
// %bb.28:
	xor.b32  	%r306, %r171, 791;
	and.b32  	%r307, %r306, 4095;
	cvt.u64.u32 	%rd1216, %r307;
	add.s64 	%rd1217, %rd126, %rd1216;
	st.global.u8 	[%rd1217], %rs1;
	add.s64 	%rd121, %rd121, -312;
	shl.b64 	%rd1218, %rd122, 5;
	add.s64 	%rd1219, %rd131, %rd1218;
	ld.u32 	%rd1220, [%rd1219];
	ld.u32 	%rd1221, [%rd1219+4];
	shl.b64 	%rd1222, %rd1221, 32;
	or.b64  	%rd1223, %rd1222, %rd1220;
	ld.u32 	%rd1224, [%rd1219+8];
	ld.u32 	%rd1225, [%rd1219+12];
	shl.b64 	%rd1226, %rd1225, 32;
	or.b64  	%rd1227, %rd1226, %rd1224;
	ld.u32 	%rd1228, [%rd1219+16];
	ld.u32 	%rd1229, [%rd1219+20];
	shl.b64 	%rd1230, %rd1229, 32;
	or.b64  	%rd1231, %rd1230, %rd1228;
	ld.u32 	%rd1232, [%rd1219+24];
	ld.u32 	%rd1233, [%rd1219+28];
	shl.b64 	%rd1234, %rd1233, 32;
	or.b64  	%rd1235, %rd1234, %rd1232;
	ld.u32 	%rd1236, [%rd1219+-32];
	ld.u32 	%rd1237, [%rd1219+-28];
	shl.b64 	%rd1238, %rd1237, 32;
	or.b64  	%rd1239, %rd1238, %rd1236;
	ld.u32 	%rd1240, [%rd1219+-24];
	ld.u32 	%rd1241, [%rd1219+-20];
	shl.b64 	%rd1242, %rd1241, 32;
	or.b64  	%rd1243, %rd1242, %rd1240;
	ld.u32 	%rd1244, [%rd1219+-16];
	ld.u32 	%rd1245, [%rd1219+-12];
	shl.b64 	%rd1246, %rd1245, 32;
	or.b64  	%rd1247, %rd1246, %rd1244;
	ld.u32 	%rd1248, [%rd1219+-8];
	ld.u32 	%rd1249, [%rd1219+-4];
	shl.b64 	%rd1250, %rd1249, 32;
	or.b64  	%rd1251, %rd1250, %rd1248;
	add.s64 	%rd122, %rd122, -2;
	ld.u32 	%rd1252, [%rd1219+-64];
	ld.u32 	%rd1253, [%rd1219+-60];
	shl.b64 	%rd1254, %rd1253, 32;
	or.b64  	%rd123, %rd1254, %rd1252;
	add.cc.s64 	%rd1255, %rd1239, %rd1223;
	addc.cc.s64 	%rd1256, %rd1243, %rd1227;
	addc.cc.s64 	%rd1257, %rd1247, %rd1231;
	addc.cc.s64 	%rd1258, %rd1251, %rd1235;
	add.u64 	%rd1259, %SP, 1440;
	add.u64 	%rd1260, %SPL, 1440;
	st.local.u32 	[%rd1260+24], %rd134;
	st.local.u32 	[%rd1260+28], %rd134;
	mov.u64 	%rd1262, 1;
	st.local.u32 	[%rd1260], %rd1262;
	st.local.u32 	[%rd1260+4], %rd134;
	st.local.u32 	[%rd1260+8], %rd134;
	st.local.u32 	[%rd1260+12], %rd134;
	st.local.u32 	[%rd1260+16], %rd134;
	st.local.u32 	[%rd1260+20], %rd134;
	add.u64 	%rd1263, %SP, 1472;
	add.u64 	%rd1264, %SPL, 1472;
	st.local.u32 	[%rd1264+16], %rd1257;
	st.local.u32 	[%rd1264+24], %rd1258;
	st.local.u32 	[%rd1264], %rd1255;
	st.local.u32 	[%rd1264+8], %rd1256;
	shr.u64 	%rd1265, %rd1257, 32;
	st.local.u32 	[%rd1264+20], %rd1265;
	shr.u64 	%rd1266, %rd1258, 32;
	st.local.u32 	[%rd1264+28], %rd1266;
	shr.u64 	%rd1267, %rd1255, 32;
	st.local.u32 	[%rd1264+4], %rd1267;
	shr.u64 	%rd1268, %rd1256, 32;
	st.local.u32 	[%rd1264+12], %rd1268;
	{ // callseq 67, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1259;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1263;
	call.uni 
	__device_sstore, 
	(
	param0, 
	param1
	);
	} // callseq 67
	{ // callseq 68, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1259;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r173, [retval0+0];
	} // callseq 68
	add.u64 	%rd1269, %SP, 1504;
	add.u64 	%rd1270, %SPL, 1504;
	st.local.u32 	[%rd1270+28], %rd134;
	st.local.u32 	[%rd1270+24], %rd134;
	st.local.u32 	[%rd1270+20], %rd134;
	st.local.u32 	[%rd1270+16], %rd134;
	st.local.u32 	[%rd1270+12], %rd134;
	st.local.u32 	[%rd1270+8], %rd134;
	st.local.u32 	[%rd1270+4], %rd134;
	st.local.u32 	[%rd1270], %rd1262;
	add.u64 	%rd1271, %SP, 1536;
	add.u64 	%rd1272, %SPL, 1536;
	{ // callseq 69, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1269;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1271;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 69
	{ // callseq 70, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1269;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r309, [retval0+0];
	} // callseq 70
	setp.eq.s32 	%p194, %r309, %r172;
	setp.eq.s32 	%p195, %r309, %r173;
	or.pred  	%p196, %p194, %p195;
	setp.eq.s32 	%p197, %r309, %r174;
	or.pred  	%p198, %p196, %p197;
	setp.eq.s32 	%p199, %r309, %r175;
	or.pred  	%p200, %p198, %p199;
	setp.eq.s32 	%p201, %r309, %r176;
	or.pred  	%p202, %p200, %p201;
	setp.eq.s32 	%p203, %r309, %r177;
	or.pred  	%p204, %p202, %p203;
	selp.u16 	%rs59, 1, 0, %p204;
	st.global.u8 	[%rd126+1], %rs59;
	ld.local.u32 	%rd1273, [%rd1272+12];
	ld.local.u32 	%rd1274, [%rd1272+8];
	ld.local.u32 	%rd1275, [%rd1272+4];
	ld.local.u32 	%rd1276, [%rd1272];
	ld.local.u32 	%rd1277, [%rd1272+28];
	ld.local.u32 	%rd1278, [%rd1272+24];
	ld.local.u32 	%rd1279, [%rd1272+20];
	ld.local.u32 	%rd1280, [%rd1272+16];
	st.u32 	[%rd1219+-48], %rd1280;
	st.u32 	[%rd1219+-44], %rd1279;
	st.u32 	[%rd1219+-40], %rd1278;
	st.u32 	[%rd1219+-36], %rd1277;
	st.u32 	[%rd1219+-64], %rd1276;
	st.u32 	[%rd1219+-60], %rd1275;
	st.u32 	[%rd1219+-56], %rd1274;
	st.u32 	[%rd1219+-52], %rd1273;
	mov.u32 	%r171, 395;
	bra.uni 	$L__BB0_98;
$L__BB0_3:                              // %.76
	st.global.u8 	[%rd126+3143], %rs1;
	setp.eq.s64 	%p4, %rd3, 1015219987;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd122, 1;
	mov.u64 	%rd121, 209496;
	mov.u32 	%r172, 0;
	mov.u32 	%r171, 1081;
	mov.u32 	%r173, %r172;
	mov.u32 	%r175, %r172;
	mov.u32 	%r176, %r172;
	mov.u32 	%r177, %r172;
	@%p4 bra 	$L__BB0_31;
	bra.uni 	$L__BB0_4;
$L__BB0_31:                             // %.297
	setp.lt.u64 	%p173, %rd121, 96;
	@%p173 bra 	$L__BB0_147;
// %bb.32:
	xor.b32  	%r288, %r171, 2132;
	and.b32  	%r289, %r288, 4095;
	cvt.u64.u32 	%rd1053, %r289;
	add.s64 	%rd1054, %rd126, %rd1053;
	st.global.u8 	[%rd1054], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd1055, [%rd124+16];
	ld.u32 	%rd1056, [%rd124];
	ld.u32 	%rd1057, [%rd124+20];
	ld.u32 	%rd1058, [%rd124+4];
	ld.u32 	%rd1059, [%rd124+24];
	ld.u32 	%rd1060, [%rd124+8];
	ld.u32 	%rd1061, [%rd124+28];
	ld.u32 	%rd1062, [%rd124+12];
	or.b64  	%rd1063, %rd1062, %rd1061;
	shl.b64 	%rd1064, %rd1063, 32;
	or.b64  	%rd1065, %rd1064, %rd1060;
	or.b64  	%rd1066, %rd1065, %rd1059;
	or.b64  	%rd1067, %rd1058, %rd1057;
	shl.b64 	%rd1068, %rd1067, 32;
	or.b64  	%rd1069, %rd1068, %rd1056;
	or.b64  	%rd1070, %rd1069, %rd1055;
	or.b64  	%rd1071, %rd1070, %rd1066;
	setp.eq.s64 	%p174, %rd1071, 0;
	add.s64 	%rd1297, %rd122, 1;
	shl.b64 	%rd1072, %rd122, 5;
	add.s64 	%rd1073, %rd131, %rd1072;
	st.u32 	[%rd1073+48], %rd1055;
	st.u32 	[%rd1073+52], %rd1057;
	st.u32 	[%rd1073+56], %rd1059;
	st.u32 	[%rd1073+60], %rd1061;
	st.u32 	[%rd1073+32], %rd1056;
	st.u32 	[%rd1073+36], %rd1058;
	st.u32 	[%rd1073+40], %rd1060;
	st.u32 	[%rd1073+44], %rd1062;
	mov.u32 	%r171, 1066;
	@%p174 bra 	$L__BB0_35;
	bra.uni 	$L__BB0_33;
$L__BB0_35:                             // %.309
	setp.lt.u64 	%p176, %rd121, 336;
	@%p176 bra 	$L__BB0_147;
// %bb.36:
	xor.b32  	%r291, %r171, 795;
	and.b32  	%r292, %r291, 4095;
	cvt.u64.u32 	%rd1074, %r292;
	add.s64 	%rd1075, %rd126, %rd1074;
	st.global.u8 	[%rd1075], %rs1;
	add.s64 	%rd121, %rd121, -336;
	shl.b64 	%rd1076, %rd1297, 5;
	add.s64 	%rd1077, %rd131, %rd1076;
	add.u64 	%rd1078, %SP, 480;
	add.u64 	%rd1079, %SPL, 480;
	{ // callseq 59, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1078;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1283;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 59
	ld.local.u32 	%rd1081, [%rd1079+12];
	ld.local.u32 	%rd1082, [%rd1079+8];
	ld.local.u32 	%rd1083, [%rd1079+4];
	ld.local.u32 	%rd1084, [%rd1079];
	ld.local.u32 	%rd1085, [%rd1079+28];
	ld.local.u32 	%rd1086, [%rd1079+24];
	ld.local.u32 	%rd1087, [%rd1079+20];
	ld.local.u32 	%rd1088, [%rd1079+16];
	add.u64 	%rd1089, %SP, 512;
	add.u64 	%rd1090, %SPL, 512;
	{ // callseq 60, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1089;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1284;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 60
	ld.local.u32 	%rd1092, [%rd1090+12];
	ld.local.u32 	%rd1093, [%rd1090+8];
	ld.local.u32 	%rd1094, [%rd1090+4];
	ld.local.u32 	%rd1095, [%rd1090];
	ld.local.u32 	%rd1096, [%rd1090+28];
	ld.local.u32 	%rd1097, [%rd1090+24];
	ld.local.u32 	%rd1098, [%rd1090+20];
	ld.local.u32 	%rd1099, [%rd1090+16];
	st.u32 	[%rd1077+16], %rd134;
	st.u32 	[%rd1077+20], %rd134;
	st.u32 	[%rd1077+24], %rd134;
	st.u32 	[%rd1077+28], %rd134;
	mov.u64 	%rd1101, 350;
	st.u32 	[%rd1077], %rd1101;
	st.u32 	[%rd1077+4], %rd134;
	st.u32 	[%rd1077+8], %rd134;
	st.u32 	[%rd1077+12], %rd134;
	add.s64 	%rd122, %rd1297, 2;
	st.u32 	[%rd1077+48], %rd1088;
	st.u32 	[%rd1077+52], %rd1087;
	st.u32 	[%rd1077+56], %rd1086;
	st.u32 	[%rd1077+60], %rd1085;
	st.u32 	[%rd1077+32], %rd1084;
	st.u32 	[%rd1077+36], %rd1083;
	st.u32 	[%rd1077+40], %rd1082;
	st.u32 	[%rd1077+44], %rd1081;
	st.u32 	[%rd1077+80], %rd1099;
	st.u32 	[%rd1077+84], %rd1098;
	st.u32 	[%rd1077+88], %rd1097;
	st.u32 	[%rd1077+92], %rd1096;
	st.u32 	[%rd1077+64], %rd1095;
	st.u32 	[%rd1077+68], %rd1094;
	st.u32 	[%rd1077+72], %rd1093;
	st.u32 	[%rd1077+76], %rd1092;
	mov.u32 	%r171, 397;
$L__BB0_37:                             // %.727
	setp.lt.u64 	%p177, %rd121, 312;
	@%p177 bra 	$L__BB0_147;
// %bb.38:
	xor.b32  	%r294, %r171, 2136;
	and.b32  	%r295, %r294, 4095;
	cvt.u64.u32 	%rd1102, %r295;
	add.s64 	%rd1103, %rd126, %rd1102;
	st.global.u8 	[%rd1103], %rs1;
	add.s64 	%rd121, %rd121, -312;
	shl.b64 	%rd1104, %rd122, 5;
	add.s64 	%rd1105, %rd131, %rd1104;
	ld.u32 	%rd1106, [%rd1105];
	ld.u32 	%rd1107, [%rd1105+4];
	shl.b64 	%rd1108, %rd1107, 32;
	or.b64  	%rd1109, %rd1108, %rd1106;
	ld.u32 	%rd1110, [%rd1105+8];
	ld.u32 	%rd1111, [%rd1105+12];
	shl.b64 	%rd1112, %rd1111, 32;
	or.b64  	%rd1113, %rd1112, %rd1110;
	ld.u32 	%rd1114, [%rd1105+16];
	ld.u32 	%rd1115, [%rd1105+20];
	shl.b64 	%rd1116, %rd1115, 32;
	or.b64  	%rd1117, %rd1116, %rd1114;
	ld.u32 	%rd1118, [%rd1105+24];
	ld.u32 	%rd1119, [%rd1105+28];
	shl.b64 	%rd1120, %rd1119, 32;
	or.b64  	%rd1121, %rd1120, %rd1118;
	ld.u32 	%rd1122, [%rd1105+-32];
	ld.u32 	%rd1123, [%rd1105+-28];
	shl.b64 	%rd1124, %rd1123, 32;
	or.b64  	%rd1125, %rd1124, %rd1122;
	ld.u32 	%rd1126, [%rd1105+-24];
	ld.u32 	%rd1127, [%rd1105+-20];
	shl.b64 	%rd1128, %rd1127, 32;
	or.b64  	%rd1129, %rd1128, %rd1126;
	ld.u32 	%rd1130, [%rd1105+-16];
	ld.u32 	%rd1131, [%rd1105+-12];
	shl.b64 	%rd1132, %rd1131, 32;
	or.b64  	%rd1133, %rd1132, %rd1130;
	ld.u32 	%rd1134, [%rd1105+-8];
	ld.u32 	%rd1135, [%rd1105+-4];
	shl.b64 	%rd1136, %rd1135, 32;
	or.b64  	%rd1137, %rd1136, %rd1134;
	add.s64 	%rd122, %rd122, -2;
	ld.u32 	%rd1138, [%rd1105+-64];
	ld.u32 	%rd1139, [%rd1105+-60];
	shl.b64 	%rd1140, %rd1139, 32;
	or.b64  	%rd123, %rd1140, %rd1138;
	sub.cc.s64 	%rd1141, %rd1125, %rd1109;
	subc.cc.s64 	%rd1142, %rd1129, %rd1113;
	subc.cc.s64 	%rd1143, %rd1133, %rd1117;
	subc.cc.s64 	%rd1144, %rd1137, %rd1121;
	add.u64 	%rd1145, %SP, 1568;
	add.u64 	%rd1146, %SPL, 1568;
	st.local.u32 	[%rd1146+24], %rd134;
	st.local.u32 	[%rd1146+28], %rd134;
	mov.u64 	%rd1148, 1;
	st.local.u32 	[%rd1146], %rd1148;
	st.local.u32 	[%rd1146+4], %rd134;
	st.local.u32 	[%rd1146+8], %rd134;
	st.local.u32 	[%rd1146+12], %rd134;
	st.local.u32 	[%rd1146+16], %rd134;
	st.local.u32 	[%rd1146+20], %rd134;
	add.u64 	%rd1149, %SP, 1600;
	add.u64 	%rd1150, %SPL, 1600;
	st.local.u32 	[%rd1150+16], %rd1143;
	st.local.u32 	[%rd1150+24], %rd1144;
	st.local.u32 	[%rd1150], %rd1141;
	st.local.u32 	[%rd1150+8], %rd1142;
	shr.u64 	%rd1151, %rd1143, 32;
	st.local.u32 	[%rd1150+20], %rd1151;
	shr.u64 	%rd1152, %rd1144, 32;
	st.local.u32 	[%rd1150+28], %rd1152;
	shr.u64 	%rd1153, %rd1141, 32;
	st.local.u32 	[%rd1150+4], %rd1153;
	shr.u64 	%rd1154, %rd1142, 32;
	st.local.u32 	[%rd1150+12], %rd1154;
	{ // callseq 61, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1145;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1149;
	call.uni 
	__device_sstore, 
	(
	param0, 
	param1
	);
	} // callseq 61
	{ // callseq 62, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1145;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r174, [retval0+0];
	} // callseq 62
	add.u64 	%rd1155, %SP, 1632;
	add.u64 	%rd1156, %SPL, 1632;
	st.local.u32 	[%rd1156+28], %rd134;
	st.local.u32 	[%rd1156+24], %rd134;
	st.local.u32 	[%rd1156+20], %rd134;
	st.local.u32 	[%rd1156+16], %rd134;
	st.local.u32 	[%rd1156+12], %rd134;
	st.local.u32 	[%rd1156+8], %rd134;
	st.local.u32 	[%rd1156+4], %rd134;
	st.local.u32 	[%rd1156], %rd1148;
	add.u64 	%rd1157, %SP, 1664;
	add.u64 	%rd1158, %SPL, 1664;
	{ // callseq 63, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1155;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1157;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 63
	{ // callseq 64, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1155;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r297, [retval0+0];
	} // callseq 64
	setp.eq.s32 	%p178, %r297, %r172;
	setp.eq.s32 	%p179, %r297, %r173;
	or.pred  	%p180, %p178, %p179;
	setp.eq.s32 	%p181, %r297, %r174;
	or.pred  	%p182, %p180, %p181;
	setp.eq.s32 	%p183, %r297, %r175;
	or.pred  	%p184, %p182, %p183;
	setp.eq.s32 	%p185, %r297, %r176;
	or.pred  	%p186, %p184, %p185;
	setp.eq.s32 	%p187, %r297, %r177;
	or.pred  	%p188, %p186, %p187;
	selp.u16 	%rs54, 1, 0, %p188;
	st.global.u8 	[%rd126+2], %rs54;
	ld.local.u32 	%rd1159, [%rd1158+12];
	ld.local.u32 	%rd1160, [%rd1158+8];
	ld.local.u32 	%rd1161, [%rd1158+4];
	ld.local.u32 	%rd1162, [%rd1158];
	ld.local.u32 	%rd1163, [%rd1158+28];
	ld.local.u32 	%rd1164, [%rd1158+24];
	ld.local.u32 	%rd1165, [%rd1158+20];
	ld.local.u32 	%rd1166, [%rd1158+16];
	st.u32 	[%rd1105+-48], %rd1166;
	st.u32 	[%rd1105+-44], %rd1165;
	st.u32 	[%rd1105+-40], %rd1164;
	st.u32 	[%rd1105+-36], %rd1163;
	st.u32 	[%rd1105+-64], %rd1162;
	st.u32 	[%rd1105+-60], %rd1161;
	st.u32 	[%rd1105+-56], %rd1160;
	st.u32 	[%rd1105+-52], %rd1159;
	mov.u32 	%r171, 1068;
	bra.uni 	$L__BB0_98;
$L__BB0_4:                              // %.87
	st.global.u8 	[%rd126+2152], %rs1;
	setp.eq.s64 	%p5, %rd3, 1183395171;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd122, 1;
	mov.u64 	%rd121, 209384;
	mov.u32 	%r172, 0;
	mov.u32 	%r171, 1576;
	mov.u32 	%r173, %r172;
	mov.u32 	%r174, %r172;
	mov.u32 	%r176, %r172;
	mov.u32 	%r177, %r172;
	@%p5 bra 	$L__BB0_41;
// %bb.5:                               // %.98
	st.global.u8 	[%rd126+2775], %rs1;
	setp.eq.s64 	%p6, %rd3, 1698111815;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd122, 1;
	mov.u64 	%rd121, 209272;
	mov.u32 	%r172, 0;
	mov.u32 	%r171, 1663;
	mov.u32 	%r173, %r172;
	mov.u32 	%r174, %r172;
	mov.u32 	%r175, %r172;
	mov.u32 	%r176, %r172;
	mov.u32 	%r177, %r172;
	@%p6 bra 	$L__BB0_51;
// %bb.6:                               // %.109
	st.global.u8 	[%rd126+565], %rs1;
	setp.eq.s64 	%p7, %rd3, 2953925346;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd122, 1;
	mov.u64 	%rd121, 209160;
	mov.u32 	%r172, 0;
	mov.u32 	%r171, 549;
	mov.u32 	%r173, %r172;
	mov.u32 	%r174, %r172;
	mov.u32 	%r175, %r172;
	mov.u32 	%r177, %r172;
	@%p7 bra 	$L__BB0_61;
// %bb.7:                               // %.120
	st.global.u8 	[%rd126+2761], %rs1;
	setp.eq.s64 	%p8, %rd3, 3225657940;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd122, 1;
	mov.u64 	%rd121, 209048;
	mov.u32 	%r172, 0;
	mov.u32 	%r171, 1142;
	mov.u32 	%r173, %r172;
	mov.u32 	%r174, %r172;
	mov.u32 	%r175, %r172;
	mov.u32 	%r176, %r172;
	mov.u32 	%r177, %r172;
	@%p8 bra 	$L__BB0_71;
// %bb.8:                               // %.131
	st.global.u8 	[%rd126+2911], %rs1;
	setp.eq.s64 	%p9, %rd3, 4291659835;
	st.u32 	[%rd131+60], %rd134;
	st.u32 	[%rd131+56], %rd134;
	st.u32 	[%rd131+52], %rd134;
	st.u32 	[%rd131+48], %rd134;
	st.u32 	[%rd131+44], %rd134;
	st.u32 	[%rd131+40], %rd134;
	st.u32 	[%rd131+36], %rd134;
	st.u32 	[%rd131+32], %rd3;
	mov.u64 	%rd122, 1;
	mov.u64 	%rd121, 208936;
	mov.u32 	%r172, 0;
	mov.u32 	%r171, 1940;
	mov.u32 	%r173, %r172;
	mov.u32 	%r174, %r172;
	mov.u32 	%r175, %r172;
	mov.u32 	%r176, %r172;
	@%p9 bra 	$L__BB0_81;
	bra.uni 	$L__BB0_9;
$L__BB0_13:                             // %.155
	setp.lt.u64 	%p12, %rd121, 40;
	@%p12 bra 	$L__BB0_147;
// %bb.14:
	st.global.u8 	[%rd126+1014], %rs1;
	bra.uni 	$L__BB0_147;
$L__BB0_23:                             // %.230
	setp.lt.u64 	%p191, %rd121, 40;
	@%p191 bra 	$L__BB0_147;
// %bb.24:
	st.global.u8 	[%rd126+1463], %rs1;
	bra.uni 	$L__BB0_147;
$L__BB0_33:                             // %.305
	setp.lt.u64 	%p175, %rd121, 40;
	@%p175 bra 	$L__BB0_147;
// %bb.34:
	st.global.u8 	[%rd126+978], %rs1;
	bra.uni 	$L__BB0_147;
$L__BB0_19:                             // %.200
	setp.lt.u64 	%p156, %rd121, 184;
	@%p156 bra 	$L__BB0_147;
// %bb.20:
	xor.b32  	%r273, %r171, 3835;
	cvt.s64.s32 	%rd917, %r273;
	add.s64 	%rd918, %rd126, %rd917;
	st.global.u8 	[%rd918], %rs1;
	shl.b64 	%rd919, %rd122, 5;
	add.s64 	%rd920, %rd131, %rd919;
	ld.u32 	%rd921, [%rd920];
	ld.u32 	%rd922, [%rd920+4];
	ld.u32 	%rd923, [%rd920+8];
	ld.u32 	%rd924, [%rd920+12];
	ld.u32 	%rd925, [%rd920+16];
	ld.u32 	%rd926, [%rd920+20];
	ld.u32 	%rd927, [%rd920+24];
	ld.u32 	%rd928, [%rd920+28];
	add.u64 	%rd929, %SP, 224;
	add.u64 	%rd930, %SPL, 224;
	{ // callseq 48, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd929;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 48
	ld.local.u32 	%rd932, [%rd930];
	ld.local.u32 	%rd933, [%rd930+4];
	shl.b64 	%rd934, %rd933, 32;
	or.b64  	%rd935, %rd934, %rd932;
	add.u64 	%rd936, %SP, 256;
	add.u64 	%rd937, %SPL, 256;
	st.local.u32 	[%rd937+28], %rd928;
	st.local.u32 	[%rd937+24], %rd927;
	st.local.u32 	[%rd937+20], %rd926;
	st.local.u32 	[%rd937+16], %rd925;
	st.local.u32 	[%rd937+12], %rd924;
	st.local.u32 	[%rd937+8], %rd923;
	st.local.u32 	[%rd937+4], %rd922;
	st.local.u32 	[%rd937], %rd921;
	{ // callseq 49, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd935;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd936;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 49
	add.u64 	%rd939, %SP, 288;
	{ // callseq 50, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd939;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 50
	bra.uni 	$L__BB0_95;
$L__BB0_29:                             // %.275
	setp.lt.u64 	%p139, %rd121, 184;
	@%p139 bra 	$L__BB0_147;
// %bb.30:
	xor.b32  	%r261, %r171, 706;
	cvt.s64.s32 	%rd841, %r261;
	add.s64 	%rd842, %rd126, %rd841;
	st.global.u8 	[%rd842], %rs1;
	shl.b64 	%rd843, %rd122, 5;
	add.s64 	%rd844, %rd131, %rd843;
	ld.u32 	%rd845, [%rd844];
	ld.u32 	%rd846, [%rd844+4];
	ld.u32 	%rd847, [%rd844+8];
	ld.u32 	%rd848, [%rd844+12];
	ld.u32 	%rd849, [%rd844+16];
	ld.u32 	%rd850, [%rd844+20];
	ld.u32 	%rd851, [%rd844+24];
	ld.u32 	%rd852, [%rd844+28];
	add.u64 	%rd853, %SP, 384;
	add.u64 	%rd854, %SPL, 384;
	{ // callseq 43, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd853;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 43
	ld.local.u32 	%rd856, [%rd854];
	ld.local.u32 	%rd857, [%rd854+4];
	shl.b64 	%rd858, %rd857, 32;
	or.b64  	%rd859, %rd858, %rd856;
	add.u64 	%rd860, %SP, 416;
	add.u64 	%rd861, %SPL, 416;
	st.local.u32 	[%rd861+28], %rd852;
	st.local.u32 	[%rd861+24], %rd851;
	st.local.u32 	[%rd861+20], %rd850;
	st.local.u32 	[%rd861+16], %rd849;
	st.local.u32 	[%rd861+12], %rd848;
	st.local.u32 	[%rd861+8], %rd847;
	st.local.u32 	[%rd861+4], %rd846;
	st.local.u32 	[%rd861], %rd845;
	{ // callseq 44, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd859;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd860;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 44
	add.u64 	%rd863, %SP, 448;
	{ // callseq 45, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd863;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 45
	bra.uni 	$L__BB0_95;
$L__BB0_39:                             // %.350
	setp.lt.u64 	%p122, %rd121, 184;
	@%p122 bra 	$L__BB0_147;
// %bb.40:
	xor.b32  	%r248, %r171, 2536;
	cvt.s64.s32 	%rd705, %r248;
	add.s64 	%rd706, %rd126, %rd705;
	st.global.u8 	[%rd706], %rs1;
	shl.b64 	%rd707, %rd122, 5;
	add.s64 	%rd708, %rd131, %rd707;
	ld.u32 	%rd709, [%rd708];
	ld.u32 	%rd710, [%rd708+4];
	ld.u32 	%rd711, [%rd708+8];
	ld.u32 	%rd712, [%rd708+12];
	ld.u32 	%rd713, [%rd708+16];
	ld.u32 	%rd714, [%rd708+20];
	ld.u32 	%rd715, [%rd708+24];
	ld.u32 	%rd716, [%rd708+28];
	add.u64 	%rd717, %SP, 544;
	add.u64 	%rd718, %SPL, 544;
	{ // callseq 34, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd717;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 34
	ld.local.u32 	%rd720, [%rd718];
	ld.local.u32 	%rd721, [%rd718+4];
	shl.b64 	%rd722, %rd721, 32;
	or.b64  	%rd723, %rd722, %rd720;
	add.u64 	%rd724, %SP, 576;
	add.u64 	%rd725, %SPL, 576;
	st.local.u32 	[%rd725+28], %rd716;
	st.local.u32 	[%rd725+24], %rd715;
	st.local.u32 	[%rd725+20], %rd714;
	st.local.u32 	[%rd725+16], %rd713;
	st.local.u32 	[%rd725+12], %rd712;
	st.local.u32 	[%rd725+8], %rd711;
	st.local.u32 	[%rd725+4], %rd710;
	st.local.u32 	[%rd725], %rd709;
	{ // callseq 35, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd723;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd724;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 35
	add.u64 	%rd727, %SP, 608;
	{ // callseq 36, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd727;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 36
	bra.uni 	$L__BB0_95;
$L__BB0_41:                             // %.372
	setp.lt.u64 	%p157, %rd121, 96;
	@%p157 bra 	$L__BB0_147;
// %bb.42:
	xor.b32  	%r276, %r171, 3559;
	and.b32  	%r277, %r276, 4095;
	cvt.u64.u32 	%rd940, %r277;
	add.s64 	%rd941, %rd126, %rd940;
	st.global.u8 	[%rd941], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd942, [%rd124+16];
	ld.u32 	%rd943, [%rd124];
	ld.u32 	%rd944, [%rd124+20];
	ld.u32 	%rd945, [%rd124+4];
	ld.u32 	%rd946, [%rd124+24];
	ld.u32 	%rd947, [%rd124+8];
	ld.u32 	%rd948, [%rd124+28];
	ld.u32 	%rd949, [%rd124+12];
	or.b64  	%rd950, %rd949, %rd948;
	shl.b64 	%rd951, %rd950, 32;
	or.b64  	%rd952, %rd951, %rd947;
	or.b64  	%rd953, %rd952, %rd946;
	or.b64  	%rd954, %rd945, %rd944;
	shl.b64 	%rd955, %rd954, 32;
	or.b64  	%rd956, %rd955, %rd943;
	or.b64  	%rd957, %rd956, %rd942;
	or.b64  	%rd958, %rd957, %rd953;
	setp.eq.s64 	%p158, %rd958, 0;
	add.s64 	%rd1301, %rd122, 1;
	shl.b64 	%rd959, %rd122, 5;
	add.s64 	%rd960, %rd131, %rd959;
	st.u32 	[%rd960+48], %rd942;
	st.u32 	[%rd960+52], %rd944;
	st.u32 	[%rd960+56], %rd946;
	st.u32 	[%rd960+60], %rd948;
	st.u32 	[%rd960+32], %rd943;
	st.u32 	[%rd960+36], %rd945;
	st.u32 	[%rd960+40], %rd947;
	st.u32 	[%rd960+44], %rd949;
	mov.u32 	%r171, 1779;
	@%p158 bra 	$L__BB0_45;
	bra.uni 	$L__BB0_43;
$L__BB0_45:                             // %.384
	setp.lt.u64 	%p160, %rd121, 336;
	@%p160 bra 	$L__BB0_147;
// %bb.46:
	xor.b32  	%r279, %r171, 3958;
	and.b32  	%r280, %r279, 4095;
	cvt.u64.u32 	%rd961, %r280;
	add.s64 	%rd962, %rd126, %rd961;
	st.global.u8 	[%rd962], %rs1;
	add.s64 	%rd121, %rd121, -336;
	shl.b64 	%rd963, %rd1301, 5;
	add.s64 	%rd964, %rd131, %rd963;
	add.u64 	%rd965, %SP, 640;
	add.u64 	%rd966, %SPL, 640;
	{ // callseq 53, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd965;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1283;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 53
	ld.local.u32 	%rd968, [%rd966+12];
	ld.local.u32 	%rd969, [%rd966+8];
	ld.local.u32 	%rd970, [%rd966+4];
	ld.local.u32 	%rd971, [%rd966];
	ld.local.u32 	%rd972, [%rd966+28];
	ld.local.u32 	%rd973, [%rd966+24];
	ld.local.u32 	%rd974, [%rd966+20];
	ld.local.u32 	%rd975, [%rd966+16];
	add.u64 	%rd976, %SP, 672;
	add.u64 	%rd977, %SPL, 672;
	{ // callseq 54, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd976;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1284;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 54
	ld.local.u32 	%rd979, [%rd977+12];
	ld.local.u32 	%rd980, [%rd977+8];
	ld.local.u32 	%rd981, [%rd977+4];
	ld.local.u32 	%rd982, [%rd977];
	ld.local.u32 	%rd983, [%rd977+28];
	ld.local.u32 	%rd984, [%rd977+24];
	ld.local.u32 	%rd985, [%rd977+20];
	ld.local.u32 	%rd986, [%rd977+16];
	st.u32 	[%rd964+16], %rd134;
	st.u32 	[%rd964+20], %rd134;
	st.u32 	[%rd964+24], %rd134;
	st.u32 	[%rd964+28], %rd134;
	mov.u64 	%rd988, 425;
	st.u32 	[%rd964], %rd988;
	st.u32 	[%rd964+4], %rd134;
	st.u32 	[%rd964+8], %rd134;
	st.u32 	[%rd964+12], %rd134;
	add.s64 	%rd122, %rd1301, 2;
	st.u32 	[%rd964+48], %rd975;
	st.u32 	[%rd964+52], %rd974;
	st.u32 	[%rd964+56], %rd973;
	st.u32 	[%rd964+60], %rd972;
	st.u32 	[%rd964+32], %rd971;
	st.u32 	[%rd964+36], %rd970;
	st.u32 	[%rd964+40], %rd969;
	st.u32 	[%rd964+44], %rd968;
	st.u32 	[%rd964+80], %rd986;
	st.u32 	[%rd964+84], %rd985;
	st.u32 	[%rd964+88], %rd984;
	st.u32 	[%rd964+92], %rd983;
	st.u32 	[%rd964+64], %rd982;
	st.u32 	[%rd964+68], %rd981;
	st.u32 	[%rd964+72], %rd980;
	st.u32 	[%rd964+76], %rd979;
	mov.u32 	%r171, 1979;
$L__BB0_47:                             // %.749
	setp.lt.u64 	%p161, %rd121, 312;
	@%p161 bra 	$L__BB0_147;
// %bb.48:
	xor.b32  	%r282, %r171, 2793;
	and.b32  	%r283, %r282, 4095;
	cvt.u64.u32 	%rd989, %r283;
	add.s64 	%rd990, %rd126, %rd989;
	st.global.u8 	[%rd990], %rs1;
	add.s64 	%rd121, %rd121, -312;
	shl.b64 	%rd991, %rd122, 5;
	add.s64 	%rd992, %rd131, %rd991;
	ld.u32 	%rd993, [%rd992];
	ld.u32 	%rd994, [%rd992+4];
	shl.b64 	%rd995, %rd994, 32;
	or.b64  	%rd996, %rd995, %rd993;
	ld.u32 	%rd997, [%rd992+8];
	ld.u32 	%rd998, [%rd992+12];
	shl.b64 	%rd999, %rd998, 32;
	or.b64  	%rd1000, %rd999, %rd997;
	ld.u32 	%rd1001, [%rd992+16];
	ld.u32 	%rd1002, [%rd992+20];
	shl.b64 	%rd1003, %rd1002, 32;
	or.b64  	%rd1004, %rd1003, %rd1001;
	ld.u32 	%rd1005, [%rd992+24];
	ld.u32 	%rd1006, [%rd992+28];
	shl.b64 	%rd1007, %rd1006, 32;
	or.b64  	%rd1008, %rd1007, %rd1005;
	ld.u32 	%rd1009, [%rd992+-32];
	ld.u32 	%rd1010, [%rd992+-28];
	shl.b64 	%rd1011, %rd1010, 32;
	or.b64  	%rd1012, %rd1011, %rd1009;
	ld.u32 	%rd1013, [%rd992+-24];
	ld.u32 	%rd1014, [%rd992+-20];
	shl.b64 	%rd1015, %rd1014, 32;
	or.b64  	%rd1016, %rd1015, %rd1013;
	ld.u32 	%rd1017, [%rd992+-16];
	ld.u32 	%rd1018, [%rd992+-12];
	shl.b64 	%rd1019, %rd1018, 32;
	or.b64  	%rd1020, %rd1019, %rd1017;
	ld.u32 	%rd1021, [%rd992+-8];
	ld.u32 	%rd1022, [%rd992+-4];
	shl.b64 	%rd1023, %rd1022, 32;
	or.b64  	%rd1024, %rd1023, %rd1021;
	add.s64 	%rd122, %rd122, -2;
	ld.u32 	%rd1025, [%rd992+-64];
	ld.u32 	%rd1026, [%rd992+-60];
	shl.b64 	%rd1027, %rd1026, 32;
	or.b64  	%rd123, %rd1027, %rd1025;
	add.cc.s64 	%rd1028, %rd1012, %rd996;
	addc.cc.s64 	%rd1029, %rd1016, %rd1000;
	addc.cc.s64 	%rd1030, %rd1020, %rd1004;
	addc.cc.s64 	%rd1031, %rd1024, %rd1008;
	add.u64 	%rd1032, %SP, 1696;
	add.u64 	%rd1033, %SPL, 1696;
	st.local.u32 	[%rd1033+24], %rd134;
	st.local.u32 	[%rd1033+28], %rd134;
	st.local.u32 	[%rd1033], %rd134;
	st.local.u32 	[%rd1033+4], %rd134;
	st.local.u32 	[%rd1033+8], %rd134;
	st.local.u32 	[%rd1033+12], %rd134;
	st.local.u32 	[%rd1033+16], %rd134;
	st.local.u32 	[%rd1033+20], %rd134;
	add.u64 	%rd1035, %SP, 1728;
	add.u64 	%rd1036, %SPL, 1728;
	st.local.u32 	[%rd1036+16], %rd1030;
	st.local.u32 	[%rd1036+24], %rd1031;
	st.local.u32 	[%rd1036], %rd1028;
	st.local.u32 	[%rd1036+8], %rd1029;
	shr.u64 	%rd1037, %rd1030, 32;
	st.local.u32 	[%rd1036+20], %rd1037;
	shr.u64 	%rd1038, %rd1031, 32;
	st.local.u32 	[%rd1036+28], %rd1038;
	shr.u64 	%rd1039, %rd1028, 32;
	st.local.u32 	[%rd1036+4], %rd1039;
	shr.u64 	%rd1040, %rd1029, 32;
	st.local.u32 	[%rd1036+12], %rd1040;
	{ // callseq 55, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1032;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1035;
	call.uni 
	__device_sstore, 
	(
	param0, 
	param1
	);
	} // callseq 55
	{ // callseq 56, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1032;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r175, [retval0+0];
	} // callseq 56
	add.u64 	%rd1041, %SP, 1760;
	add.u64 	%rd1042, %SPL, 1760;
	st.local.u32 	[%rd1042+28], %rd134;
	st.local.u32 	[%rd1042+24], %rd134;
	st.local.u32 	[%rd1042+20], %rd134;
	st.local.u32 	[%rd1042+16], %rd134;
	st.local.u32 	[%rd1042+12], %rd134;
	st.local.u32 	[%rd1042+8], %rd134;
	st.local.u32 	[%rd1042+4], %rd134;
	st.local.u32 	[%rd1042], %rd134;
	add.u64 	%rd1043, %SP, 1792;
	add.u64 	%rd1044, %SPL, 1792;
	{ // callseq 57, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1041;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1043;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 57
	{ // callseq 58, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1041;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r285, [retval0+0];
	} // callseq 58
	setp.eq.s32 	%p162, %r285, %r172;
	setp.eq.s32 	%p163, %r285, %r173;
	or.pred  	%p164, %p162, %p163;
	setp.eq.s32 	%p165, %r285, %r174;
	or.pred  	%p166, %p164, %p165;
	setp.eq.s32 	%p167, %r285, %r175;
	or.pred  	%p168, %p166, %p167;
	setp.eq.s32 	%p169, %r285, %r176;
	or.pred  	%p170, %p168, %p169;
	setp.eq.s32 	%p171, %r285, %r177;
	or.pred  	%p172, %p170, %p171;
	selp.u16 	%rs49, 1, 0, %p172;
	st.global.u8 	[%rd126+3], %rs49;
	ld.local.u32 	%rd1045, [%rd1044+12];
	ld.local.u32 	%rd1046, [%rd1044+8];
	ld.local.u32 	%rd1047, [%rd1044+4];
	ld.local.u32 	%rd1048, [%rd1044];
	ld.local.u32 	%rd1049, [%rd1044+28];
	ld.local.u32 	%rd1050, [%rd1044+24];
	ld.local.u32 	%rd1051, [%rd1044+20];
	ld.local.u32 	%rd1052, [%rd1044+16];
	st.u32 	[%rd992+-48], %rd1052;
	st.u32 	[%rd992+-44], %rd1051;
	st.u32 	[%rd992+-40], %rd1050;
	st.u32 	[%rd992+-36], %rd1049;
	st.u32 	[%rd992+-64], %rd1048;
	st.u32 	[%rd992+-60], %rd1047;
	st.u32 	[%rd992+-56], %rd1046;
	st.u32 	[%rd992+-52], %rd1045;
	mov.u32 	%r171, 1396;
	bra.uni 	$L__BB0_98;
$L__BB0_43:                             // %.380
	setp.lt.u64 	%p159, %rd121, 40;
	@%p159 bra 	$L__BB0_147;
// %bb.44:
	st.global.u8 	[%rd126+1406], %rs1;
	bra.uni 	$L__BB0_147;
$L__BB0_49:                             // %.425
	setp.lt.u64 	%p105, %rd121, 184;
	@%p105 bra 	$L__BB0_147;
// %bb.50:
	xor.b32  	%r236, %r171, 1370;
	cvt.s64.s32 	%rd628, %r236;
	add.s64 	%rd629, %rd126, %rd628;
	st.global.u8 	[%rd629], %rs1;
	shl.b64 	%rd630, %rd122, 5;
	add.s64 	%rd631, %rd131, %rd630;
	ld.u32 	%rd632, [%rd631];
	ld.u32 	%rd633, [%rd631+4];
	ld.u32 	%rd634, [%rd631+8];
	ld.u32 	%rd635, [%rd631+12];
	ld.u32 	%rd636, [%rd631+16];
	ld.u32 	%rd637, [%rd631+20];
	ld.u32 	%rd638, [%rd631+24];
	ld.u32 	%rd639, [%rd631+28];
	add.u64 	%rd640, %SP, 704;
	add.u64 	%rd641, %SPL, 704;
	{ // callseq 29, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd640;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 29
	ld.local.u32 	%rd643, [%rd641];
	ld.local.u32 	%rd644, [%rd641+4];
	shl.b64 	%rd645, %rd644, 32;
	or.b64  	%rd646, %rd645, %rd643;
	add.u64 	%rd647, %SP, 736;
	add.u64 	%rd648, %SPL, 736;
	st.local.u32 	[%rd648+28], %rd639;
	st.local.u32 	[%rd648+24], %rd638;
	st.local.u32 	[%rd648+20], %rd637;
	st.local.u32 	[%rd648+16], %rd636;
	st.local.u32 	[%rd648+12], %rd635;
	st.local.u32 	[%rd648+8], %rd634;
	st.local.u32 	[%rd648+4], %rd633;
	st.local.u32 	[%rd648], %rd632;
	{ // callseq 30, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd646;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd647;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 30
	add.u64 	%rd650, %SP, 768;
	{ // callseq 31, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd650;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 31
	bra.uni 	$L__BB0_95;
$L__BB0_51:                             // %.447
	setp.lt.u64 	%p140, %rd121, 96;
	@%p140 bra 	$L__BB0_147;
// %bb.52:
	xor.b32  	%r263, %r171, 2350;
	and.b32  	%r264, %r263, 4095;
	cvt.u64.u32 	%rd864, %r264;
	add.s64 	%rd865, %rd126, %rd864;
	st.global.u8 	[%rd865], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd866, [%rd124+16];
	ld.u32 	%rd867, [%rd124];
	ld.u32 	%rd868, [%rd124+20];
	ld.u32 	%rd869, [%rd124+4];
	ld.u32 	%rd870, [%rd124+24];
	ld.u32 	%rd871, [%rd124+8];
	ld.u32 	%rd872, [%rd124+28];
	ld.u32 	%rd873, [%rd124+12];
	or.b64  	%rd874, %rd873, %rd872;
	shl.b64 	%rd875, %rd874, 32;
	or.b64  	%rd876, %rd875, %rd871;
	or.b64  	%rd877, %rd876, %rd870;
	or.b64  	%rd878, %rd869, %rd868;
	shl.b64 	%rd879, %rd878, 32;
	or.b64  	%rd880, %rd879, %rd867;
	or.b64  	%rd881, %rd880, %rd866;
	or.b64  	%rd882, %rd881, %rd877;
	setp.eq.s64 	%p141, %rd882, 0;
	add.s64 	%rd1305, %rd122, 1;
	shl.b64 	%rd883, %rd122, 5;
	add.s64 	%rd884, %rd131, %rd883;
	st.u32 	[%rd884+48], %rd866;
	st.u32 	[%rd884+52], %rd868;
	st.u32 	[%rd884+56], %rd870;
	st.u32 	[%rd884+60], %rd872;
	st.u32 	[%rd884+32], %rd867;
	st.u32 	[%rd884+36], %rd869;
	st.u32 	[%rd884+40], %rd871;
	st.u32 	[%rd884+44], %rd873;
	mov.u32 	%r171, 1175;
	@%p141 bra 	$L__BB0_55;
	bra.uni 	$L__BB0_53;
$L__BB0_55:                             // %.459
	setp.lt.u64 	%p143, %rd121, 120;
	@%p143 bra 	$L__BB0_147;
// %bb.56:
	xor.b32  	%r266, %r171, 563;
	and.b32  	%r267, %r266, 4095;
	cvt.u64.u32 	%rd885, %r267;
	add.s64 	%rd886, %rd126, %rd885;
	st.global.u8 	[%rd886], %rs1;
	add.s64 	%rd121, %rd121, -120;
	shl.b64 	%rd887, %rd1305, 5;
	add.s64 	%rd888, %rd131, %rd887;
	st.u32 	[%rd888+28], %rd134;
	st.u32 	[%rd888+24], %rd134;
	st.u32 	[%rd888+20], %rd134;
	st.u32 	[%rd888+16], %rd134;
	st.u32 	[%rd888+12], %rd134;
	st.u32 	[%rd888+8], %rd134;
	st.u32 	[%rd888+4], %rd134;
	mov.u64 	%rd890, 468;
	st.u32 	[%rd888], %rd890;
	mov.u32 	%r171, 281;
	mov.u64 	%rd122, %rd1305;
$L__BB0_57:                             // %.771
	setp.lt.u64 	%p144, %rd121, 216;
	@%p144 bra 	$L__BB0_147;
// %bb.58:
	xor.b32  	%r269, %r171, 1118;
	and.b32  	%r270, %r269, 4095;
	cvt.u64.u32 	%rd891, %r270;
	add.s64 	%rd892, %rd126, %rd891;
	st.global.u8 	[%rd892], %rs1;
	add.s64 	%rd121, %rd121, -216;
	shl.b64 	%rd893, %rd122, 5;
	add.s64 	%rd894, %rd131, %rd893;
	ld.u32 	%rd895, [%rd894];
	ld.u32 	%rd896, [%rd894+4];
	shl.b64 	%rd897, %rd896, 32;
	or.b64  	%rd123, %rd897, %rd895;
	ld.u32 	%rd898, [%rd894+12];
	ld.u32 	%rd899, [%rd894+8];
	ld.u32 	%rd900, [%rd894+28];
	ld.u32 	%rd901, [%rd894+24];
	ld.u32 	%rd902, [%rd894+20];
	ld.u32 	%rd903, [%rd894+16];
	add.u64 	%rd904, %SP, 1824;
	add.u64 	%rd905, %SPL, 1824;
	st.local.u32 	[%rd905+16], %rd134;
	st.local.u32 	[%rd905+20], %rd134;
	st.local.u32 	[%rd905+24], %rd134;
	st.local.u32 	[%rd905+28], %rd134;
	st.local.u32 	[%rd905], %rd134;
	st.local.u32 	[%rd905+4], %rd134;
	st.local.u32 	[%rd905+8], %rd134;
	st.local.u32 	[%rd905+12], %rd134;
	add.u64 	%rd907, %SP, 1856;
	add.u64 	%rd908, %SPL, 1856;
	{ // callseq 46, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd904;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd907;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 46
	{ // callseq 47, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd904;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r271, [retval0+0];
	} // callseq 47
	setp.eq.s32 	%p145, %r271, %r172;
	setp.eq.s32 	%p146, %r271, %r173;
	or.pred  	%p147, %p145, %p146;
	setp.eq.s32 	%p148, %r271, %r174;
	or.pred  	%p149, %p147, %p148;
	setp.eq.s32 	%p150, %r271, %r175;
	or.pred  	%p151, %p149, %p150;
	setp.eq.s32 	%p152, %r271, %r176;
	or.pred  	%p153, %p151, %p152;
	setp.eq.s32 	%p154, %r271, %r177;
	or.pred  	%p155, %p153, %p154;
	selp.u16 	%rs43, 1, 0, %p155;
	st.global.u8 	[%rd126+4], %rs43;
	ld.local.u32 	%rd909, [%rd908+12];
	ld.local.u32 	%rd910, [%rd908+8];
	ld.local.u32 	%rd911, [%rd908+4];
	ld.local.u32 	%rd912, [%rd908];
	ld.local.u32 	%rd913, [%rd908+28];
	ld.local.u32 	%rd914, [%rd908+24];
	ld.local.u32 	%rd915, [%rd908+20];
	ld.local.u32 	%rd916, [%rd908+16];
	add.s64 	%rd122, %rd122, 1;
	st.u32 	[%rd894+16], %rd903;
	st.u32 	[%rd894+20], %rd902;
	st.u32 	[%rd894+24], %rd901;
	st.u32 	[%rd894+28], %rd900;
	st.u32 	[%rd894], %rd895;
	st.u32 	[%rd894+4], %rd896;
	st.u32 	[%rd894+8], %rd899;
	st.u32 	[%rd894+12], %rd898;
	st.u32 	[%rd894+48], %rd916;
	st.u32 	[%rd894+52], %rd915;
	st.u32 	[%rd894+56], %rd914;
	st.u32 	[%rd894+60], %rd913;
	st.u32 	[%rd894+32], %rd912;
	st.u32 	[%rd894+36], %rd911;
	st.u32 	[%rd894+40], %rd910;
	st.u32 	[%rd894+44], %rd909;
	mov.u32 	%r171, 559;
	bra.uni 	$L__BB0_98;
$L__BB0_53:                             // %.455
	setp.lt.u64 	%p142, %rd121, 40;
	@%p142 bra 	$L__BB0_147;
// %bb.54:
	st.global.u8 	[%rd126+1780], %rs1;
	bra.uni 	$L__BB0_147;
$L__BB0_59:                             // %.468
	setp.lt.u64 	%p78, %rd121, 184;
	@%p78 bra 	$L__BB0_147;
// %bb.60:
	xor.b32  	%r211, %r171, 1951;
	cvt.s64.s32 	%rd387, %r211;
	add.s64 	%rd388, %rd126, %rd387;
	st.global.u8 	[%rd388], %rs1;
	shl.b64 	%rd389, %rd122, 5;
	add.s64 	%rd390, %rd131, %rd389;
	ld.u32 	%rd391, [%rd390];
	ld.u32 	%rd392, [%rd390+4];
	ld.u32 	%rd393, [%rd390+8];
	ld.u32 	%rd394, [%rd390+12];
	ld.u32 	%rd395, [%rd390+16];
	ld.u32 	%rd396, [%rd390+20];
	ld.u32 	%rd397, [%rd390+24];
	ld.u32 	%rd398, [%rd390+28];
	add.u64 	%rd399, %SP, 800;
	add.u64 	%rd400, %SPL, 800;
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd399;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 20
	ld.local.u32 	%rd402, [%rd400];
	ld.local.u32 	%rd403, [%rd400+4];
	shl.b64 	%rd404, %rd403, 32;
	or.b64  	%rd405, %rd404, %rd402;
	add.u64 	%rd406, %SP, 832;
	add.u64 	%rd407, %SPL, 832;
	st.local.u32 	[%rd407+28], %rd398;
	st.local.u32 	[%rd407+24], %rd397;
	st.local.u32 	[%rd407+20], %rd396;
	st.local.u32 	[%rd407+16], %rd395;
	st.local.u32 	[%rd407+12], %rd394;
	st.local.u32 	[%rd407+8], %rd393;
	st.local.u32 	[%rd407+4], %rd392;
	st.local.u32 	[%rd407], %rd391;
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd405;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd406;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 21
	add.u64 	%rd409, %SP, 864;
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd409;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 22
	bra.uni 	$L__BB0_95;
$L__BB0_61:                             // %.490
	setp.lt.u64 	%p123, %rd121, 96;
	@%p123 bra 	$L__BB0_147;
// %bb.62:
	xor.b32  	%r250, %r171, 1225;
	and.b32  	%r251, %r250, 4095;
	cvt.u64.u32 	%rd728, %r251;
	add.s64 	%rd729, %rd126, %rd728;
	st.global.u8 	[%rd729], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd730, [%rd124+16];
	ld.u32 	%rd731, [%rd124];
	ld.u32 	%rd732, [%rd124+20];
	ld.u32 	%rd733, [%rd124+4];
	ld.u32 	%rd734, [%rd124+24];
	ld.u32 	%rd735, [%rd124+8];
	ld.u32 	%rd736, [%rd124+28];
	ld.u32 	%rd737, [%rd124+12];
	or.b64  	%rd738, %rd737, %rd736;
	shl.b64 	%rd739, %rd738, 32;
	or.b64  	%rd740, %rd739, %rd735;
	or.b64  	%rd741, %rd740, %rd734;
	or.b64  	%rd742, %rd733, %rd732;
	shl.b64 	%rd743, %rd742, 32;
	or.b64  	%rd744, %rd743, %rd731;
	or.b64  	%rd745, %rd744, %rd730;
	or.b64  	%rd746, %rd745, %rd741;
	setp.eq.s64 	%p124, %rd746, 0;
	add.s64 	%rd1309, %rd122, 1;
	shl.b64 	%rd747, %rd122, 5;
	add.s64 	%rd748, %rd131, %rd747;
	st.u32 	[%rd748+48], %rd730;
	st.u32 	[%rd748+52], %rd732;
	st.u32 	[%rd748+56], %rd734;
	st.u32 	[%rd748+60], %rd736;
	st.u32 	[%rd748+32], %rd731;
	st.u32 	[%rd748+36], %rd733;
	st.u32 	[%rd748+40], %rd735;
	st.u32 	[%rd748+44], %rd737;
	mov.u32 	%r171, 612;
	@%p124 bra 	$L__BB0_65;
	bra.uni 	$L__BB0_63;
$L__BB0_65:                             // %.502
	setp.lt.u64 	%p126, %rd121, 336;
	@%p126 bra 	$L__BB0_147;
// %bb.66:
	xor.b32  	%r253, %r171, 2918;
	and.b32  	%r254, %r253, 4095;
	cvt.u64.u32 	%rd749, %r254;
	add.s64 	%rd750, %rd126, %rd749;
	st.global.u8 	[%rd750], %rs1;
	add.s64 	%rd121, %rd121, -336;
	shl.b64 	%rd751, %rd1309, 5;
	add.s64 	%rd752, %rd131, %rd751;
	add.u64 	%rd753, %SP, 896;
	add.u64 	%rd754, %SPL, 896;
	{ // callseq 37, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd753;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1283;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 37
	ld.local.u32 	%rd756, [%rd754+12];
	ld.local.u32 	%rd757, [%rd754+8];
	ld.local.u32 	%rd758, [%rd754+4];
	ld.local.u32 	%rd759, [%rd754];
	ld.local.u32 	%rd760, [%rd754+28];
	ld.local.u32 	%rd761, [%rd754+24];
	ld.local.u32 	%rd762, [%rd754+20];
	ld.local.u32 	%rd763, [%rd754+16];
	add.u64 	%rd764, %SP, 928;
	add.u64 	%rd765, %SPL, 928;
	{ // callseq 38, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd764;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1284;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 38
	ld.local.u32 	%rd767, [%rd765+12];
	ld.local.u32 	%rd768, [%rd765+8];
	ld.local.u32 	%rd769, [%rd765+4];
	ld.local.u32 	%rd770, [%rd765];
	ld.local.u32 	%rd771, [%rd765+28];
	ld.local.u32 	%rd772, [%rd765+24];
	ld.local.u32 	%rd773, [%rd765+20];
	ld.local.u32 	%rd774, [%rd765+16];
	st.u32 	[%rd752+16], %rd134;
	st.u32 	[%rd752+20], %rd134;
	st.u32 	[%rd752+24], %rd134;
	st.u32 	[%rd752+28], %rd134;
	mov.u64 	%rd776, 543;
	st.u32 	[%rd752], %rd776;
	st.u32 	[%rd752+4], %rd134;
	st.u32 	[%rd752+8], %rd134;
	st.u32 	[%rd752+12], %rd134;
	add.s64 	%rd122, %rd1309, 2;
	st.u32 	[%rd752+48], %rd763;
	st.u32 	[%rd752+52], %rd762;
	st.u32 	[%rd752+56], %rd761;
	st.u32 	[%rd752+60], %rd760;
	st.u32 	[%rd752+32], %rd759;
	st.u32 	[%rd752+36], %rd758;
	st.u32 	[%rd752+40], %rd757;
	st.u32 	[%rd752+44], %rd756;
	st.u32 	[%rd752+80], %rd774;
	st.u32 	[%rd752+84], %rd773;
	st.u32 	[%rd752+88], %rd772;
	st.u32 	[%rd752+92], %rd771;
	st.u32 	[%rd752+64], %rd770;
	st.u32 	[%rd752+68], %rd769;
	st.u32 	[%rd752+72], %rd768;
	st.u32 	[%rd752+76], %rd767;
	mov.u32 	%r171, 1459;
$L__BB0_67:                             // %.777
	setp.lt.u64 	%p127, %rd121, 312;
	@%p127 bra 	$L__BB0_147;
// %bb.68:
	xor.b32  	%r256, %r171, 2260;
	and.b32  	%r257, %r256, 4095;
	cvt.u64.u32 	%rd777, %r257;
	add.s64 	%rd778, %rd126, %rd777;
	st.global.u8 	[%rd778], %rs1;
	add.s64 	%rd121, %rd121, -312;
	shl.b64 	%rd779, %rd122, 5;
	add.s64 	%rd780, %rd131, %rd779;
	ld.u32 	%rd781, [%rd780];
	ld.u32 	%rd782, [%rd780+4];
	shl.b64 	%rd783, %rd782, 32;
	or.b64  	%rd784, %rd783, %rd781;
	ld.u32 	%rd785, [%rd780+8];
	ld.u32 	%rd786, [%rd780+12];
	shl.b64 	%rd787, %rd786, 32;
	or.b64  	%rd788, %rd787, %rd785;
	ld.u32 	%rd789, [%rd780+16];
	ld.u32 	%rd790, [%rd780+20];
	shl.b64 	%rd791, %rd790, 32;
	or.b64  	%rd792, %rd791, %rd789;
	ld.u32 	%rd793, [%rd780+24];
	ld.u32 	%rd794, [%rd780+28];
	shl.b64 	%rd795, %rd794, 32;
	or.b64  	%rd796, %rd795, %rd793;
	ld.u32 	%rd797, [%rd780+-32];
	ld.u32 	%rd798, [%rd780+-28];
	shl.b64 	%rd799, %rd798, 32;
	or.b64  	%rd800, %rd799, %rd797;
	ld.u32 	%rd801, [%rd780+-24];
	ld.u32 	%rd802, [%rd780+-20];
	shl.b64 	%rd803, %rd802, 32;
	or.b64  	%rd804, %rd803, %rd801;
	ld.u32 	%rd805, [%rd780+-16];
	ld.u32 	%rd806, [%rd780+-12];
	shl.b64 	%rd807, %rd806, 32;
	or.b64  	%rd808, %rd807, %rd805;
	ld.u32 	%rd809, [%rd780+-8];
	ld.u32 	%rd810, [%rd780+-4];
	shl.b64 	%rd811, %rd810, 32;
	or.b64  	%rd812, %rd811, %rd809;
	add.s64 	%rd122, %rd122, -2;
	ld.u32 	%rd813, [%rd780+-64];
	ld.u32 	%rd814, [%rd780+-60];
	shl.b64 	%rd815, %rd814, 32;
	or.b64  	%rd123, %rd815, %rd813;
	sub.cc.s64 	%rd816, %rd800, %rd784;
	subc.cc.s64 	%rd817, %rd804, %rd788;
	subc.cc.s64 	%rd818, %rd808, %rd792;
	subc.cc.s64 	%rd819, %rd812, %rd796;
	add.u64 	%rd820, %SP, 1888;
	add.u64 	%rd821, %SPL, 1888;
	st.local.u32 	[%rd821+24], %rd134;
	st.local.u32 	[%rd821+28], %rd134;
	st.local.u32 	[%rd821], %rd134;
	st.local.u32 	[%rd821+4], %rd134;
	st.local.u32 	[%rd821+8], %rd134;
	st.local.u32 	[%rd821+12], %rd134;
	st.local.u32 	[%rd821+16], %rd134;
	st.local.u32 	[%rd821+20], %rd134;
	add.u64 	%rd823, %SP, 1920;
	add.u64 	%rd824, %SPL, 1920;
	st.local.u32 	[%rd824+16], %rd818;
	st.local.u32 	[%rd824+24], %rd819;
	st.local.u32 	[%rd824], %rd816;
	st.local.u32 	[%rd824+8], %rd817;
	shr.u64 	%rd825, %rd818, 32;
	st.local.u32 	[%rd824+20], %rd825;
	shr.u64 	%rd826, %rd819, 32;
	st.local.u32 	[%rd824+28], %rd826;
	shr.u64 	%rd827, %rd816, 32;
	st.local.u32 	[%rd824+4], %rd827;
	shr.u64 	%rd828, %rd817, 32;
	st.local.u32 	[%rd824+12], %rd828;
	{ // callseq 39, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd820;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd823;
	call.uni 
	__device_sstore, 
	(
	param0, 
	param1
	);
	} // callseq 39
	{ // callseq 40, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd820;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r176, [retval0+0];
	} // callseq 40
	add.u64 	%rd829, %SP, 1952;
	add.u64 	%rd830, %SPL, 1952;
	st.local.u32 	[%rd830+28], %rd134;
	st.local.u32 	[%rd830+24], %rd134;
	st.local.u32 	[%rd830+20], %rd134;
	st.local.u32 	[%rd830+16], %rd134;
	st.local.u32 	[%rd830+12], %rd134;
	st.local.u32 	[%rd830+8], %rd134;
	st.local.u32 	[%rd830+4], %rd134;
	st.local.u32 	[%rd830], %rd134;
	add.u64 	%rd831, %SP, 1984;
	add.u64 	%rd832, %SPL, 1984;
	{ // callseq 41, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd829;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd831;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 41
	{ // callseq 42, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd829;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r259, [retval0+0];
	} // callseq 42
	setp.eq.s32 	%p128, %r259, %r172;
	setp.eq.s32 	%p129, %r259, %r173;
	or.pred  	%p130, %p128, %p129;
	setp.eq.s32 	%p131, %r259, %r174;
	or.pred  	%p132, %p130, %p131;
	setp.eq.s32 	%p133, %r259, %r175;
	or.pred  	%p134, %p132, %p133;
	setp.eq.s32 	%p135, %r259, %r176;
	or.pred  	%p136, %p134, %p135;
	setp.eq.s32 	%p137, %r259, %r177;
	or.pred  	%p138, %p136, %p137;
	selp.u16 	%rs37, 1, 0, %p138;
	st.global.u8 	[%rd126+5], %rs37;
	ld.local.u32 	%rd833, [%rd832+12];
	ld.local.u32 	%rd834, [%rd832+8];
	ld.local.u32 	%rd835, [%rd832+4];
	ld.local.u32 	%rd836, [%rd832];
	ld.local.u32 	%rd837, [%rd832+28];
	ld.local.u32 	%rd838, [%rd832+24];
	ld.local.u32 	%rd839, [%rd832+20];
	ld.local.u32 	%rd840, [%rd832+16];
	st.u32 	[%rd780+-48], %rd840;
	st.u32 	[%rd780+-44], %rd839;
	st.u32 	[%rd780+-40], %rd838;
	st.u32 	[%rd780+-36], %rd837;
	st.u32 	[%rd780+-64], %rd836;
	st.u32 	[%rd780+-60], %rd835;
	st.u32 	[%rd780+-56], %rd834;
	st.u32 	[%rd780+-52], %rd833;
	mov.u32 	%r171, 1130;
	bra.uni 	$L__BB0_98;
$L__BB0_63:                             // %.498
	setp.lt.u64 	%p125, %rd121, 40;
	@%p125 bra 	$L__BB0_147;
// %bb.64:
	st.global.u8 	[%rd126+1534], %rs1;
	bra.uni 	$L__BB0_147;
$L__BB0_69:                             // %.543
	setp.lt.u64 	%p77, %rd121, 184;
	@%p77 bra 	$L__BB0_147;
// %bb.70:
	xor.b32  	%r210, %r171, 3378;
	cvt.s64.s32 	%rd364, %r210;
	add.s64 	%rd365, %rd126, %rd364;
	st.global.u8 	[%rd365], %rs1;
	shl.b64 	%rd366, %rd122, 5;
	add.s64 	%rd367, %rd131, %rd366;
	ld.u32 	%rd368, [%rd367];
	ld.u32 	%rd369, [%rd367+4];
	ld.u32 	%rd370, [%rd367+8];
	ld.u32 	%rd371, [%rd367+12];
	ld.u32 	%rd372, [%rd367+16];
	ld.u32 	%rd373, [%rd367+20];
	ld.u32 	%rd374, [%rd367+24];
	ld.u32 	%rd375, [%rd367+28];
	add.u64 	%rd376, %SP, 960;
	add.u64 	%rd377, %SPL, 960;
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd376;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 17
	ld.local.u32 	%rd379, [%rd377];
	ld.local.u32 	%rd380, [%rd377+4];
	shl.b64 	%rd381, %rd380, 32;
	or.b64  	%rd382, %rd381, %rd379;
	add.u64 	%rd383, %SP, 992;
	add.u64 	%rd384, %SPL, 992;
	st.local.u32 	[%rd384+28], %rd375;
	st.local.u32 	[%rd384+24], %rd374;
	st.local.u32 	[%rd384+20], %rd373;
	st.local.u32 	[%rd384+16], %rd372;
	st.local.u32 	[%rd384+12], %rd371;
	st.local.u32 	[%rd384+8], %rd370;
	st.local.u32 	[%rd384+4], %rd369;
	st.local.u32 	[%rd384], %rd368;
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd382;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd383;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 18
	add.u64 	%rd386, %SP, 1024;
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd386;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 19
	bra.uni 	$L__BB0_95;
$L__BB0_71:                             // %.565
	setp.lt.u64 	%p106, %rd121, 96;
	@%p106 bra 	$L__BB0_147;
// %bb.72:
	xor.b32  	%r238, %r171, 13;
	and.b32  	%r239, %r238, 4095;
	cvt.u64.u32 	%rd651, %r239;
	add.s64 	%rd652, %rd126, %rd651;
	st.global.u8 	[%rd652], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd653, [%rd124+16];
	ld.u32 	%rd654, [%rd124];
	ld.u32 	%rd655, [%rd124+20];
	ld.u32 	%rd656, [%rd124+4];
	ld.u32 	%rd657, [%rd124+24];
	ld.u32 	%rd658, [%rd124+8];
	ld.u32 	%rd659, [%rd124+28];
	ld.u32 	%rd660, [%rd124+12];
	or.b64  	%rd661, %rd660, %rd659;
	shl.b64 	%rd662, %rd661, 32;
	or.b64  	%rd663, %rd662, %rd658;
	or.b64  	%rd664, %rd663, %rd657;
	or.b64  	%rd665, %rd656, %rd655;
	shl.b64 	%rd666, %rd665, 32;
	or.b64  	%rd667, %rd666, %rd654;
	or.b64  	%rd668, %rd667, %rd653;
	or.b64  	%rd669, %rd668, %rd664;
	setp.eq.s64 	%p107, %rd669, 0;
	add.s64 	%rd1313, %rd122, 1;
	shl.b64 	%rd670, %rd122, 5;
	add.s64 	%rd671, %rd131, %rd670;
	st.u32 	[%rd671+48], %rd653;
	st.u32 	[%rd671+52], %rd655;
	st.u32 	[%rd671+56], %rd657;
	st.u32 	[%rd671+60], %rd659;
	st.u32 	[%rd671+32], %rd654;
	st.u32 	[%rd671+36], %rd656;
	st.u32 	[%rd671+40], %rd658;
	st.u32 	[%rd671+44], %rd660;
	mov.u32 	%r171, 6;
	@%p107 bra 	$L__BB0_75;
	bra.uni 	$L__BB0_73;
$L__BB0_75:                             // %.577
	setp.lt.u64 	%p109, %rd121, 120;
	@%p109 bra 	$L__BB0_147;
// %bb.76:
	xor.b32  	%r241, %r171, 2609;
	and.b32  	%r242, %r241, 4095;
	cvt.u64.u32 	%rd672, %r242;
	add.s64 	%rd673, %rd126, %rd672;
	st.global.u8 	[%rd673], %rs1;
	add.s64 	%rd121, %rd121, -120;
	shl.b64 	%rd674, %rd1313, 5;
	add.s64 	%rd675, %rd131, %rd674;
	st.u32 	[%rd675+28], %rd134;
	st.u32 	[%rd675+24], %rd134;
	st.u32 	[%rd675+20], %rd134;
	st.u32 	[%rd675+16], %rd134;
	st.u32 	[%rd675+12], %rd134;
	st.u32 	[%rd675+8], %rd134;
	st.u32 	[%rd675+4], %rd134;
	mov.u64 	%rd677, 586;
	st.u32 	[%rd675], %rd677;
	mov.u32 	%r171, 1304;
	mov.u64 	%rd122, %rd1313;
$L__BB0_77:                             // %.799
	setp.lt.u64 	%p110, %rd121, 216;
	@%p110 bra 	$L__BB0_147;
// %bb.78:
	xor.b32  	%r244, %r171, 3499;
	and.b32  	%r245, %r244, 4095;
	cvt.u64.u32 	%rd678, %r245;
	add.s64 	%rd679, %rd126, %rd678;
	st.global.u8 	[%rd679], %rs1;
	add.s64 	%rd121, %rd121, -216;
	shl.b64 	%rd680, %rd122, 5;
	add.s64 	%rd681, %rd131, %rd680;
	ld.u32 	%rd682, [%rd681];
	ld.u32 	%rd683, [%rd681+4];
	shl.b64 	%rd684, %rd683, 32;
	or.b64  	%rd123, %rd684, %rd682;
	ld.u32 	%rd685, [%rd681+12];
	ld.u32 	%rd686, [%rd681+8];
	ld.u32 	%rd687, [%rd681+28];
	ld.u32 	%rd688, [%rd681+24];
	ld.u32 	%rd689, [%rd681+20];
	ld.u32 	%rd690, [%rd681+16];
	add.u64 	%rd691, %SP, 2016;
	add.u64 	%rd692, %SPL, 2016;
	st.local.u32 	[%rd692+16], %rd134;
	st.local.u32 	[%rd692+20], %rd134;
	st.local.u32 	[%rd692+24], %rd134;
	st.local.u32 	[%rd692+28], %rd134;
	mov.u64 	%rd694, 1;
	st.local.u32 	[%rd692], %rd694;
	st.local.u32 	[%rd692+4], %rd134;
	st.local.u32 	[%rd692+8], %rd134;
	st.local.u32 	[%rd692+12], %rd134;
	add.u64 	%rd695, %SP, 2048;
	add.u64 	%rd696, %SPL, 2048;
	{ // callseq 32, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd691;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd695;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 32
	{ // callseq 33, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd691;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r246, [retval0+0];
	} // callseq 33
	setp.eq.s32 	%p111, %r246, %r172;
	setp.eq.s32 	%p112, %r246, %r173;
	or.pred  	%p113, %p111, %p112;
	setp.eq.s32 	%p114, %r246, %r174;
	or.pred  	%p115, %p113, %p114;
	setp.eq.s32 	%p116, %r246, %r175;
	or.pred  	%p117, %p115, %p116;
	setp.eq.s32 	%p118, %r246, %r176;
	or.pred  	%p119, %p117, %p118;
	setp.eq.s32 	%p120, %r246, %r177;
	or.pred  	%p121, %p119, %p120;
	selp.u16 	%rs31, 1, 0, %p121;
	st.global.u8 	[%rd126+6], %rs31;
	ld.local.u32 	%rd697, [%rd696+12];
	ld.local.u32 	%rd698, [%rd696+8];
	ld.local.u32 	%rd699, [%rd696+4];
	ld.local.u32 	%rd700, [%rd696];
	ld.local.u32 	%rd701, [%rd696+28];
	ld.local.u32 	%rd702, [%rd696+24];
	ld.local.u32 	%rd703, [%rd696+20];
	ld.local.u32 	%rd704, [%rd696+16];
	add.s64 	%rd122, %rd122, 1;
	st.u32 	[%rd681+16], %rd690;
	st.u32 	[%rd681+20], %rd689;
	st.u32 	[%rd681+24], %rd688;
	st.u32 	[%rd681+28], %rd687;
	st.u32 	[%rd681], %rd682;
	st.u32 	[%rd681+4], %rd683;
	st.u32 	[%rd681+8], %rd686;
	st.u32 	[%rd681+12], %rd685;
	st.u32 	[%rd681+48], %rd704;
	st.u32 	[%rd681+52], %rd703;
	st.u32 	[%rd681+56], %rd702;
	st.u32 	[%rd681+60], %rd701;
	st.u32 	[%rd681+32], %rd700;
	st.u32 	[%rd681+36], %rd699;
	st.u32 	[%rd681+40], %rd698;
	st.u32 	[%rd681+44], %rd697;
	mov.u32 	%r171, 1749;
	bra.uni 	$L__BB0_98;
$L__BB0_73:                             // %.573
	setp.lt.u64 	%p108, %rd121, 40;
	@%p108 bra 	$L__BB0_147;
// %bb.74:
	st.global.u8 	[%rd126+1969], %rs1;
	bra.uni 	$L__BB0_147;
$L__BB0_79:                             // %.586
	setp.lt.u64 	%p76, %rd121, 184;
	@%p76 bra 	$L__BB0_147;
// %bb.80:
	xor.b32  	%r209, %r171, 1112;
	cvt.s64.s32 	%rd341, %r209;
	add.s64 	%rd342, %rd126, %rd341;
	st.global.u8 	[%rd342], %rs1;
	shl.b64 	%rd343, %rd122, 5;
	add.s64 	%rd344, %rd131, %rd343;
	ld.u32 	%rd345, [%rd344];
	ld.u32 	%rd346, [%rd344+4];
	ld.u32 	%rd347, [%rd344+8];
	ld.u32 	%rd348, [%rd344+12];
	ld.u32 	%rd349, [%rd344+16];
	ld.u32 	%rd350, [%rd344+20];
	ld.u32 	%rd351, [%rd344+24];
	ld.u32 	%rd352, [%rd344+28];
	add.u64 	%rd353, %SP, 1056;
	add.u64 	%rd354, %SPL, 1056;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd353;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 14
	ld.local.u32 	%rd356, [%rd354];
	ld.local.u32 	%rd357, [%rd354+4];
	shl.b64 	%rd358, %rd357, 32;
	or.b64  	%rd359, %rd358, %rd356;
	add.u64 	%rd360, %SP, 1088;
	add.u64 	%rd361, %SPL, 1088;
	st.local.u32 	[%rd361+28], %rd352;
	st.local.u32 	[%rd361+24], %rd351;
	st.local.u32 	[%rd361+20], %rd350;
	st.local.u32 	[%rd361+16], %rd349;
	st.local.u32 	[%rd361+12], %rd348;
	st.local.u32 	[%rd361+8], %rd347;
	st.local.u32 	[%rd361+4], %rd346;
	st.local.u32 	[%rd361], %rd345;
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd359;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd360;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 15
	add.u64 	%rd363, %SP, 1120;
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd363;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 16
	bra.uni 	$L__BB0_95;
$L__BB0_81:                             // %.608
	setp.lt.u64 	%p79, %rd121, 96;
	@%p79 bra 	$L__BB0_147;
// %bb.82:
	xor.b32  	%r213, %r171, 163;
	and.b32  	%r214, %r213, 4095;
	cvt.u64.u32 	%rd410, %r214;
	add.s64 	%rd411, %rd126, %rd410;
	st.global.u8 	[%rd411], %rs1;
	add.s64 	%rd121, %rd121, -96;
	ld.u32 	%rd412, [%rd124+16];
	ld.u32 	%rd413, [%rd124];
	ld.u32 	%rd414, [%rd124+20];
	ld.u32 	%rd415, [%rd124+4];
	ld.u32 	%rd416, [%rd124+24];
	ld.u32 	%rd417, [%rd124+8];
	ld.u32 	%rd418, [%rd124+28];
	ld.u32 	%rd419, [%rd124+12];
	or.b64  	%rd420, %rd419, %rd418;
	shl.b64 	%rd421, %rd420, 32;
	or.b64  	%rd422, %rd421, %rd417;
	or.b64  	%rd423, %rd422, %rd416;
	or.b64  	%rd424, %rd415, %rd414;
	shl.b64 	%rd425, %rd424, 32;
	or.b64  	%rd426, %rd425, %rd413;
	or.b64  	%rd427, %rd426, %rd412;
	or.b64  	%rd428, %rd427, %rd423;
	setp.eq.s64 	%p80, %rd428, 0;
	add.s64 	%rd1317, %rd122, 1;
	shl.b64 	%rd429, %rd122, 5;
	add.s64 	%rd430, %rd131, %rd429;
	st.u32 	[%rd430+48], %rd412;
	st.u32 	[%rd430+52], %rd414;
	st.u32 	[%rd430+56], %rd416;
	st.u32 	[%rd430+60], %rd418;
	st.u32 	[%rd430+32], %rd413;
	st.u32 	[%rd430+36], %rd415;
	st.u32 	[%rd430+40], %rd417;
	st.u32 	[%rd430+44], %rd419;
	mov.u32 	%r171, 81;
	@%p80 bra 	$L__BB0_85;
	bra.uni 	$L__BB0_83;
$L__BB0_85:                             // %.620
	setp.lt.u64 	%p82, %rd121, 336;
	@%p82 bra 	$L__BB0_147;
// %bb.86:
	xor.b32  	%r216, %r171, 293;
	and.b32  	%r217, %r216, 4095;
	cvt.u64.u32 	%rd431, %r217;
	add.s64 	%rd432, %rd126, %rd431;
	st.global.u8 	[%rd432], %rs1;
	add.s64 	%rd121, %rd121, -336;
	shl.b64 	%rd433, %rd1317, 5;
	add.s64 	%rd434, %rd131, %rd433;
	add.u64 	%rd435, %SP, 1152;
	add.u64 	%rd436, %SPL, 1152;
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd435;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1283;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 23
	ld.local.u32 	%rd438, [%rd436+12];
	ld.local.u32 	%rd439, [%rd436+8];
	ld.local.u32 	%rd440, [%rd436+4];
	ld.local.u32 	%rd441, [%rd436];
	ld.local.u32 	%rd442, [%rd436+28];
	ld.local.u32 	%rd443, [%rd436+24];
	ld.local.u32 	%rd444, [%rd436+20];
	ld.local.u32 	%rd445, [%rd436+16];
	add.u64 	%rd446, %SP, 1184;
	add.u64 	%rd447, %SPL, 1184;
	{ // callseq 24, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd446;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd125;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1284;
	call.uni 
	__device_calldataload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 24
	ld.local.u32 	%rd449, [%rd447+12];
	ld.local.u32 	%rd450, [%rd447+8];
	ld.local.u32 	%rd451, [%rd447+4];
	ld.local.u32 	%rd452, [%rd447];
	ld.local.u32 	%rd453, [%rd447+28];
	ld.local.u32 	%rd454, [%rd447+24];
	ld.local.u32 	%rd455, [%rd447+20];
	ld.local.u32 	%rd456, [%rd447+16];
	st.u32 	[%rd434+16], %rd134;
	st.u32 	[%rd434+20], %rd134;
	st.u32 	[%rd434+24], %rd134;
	st.u32 	[%rd434+28], %rd134;
	mov.u64 	%rd458, 661;
	st.u32 	[%rd434], %rd458;
	st.u32 	[%rd434+4], %rd134;
	st.u32 	[%rd434+8], %rd134;
	st.u32 	[%rd434+12], %rd134;
	add.s64 	%rd122, %rd1317, 2;
	st.u32 	[%rd434+48], %rd445;
	st.u32 	[%rd434+52], %rd444;
	st.u32 	[%rd434+56], %rd443;
	st.u32 	[%rd434+60], %rd442;
	st.u32 	[%rd434+32], %rd441;
	st.u32 	[%rd434+36], %rd440;
	st.u32 	[%rd434+40], %rd439;
	st.u32 	[%rd434+44], %rd438;
	st.u32 	[%rd434+80], %rd456;
	st.u32 	[%rd434+84], %rd455;
	st.u32 	[%rd434+88], %rd454;
	st.u32 	[%rd434+92], %rd453;
	st.u32 	[%rd434+64], %rd452;
	st.u32 	[%rd434+68], %rd451;
	st.u32 	[%rd434+72], %rd450;
	st.u32 	[%rd434+76], %rd449;
	mov.u32 	%r171, 146;
$L__BB0_87:                             // %.805
	shl.b64 	%rd459, %rd122, 5;
	add.s64 	%rd460, %rd131, %rd459;
	st.u32 	[%rd460+60], %rd134;
	st.u32 	[%rd460+56], %rd134;
	st.u32 	[%rd460+52], %rd134;
	st.u32 	[%rd460+48], %rd134;
	st.u32 	[%rd460+44], %rd134;
	st.u32 	[%rd460+40], %rd134;
	st.u32 	[%rd460+36], %rd134;
	st.u32 	[%rd460+32], %rd134;
	st.u32 	[%rd460+92], %rd134;
	st.u32 	[%rd460+88], %rd134;
	st.u32 	[%rd460+84], %rd134;
	st.u32 	[%rd460+80], %rd134;
	st.u32 	[%rd460+76], %rd134;
	st.u32 	[%rd460+72], %rd134;
	st.u32 	[%rd460+68], %rd134;
	mov.u64 	%rd462, 1;
	st.u32 	[%rd460+64], %rd462;
	add.s64 	%rd122, %rd122, 3;
	st.u32 	[%rd460+124], %rd134;
	st.u32 	[%rd460+120], %rd134;
	st.u32 	[%rd460+116], %rd134;
	st.u32 	[%rd460+112], %rd134;
	st.u32 	[%rd460+108], %rd134;
	st.u32 	[%rd460+104], %rd134;
	st.u32 	[%rd460+100], %rd134;
	st.u32 	[%rd460+96], %rd134;
$L__BB0_88:                             // %.819.preheader
	shl.b64 	%rd465, %rd122, 5;
	add.s64 	%rd113, %rd131, %rd465;
	add.s64 	%rd114, %rd122, -3;
	shl.b64 	%rd533, %rd114, 5;
	add.s64 	%rd534, %rd131, %rd533;
$L__BB0_89:                             // %.819
                                        // =>This Inner Loop Header: Depth=1
	setp.lt.u64 	%p83, %rd121, 432;
	@%p83 bra 	$L__BB0_147;
// %bb.90:                              //   in Loop: Header=BB0_89 Depth=1
	xor.b32  	%r219, %r171, 3250;
	and.b32  	%r220, %r219, 4095;
	cvt.u64.u32 	%rd463, %r220;
	add.s64 	%rd464, %rd126, %rd463;
	st.global.u8 	[%rd464], %rs1;
	add.s64 	%rd121, %rd121, -432;
	ld.u32 	%rd466, [%rd113];
	ld.u32 	%rd467, [%rd113+4];
	shl.b64 	%rd468, %rd467, 32;
	or.b64  	%rd469, %rd468, %rd466;
	ld.u32 	%rd470, [%rd113+8];
	ld.u32 	%rd471, [%rd113+12];
	shl.b64 	%rd472, %rd471, 32;
	or.b64  	%rd473, %rd472, %rd470;
	ld.u32 	%rd474, [%rd113+16];
	ld.u32 	%rd475, [%rd113+20];
	shl.b64 	%rd476, %rd475, 32;
	or.b64  	%rd477, %rd476, %rd474;
	ld.u32 	%rd478, [%rd113+24];
	ld.u32 	%rd479, [%rd113+28];
	shl.b64 	%rd480, %rd479, 32;
	or.b64  	%rd481, %rd480, %rd478;
	ld.u32 	%rd482, [%rd113+-96];
	ld.u32 	%rd483, [%rd113+-92];
	shl.b64 	%rd484, %rd483, 32;
	or.b64  	%rd485, %rd484, %rd482;
	ld.u32 	%rd486, [%rd113+-88];
	ld.u32 	%rd487, [%rd113+-84];
	shl.b64 	%rd488, %rd487, 32;
	or.b64  	%rd489, %rd488, %rd486;
	ld.u32 	%rd490, [%rd113+-80];
	ld.u32 	%rd491, [%rd113+-76];
	shl.b64 	%rd492, %rd491, 32;
	or.b64  	%rd493, %rd492, %rd490;
	ld.u32 	%rd494, [%rd113+-72];
	ld.u32 	%rd495, [%rd113+-68];
	shl.b64 	%rd496, %rd495, 32;
	or.b64  	%rd497, %rd496, %rd494;
	setp.eq.s64 	%p84, %rd481, %rd497;
	setp.ge.u64 	%p85, %rd481, %rd497;
	selp.u32 	%r221, -1, 0, %p85;
	setp.ge.u64 	%p86, %rd477, %rd493;
	selp.u32 	%r222, -1, 0, %p86;
	selp.b32 	%r223, %r222, %r221, %p84;
	setp.eq.s64 	%p87, %rd473, %rd489;
	setp.ge.u64 	%p88, %rd473, %rd489;
	selp.u32 	%r224, -1, 0, %p88;
	setp.ge.u64 	%p89, %rd469, %rd485;
	selp.u32 	%r225, -1, 0, %p89;
	selp.b32 	%r226, %r225, %r224, %p87;
	xor.b64  	%rd498, %rd481, %rd497;
	xor.b64  	%rd499, %rd477, %rd493;
	or.b64  	%rd500, %rd499, %rd498;
	setp.eq.s64 	%p90, %rd500, 0;
	selp.b32 	%r227, %r226, %r223, %p90;
	and.b32  	%r228, %r227, 1;
	setp.eq.b32 	%p91, %r228, 1;
	mov.u32 	%r171, 1625;
	@%p91 bra 	$L__BB0_96;
// %bb.91:                              // %.828
                                        //   in Loop: Header=BB0_89 Depth=1
	setp.lt.u64 	%p92, %rd121, 520;
	@%p92 bra 	$L__BB0_147;
// %bb.92:                              //   in Loop: Header=BB0_89 Depth=1
	st.global.u8 	[%rd126+1684], %rs1;
	add.s64 	%rd121, %rd121, -520;
	ld.u32 	%rd501, [%rd113];
	ld.u32 	%rd502, [%rd113+4];
	shl.b64 	%rd503, %rd502, 32;
	or.b64  	%rd504, %rd503, %rd501;
	ld.u32 	%rd505, [%rd113+8];
	ld.u32 	%rd506, [%rd113+12];
	shl.b64 	%rd507, %rd506, 32;
	or.b64  	%rd508, %rd507, %rd505;
	ld.u32 	%rd509, [%rd113+16];
	ld.u32 	%rd510, [%rd113+20];
	shl.b64 	%rd511, %rd510, 32;
	or.b64  	%rd512, %rd511, %rd509;
	ld.u32 	%rd513, [%rd113+24];
	ld.u32 	%rd514, [%rd113+28];
	shl.b64 	%rd515, %rd514, 32;
	or.b64  	%rd516, %rd515, %rd513;
	ld.u32 	%rd517, [%rd113+-16];
	ld.u32 	%rd518, [%rd113+-12];
	shl.b64 	%rd519, %rd518, 32;
	or.b64  	%rd520, %rd519, %rd517;
	ld.u32 	%rd521, [%rd113+-8];
	ld.u32 	%rd522, [%rd113+-4];
	shl.b64 	%rd523, %rd522, 32;
	or.b64  	%rd524, %rd523, %rd521;
	ld.u32 	%rd525, [%rd113+-24];
	ld.u32 	%rd526, [%rd113+-20];
	shl.b64 	%rd527, %rd526, 32;
	or.b64  	%rd528, %rd527, %rd525;
	ld.u32 	%rd529, [%rd113+-32];
	ld.u32 	%rd530, [%rd113+-28];
	shl.b64 	%rd531, %rd530, 32;
	or.b64  	%rd532, %rd531, %rd529;
	ld.u32 	%rd535, [%rd534+-8];
	ld.u32 	%rd536, [%rd534+-4];
	shl.b64 	%rd537, %rd536, 32;
	or.b64  	%rd538, %rd537, %rd535;
	ld.u32 	%rd539, [%rd534+-16];
	ld.u32 	%rd540, [%rd534+-12];
	shl.b64 	%rd541, %rd540, 32;
	or.b64  	%rd542, %rd541, %rd539;
	ld.u32 	%rd543, [%rd534+-24];
	ld.u32 	%rd544, [%rd534+-20];
	shl.b64 	%rd545, %rd544, 32;
	or.b64  	%rd546, %rd545, %rd543;
	ld.u32 	%rd547, [%rd534+-32];
	ld.u32 	%rd548, [%rd534+-28];
	shl.b64 	%rd549, %rd548, 32;
	or.b64  	%rd550, %rd549, %rd547;
	mul.hi.u64 	%rd551, %rd532, %rd550;
	mul.lo.s64 	%rd552, %rd528, %rd550;
	mul.hi.u64 	%rd553, %rd528, %rd550;
	add.cc.s64 	%rd554, %rd552, %rd551;
	addc.cc.s64 	%rd555, %rd553, 0;
	mul.lo.s64 	%rd556, %rd532, %rd546;
	mul.hi.u64 	%rd557, %rd532, %rd546;
	add.cc.s64 	%rd558, %rd556, %rd554;
	addc.cc.s64 	%rd559, %rd557, 0;
	add.cc.s64 	%rd561, %rd555, %rd559;
	addc.cc.s64 	%rd562, %rd134, 0;
	mul.lo.s64 	%rd563, %rd528, %rd546;
	mul.hi.u64 	%rd564, %rd528, %rd546;
	add.cc.s64 	%rd565, %rd563, %rd561;
	addc.cc.s64 	%rd566, %rd564, %rd562;
	mul.lo.s64 	%rd567, %rd550, %rd524;
	mul.hi.u64 	%rd568, %rd550, %rd520;
	add.s64 	%rd569, %rd568, %rd567;
	mul.lo.s64 	%rd570, %rd546, %rd520;
	add.s64 	%rd571, %rd569, %rd570;
	mul.lo.s64 	%rd572, %rd542, %rd528;
	mul.hi.u64 	%rd573, %rd542, %rd532;
	add.s64 	%rd574, %rd573, %rd572;
	mul.lo.s64 	%rd575, %rd538, %rd532;
	add.s64 	%rd576, %rd574, %rd575;
	mul.lo.s64 	%rd577, %rd550, %rd520;
	mul.lo.s64 	%rd578, %rd542, %rd532;
	add.cc.s64 	%rd579, %rd578, %rd577;
	addc.cc.s64 	%rd580, %rd576, %rd571;
	add.cc.s64 	%rd581, %rd565, %rd579;
	addc.cc.s64 	%rd582, %rd566, %rd580;
	mul.lo.s64 	%rd583, %rd532, %rd550;
	add.cc.s64 	%rd584, %rd504, 1;
	addc.cc.s64 	%rd585, %rd508, 0;
	addc.cc.s64 	%rd586, %rd512, 0;
	addc.cc.s64 	%rd587, %rd516, 0;
	st.u32 	[%rd113+-32], %rd583;
	shr.u64 	%rd588, %rd583, 32;
	st.u32 	[%rd113+-28], %rd588;
	st.u32 	[%rd113+-24], %rd558;
	shr.u64 	%rd589, %rd558, 32;
	st.u32 	[%rd113+-20], %rd589;
	st.u32 	[%rd113+-16], %rd581;
	st.u32 	[%rd113+-8], %rd582;
	shr.u64 	%rd590, %rd581, 32;
	st.u32 	[%rd113+-12], %rd590;
	shr.u64 	%rd591, %rd582, 32;
	st.u32 	[%rd113+-4], %rd591;
	st.u32 	[%rd113+16], %rd586;
	st.u32 	[%rd113+24], %rd587;
	st.u32 	[%rd113], %rd584;
	st.u32 	[%rd113+8], %rd585;
	shr.u64 	%rd592, %rd586, 32;
	st.u32 	[%rd113+20], %rd592;
	shr.u64 	%rd593, %rd587, 32;
	st.u32 	[%rd113+28], %rd593;
	shr.u64 	%rd594, %rd584, 32;
	st.u32 	[%rd113+4], %rd594;
	shr.u64 	%rd595, %rd585, 32;
	st.u32 	[%rd113+12], %rd595;
	mov.u32 	%r171, 102;
	bra.uni 	$L__BB0_89;
$L__BB0_83:                             // %.616
	setp.lt.u64 	%p81, %rd121, 40;
	@%p81 bra 	$L__BB0_147;
// %bb.84:
	st.global.u8 	[%rd126+2315], %rs1;
	bra.uni 	$L__BB0_147;
$L__BB0_93:                             // %.661
	setp.lt.u64 	%p75, %rd121, 184;
	@%p75 bra 	$L__BB0_147;
// %bb.94:
	xor.b32  	%r208, %r171, 2397;
	cvt.s64.s32 	%rd318, %r208;
	add.s64 	%rd319, %rd126, %rd318;
	st.global.u8 	[%rd319], %rs1;
	shl.b64 	%rd320, %rd122, 5;
	add.s64 	%rd321, %rd131, %rd320;
	ld.u32 	%rd322, [%rd321];
	ld.u32 	%rd323, [%rd321+4];
	ld.u32 	%rd324, [%rd321+8];
	ld.u32 	%rd325, [%rd321+12];
	ld.u32 	%rd326, [%rd321+16];
	ld.u32 	%rd327, [%rd321+20];
	ld.u32 	%rd328, [%rd321+24];
	ld.u32 	%rd329, [%rd321+28];
	add.u64 	%rd330, %SP, 1216;
	add.u64 	%rd331, %SPL, 1216;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd330;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 11
	ld.local.u32 	%rd333, [%rd331];
	ld.local.u32 	%rd334, [%rd331+4];
	shl.b64 	%rd335, %rd334, 32;
	or.b64  	%rd336, %rd335, %rd333;
	add.u64 	%rd337, %SP, 1248;
	add.u64 	%rd338, %SPL, 1248;
	st.local.u32 	[%rd338+28], %rd329;
	st.local.u32 	[%rd338+24], %rd328;
	st.local.u32 	[%rd338+20], %rd327;
	st.local.u32 	[%rd338+16], %rd326;
	st.local.u32 	[%rd338+12], %rd325;
	st.local.u32 	[%rd338+8], %rd324;
	st.local.u32 	[%rd338+4], %rd323;
	st.local.u32 	[%rd338], %rd322;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd336;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd337;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd137;
	call.uni 
	__device_mstore, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 12
	add.u64 	%rd340, %SP, 1280;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd340;
	call.uni 
	__device_mload, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 13
$L__BB0_95:                             // %Exit
	{ // callseq 51, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 51
	{ // callseq 52, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd131;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 52
	mov.u32 	%r274, 1;
	st.param.b32 	[func_retval0+0], %r274;
	ret;
$L__BB0_96:                             // %.845
	setp.lt.u64 	%p93, %rd121, 448;
	@%p93 bra 	$L__BB0_147;
// %bb.97:
	xor.b32  	%r231, %r171, 198;
	and.b32  	%r232, %r231, 4095;
	cvt.u64.u32 	%rd596, %r232;
	add.s64 	%rd597, %rd126, %rd596;
	st.global.u8 	[%rd597], %rs1;
	add.s64 	%rd121, %rd121, -448;
	shl.b64 	%rd598, %rd122, 5;
	add.s64 	%rd599, %rd131, %rd598;
	ld.u32 	%rd600, [%rd599+-20];
	ld.u32 	%rd601, [%rd599+-24];
	ld.u32 	%rd602, [%rd599+-28];
	ld.u32 	%rd603, [%rd599+-32];
	ld.u32 	%rd604, [%rd599+-4];
	ld.u32 	%rd605, [%rd599+-8];
	ld.u32 	%rd606, [%rd599+-12];
	ld.u32 	%rd607, [%rd599+-16];
	add.s64 	%rd122, %rd122, -5;
	ld.u32 	%rd608, [%rd599+-160];
	ld.u32 	%rd609, [%rd599+-156];
	shl.b64 	%rd610, %rd609, 32;
	or.b64  	%rd123, %rd610, %rd608;
	add.u64 	%rd611, %SP, 2080;
	add.u64 	%rd612, %SPL, 2080;
	st.local.u32 	[%rd612+24], %rd134;
	st.local.u32 	[%rd612+28], %rd134;
	st.local.u32 	[%rd612], %rd134;
	st.local.u32 	[%rd612+4], %rd134;
	st.local.u32 	[%rd612+8], %rd134;
	st.local.u32 	[%rd612+12], %rd134;
	st.local.u32 	[%rd612+16], %rd134;
	st.local.u32 	[%rd612+20], %rd134;
	add.u64 	%rd614, %SP, 2112;
	add.u64 	%rd615, %SPL, 2112;
	st.local.u32 	[%rd615+16], %rd607;
	st.local.u32 	[%rd615+20], %rd606;
	st.local.u32 	[%rd615+24], %rd605;
	st.local.u32 	[%rd615+28], %rd604;
	st.local.u32 	[%rd615], %rd603;
	st.local.u32 	[%rd615+4], %rd602;
	st.local.u32 	[%rd615+8], %rd601;
	st.local.u32 	[%rd615+12], %rd600;
	{ // callseq 25, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd611;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd614;
	call.uni 
	__device_sstore, 
	(
	param0, 
	param1
	);
	} // callseq 25
	{ // callseq 26, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd611;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r177, [retval0+0];
	} // callseq 26
	add.u64 	%rd616, %SP, 2144;
	add.u64 	%rd617, %SPL, 2144;
	st.local.u32 	[%rd617+28], %rd134;
	st.local.u32 	[%rd617+24], %rd134;
	st.local.u32 	[%rd617+20], %rd134;
	st.local.u32 	[%rd617+16], %rd134;
	st.local.u32 	[%rd617+12], %rd134;
	st.local.u32 	[%rd617+8], %rd134;
	st.local.u32 	[%rd617+4], %rd134;
	st.local.u32 	[%rd617], %rd134;
	add.u64 	%rd618, %SP, 2176;
	add.u64 	%rd619, %SPL, 2176;
	{ // callseq 27, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd616;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd618;
	call.uni 
	__device_sload, 
	(
	param0, 
	param1
	);
	} // callseq 27
	{ // callseq 28, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd616;
	.param .b32 retval0;
	call.uni (retval0), 
	__hashword, 
	(
	param0
	);
	ld.param.b32 	%r234, [retval0+0];
	} // callseq 28
	setp.eq.s32 	%p94, %r234, %r172;
	setp.eq.s32 	%p95, %r234, %r173;
	or.pred  	%p96, %p94, %p95;
	setp.eq.s32 	%p97, %r234, %r174;
	or.pred  	%p98, %p96, %p97;
	setp.eq.s32 	%p99, %r234, %r175;
	or.pred  	%p100, %p98, %p99;
	setp.eq.s32 	%p101, %r234, %r176;
	or.pred  	%p102, %p100, %p101;
	setp.eq.s32 	%p103, %r234, %r177;
	or.pred  	%p104, %p102, %p103;
	selp.u16 	%rs25, 1, 0, %p104;
	st.global.u8 	[%rd126+7], %rs25;
	ld.local.u32 	%rd620, [%rd619+12];
	ld.local.u32 	%rd621, [%rd619+8];
	ld.local.u32 	%rd622, [%rd619+4];
	ld.local.u32 	%rd623, [%rd619];
	ld.local.u32 	%rd624, [%rd619+28];
	ld.local.u32 	%rd625, [%rd619+24];
	ld.local.u32 	%rd626, [%rd619+20];
	ld.local.u32 	%rd627, [%rd619+16];
	st.u32 	[%rd599+-144], %rd627;
	st.u32 	[%rd599+-140], %rd626;
	st.u32 	[%rd599+-136], %rd625;
	st.u32 	[%rd599+-132], %rd624;
	st.u32 	[%rd599+-160], %rd623;
	st.u32 	[%rd599+-156], %rd622;
	st.u32 	[%rd599+-152], %rd621;
	st.u32 	[%rd599+-148], %rd620;
	mov.u32 	%r171, 99;
$L__BB0_98:                             // %JumpTable
	setp.gt.s64 	%p26, %rd123, 576;
	@%p26 bra 	$L__BB0_126;
// %bb.99:                              // %JumpTable
	setp.gt.s64 	%p48, %rd123, 371;
	@%p48 bra 	$L__BB0_113;
	bra.uni 	$L__BB0_100;
$L__BB0_113:                            // %JumpTable
	setp.gt.s64 	%p49, %rd123, 467;
	@%p49 bra 	$L__BB0_120;
// %bb.114:                             // %JumpTable
	setp.gt.s64 	%p56, %rd123, 424;
	@%p56 bra 	$L__BB0_117;
	bra.uni 	$L__BB0_115;
$L__BB0_117:                            // %JumpTable
	setp.eq.s64 	%p57, %rd123, 447;
	@%p57 bra 	$L__BB0_51;
// %bb.118:                             // %JumpTable
	setp.eq.s64 	%p58, %rd123, 459;
	mov.u64 	%rd1305, %rd122;
	@%p58 bra 	$L__BB0_55;
// %bb.119:                             // %JumpTable
	setp.eq.s64 	%p59, %rd123, 425;
	@%p59 bra 	$L__BB0_49;
	bra.uni 	$L__BB0_147;
$L__BB0_126:                            // %JumpTable
	setp.gt.s64 	%p27, %rd123, 748;
	@%p27 bra 	$L__BB0_138;
	bra.uni 	$L__BB0_127;
$L__BB0_138:                            // %JumpTable
	setp.gt.s64 	%p28, %rd123, 798;
	@%p28 bra 	$L__BB0_142;
	bra.uni 	$L__BB0_139;
$L__BB0_142:                            // %JumpTable
	setp.gt.s64 	%p29, %rd123, 818;
	@%p29 bra 	$L__BB0_145;
// %bb.143:                             // %JumpTable
	setp.eq.s64 	%p32, %rd123, 799;
	@%p32 bra 	$L__BB0_77;
// %bb.144:                             // %JumpTable
	setp.eq.s64 	%p33, %rd123, 805;
	@%p33 bra 	$L__BB0_87;
	bra.uni 	$L__BB0_147;
$L__BB0_100:                            // %JumpTable
	setp.gt.s64 	%p62, %rd123, 233;
	@%p62 bra 	$L__BB0_107;
// %bb.101:                             // %JumpTable
	setp.gt.s64 	%p69, %rd123, 158;
	@%p69 bra 	$L__BB0_104;
	bra.uni 	$L__BB0_102;
$L__BB0_104:                            // %JumpTable
	setp.eq.s64 	%p70, %rd123, 159;
	mov.u64 	%rd1289, %rd122;
	@%p70 bra 	$L__BB0_15;
// %bb.105:                             // %JumpTable
	setp.eq.s64 	%p71, %rd123, 222;
	@%p71 bra 	$L__BB0_21;
// %bb.106:                             // %JumpTable
	setp.eq.s64 	%p72, %rd123, 200;
	@%p72 bra 	$L__BB0_19;
	bra.uni 	$L__BB0_147;
$L__BB0_127:                            // %JumpTable
	setp.gt.s64 	%p37, %rd123, 660;
	@%p37 bra 	$L__BB0_133;
// %bb.128:                             // %JumpTable
	setp.gt.s64 	%p43, %rd123, 607;
	@%p43 bra 	$L__BB0_131;
	bra.uni 	$L__BB0_129;
$L__BB0_131:                            // %JumpTable
	setp.eq.s64 	%p44, %rd123, 608;
	@%p44 bra 	$L__BB0_81;
// %bb.132:                             // %JumpTable
	setp.eq.s64 	%p45, %rd123, 620;
	mov.u64 	%rd1317, %rd122;
	@%p45 bra 	$L__BB0_85;
	bra.uni 	$L__BB0_147;
$L__BB0_120:                            // %JumpTable
	setp.gt.s64 	%p50, %rd123, 501;
	@%p50 bra 	$L__BB0_123;
	bra.uni 	$L__BB0_121;
$L__BB0_123:                            // %JumpTable
	setp.eq.s64 	%p51, %rd123, 502;
	mov.u64 	%rd1309, %rd122;
	@%p51 bra 	$L__BB0_65;
// %bb.124:                             // %JumpTable
	setp.eq.s64 	%p52, %rd123, 565;
	@%p52 bra 	$L__BB0_71;
// %bb.125:                             // %JumpTable
	setp.eq.s64 	%p53, %rd123, 543;
	@%p53 bra 	$L__BB0_69;
	bra.uni 	$L__BB0_147;
$L__BB0_107:                            // %JumpTable
	setp.gt.s64 	%p63, %rd123, 296;
	@%p63 bra 	$L__BB0_110;
	bra.uni 	$L__BB0_108;
$L__BB0_110:                            // %JumpTable
	setp.eq.s64 	%p64, %rd123, 297;
	@%p64 bra 	$L__BB0_31;
// %bb.111:                             // %JumpTable
	setp.eq.s64 	%p65, %rd123, 309;
	mov.u64 	%rd1297, %rd122;
	@%p65 bra 	$L__BB0_35;
// %bb.112:                             // %JumpTable
	setp.eq.s64 	%p66, %rd123, 350;
	@%p66 bra 	$L__BB0_39;
	bra.uni 	$L__BB0_147;
$L__BB0_133:                            // %JumpTable
	setp.gt.s64 	%p38, %rd123, 704;
	@%p38 bra 	$L__BB0_136;
	bra.uni 	$L__BB0_134;
$L__BB0_136:                            // %JumpTable
	setp.eq.s64 	%p39, %rd123, 705;
	@%p39 bra 	$L__BB0_27;
// %bb.137:                             // %JumpTable
	setp.eq.s64 	%p40, %rd123, 727;
	@%p40 bra 	$L__BB0_37;
	bra.uni 	$L__BB0_147;
$L__BB0_139:                            // %JumpTable
	setp.eq.s64 	%p34, %rd123, 749;
	@%p34 bra 	$L__BB0_47;
// %bb.140:                             // %JumpTable
	setp.eq.s64 	%p35, %rd123, 771;
	@%p35 bra 	$L__BB0_57;
// %bb.141:                             // %JumpTable
	setp.eq.s64 	%p36, %rd123, 777;
	@%p36 bra 	$L__BB0_67;
	bra.uni 	$L__BB0_147;
$L__BB0_115:                            // %JumpTable
	setp.eq.s64 	%p60, %rd123, 372;
	@%p60 bra 	$L__BB0_41;
// %bb.116:                             // %JumpTable
	setp.eq.s64 	%p61, %rd123, 384;
	mov.u64 	%rd1301, %rd122;
	@%p61 bra 	$L__BB0_45;
	bra.uni 	$L__BB0_147;
$L__BB0_145:                            // %JumpTable
	setp.eq.s64 	%p30, %rd123, 819;
	@%p30 bra 	$L__BB0_88;
// %bb.146:                             // %JumpTable
	setp.eq.s64 	%p31, %rd123, 845;
	@%p31 bra 	$L__BB0_96;
	bra.uni 	$L__BB0_147;
$L__BB0_102:                            // %JumpTable
	setp.eq.s64 	%p73, %rd123, 147;
	@%p73 bra 	$L__BB0_11;
// %bb.103:                             // %JumpTable
	setp.eq.s64 	%p74, %rd123, 142;
	@%p74 bra 	$L__BB0_9;
	bra.uni 	$L__BB0_147;
$L__BB0_129:                            // %JumpTable
	setp.eq.s64 	%p46, %rd123, 577;
	mov.u64 	%rd1313, %rd122;
	@%p46 bra 	$L__BB0_75;
// %bb.130:                             // %JumpTable
	setp.eq.s64 	%p47, %rd123, 586;
	@%p47 bra 	$L__BB0_79;
	bra.uni 	$L__BB0_147;
$L__BB0_121:                            // %JumpTable
	setp.eq.s64 	%p54, %rd123, 490;
	@%p54 bra 	$L__BB0_61;
// %bb.122:                             // %JumpTable
	setp.eq.s64 	%p55, %rd123, 468;
	@%p55 bra 	$L__BB0_59;
	bra.uni 	$L__BB0_147;
$L__BB0_108:                            // %JumpTable
	setp.eq.s64 	%p67, %rd123, 234;
	mov.u64 	%rd1293, %rd122;
	@%p67 bra 	$L__BB0_25;
// %bb.109:                             // %JumpTable
	setp.eq.s64 	%p68, %rd123, 275;
	@%p68 bra 	$L__BB0_29;
	bra.uni 	$L__BB0_147;
$L__BB0_134:                            // %JumpTable
	setp.eq.s64 	%p41, %rd123, 683;
	@%p41 bra 	$L__BB0_17;
// %bb.135:                             // %JumpTable
	setp.eq.s64 	%p42, %rd123, 661;
	@%p42 bra 	$L__BB0_93;
	bra.uni 	$L__BB0_147;
                                        // -- End function
}
.func evm_$_udiv_$_i256(
	.param .b64 evm_$_udiv_$_i256_param_0,
	.param .b64 evm_$_udiv_$_i256_param_1,
	.param .b64 evm_$_udiv_$_i256_param_2
)                                       // -- Begin function evm_$_udiv_$_i256
                                        // @"evm_$_udiv_$_i256"
{
	.local .align 8 .b8 	__local_depot1[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b64 	%rd<5>;

// %bb.0:
	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [evm_$_udiv_$_i256_param_0];
	ld.param.u64 	%rd2, [evm_$_udiv_$_i256_param_1];
	ld.param.u64 	%rd3, [evm_$_udiv_$_i256_param_2];
	add.u64 	%rd4, %SP, 0;
	{ // callseq 73, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd2;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd3;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd4;
	call.uni 
	evm_$_udivrem_$_i256, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 73
	ret;
                                        // -- End function
}
.func evm_$_udivrem_$_i256(
	.param .b64 evm_$_udivrem_$_i256_param_0,
	.param .b64 evm_$_udivrem_$_i256_param_1,
	.param .b64 evm_$_udivrem_$_i256_param_2,
	.param .b64 evm_$_udivrem_$_i256_param_3
)                                       // -- Begin function evm_$_udivrem_$_i256
                                        // @"evm_$_udivrem_$_i256"
{
	.reg .pred 	%p<25>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<207>;

// %bb.0:                               // %Entry
	ld.param.u64 	%rd74, [evm_$_udivrem_$_i256_param_3];
	ld.param.u64 	%rd73, [evm_$_udivrem_$_i256_param_2];
	ld.param.u64 	%rd79, [evm_$_udivrem_$_i256_param_0];
	ld.u32 	%rd80, [%rd79];
	ld.u32 	%rd81, [%rd79+4];
	shl.b64 	%rd82, %rd81, 32;
	or.b64  	%rd187, %rd82, %rd80;
	ld.u32 	%rd83, [%rd79+8];
	ld.u32 	%rd84, [%rd79+12];
	shl.b64 	%rd85, %rd84, 32;
	or.b64  	%rd188, %rd85, %rd83;
	ld.u32 	%rd86, [%rd79+16];
	ld.u32 	%rd87, [%rd79+20];
	shl.b64 	%rd88, %rd87, 32;
	or.b64  	%rd189, %rd88, %rd86;
	ld.u32 	%rd89, [%rd79+24];
	ld.u32 	%rd90, [%rd79+28];
	shl.b64 	%rd91, %rd90, 32;
	or.b64  	%rd190, %rd91, %rd89;
	ld.param.u64 	%rd92, [evm_$_udivrem_$_i256_param_1];
	ld.u32 	%rd93, [%rd92];
	ld.u32 	%rd94, [%rd92+4];
	shl.b64 	%rd95, %rd94, 32;
	or.b64  	%rd179, %rd95, %rd93;
	ld.u32 	%rd96, [%rd92+8];
	ld.u32 	%rd97, [%rd92+12];
	shl.b64 	%rd98, %rd97, 32;
	or.b64  	%rd180, %rd98, %rd96;
	ld.u32 	%rd99, [%rd92+16];
	ld.u32 	%rd100, [%rd92+20];
	shl.b64 	%rd101, %rd100, 32;
	or.b64  	%rd181, %rd101, %rd99;
	ld.u32 	%rd102, [%rd92+24];
	ld.u32 	%rd103, [%rd92+28];
	shl.b64 	%rd104, %rd103, 32;
	or.b64  	%rd182, %rd104, %rd102;
	setp.eq.s64 	%p1, %rd182, %rd190;
	setp.gt.u64 	%p2, %rd182, %rd190;
	selp.u32 	%r1, -1, 0, %p2;
	setp.gt.u64 	%p3, %rd181, %rd189;
	selp.u32 	%r2, -1, 0, %p3;
	selp.b32 	%r3, %r2, %r1, %p1;
	setp.eq.s64 	%p4, %rd180, %rd188;
	setp.gt.u64 	%p5, %rd180, %rd188;
	selp.u32 	%r4, -1, 0, %p5;
	setp.gt.u64 	%p6, %rd179, %rd187;
	selp.u32 	%r5, -1, 0, %p6;
	selp.b32 	%r6, %r5, %r4, %p4;
	xor.b64  	%rd105, %rd182, %rd190;
	xor.b64  	%rd106, %rd181, %rd189;
	or.b64  	%rd107, %rd106, %rd105;
	setp.eq.s64 	%p7, %rd107, 0;
	selp.b32 	%r7, %r6, %r3, %p7;
	and.b32  	%r8, %r7, 1;
	setp.eq.b32 	%p8, %r8, 1;
	mov.u64 	%rd199, 0;
	mov.u64 	%rd200, %rd199;
	mov.u64 	%rd201, %rd199;
	mov.u64 	%rd202, %rd199;
	@%p8 bra 	$L__BB2_6;
// %bb.1:                               // %Main
	setp.ne.s64 	%p9, %rd182, 0;
	clz.b64 	%r9, %rd181;
	cvt.u64.u32 	%rd108, %r9;
	add.s64 	%rd109, %rd108, 64;
	clz.b64 	%r10, %rd182;
	cvt.u64.u32 	%rd110, %r10;
	selp.b64 	%rd111, %rd110, %rd109, %p9;
	setp.ne.s64 	%p10, %rd180, 0;
	clz.b64 	%r11, %rd179;
	cvt.u64.u32 	%rd112, %r11;
	add.s64 	%rd113, %rd112, 64;
	clz.b64 	%r12, %rd180;
	cvt.u64.u32 	%rd114, %r12;
	selp.b64 	%rd115, %rd114, %rd113, %p10;
	add.s64 	%rd116, %rd115, 128;
	or.b64  	%rd117, %rd181, %rd182;
	setp.ne.s64 	%p11, %rd117, 0;
	selp.b64 	%rd118, %rd111, %rd116, %p11;
	setp.ne.s64 	%p12, %rd190, 0;
	clz.b64 	%r13, %rd189;
	cvt.u64.u32 	%rd119, %r13;
	add.s64 	%rd120, %rd119, 64;
	clz.b64 	%r14, %rd190;
	cvt.u64.u32 	%rd121, %r14;
	selp.b64 	%rd122, %rd121, %rd120, %p12;
	setp.ne.s64 	%p13, %rd188, 0;
	clz.b64 	%r15, %rd187;
	cvt.u64.u32 	%rd123, %r15;
	add.s64 	%rd124, %rd123, 64;
	clz.b64 	%r16, %rd188;
	cvt.u64.u32 	%rd125, %r16;
	selp.b64 	%rd126, %rd125, %rd124, %p13;
	add.s64 	%rd127, %rd126, 128;
	or.b64  	%rd128, %rd189, %rd190;
	setp.ne.s64 	%p14, %rd128, 0;
	selp.b64 	%rd129, %rd122, %rd127, %p14;
	mov.u64 	%rd195, 0;
	sub.cc.s64 	%rd191, %rd118, %rd129;
	subc.cc.s64 	%rd192, %rd195, 0;
	subc.cc.s64 	%rd193, %rd195, 0;
	subc.cc.s64 	%rd194, %rd195, 0;
	mov.u64 	%rd175, %rd191;
	mov.u64 	%rd176, %rd192;
	mov.u64 	%rd177, %rd193;
	mov.u64 	%rd178, %rd194;
$L__BB2_2:                              // %beforeloopY
                                        // =>This Inner Loop Header: Depth=1
	or.b64  	%rd131, %rd175, %rd177;
	or.b64  	%rd132, %rd176, %rd178;
	or.b64  	%rd133, %rd131, %rd132;
	setp.ne.s64 	%p15, %rd133, 0;
	@%p15 bra 	$L__BB2_7;
	bra.uni 	$L__BB2_3;
$L__BB2_7:                              // %LoopY
                                        //   in Loop: Header=BB2_2 Depth=1
	shr.u64 	%rd169, %rd179, 63;
	shl.b64 	%rd170, %rd180, 1;
	or.b64  	%rd22, %rd170, %rd169;
	shr.u64 	%rd171, %rd180, 63;
	shl.b64 	%rd172, %rd181, 1;
	or.b64  	%rd23, %rd172, %rd171;
	shr.u64 	%rd173, %rd181, 63;
	shl.b64 	%rd174, %rd182, 1;
	or.b64  	%rd182, %rd174, %rd173;
	shl.b64 	%rd179, %rd179, 1;
	add.cc.s64 	%rd175, %rd175, -1;
	addc.cc.s64 	%rd176, %rd176, -1;
	addc.cc.s64 	%rd177, %rd177, -1;
	addc.cc.s64 	%rd178, %rd178, -1;
	mov.u64 	%rd180, %rd22;
	mov.u64 	%rd181, %rd23;
	bra.uni 	$L__BB2_2;
$L__BB2_3:                              // %Loop.preheader
	mov.u64 	%rd200, %rd195;
	mov.u64 	%rd201, %rd195;
	mov.u64 	%rd202, %rd195;
$L__BB2_4:                              // %Loop
                                        // =>This Inner Loop Header: Depth=1
	sub.cc.s64 	%rd138, %rd187, %rd179;
	subc.cc.s64 	%rd139, %rd188, %rd180;
	subc.cc.s64 	%rd140, %rd189, %rd181;
	subc.cc.s64 	%rd141, %rd190, %rd182;
	or.b64  	%rd142, %rd195, 1;
	setp.eq.s64 	%p16, %rd188, %rd180;
	setp.ge.u64 	%p17, %rd187, %rd179;
	selp.u32 	%r17, -1, 0, %p17;
	setp.ge.u64 	%p18, %rd188, %rd180;
	selp.u32 	%r18, -1, 0, %p18;
	selp.b32 	%r19, %r17, %r18, %p16;
	setp.eq.s64 	%p19, %rd190, %rd182;
	setp.ge.u64 	%p20, %rd189, %rd181;
	selp.u32 	%r20, -1, 0, %p20;
	setp.ge.u64 	%p21, %rd190, %rd182;
	selp.u32 	%r21, -1, 0, %p21;
	selp.b32 	%r22, %r20, %r21, %p19;
	xor.b64  	%rd143, %rd189, %rd181;
	xor.b64  	%rd144, %rd190, %rd182;
	or.b64  	%rd145, %rd143, %rd144;
	setp.eq.s64 	%p22, %rd145, 0;
	selp.b32 	%r23, %r19, %r22, %p22;
	and.b32  	%r24, %r23, 1;
	setp.eq.b32 	%p23, %r24, 1;
	selp.b64 	%rd190, %rd141, %rd190, %p23;
	selp.b64 	%rd189, %rd140, %rd189, %p23;
	selp.b64 	%rd188, %rd139, %rd188, %p23;
	selp.b64 	%rd187, %rd138, %rd187, %p23;
	selp.b64 	%rd199, %rd142, %rd195, %p23;
	or.b64  	%rd146, %rd191, %rd193;
	or.b64  	%rd147, %rd192, %rd194;
	or.b64  	%rd148, %rd146, %rd147;
	setp.eq.s64 	%p24, %rd148, 0;
	@%p24 bra 	$L__BB2_6;
// %bb.5:                               // %Continue
                                        //   in Loop: Header=BB2_4 Depth=1
	add.cc.s64 	%rd191, %rd191, -1;
	addc.cc.s64 	%rd192, %rd192, -1;
	addc.cc.s64 	%rd193, %rd193, -1;
	addc.cc.s64 	%rd194, %rd194, -1;
	shr.u64 	%rd149, %rd199, 63;
	shl.b64 	%rd150, %rd200, 1;
	or.b64  	%rd58, %rd150, %rd149;
	shr.u64 	%rd151, %rd200, 63;
	shl.b64 	%rd152, %rd201, 1;
	or.b64  	%rd59, %rd152, %rd151;
	shr.u64 	%rd153, %rd201, 63;
	shl.b64 	%rd154, %rd202, 1;
	or.b64  	%rd202, %rd154, %rd153;
	shl.b64 	%rd195, %rd199, 1;
	shr.u64 	%rd155, %rd179, 1;
	shl.b64 	%rd156, %rd180, 63;
	or.b64  	%rd179, %rd155, %rd156;
	shr.u64 	%rd157, %rd180, 1;
	shl.b64 	%rd158, %rd181, 63;
	or.b64  	%rd180, %rd157, %rd158;
	shr.u64 	%rd159, %rd181, 1;
	shl.b64 	%rd160, %rd182, 63;
	or.b64  	%rd181, %rd159, %rd160;
	shr.u64 	%rd182, %rd182, 1;
	mov.u64 	%rd200, %rd58;
	mov.u64 	%rd201, %rd59;
	bra.uni 	$L__BB2_4;
$L__BB2_6:                              // %Return
	st.u32 	[%rd73], %rd199;
	st.u32 	[%rd73+8], %rd200;
	shr.u64 	%rd161, %rd199, 32;
	st.u32 	[%rd73+4], %rd161;
	st.u32 	[%rd73+16], %rd201;
	shr.u64 	%rd162, %rd200, 32;
	st.u32 	[%rd73+12], %rd162;
	st.u32 	[%rd73+24], %rd202;
	shr.u64 	%rd163, %rd201, 32;
	st.u32 	[%rd73+20], %rd163;
	shr.u64 	%rd164, %rd202, 32;
	st.u32 	[%rd73+28], %rd164;
	st.u32 	[%rd74+16], %rd189;
	shr.u64 	%rd165, %rd189, 32;
	st.u32 	[%rd74+20], %rd165;
	st.u32 	[%rd74+24], %rd190;
	shr.u64 	%rd166, %rd190, 32;
	st.u32 	[%rd74+28], %rd166;
	st.u32 	[%rd74], %rd187;
	shr.u64 	%rd167, %rd187, 32;
	st.u32 	[%rd74+4], %rd167;
	st.u32 	[%rd74+8], %rd188;
	shr.u64 	%rd168, %rd188, 32;
	st.u32 	[%rd74+12], %rd168;
	ret;
                                        // -- End function
}
	// .globl	rand                    // -- Begin function rand
.visible .func  (.param .b32 func_retval0) rand() // @rand
{
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<4>;

// %bb.0:
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mul.wide.u32 	%rd1, %r4, 4;
	mov.u64 	%rd2, cuda_states;
	add.s64 	%rd3, %rd2, %rd1;
	ld.global.u32 	%r5, [%rd3];
	mad.lo.s32 	%r6, %r5, 1103515245, 12345;
	mad.lo.s32 	%r7, %r6, 1103515245, 12345;
	shr.u32 	%r8, %r6, 6;
	and.b32  	%r9, %r8, 2096128;
	bfe.u32 	%r10, %r7, 16, 10;
	or.b32  	%r11, %r10, %r9;
	mad.lo.s32 	%r12, %r7, 1103515245, 12345;
	shl.b32 	%r13, %r11, 10;
	bfe.u32 	%r14, %r12, 16, 10;
	or.b32  	%r15, %r13, %r14;
	st.global.u32 	[%rd3], %r12;
	st.param.b32 	[func_retval0+0], %r15;
	ret;
                                        // -- End function
}
	// .globl	bytesToString           // -- Begin function bytesToString
.visible .func bytesToString(
	.param .b64 bytesToString_param_0,
	.param .b64 bytesToString_param_1,
	.param .b32 bytesToString_param_2
)                                       // @bytesToString
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<23>;
	.reg .b32 	%r<15>;
	.reg .b64 	%rd<35>;

// %bb.0:
	ld.param.u32 	%r6, [bytesToString_param_2];
	ld.param.u64 	%rd4, [bytesToString_param_0];
	setp.eq.s32 	%p1, %r6, 0;
	@%p1 bra 	$L__BB4_6;
// %bb.1:
	ld.param.u64 	%rd5, [bytesToString_param_1];
	and.b32  	%r1, %r6, 1;
	setp.eq.s32 	%p2, %r6, 1;
	mov.u32 	%r13, 0;
	mov.u64 	%rd33, __const_$_printbytes_$_hexmap;
	@%p2 bra 	$L__BB4_4;
// %bb.2:
	cvt.u64.u32 	%rd7, %r6;
	and.b64  	%rd1, %rd7, 4294967294;
	mov.u32 	%r14, 2;
	mov.u64 	%rd34, 0;
	cvt.u32.u64 	%r10, %rd1;
$L__BB4_3:                              // =>This Inner Loop Header: Depth=1
	add.s64 	%rd8, %rd5, %rd34;
	ld.u8 	%rs1, [%rd8];
	and.b16  	%rs2, %rs1, 15;
	cvt.u64.u16 	%rd9, %rs2;
	add.s64 	%rd11, %rd33, %rd9;
	ld.global.nc.u8 	%rs3, [%rd11];
	cvt.u16.u8 	%rs4, %rs3;
	add.s32 	%r9, %r14, -2;
	cvt.u64.u32 	%rd12, %r9;
	add.s64 	%rd13, %rd4, %rd12;
	st.u8 	[%rd13+1], %rs4;
	shr.u16 	%rs5, %rs1, 4;
	cvt.u64.u16 	%rd14, %rs5;
	add.s64 	%rd15, %rd33, %rd14;
	ld.global.nc.u8 	%rs6, [%rd15];
	cvt.u16.u8 	%rs7, %rs6;
	st.u8 	[%rd13], %rs7;
	ld.u8 	%rs8, [%rd8+1];
	and.b16  	%rs9, %rs8, 15;
	cvt.u64.u16 	%rd16, %rs9;
	add.s64 	%rd17, %rd33, %rd16;
	ld.global.nc.u8 	%rs10, [%rd17];
	cvt.u16.u8 	%rs11, %rs10;
	cvt.u64.u32 	%rd18, %r14;
	add.s64 	%rd19, %rd4, %rd18;
	st.u8 	[%rd19+1], %rs11;
	shr.u16 	%rs12, %rs8, 4;
	cvt.u64.u16 	%rd20, %rs12;
	add.s64 	%rd21, %rd33, %rd20;
	ld.global.nc.u8 	%rs13, [%rd21];
	cvt.u16.u8 	%rs14, %rs13;
	st.u8 	[%rd19], %rs14;
	add.s32 	%r14, %r14, 4;
	add.s64 	%rd34, %rd34, 2;
	cvt.u32.u64 	%r13, %rd34;
	setp.eq.s32 	%p3, %r10, %r13;
	@%p3 bra 	$L__BB4_4;
	bra.uni 	$L__BB4_3;
$L__BB4_4:
	setp.eq.s32 	%p4, %r1, 0;
	@%p4 bra 	$L__BB4_6;
// %bb.5:
	cvt.u64.u32 	%rd22, %r13;
	add.s64 	%rd23, %rd5, %rd22;
	ld.u8 	%rs15, [%rd23];
	and.b16  	%rs16, %rs15, 15;
	cvt.u64.u16 	%rd24, %rs16;
	add.s64 	%rd26, %rd33, %rd24;
	ld.global.nc.u8 	%rs17, [%rd26];
	cvt.u16.u8 	%rs18, %rs17;
	shl.b32 	%r11, %r13, 1;
	cvt.u64.u32 	%rd27, %r11;
	add.s64 	%rd28, %rd4, %rd27;
	st.u8 	[%rd28+1], %rs18;
	shr.u16 	%rs19, %rs15, 4;
	cvt.u64.u16 	%rd29, %rs19;
	add.s64 	%rd30, %rd33, %rd29;
	ld.global.nc.u8 	%rs20, [%rd30];
	cvt.u16.u8 	%rs21, %rs20;
	st.u8 	[%rd28], %rs21;
$L__BB4_6:
	shl.b32 	%r12, %r6, 1;
	cvt.u64.u32 	%rd31, %r12;
	add.s64 	%rd32, %rd4, %rd31;
	mov.u16 	%rs22, 0;
	st.u8 	[%rd32], %rs22;
	ret;
                                        // -- End function
}
	// .globl	printbytes              // -- Begin function printbytes
.visible .func printbytes(
	.param .b64 printbytes_param_0,
	.param .b64 printbytes_param_1,
	.param .b32 printbytes_param_2
)                                       // @printbytes
{
	.local .align 8 .b8 	__local_depot5[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<23>;
	.reg .b32 	%r<18>;
	.reg .b64 	%rd<41>;

// %bb.0:
	mov.u64 	%SPL, __local_depot5;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r7, [printbytes_param_2];
	ld.param.u64 	%rd6, [printbytes_param_0];
	add.u64 	%rd8, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	shl.b32 	%r1, %r7, 1;
	or.b32  	%r8, %r1, 1;
	cvt.u64.u32 	%rd9, %r8;
	{ // callseq 74, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	malloc, 
	(
	param0
	);
	ld.param.b64 	%rd10, [retval0+0];
	} // callseq 74
	setp.eq.s32 	%p1, %r7, 0;
	@%p1 bra 	$L__BB5_6;
// %bb.1:
	ld.param.u64 	%rd7, [printbytes_param_1];
	and.b32  	%r2, %r7, 1;
	setp.eq.s32 	%p2, %r7, 1;
	mov.u32 	%r16, 0;
	mov.u64 	%rd39, __const_$_printbytes_$_hexmap;
	@%p2 bra 	$L__BB5_4;
// %bb.2:
	cvt.u64.u32 	%rd12, %r7;
	and.b64  	%rd3, %rd12, 4294967294;
	mov.u32 	%r17, 2;
	mov.u64 	%rd40, 0;
	cvt.u32.u64 	%r12, %rd3;
$L__BB5_3:                              // =>This Inner Loop Header: Depth=1
	add.s64 	%rd13, %rd7, %rd40;
	ld.u8 	%rs1, [%rd13];
	and.b16  	%rs2, %rs1, 15;
	cvt.u64.u16 	%rd14, %rs2;
	add.s64 	%rd16, %rd39, %rd14;
	ld.global.nc.u8 	%rs3, [%rd16];
	cvt.u16.u8 	%rs4, %rs3;
	add.s32 	%r11, %r17, -2;
	cvt.u64.u32 	%rd17, %r11;
	add.s64 	%rd18, %rd10, %rd17;
	shr.u16 	%rs5, %rs1, 4;
	cvt.u64.u16 	%rd19, %rs5;
	add.s64 	%rd20, %rd39, %rd19;
	ld.global.nc.u8 	%rs6, [%rd20];
	cvt.u16.u8 	%rs7, %rs6;
	ld.u8 	%rs8, [%rd13+1];
	and.b16  	%rs9, %rs8, 15;
	cvt.u64.u16 	%rd21, %rs9;
	add.s64 	%rd22, %rd39, %rd21;
	ld.global.nc.u8 	%rs10, [%rd22];
	cvt.u16.u8 	%rs11, %rs10;
	shr.u16 	%rs12, %rs8, 4;
	cvt.u64.u16 	%rd23, %rs12;
	add.s64 	%rd24, %rd39, %rd23;
	ld.global.nc.u8 	%rs13, [%rd24];
	cvt.u16.u8 	%rs14, %rs13;
	st.v4.u8 	[%rd18], {%rs7, %rs4, %rs14, %rs11};
	add.s32 	%r17, %r17, 4;
	add.s64 	%rd40, %rd40, 2;
	cvt.u32.u64 	%r16, %rd40;
	setp.eq.s32 	%p3, %r12, %r16;
	@%p3 bra 	$L__BB5_4;
	bra.uni 	$L__BB5_3;
$L__BB5_4:
	setp.eq.s32 	%p4, %r2, 0;
	@%p4 bra 	$L__BB5_6;
// %bb.5:
	cvt.u64.u32 	%rd25, %r16;
	add.s64 	%rd26, %rd7, %rd25;
	ld.u8 	%rs15, [%rd26];
	and.b16  	%rs16, %rs15, 15;
	cvt.u64.u16 	%rd27, %rs16;
	add.s64 	%rd29, %rd39, %rd27;
	ld.global.nc.u8 	%rs17, [%rd29];
	cvt.u16.u8 	%rs18, %rs17;
	shl.b32 	%r13, %r16, 1;
	cvt.u64.u32 	%rd30, %r13;
	add.s64 	%rd31, %rd10, %rd30;
	shr.u16 	%rs19, %rs15, 4;
	cvt.u64.u16 	%rd32, %rs19;
	add.s64 	%rd33, %rd39, %rd32;
	ld.global.nc.u8 	%rs20, [%rd33];
	cvt.u16.u8 	%rs21, %rs20;
	st.v2.u8 	[%rd31], {%rs21, %rs18};
$L__BB5_6:
	cvt.u64.u32 	%rd34, %r1;
	add.s64 	%rd35, %rd10, %rd34;
	mov.u16 	%rs22, 0;
	st.u8 	[%rd35], %rs22;
	st.local.u64 	[%rd1], %rd6;
	st.local.u64 	[%rd1+8], %rd10;
	mov.u64 	%rd36, _$_str;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 75, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd37;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd8;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r14, [retval0+0];
	} // callseq 75
	{ // callseq 76, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd10;
	call.uni 
	free, 
	(
	param0
	);
	} // callseq 76
	ret;
                                        // -- End function
}
	// .globl	__clear_bitmap          // -- Begin function __clear_bitmap
.visible .func __clear_bitmap(
	.param .b64 __clear_bitmap_param_0
)                                       // @__clear_bitmap
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<8>;

// %bb.0:
	mov.u64 	%rd4, 0;
	ld.param.u64 	%rd3, [__clear_bitmap_param_0];
	mov.u64 	%rd7, %rd4;
$L__BB6_1:                              // =>This Inner Loop Header: Depth=1
	add.s64 	%rd5, %rd3, %rd7;
	st.global.u64 	[%rd5], %rd4;
	st.global.u64 	[%rd5+8], %rd4;
	st.global.u64 	[%rd5+16], %rd4;
	st.global.u64 	[%rd5+24], %rd4;
	st.global.u64 	[%rd5+32], %rd4;
	st.global.u64 	[%rd5+40], %rd4;
	st.global.u64 	[%rd5+48], %rd4;
	st.global.u64 	[%rd5+56], %rd4;
	st.global.u64 	[%rd5+64], %rd4;
	st.global.u64 	[%rd5+72], %rd4;
	st.global.u64 	[%rd5+80], %rd4;
	st.global.u64 	[%rd5+88], %rd4;
	st.global.u64 	[%rd5+96], %rd4;
	st.global.u64 	[%rd5+104], %rd4;
	st.global.u64 	[%rd5+112], %rd4;
	st.global.u64 	[%rd5+120], %rd4;
	add.s64 	%rd7, %rd7, 128;
	cvt.u32.u64 	%r1, %rd7;
	setp.ne.s32 	%p1, %r1, 4096;
	@%p1 bra 	$L__BB6_1;
// %bb.2:
	ret;
                                        // -- End function
}
	// .globl	__device_sha3           // -- Begin function __device_sha3
.visible .func __device_sha3(
	.param .b64 __device_sha3_param_0,
	.param .b32 __device_sha3_param_1,
	.param .b64 __device_sha3_param_2
)                                       // @__device_sha3
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<3>;

// %bb.0:
	ld.param.u64 	%rd1, [__device_sha3_param_0];
	ld.param.u32 	%r1, [__device_sha3_param_1];
	ld.param.u64 	%rd2, [__device_sha3_param_2];
	{ // callseq 77, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r1;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd2;
	call.uni 
	keccak256, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 77
	ret;
                                        // -- End function
}
	// .globl	keccak256               // -- Begin function keccak256
.visible .func keccak256(
	.param .b64 keccak256_param_0,
	.param .b32 keccak256_param_1,
	.param .b64 keccak256_param_2
)                                       // @keccak256
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<6>;

// %bb.0:
	ld.param.u64 	%rd1, [keccak256_param_0];
	ld.param.u32 	%rd2, [keccak256_param_1];
	ld.param.u64 	%rd3, [keccak256_param_2];
	mov.u64 	%rd4, 32;
	mov.u64 	%rd5, 136;
	mov.u32 	%r1, 1;
	{ // callseq 78, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd3;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd1;
	.param .b64 param3;
	st.param.b64 	[param3+0], %rd2;
	.param .b64 param4;
	st.param.b64 	[param4+0], %rd5;
	.param .b32 param5;
	st.param.b32 	[param5+0], %r1;
	call.uni 
	hash, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4, 
	param5
	);
	} // callseq 78
	ret;
                                        // -- End function
}
	// .globl	hash                    // -- Begin function hash
.visible .func hash(
	.param .b64 hash_param_0,
	.param .b64 hash_param_1,
	.param .b64 hash_param_2,
	.param .b64 hash_param_3,
	.param .b64 hash_param_4,
	.param .b32 hash_param_5
)                                       // @hash
{
	.local .align 8 .b8 	__local_depot9[200];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<36>;
	.reg .b16 	%rs<97>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<1001>;

// %bb.0:
	mov.u64 	%SPL, __local_depot9;
	ld.param.u64 	%rd373, [hash_param_4];
	ld.param.u64 	%rd899, [hash_param_3];
	add.u64 	%rd1, %SPL, 0;
	mov.u64 	%rd815, 0;
	mov.pred 	%p1, 0;
	mov.u16 	%rs94, 0;
	@%p1 bra 	$L__BB9_2;
$L__BB9_1:                              // %loadstoreloop
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd376, %rd1, %rd815;
	st.local.u8 	[%rd376], %rs94;
	add.s64 	%rd815, %rd815, 1;
	setp.lt.u64 	%p2, %rd815, 200;
	@%p2 bra 	$L__BB9_1;
$L__BB9_2:                              // %split
	ld.param.u8 	%rs7, [hash_param_5];
	ld.param.u64 	%rd898, [hash_param_2];
	setp.lt.u64 	%p3, %rd899, %rd373;
	add.s64 	%rd811, %rd373, -1;
	mov.u64 	%rd812, RC;
	@%p3 bra 	$L__BB9_17;
// %bb.3:
	mov.u64 	%rd813, 1;
	add.s64 	%rd4, %rd373, -2;
	and.b64  	%rd5, %rd811, 7;
	and.b64  	%rd6, %rd811, -8;
	add.s64 	%rd7, %rd1, 4;
	mov.u64 	%rd871, 0;
	setp.eq.s64 	%p4, %rd373, 0;
	setp.eq.s64 	%p5, %rd373, 1;
	setp.lt.u64 	%p6, %rd4, 7;
	setp.eq.s64 	%p8, %rd5, 0;
	mov.u64 	%rd870, %rd871;
	mov.u64 	%rd869, %rd871;
	mov.u64 	%rd868, %rd871;
	mov.u64 	%rd867, %rd871;
	mov.u64 	%rd866, %rd871;
	mov.u64 	%rd865, %rd871;
	mov.u64 	%rd864, %rd871;
	mov.u64 	%rd863, %rd871;
	mov.u64 	%rd862, %rd871;
	mov.u64 	%rd861, %rd871;
	mov.u64 	%rd860, %rd871;
	mov.u64 	%rd859, %rd871;
	mov.u64 	%rd858, %rd871;
	mov.u64 	%rd857, %rd871;
	mov.u64 	%rd856, %rd871;
	mov.u64 	%rd855, %rd871;
	mov.u64 	%rd854, %rd871;
	mov.u64 	%rd853, %rd871;
	mov.u64 	%rd852, %rd871;
	mov.u64 	%rd851, %rd871;
	mov.u64 	%rd850, %rd871;
	mov.u64 	%rd849, %rd871;
	mov.u64 	%rd848, %rd871;
	mov.u64 	%rd847, %rd871;
$L__BB9_4:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB9_8 Depth 2
                                        //     Child Loop BB9_12 Depth 2
                                        //     Child Loop BB9_15 Depth 2
	@%p4 bra 	$L__BB9_14;
// %bb.5:                               //   in Loop: Header=BB9_4 Depth=1
	ld.u8 	%rs10, [%rd898];
	xor.b16  	%rs11, %rs94, %rs10;
	st.local.u8 	[%rd1], %rs11;
	@%p5 bra 	$L__BB9_13;
// %bb.6:                               //   in Loop: Header=BB9_4 Depth=1
	mov.u64 	%rd845, %rd813;
	@%p6 bra 	$L__BB9_10;
// %bb.7:                               // %.preheader15
                                        //   in Loop: Header=BB9_4 Depth=1
	mov.u64 	%rd843, 0;
$L__BB9_8:                              //   Parent Loop BB9_4 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add.s64 	%rd381, %rd7, %rd843;
	ld.local.u8 	%rs12, [%rd381+-3];
	add.s64 	%rd382, %rd898, %rd843;
	ld.u8 	%rs13, [%rd382+1];
	xor.b16  	%rs14, %rs12, %rs13;
	st.local.u8 	[%rd381+-3], %rs14;
	ld.local.u8 	%rs15, [%rd381+-2];
	ld.u8 	%rs16, [%rd382+2];
	xor.b16  	%rs17, %rs15, %rs16;
	st.local.u8 	[%rd381+-2], %rs17;
	ld.local.u8 	%rs18, [%rd381+-1];
	ld.u8 	%rs19, [%rd382+3];
	xor.b16  	%rs20, %rs18, %rs19;
	st.local.u8 	[%rd381+-1], %rs20;
	ld.local.u8 	%rs21, [%rd381];
	ld.u8 	%rs22, [%rd382+4];
	xor.b16  	%rs23, %rs21, %rs22;
	st.local.u8 	[%rd381], %rs23;
	ld.local.u8 	%rs24, [%rd381+1];
	ld.u8 	%rs25, [%rd382+5];
	xor.b16  	%rs26, %rs24, %rs25;
	st.local.u8 	[%rd381+1], %rs26;
	ld.local.u8 	%rs27, [%rd381+2];
	ld.u8 	%rs28, [%rd382+6];
	xor.b16  	%rs29, %rs27, %rs28;
	st.local.u8 	[%rd381+2], %rs29;
	ld.local.u8 	%rs30, [%rd381+3];
	ld.u8 	%rs31, [%rd382+7];
	xor.b16  	%rs32, %rs30, %rs31;
	st.local.u8 	[%rd381+3], %rs32;
	ld.local.u8 	%rs33, [%rd381+4];
	ld.u8 	%rs34, [%rd382+8];
	xor.b16  	%rs35, %rs33, %rs34;
	st.local.u8 	[%rd381+4], %rs35;
	add.s64 	%rd843, %rd843, 8;
	setp.ne.s64 	%p7, %rd6, %rd843;
	@%p7 bra 	$L__BB9_8;
// %bb.9:                               // %.loopexit16
                                        //   in Loop: Header=BB9_4 Depth=1
	add.s64 	%rd845, %rd843, 1;
$L__BB9_10:                             //   in Loop: Header=BB9_4 Depth=1
	@%p8 bra 	$L__BB9_13;
// %bb.11:                              // %.preheader13
                                        //   in Loop: Header=BB9_4 Depth=1
	mov.u64 	%rd846, %rd5;
$L__BB9_12:                             //   Parent Loop BB9_4 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	.pragma "nounroll";
	add.s64 	%rd383, %rd1, %rd845;
	ld.local.u8 	%rs36, [%rd383];
	add.s64 	%rd384, %rd898, %rd845;
	ld.u8 	%rs37, [%rd384];
	xor.b16  	%rs38, %rs36, %rs37;
	st.local.u8 	[%rd383], %rs38;
	add.s64 	%rd845, %rd845, 1;
	add.s64 	%rd846, %rd846, -1;
	setp.ne.s64 	%p9, %rd846, 0;
	@%p9 bra 	$L__BB9_12;
$L__BB9_13:                             //   in Loop: Header=BB9_4 Depth=1
	ld.local.u64 	%rd847, [%rd1];
	ld.local.u64 	%rd848, [%rd1+40];
	ld.local.u64 	%rd849, [%rd1+80];
	ld.local.u64 	%rd850, [%rd1+120];
	ld.local.u64 	%rd851, [%rd1+160];
	ld.local.u64 	%rd852, [%rd1+8];
	ld.local.u64 	%rd853, [%rd1+48];
	ld.local.u64 	%rd854, [%rd1+88];
	ld.local.u64 	%rd855, [%rd1+128];
	ld.local.u64 	%rd856, [%rd1+168];
	ld.local.u64 	%rd857, [%rd1+16];
	ld.local.u64 	%rd858, [%rd1+56];
	ld.local.u64 	%rd859, [%rd1+96];
	ld.local.u64 	%rd860, [%rd1+136];
	ld.local.u64 	%rd861, [%rd1+176];
	ld.local.u64 	%rd862, [%rd1+24];
	ld.local.u64 	%rd863, [%rd1+64];
	ld.local.u64 	%rd864, [%rd1+104];
	ld.local.u64 	%rd865, [%rd1+144];
	ld.local.u64 	%rd866, [%rd1+184];
	ld.local.u64 	%rd867, [%rd1+32];
	ld.local.u64 	%rd868, [%rd1+72];
	ld.local.u64 	%rd869, [%rd1+112];
	ld.local.u64 	%rd870, [%rd1+152];
	ld.local.u64 	%rd871, [%rd1+192];
$L__BB9_14:                             //   in Loop: Header=BB9_4 Depth=1
	mov.u64 	%rd872, 0;
$L__BB9_15:                             //   Parent Loop BB9_4 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	xor.b64  	%rd386, %rd848, %rd847;
	xor.b64  	%rd387, %rd386, %rd849;
	xor.b64  	%rd388, %rd387, %rd850;
	xor.b64  	%rd389, %rd388, %rd851;
	xor.b64  	%rd390, %rd853, %rd852;
	xor.b64  	%rd391, %rd390, %rd854;
	xor.b64  	%rd392, %rd391, %rd855;
	xor.b64  	%rd393, %rd392, %rd856;
	xor.b64  	%rd394, %rd858, %rd857;
	xor.b64  	%rd395, %rd394, %rd859;
	xor.b64  	%rd396, %rd395, %rd860;
	xor.b64  	%rd397, %rd396, %rd861;
	xor.b64  	%rd398, %rd863, %rd862;
	xor.b64  	%rd399, %rd398, %rd864;
	xor.b64  	%rd400, %rd399, %rd865;
	xor.b64  	%rd401, %rd400, %rd866;
	xor.b64  	%rd402, %rd868, %rd867;
	xor.b64  	%rd403, %rd402, %rd869;
	xor.b64  	%rd404, %rd403, %rd870;
	xor.b64  	%rd405, %rd404, %rd871;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd393, 1;
	shr.b64 	%rhs, %rd393, 63;
	add.u64 	%rd406, %lhs, %rhs;
	}
	xor.b64  	%rd407, %rd405, %rd406;
	xor.b64  	%rd408, %rd407, %rd847;
	xor.b64  	%rd409, %rd407, %rd848;
	xor.b64  	%rd410, %rd407, %rd849;
	xor.b64  	%rd411, %rd407, %rd850;
	xor.b64  	%rd412, %rd407, %rd851;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd397, 1;
	shr.b64 	%rhs, %rd397, 63;
	add.u64 	%rd413, %lhs, %rhs;
	}
	xor.b64  	%rd414, %rd413, %rd389;
	xor.b64  	%rd415, %rd414, %rd852;
	xor.b64  	%rd416, %rd414, %rd853;
	xor.b64  	%rd417, %rd414, %rd854;
	xor.b64  	%rd418, %rd414, %rd855;
	xor.b64  	%rd419, %rd414, %rd856;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd401, 1;
	shr.b64 	%rhs, %rd401, 63;
	add.u64 	%rd420, %lhs, %rhs;
	}
	xor.b64  	%rd421, %rd420, %rd393;
	xor.b64  	%rd422, %rd421, %rd857;
	xor.b64  	%rd423, %rd421, %rd858;
	xor.b64  	%rd424, %rd421, %rd859;
	xor.b64  	%rd425, %rd421, %rd860;
	xor.b64  	%rd426, %rd421, %rd861;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd405, 1;
	shr.b64 	%rhs, %rd405, 63;
	add.u64 	%rd427, %lhs, %rhs;
	}
	xor.b64  	%rd428, %rd427, %rd397;
	xor.b64  	%rd429, %rd428, %rd862;
	xor.b64  	%rd430, %rd428, %rd863;
	xor.b64  	%rd431, %rd428, %rd864;
	xor.b64  	%rd432, %rd428, %rd865;
	xor.b64  	%rd433, %rd428, %rd866;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd389, 1;
	shr.b64 	%rhs, %rd389, 63;
	add.u64 	%rd434, %lhs, %rhs;
	}
	xor.b64  	%rd435, %rd401, %rd434;
	xor.b64  	%rd436, %rd435, %rd867;
	xor.b64  	%rd437, %rd868, %rd435;
	xor.b64  	%rd438, %rd869, %rd435;
	xor.b64  	%rd439, %rd870, %rd435;
	xor.b64  	%rd440, %rd871, %rd435;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd415, 1;
	shr.b64 	%rhs, %rd415, 63;
	add.u64 	%rd441, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd410, 3;
	shr.b64 	%rhs, %rd410, 61;
	add.u64 	%rd442, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd423, 6;
	shr.b64 	%rhs, %rd423, 58;
	add.u64 	%rd443, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd417, 10;
	shr.b64 	%rhs, %rd417, 54;
	add.u64 	%rd444, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd425, 15;
	shr.b64 	%rhs, %rd425, 49;
	add.u64 	%rd445, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd432, 21;
	shr.b64 	%rhs, %rd432, 43;
	add.u64 	%rd446, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd429, 28;
	shr.b64 	%rhs, %rd429, 36;
	add.u64 	%rd447, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd409, 36;
	shr.b64 	%rhs, %rd409, 28;
	add.u64 	%rd448, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd418, 45;
	shr.b64 	%rhs, %rd418, 19;
	add.u64 	%rd449, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd430, 55;
	shr.b64 	%rhs, %rd430, 9;
	add.u64 	%rd450, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd419, 2;
	shr.b64 	%rhs, %rd419, 62;
	add.u64 	%rd451, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd440, 14;
	shr.b64 	%rhs, %rd440, 50;
	add.u64 	%rd452, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd436, 27;
	shr.b64 	%rhs, %rd436, 37;
	add.u64 	%rd453, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd411, 41;
	shr.b64 	%rhs, %rd411, 23;
	add.u64 	%rd454, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd433, 56;
	shr.b64 	%rhs, %rd433, 8;
	add.u64 	%rd455, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd439, 8;
	shr.b64 	%rhs, %rd439, 56;
	add.u64 	%rd456, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd431, 25;
	shr.b64 	%rhs, %rd431, 39;
	add.u64 	%rd457, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd424, 43;
	shr.b64 	%rhs, %rd424, 21;
	add.u64 	%rd458, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd422, 62;
	shr.b64 	%rhs, %rd422, 2;
	add.u64 	%rd459, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd412, 18;
	shr.b64 	%rhs, %rd412, 46;
	add.u64 	%rd460, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd438, 39;
	shr.b64 	%rhs, %rd438, 25;
	add.u64 	%rd461, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd426, 61;
	shr.b64 	%rhs, %rd426, 3;
	add.u64 	%rd462, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd437, 20;
	shr.b64 	%rhs, %rd437, 44;
	add.u64 	%rd463, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd416, 44;
	shr.b64 	%rhs, %rd416, 20;
	add.u64 	%rd464, %lhs, %rhs;
	}
	not.b64 	%rd465, %rd464;
	and.b64  	%rd466, %rd458, %rd465;
	not.b64 	%rd467, %rd458;
	and.b64  	%rd468, %rd446, %rd467;
	xor.b64  	%rd852, %rd468, %rd464;
	not.b64 	%rd469, %rd446;
	and.b64  	%rd470, %rd452, %rd469;
	xor.b64  	%rd857, %rd470, %rd458;
	not.b64 	%rd471, %rd452;
	and.b64  	%rd472, %rd408, %rd471;
	xor.b64  	%rd862, %rd446, %rd472;
	not.b64 	%rd473, %rd408;
	and.b64  	%rd474, %rd464, %rd473;
	xor.b64  	%rd867, %rd474, %rd452;
	not.b64 	%rd475, %rd463;
	and.b64  	%rd476, %rd442, %rd475;
	xor.b64  	%rd848, %rd447, %rd476;
	not.b64 	%rd477, %rd442;
	and.b64  	%rd478, %rd449, %rd477;
	xor.b64  	%rd853, %rd478, %rd463;
	not.b64 	%rd479, %rd449;
	and.b64  	%rd480, %rd462, %rd479;
	xor.b64  	%rd858, %rd442, %rd480;
	not.b64 	%rd481, %rd462;
	and.b64  	%rd482, %rd447, %rd481;
	xor.b64  	%rd863, %rd482, %rd449;
	not.b64 	%rd483, %rd447;
	and.b64  	%rd484, %rd463, %rd483;
	xor.b64  	%rd868, %rd484, %rd462;
	not.b64 	%rd485, %rd443;
	and.b64  	%rd486, %rd457, %rd485;
	xor.b64  	%rd849, %rd486, %rd441;
	not.b64 	%rd487, %rd457;
	and.b64  	%rd488, %rd456, %rd487;
	xor.b64  	%rd854, %rd488, %rd443;
	not.b64 	%rd489, %rd456;
	and.b64  	%rd490, %rd460, %rd489;
	xor.b64  	%rd859, %rd457, %rd490;
	not.b64 	%rd491, %rd460;
	and.b64  	%rd492, %rd441, %rd491;
	xor.b64  	%rd864, %rd492, %rd456;
	not.b64 	%rd493, %rd441;
	and.b64  	%rd494, %rd443, %rd493;
	xor.b64  	%rd869, %rd460, %rd494;
	not.b64 	%rd495, %rd448;
	and.b64  	%rd496, %rd444, %rd495;
	xor.b64  	%rd850, %rd496, %rd453;
	not.b64 	%rd497, %rd444;
	and.b64  	%rd498, %rd445, %rd497;
	xor.b64  	%rd855, %rd448, %rd498;
	not.b64 	%rd499, %rd445;
	and.b64  	%rd500, %rd455, %rd499;
	xor.b64  	%rd860, %rd500, %rd444;
	not.b64 	%rd501, %rd455;
	and.b64  	%rd502, %rd453, %rd501;
	xor.b64  	%rd865, %rd502, %rd445;
	not.b64 	%rd503, %rd453;
	and.b64  	%rd504, %rd448, %rd503;
	xor.b64  	%rd870, %rd455, %rd504;
	not.b64 	%rd505, %rd450;
	and.b64  	%rd506, %rd461, %rd505;
	xor.b64  	%rd851, %rd506, %rd459;
	not.b64 	%rd507, %rd461;
	and.b64  	%rd508, %rd454, %rd507;
	xor.b64  	%rd856, %rd450, %rd508;
	not.b64 	%rd509, %rd454;
	and.b64  	%rd510, %rd451, %rd509;
	xor.b64  	%rd861, %rd510, %rd461;
	not.b64 	%rd511, %rd451;
	and.b64  	%rd512, %rd459, %rd511;
	xor.b64  	%rd866, %rd454, %rd512;
	not.b64 	%rd513, %rd459;
	and.b64  	%rd514, %rd450, %rd513;
	xor.b64  	%rd871, %rd514, %rd451;
	add.s64 	%rd516, %rd812, %rd872;
	ld.global.nc.u64 	%rd517, [%rd516];
	xor.b64  	%rd518, %rd517, %rd466;
	xor.b64  	%rd847, %rd518, %rd408;
	add.s64 	%rd872, %rd872, 8;
	cvt.u32.u64 	%r1, %rd872;
	setp.ne.s32 	%p10, %r1, 192;
	@%p10 bra 	$L__BB9_15;
// %bb.16:                              //   in Loop: Header=BB9_4 Depth=1
	st.local.u64 	[%rd1], %rd847;
	st.local.u64 	[%rd1+40], %rd848;
	st.local.u64 	[%rd1+80], %rd849;
	st.local.u64 	[%rd1+120], %rd850;
	st.local.u64 	[%rd1+160], %rd851;
	st.local.u64 	[%rd1+8], %rd852;
	st.local.u64 	[%rd1+48], %rd853;
	st.local.u64 	[%rd1+88], %rd854;
	st.local.u64 	[%rd1+128], %rd855;
	st.local.u64 	[%rd1+168], %rd856;
	st.local.u64 	[%rd1+16], %rd857;
	st.local.u64 	[%rd1+56], %rd858;
	st.local.u64 	[%rd1+96], %rd859;
	st.local.u64 	[%rd1+136], %rd860;
	st.local.u64 	[%rd1+176], %rd861;
	st.local.u64 	[%rd1+24], %rd862;
	st.local.u64 	[%rd1+64], %rd863;
	st.local.u64 	[%rd1+104], %rd864;
	st.local.u64 	[%rd1+144], %rd865;
	st.local.u64 	[%rd1+184], %rd866;
	st.local.u64 	[%rd1+32], %rd867;
	st.local.u64 	[%rd1+72], %rd868;
	st.local.u64 	[%rd1+112], %rd869;
	st.local.u64 	[%rd1+152], %rd870;
	st.local.u64 	[%rd1+192], %rd871;
	add.s64 	%rd898, %rd898, %rd373;
	sub.s64 	%rd899, %rd899, %rd373;
	cvt.u16.u64 	%rs94, %rd847;
	setp.ge.u64 	%p11, %rd899, %rd373;
	@%p11 bra 	$L__BB9_4;
$L__BB9_17:
	add.s64 	%rd519, %rd1, %rd899;
	ld.local.u8 	%rs39, [%rd519];
	xor.b16  	%rs40, %rs39, %rs7;
	st.local.u8 	[%rd519], %rs40;
	add.s64 	%rd520, %rd1, %rd373;
	ld.local.u8 	%rs41, [%rd520+-1];
	xor.b16  	%rs42, %rs41, 128;
	st.local.u8 	[%rd520+-1], %rs42;
	setp.eq.s64 	%p12, %rd899, 0;
	@%p12 bra 	$L__BB9_24;
// %bb.18:
	add.s64 	%rd522, %rd899, -1;
	and.b64  	%rd904, %rd899, 7;
	setp.lt.u64 	%p13, %rd522, 7;
	mov.u64 	%rd901, 0;
	@%p13 bra 	$L__BB9_21;
// %bb.19:
	and.b64  	%rd151, %rd899, -8;
	mov.u64 	%rd901, 0;
$L__BB9_20:                             // =>This Inner Loop Header: Depth=1
	add.s64 	%rd524, %rd898, %rd901;
	ld.u8 	%rs43, [%rd524];
	add.s64 	%rd525, %rd1, %rd901;
	ld.local.v4.u8 	{%rs44, %rs45, %rs46, %rs47}, [%rd525+4];
	ld.local.v4.u8 	{%rs48, %rs49, %rs50, %rs51}, [%rd525];
	xor.b16  	%rs52, %rs48, %rs43;
	st.local.u8 	[%rd525], %rs52;
	ld.u8 	%rs53, [%rd524+1];
	xor.b16  	%rs54, %rs49, %rs53;
	st.local.u8 	[%rd525+1], %rs54;
	ld.u8 	%rs55, [%rd524+2];
	xor.b16  	%rs56, %rs50, %rs55;
	st.local.u8 	[%rd525+2], %rs56;
	ld.u8 	%rs57, [%rd524+3];
	xor.b16  	%rs58, %rs51, %rs57;
	st.local.u8 	[%rd525+3], %rs58;
	ld.u8 	%rs59, [%rd524+4];
	xor.b16  	%rs60, %rs44, %rs59;
	st.local.u8 	[%rd525+4], %rs60;
	ld.u8 	%rs61, [%rd524+5];
	xor.b16  	%rs62, %rs45, %rs61;
	st.local.u8 	[%rd525+5], %rs62;
	ld.u8 	%rs63, [%rd524+6];
	xor.b16  	%rs64, %rs46, %rs63;
	st.local.u8 	[%rd525+6], %rs64;
	ld.u8 	%rs65, [%rd524+7];
	xor.b16  	%rs66, %rs47, %rs65;
	st.local.u8 	[%rd525+7], %rs66;
	add.s64 	%rd901, %rd901, 8;
	setp.ne.s64 	%p14, %rd151, %rd901;
	@%p14 bra 	$L__BB9_20;
$L__BB9_21:
	setp.eq.s64 	%p15, %rd904, 0;
	@%p15 bra 	$L__BB9_24;
// %bb.22:                              // %.preheader10
	add.s64 	%rd903, %rd1, %rd901;
	add.s64 	%rd902, %rd898, %rd901;
$L__BB9_23:                             // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	ld.u8 	%rs67, [%rd902];
	ld.local.u8 	%rs68, [%rd903];
	xor.b16  	%rs69, %rs68, %rs67;
	st.local.u8 	[%rd903], %rs69;
	add.s64 	%rd904, %rd904, -1;
	add.s64 	%rd903, %rd903, 1;
	add.s64 	%rd902, %rd902, 1;
	setp.ne.s64 	%p16, %rd904, 0;
	@%p16 bra 	$L__BB9_23;
$L__BB9_24:
	ld.param.u64 	%rd988, [hash_param_1];
	ld.param.u64 	%rd989, [hash_param_0];
	ld.local.u64 	%rd963, [%rd1];
	ld.local.u64 	%rd964, [%rd1+40];
	ld.local.u64 	%rd965, [%rd1+80];
	ld.local.u64 	%rd966, [%rd1+120];
	ld.local.u64 	%rd967, [%rd1+160];
	ld.local.u64 	%rd968, [%rd1+8];
	ld.local.u64 	%rd969, [%rd1+48];
	ld.local.u64 	%rd970, [%rd1+88];
	ld.local.u64 	%rd971, [%rd1+128];
	ld.local.u64 	%rd972, [%rd1+168];
	ld.local.u64 	%rd973, [%rd1+16];
	ld.local.u64 	%rd974, [%rd1+56];
	ld.local.u64 	%rd975, [%rd1+96];
	ld.local.u64 	%rd976, [%rd1+136];
	ld.local.u64 	%rd977, [%rd1+176];
	ld.local.u64 	%rd978, [%rd1+24];
	ld.local.u64 	%rd979, [%rd1+64];
	ld.local.u64 	%rd980, [%rd1+104];
	ld.local.u64 	%rd981, [%rd1+144];
	ld.local.u64 	%rd982, [%rd1+184];
	ld.local.u64 	%rd983, [%rd1+32];
	ld.local.u64 	%rd984, [%rd1+72];
	ld.local.u64 	%rd985, [%rd1+112];
	ld.local.u64 	%rd986, [%rd1+152];
	ld.local.u64 	%rd987, [%rd1+192];
	mov.u64 	%rd905, 0;
$L__BB9_25:                             // =>This Inner Loop Header: Depth=1
	xor.b64  	%rd527, %rd964, %rd963;
	xor.b64  	%rd528, %rd527, %rd965;
	xor.b64  	%rd529, %rd528, %rd966;
	xor.b64  	%rd530, %rd529, %rd967;
	xor.b64  	%rd531, %rd969, %rd968;
	xor.b64  	%rd532, %rd531, %rd970;
	xor.b64  	%rd533, %rd532, %rd971;
	xor.b64  	%rd534, %rd533, %rd972;
	xor.b64  	%rd535, %rd974, %rd973;
	xor.b64  	%rd536, %rd535, %rd975;
	xor.b64  	%rd537, %rd536, %rd976;
	xor.b64  	%rd538, %rd537, %rd977;
	xor.b64  	%rd539, %rd979, %rd978;
	xor.b64  	%rd540, %rd539, %rd980;
	xor.b64  	%rd541, %rd540, %rd981;
	xor.b64  	%rd542, %rd541, %rd982;
	xor.b64  	%rd543, %rd984, %rd983;
	xor.b64  	%rd544, %rd543, %rd985;
	xor.b64  	%rd545, %rd544, %rd986;
	xor.b64  	%rd546, %rd545, %rd987;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd534, 1;
	shr.b64 	%rhs, %rd534, 63;
	add.u64 	%rd547, %lhs, %rhs;
	}
	xor.b64  	%rd548, %rd546, %rd547;
	xor.b64  	%rd549, %rd548, %rd963;
	xor.b64  	%rd550, %rd548, %rd964;
	xor.b64  	%rd551, %rd548, %rd965;
	xor.b64  	%rd552, %rd548, %rd966;
	xor.b64  	%rd553, %rd548, %rd967;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd538, 1;
	shr.b64 	%rhs, %rd538, 63;
	add.u64 	%rd554, %lhs, %rhs;
	}
	xor.b64  	%rd555, %rd554, %rd530;
	xor.b64  	%rd556, %rd555, %rd968;
	xor.b64  	%rd557, %rd555, %rd969;
	xor.b64  	%rd558, %rd555, %rd970;
	xor.b64  	%rd559, %rd555, %rd971;
	xor.b64  	%rd560, %rd555, %rd972;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd542, 1;
	shr.b64 	%rhs, %rd542, 63;
	add.u64 	%rd561, %lhs, %rhs;
	}
	xor.b64  	%rd562, %rd561, %rd534;
	xor.b64  	%rd563, %rd562, %rd973;
	xor.b64  	%rd564, %rd562, %rd974;
	xor.b64  	%rd565, %rd562, %rd975;
	xor.b64  	%rd566, %rd562, %rd976;
	xor.b64  	%rd567, %rd562, %rd977;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd546, 1;
	shr.b64 	%rhs, %rd546, 63;
	add.u64 	%rd568, %lhs, %rhs;
	}
	xor.b64  	%rd569, %rd568, %rd538;
	xor.b64  	%rd570, %rd569, %rd978;
	xor.b64  	%rd571, %rd569, %rd979;
	xor.b64  	%rd572, %rd569, %rd980;
	xor.b64  	%rd573, %rd569, %rd981;
	xor.b64  	%rd574, %rd569, %rd982;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd530, 1;
	shr.b64 	%rhs, %rd530, 63;
	add.u64 	%rd575, %lhs, %rhs;
	}
	xor.b64  	%rd576, %rd542, %rd575;
	xor.b64  	%rd577, %rd576, %rd983;
	xor.b64  	%rd578, %rd984, %rd576;
	xor.b64  	%rd579, %rd985, %rd576;
	xor.b64  	%rd580, %rd986, %rd576;
	xor.b64  	%rd581, %rd987, %rd576;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd556, 1;
	shr.b64 	%rhs, %rd556, 63;
	add.u64 	%rd582, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd551, 3;
	shr.b64 	%rhs, %rd551, 61;
	add.u64 	%rd583, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd564, 6;
	shr.b64 	%rhs, %rd564, 58;
	add.u64 	%rd584, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd558, 10;
	shr.b64 	%rhs, %rd558, 54;
	add.u64 	%rd585, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd566, 15;
	shr.b64 	%rhs, %rd566, 49;
	add.u64 	%rd586, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd573, 21;
	shr.b64 	%rhs, %rd573, 43;
	add.u64 	%rd587, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd570, 28;
	shr.b64 	%rhs, %rd570, 36;
	add.u64 	%rd588, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd550, 36;
	shr.b64 	%rhs, %rd550, 28;
	add.u64 	%rd589, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd559, 45;
	shr.b64 	%rhs, %rd559, 19;
	add.u64 	%rd590, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd571, 55;
	shr.b64 	%rhs, %rd571, 9;
	add.u64 	%rd591, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd560, 2;
	shr.b64 	%rhs, %rd560, 62;
	add.u64 	%rd592, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd581, 14;
	shr.b64 	%rhs, %rd581, 50;
	add.u64 	%rd593, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd577, 27;
	shr.b64 	%rhs, %rd577, 37;
	add.u64 	%rd594, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd552, 41;
	shr.b64 	%rhs, %rd552, 23;
	add.u64 	%rd595, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd574, 56;
	shr.b64 	%rhs, %rd574, 8;
	add.u64 	%rd596, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd580, 8;
	shr.b64 	%rhs, %rd580, 56;
	add.u64 	%rd597, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd572, 25;
	shr.b64 	%rhs, %rd572, 39;
	add.u64 	%rd598, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd565, 43;
	shr.b64 	%rhs, %rd565, 21;
	add.u64 	%rd599, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd563, 62;
	shr.b64 	%rhs, %rd563, 2;
	add.u64 	%rd600, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd553, 18;
	shr.b64 	%rhs, %rd553, 46;
	add.u64 	%rd601, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd579, 39;
	shr.b64 	%rhs, %rd579, 25;
	add.u64 	%rd602, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd567, 61;
	shr.b64 	%rhs, %rd567, 3;
	add.u64 	%rd603, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd578, 20;
	shr.b64 	%rhs, %rd578, 44;
	add.u64 	%rd604, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd557, 44;
	shr.b64 	%rhs, %rd557, 20;
	add.u64 	%rd605, %lhs, %rhs;
	}
	not.b64 	%rd606, %rd605;
	and.b64  	%rd607, %rd599, %rd606;
	not.b64 	%rd608, %rd599;
	and.b64  	%rd609, %rd587, %rd608;
	xor.b64  	%rd968, %rd609, %rd605;
	not.b64 	%rd610, %rd587;
	and.b64  	%rd611, %rd593, %rd610;
	xor.b64  	%rd973, %rd611, %rd599;
	not.b64 	%rd612, %rd593;
	and.b64  	%rd613, %rd549, %rd612;
	xor.b64  	%rd978, %rd587, %rd613;
	not.b64 	%rd614, %rd549;
	and.b64  	%rd615, %rd605, %rd614;
	xor.b64  	%rd983, %rd615, %rd593;
	not.b64 	%rd616, %rd604;
	and.b64  	%rd617, %rd583, %rd616;
	xor.b64  	%rd964, %rd588, %rd617;
	not.b64 	%rd618, %rd583;
	and.b64  	%rd619, %rd590, %rd618;
	xor.b64  	%rd969, %rd619, %rd604;
	not.b64 	%rd620, %rd590;
	and.b64  	%rd621, %rd603, %rd620;
	xor.b64  	%rd974, %rd583, %rd621;
	not.b64 	%rd622, %rd603;
	and.b64  	%rd623, %rd588, %rd622;
	xor.b64  	%rd979, %rd623, %rd590;
	not.b64 	%rd624, %rd588;
	and.b64  	%rd625, %rd604, %rd624;
	xor.b64  	%rd984, %rd625, %rd603;
	not.b64 	%rd626, %rd584;
	and.b64  	%rd627, %rd598, %rd626;
	xor.b64  	%rd965, %rd627, %rd582;
	not.b64 	%rd628, %rd598;
	and.b64  	%rd629, %rd597, %rd628;
	xor.b64  	%rd970, %rd629, %rd584;
	not.b64 	%rd630, %rd597;
	and.b64  	%rd631, %rd601, %rd630;
	xor.b64  	%rd975, %rd598, %rd631;
	not.b64 	%rd632, %rd601;
	and.b64  	%rd633, %rd582, %rd632;
	xor.b64  	%rd980, %rd633, %rd597;
	not.b64 	%rd634, %rd582;
	and.b64  	%rd635, %rd584, %rd634;
	xor.b64  	%rd985, %rd601, %rd635;
	not.b64 	%rd636, %rd589;
	and.b64  	%rd637, %rd585, %rd636;
	xor.b64  	%rd966, %rd637, %rd594;
	not.b64 	%rd638, %rd585;
	and.b64  	%rd639, %rd586, %rd638;
	xor.b64  	%rd971, %rd589, %rd639;
	not.b64 	%rd640, %rd586;
	and.b64  	%rd641, %rd596, %rd640;
	xor.b64  	%rd976, %rd641, %rd585;
	not.b64 	%rd642, %rd596;
	and.b64  	%rd643, %rd594, %rd642;
	xor.b64  	%rd981, %rd643, %rd586;
	not.b64 	%rd644, %rd594;
	and.b64  	%rd645, %rd589, %rd644;
	xor.b64  	%rd986, %rd596, %rd645;
	not.b64 	%rd646, %rd591;
	and.b64  	%rd647, %rd602, %rd646;
	xor.b64  	%rd967, %rd647, %rd600;
	not.b64 	%rd648, %rd602;
	and.b64  	%rd649, %rd595, %rd648;
	xor.b64  	%rd972, %rd591, %rd649;
	not.b64 	%rd650, %rd595;
	and.b64  	%rd651, %rd592, %rd650;
	xor.b64  	%rd977, %rd651, %rd602;
	not.b64 	%rd652, %rd592;
	and.b64  	%rd653, %rd600, %rd652;
	xor.b64  	%rd982, %rd595, %rd653;
	not.b64 	%rd654, %rd600;
	and.b64  	%rd655, %rd591, %rd654;
	xor.b64  	%rd987, %rd655, %rd592;
	add.s64 	%rd657, %rd812, %rd905;
	ld.global.nc.u64 	%rd658, [%rd657];
	xor.b64  	%rd659, %rd658, %rd607;
	xor.b64  	%rd963, %rd659, %rd549;
	add.s64 	%rd905, %rd905, 8;
	cvt.u32.u64 	%r2, %rd905;
	setp.ne.s32 	%p17, %r2, 192;
	@%p17 bra 	$L__BB9_25;
// %bb.26:
	st.local.u64 	[%rd1], %rd963;
	st.local.u64 	[%rd1+40], %rd964;
	st.local.u64 	[%rd1+80], %rd965;
	st.local.u64 	[%rd1+120], %rd966;
	st.local.u64 	[%rd1+160], %rd967;
	st.local.u64 	[%rd1+8], %rd968;
	st.local.u64 	[%rd1+48], %rd969;
	st.local.u64 	[%rd1+88], %rd970;
	st.local.u64 	[%rd1+128], %rd971;
	st.local.u64 	[%rd1+168], %rd972;
	st.local.u64 	[%rd1+16], %rd973;
	st.local.u64 	[%rd1+56], %rd974;
	st.local.u64 	[%rd1+96], %rd975;
	st.local.u64 	[%rd1+136], %rd976;
	st.local.u64 	[%rd1+176], %rd977;
	st.local.u64 	[%rd1+24], %rd978;
	st.local.u64 	[%rd1+64], %rd979;
	st.local.u64 	[%rd1+104], %rd980;
	st.local.u64 	[%rd1+144], %rd981;
	st.local.u64 	[%rd1+184], %rd982;
	st.local.u64 	[%rd1+32], %rd983;
	st.local.u64 	[%rd1+72], %rd984;
	st.local.u64 	[%rd1+112], %rd985;
	st.local.u64 	[%rd1+152], %rd986;
	st.local.u64 	[%rd1+192], %rd987;
	setp.lt.u64 	%p18, %rd988, %rd373;
	cvt.u16.u64 	%rs96, %rd963;
	@%p18 bra 	$L__BB9_39;
// %bb.27:
	add.s64 	%rd240, %rd373, -2;
	and.b64  	%rd241, %rd811, 7;
	and.b64  	%rd242, %rd811, -8;
	add.s64 	%rd243, %rd1, 4;
	setp.eq.s64 	%p19, %rd373, 1;
	setp.lt.u64 	%p20, %rd240, 7;
	setp.eq.s64 	%p22, %rd241, 0;
$L__BB9_28:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB9_31 Depth 2
                                        //     Child Loop BB9_35 Depth 2
                                        //     Child Loop BB9_37 Depth 2
	st.u8 	[%rd989], %rs96;
	@%p19 bra 	$L__BB9_36;
// %bb.29:                              //   in Loop: Header=BB9_28 Depth=1
	mov.u64 	%rd960, 1;
	@%p20 bra 	$L__BB9_33;
// %bb.30:                              // %.preheader7
                                        //   in Loop: Header=BB9_28 Depth=1
	mov.u64 	%rd958, 0;
$L__BB9_31:                             //   Parent Loop BB9_28 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add.s64 	%rd662, %rd243, %rd958;
	ld.local.u8 	%rs70, [%rd662+-3];
	add.s64 	%rd663, %rd989, %rd958;
	st.u8 	[%rd663+1], %rs70;
	ld.local.u8 	%rs71, [%rd662+-2];
	st.u8 	[%rd663+2], %rs71;
	ld.local.u8 	%rs72, [%rd662+-1];
	st.u8 	[%rd663+3], %rs72;
	ld.local.u8 	%rs73, [%rd662];
	st.u8 	[%rd663+4], %rs73;
	ld.local.u8 	%rs74, [%rd662+1];
	st.u8 	[%rd663+5], %rs74;
	ld.local.u8 	%rs75, [%rd662+2];
	st.u8 	[%rd663+6], %rs75;
	ld.local.u8 	%rs76, [%rd662+3];
	st.u8 	[%rd663+7], %rs76;
	ld.local.u8 	%rs77, [%rd662+4];
	st.u8 	[%rd663+8], %rs77;
	add.s64 	%rd958, %rd958, 8;
	setp.ne.s64 	%p21, %rd242, %rd958;
	@%p21 bra 	$L__BB9_31;
// %bb.32:                              // %.loopexit8
                                        //   in Loop: Header=BB9_28 Depth=1
	add.s64 	%rd960, %rd958, 1;
$L__BB9_33:                             //   in Loop: Header=BB9_28 Depth=1
	@%p22 bra 	$L__BB9_36;
// %bb.34:                              // %.preheader5
                                        //   in Loop: Header=BB9_28 Depth=1
	mov.u64 	%rd961, %rd241;
$L__BB9_35:                             //   Parent Loop BB9_28 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	.pragma "nounroll";
	add.s64 	%rd664, %rd1, %rd960;
	ld.local.u8 	%rs78, [%rd664];
	add.s64 	%rd665, %rd989, %rd960;
	st.u8 	[%rd665], %rs78;
	add.s64 	%rd960, %rd960, 1;
	add.s64 	%rd961, %rd961, -1;
	setp.ne.s64 	%p23, %rd961, 0;
	@%p23 bra 	$L__BB9_35;
$L__BB9_36:                             //   in Loop: Header=BB9_28 Depth=1
	mov.u64 	%rd962, 0;
$L__BB9_37:                             //   Parent Loop BB9_28 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	xor.b64  	%rd667, %rd964, %rd963;
	xor.b64  	%rd668, %rd667, %rd965;
	xor.b64  	%rd669, %rd668, %rd966;
	xor.b64  	%rd670, %rd669, %rd967;
	xor.b64  	%rd671, %rd969, %rd968;
	xor.b64  	%rd672, %rd671, %rd970;
	xor.b64  	%rd673, %rd672, %rd971;
	xor.b64  	%rd674, %rd673, %rd972;
	xor.b64  	%rd675, %rd974, %rd973;
	xor.b64  	%rd676, %rd675, %rd975;
	xor.b64  	%rd677, %rd676, %rd976;
	xor.b64  	%rd678, %rd677, %rd977;
	xor.b64  	%rd679, %rd979, %rd978;
	xor.b64  	%rd680, %rd679, %rd980;
	xor.b64  	%rd681, %rd680, %rd981;
	xor.b64  	%rd682, %rd681, %rd982;
	xor.b64  	%rd683, %rd984, %rd983;
	xor.b64  	%rd684, %rd683, %rd985;
	xor.b64  	%rd685, %rd684, %rd986;
	xor.b64  	%rd686, %rd685, %rd987;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd674, 1;
	shr.b64 	%rhs, %rd674, 63;
	add.u64 	%rd687, %lhs, %rhs;
	}
	xor.b64  	%rd688, %rd686, %rd687;
	xor.b64  	%rd689, %rd688, %rd963;
	xor.b64  	%rd690, %rd688, %rd964;
	xor.b64  	%rd691, %rd688, %rd965;
	xor.b64  	%rd692, %rd688, %rd966;
	xor.b64  	%rd693, %rd688, %rd967;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd678, 1;
	shr.b64 	%rhs, %rd678, 63;
	add.u64 	%rd694, %lhs, %rhs;
	}
	xor.b64  	%rd695, %rd694, %rd670;
	xor.b64  	%rd696, %rd695, %rd968;
	xor.b64  	%rd697, %rd695, %rd969;
	xor.b64  	%rd698, %rd695, %rd970;
	xor.b64  	%rd699, %rd695, %rd971;
	xor.b64  	%rd700, %rd695, %rd972;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd682, 1;
	shr.b64 	%rhs, %rd682, 63;
	add.u64 	%rd701, %lhs, %rhs;
	}
	xor.b64  	%rd702, %rd701, %rd674;
	xor.b64  	%rd703, %rd702, %rd973;
	xor.b64  	%rd704, %rd702, %rd974;
	xor.b64  	%rd705, %rd702, %rd975;
	xor.b64  	%rd706, %rd702, %rd976;
	xor.b64  	%rd707, %rd702, %rd977;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd686, 1;
	shr.b64 	%rhs, %rd686, 63;
	add.u64 	%rd708, %lhs, %rhs;
	}
	xor.b64  	%rd709, %rd708, %rd678;
	xor.b64  	%rd710, %rd709, %rd978;
	xor.b64  	%rd711, %rd709, %rd979;
	xor.b64  	%rd712, %rd709, %rd980;
	xor.b64  	%rd713, %rd709, %rd981;
	xor.b64  	%rd714, %rd709, %rd982;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd670, 1;
	shr.b64 	%rhs, %rd670, 63;
	add.u64 	%rd715, %lhs, %rhs;
	}
	xor.b64  	%rd716, %rd682, %rd715;
	xor.b64  	%rd717, %rd716, %rd983;
	xor.b64  	%rd718, %rd984, %rd716;
	xor.b64  	%rd719, %rd985, %rd716;
	xor.b64  	%rd720, %rd986, %rd716;
	xor.b64  	%rd721, %rd987, %rd716;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd696, 1;
	shr.b64 	%rhs, %rd696, 63;
	add.u64 	%rd722, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd691, 3;
	shr.b64 	%rhs, %rd691, 61;
	add.u64 	%rd723, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd704, 6;
	shr.b64 	%rhs, %rd704, 58;
	add.u64 	%rd724, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd698, 10;
	shr.b64 	%rhs, %rd698, 54;
	add.u64 	%rd725, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd706, 15;
	shr.b64 	%rhs, %rd706, 49;
	add.u64 	%rd726, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd713, 21;
	shr.b64 	%rhs, %rd713, 43;
	add.u64 	%rd727, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd710, 28;
	shr.b64 	%rhs, %rd710, 36;
	add.u64 	%rd728, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd690, 36;
	shr.b64 	%rhs, %rd690, 28;
	add.u64 	%rd729, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd699, 45;
	shr.b64 	%rhs, %rd699, 19;
	add.u64 	%rd730, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd711, 55;
	shr.b64 	%rhs, %rd711, 9;
	add.u64 	%rd731, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd700, 2;
	shr.b64 	%rhs, %rd700, 62;
	add.u64 	%rd732, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd721, 14;
	shr.b64 	%rhs, %rd721, 50;
	add.u64 	%rd733, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd717, 27;
	shr.b64 	%rhs, %rd717, 37;
	add.u64 	%rd734, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd692, 41;
	shr.b64 	%rhs, %rd692, 23;
	add.u64 	%rd735, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd714, 56;
	shr.b64 	%rhs, %rd714, 8;
	add.u64 	%rd736, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd720, 8;
	shr.b64 	%rhs, %rd720, 56;
	add.u64 	%rd737, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd712, 25;
	shr.b64 	%rhs, %rd712, 39;
	add.u64 	%rd738, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd705, 43;
	shr.b64 	%rhs, %rd705, 21;
	add.u64 	%rd739, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd703, 62;
	shr.b64 	%rhs, %rd703, 2;
	add.u64 	%rd740, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd693, 18;
	shr.b64 	%rhs, %rd693, 46;
	add.u64 	%rd741, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd719, 39;
	shr.b64 	%rhs, %rd719, 25;
	add.u64 	%rd742, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd707, 61;
	shr.b64 	%rhs, %rd707, 3;
	add.u64 	%rd743, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd718, 20;
	shr.b64 	%rhs, %rd718, 44;
	add.u64 	%rd744, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd697, 44;
	shr.b64 	%rhs, %rd697, 20;
	add.u64 	%rd745, %lhs, %rhs;
	}
	not.b64 	%rd746, %rd745;
	and.b64  	%rd747, %rd739, %rd746;
	not.b64 	%rd748, %rd739;
	and.b64  	%rd749, %rd727, %rd748;
	xor.b64  	%rd968, %rd749, %rd745;
	not.b64 	%rd750, %rd727;
	and.b64  	%rd751, %rd733, %rd750;
	xor.b64  	%rd973, %rd751, %rd739;
	not.b64 	%rd752, %rd733;
	and.b64  	%rd753, %rd689, %rd752;
	xor.b64  	%rd978, %rd727, %rd753;
	not.b64 	%rd754, %rd689;
	and.b64  	%rd755, %rd745, %rd754;
	xor.b64  	%rd983, %rd755, %rd733;
	not.b64 	%rd756, %rd744;
	and.b64  	%rd757, %rd723, %rd756;
	xor.b64  	%rd964, %rd728, %rd757;
	not.b64 	%rd758, %rd723;
	and.b64  	%rd759, %rd730, %rd758;
	xor.b64  	%rd969, %rd759, %rd744;
	not.b64 	%rd760, %rd730;
	and.b64  	%rd761, %rd743, %rd760;
	xor.b64  	%rd974, %rd723, %rd761;
	not.b64 	%rd762, %rd743;
	and.b64  	%rd763, %rd728, %rd762;
	xor.b64  	%rd979, %rd763, %rd730;
	not.b64 	%rd764, %rd728;
	and.b64  	%rd765, %rd744, %rd764;
	xor.b64  	%rd984, %rd765, %rd743;
	not.b64 	%rd766, %rd724;
	and.b64  	%rd767, %rd738, %rd766;
	xor.b64  	%rd965, %rd767, %rd722;
	not.b64 	%rd768, %rd738;
	and.b64  	%rd769, %rd737, %rd768;
	xor.b64  	%rd970, %rd769, %rd724;
	not.b64 	%rd770, %rd737;
	and.b64  	%rd771, %rd741, %rd770;
	xor.b64  	%rd975, %rd738, %rd771;
	not.b64 	%rd772, %rd741;
	and.b64  	%rd773, %rd722, %rd772;
	xor.b64  	%rd980, %rd773, %rd737;
	not.b64 	%rd774, %rd722;
	and.b64  	%rd775, %rd724, %rd774;
	xor.b64  	%rd985, %rd741, %rd775;
	not.b64 	%rd776, %rd729;
	and.b64  	%rd777, %rd725, %rd776;
	xor.b64  	%rd966, %rd777, %rd734;
	not.b64 	%rd778, %rd725;
	and.b64  	%rd779, %rd726, %rd778;
	xor.b64  	%rd971, %rd729, %rd779;
	not.b64 	%rd780, %rd726;
	and.b64  	%rd781, %rd736, %rd780;
	xor.b64  	%rd976, %rd781, %rd725;
	not.b64 	%rd782, %rd736;
	and.b64  	%rd783, %rd734, %rd782;
	xor.b64  	%rd981, %rd783, %rd726;
	not.b64 	%rd784, %rd734;
	and.b64  	%rd785, %rd729, %rd784;
	xor.b64  	%rd986, %rd736, %rd785;
	not.b64 	%rd786, %rd731;
	and.b64  	%rd787, %rd742, %rd786;
	xor.b64  	%rd967, %rd787, %rd740;
	not.b64 	%rd788, %rd742;
	and.b64  	%rd789, %rd735, %rd788;
	xor.b64  	%rd972, %rd731, %rd789;
	not.b64 	%rd790, %rd735;
	and.b64  	%rd791, %rd732, %rd790;
	xor.b64  	%rd977, %rd791, %rd742;
	not.b64 	%rd792, %rd732;
	and.b64  	%rd793, %rd740, %rd792;
	xor.b64  	%rd982, %rd735, %rd793;
	not.b64 	%rd794, %rd740;
	and.b64  	%rd795, %rd731, %rd794;
	xor.b64  	%rd987, %rd795, %rd732;
	add.s64 	%rd797, %rd812, %rd962;
	ld.global.nc.u64 	%rd798, [%rd797];
	xor.b64  	%rd799, %rd798, %rd747;
	xor.b64  	%rd963, %rd799, %rd689;
	add.s64 	%rd962, %rd962, 8;
	cvt.u32.u64 	%r3, %rd962;
	setp.ne.s32 	%p24, %r3, 192;
	@%p24 bra 	$L__BB9_37;
// %bb.38:                              //   in Loop: Header=BB9_28 Depth=1
	st.local.u64 	[%rd1], %rd963;
	st.local.u64 	[%rd1+40], %rd964;
	st.local.u64 	[%rd1+80], %rd965;
	st.local.u64 	[%rd1+120], %rd966;
	st.local.u64 	[%rd1+160], %rd967;
	st.local.u64 	[%rd1+8], %rd968;
	st.local.u64 	[%rd1+48], %rd969;
	st.local.u64 	[%rd1+88], %rd970;
	st.local.u64 	[%rd1+128], %rd971;
	st.local.u64 	[%rd1+168], %rd972;
	st.local.u64 	[%rd1+16], %rd973;
	st.local.u64 	[%rd1+56], %rd974;
	st.local.u64 	[%rd1+96], %rd975;
	st.local.u64 	[%rd1+136], %rd976;
	st.local.u64 	[%rd1+176], %rd977;
	st.local.u64 	[%rd1+24], %rd978;
	st.local.u64 	[%rd1+64], %rd979;
	st.local.u64 	[%rd1+104], %rd980;
	st.local.u64 	[%rd1+144], %rd981;
	st.local.u64 	[%rd1+184], %rd982;
	st.local.u64 	[%rd1+32], %rd983;
	st.local.u64 	[%rd1+72], %rd984;
	st.local.u64 	[%rd1+112], %rd985;
	st.local.u64 	[%rd1+152], %rd986;
	st.local.u64 	[%rd1+192], %rd987;
	add.s64 	%rd989, %rd989, %rd373;
	sub.s64 	%rd988, %rd988, %rd373;
	cvt.u16.u64 	%rs96, %rd963;
	setp.ge.u64 	%p25, %rd988, %rd373;
	@%p25 bra 	$L__BB9_28;
$L__BB9_39:
	setp.eq.s64 	%p26, %rd988, 0;
	@%p26 bra 	$L__BB9_55;
// %bb.40:
	st.u8 	[%rd989], %rs96;
	setp.eq.s64 	%p27, %rd988, 1;
	add.s64 	%rd814, %rd988, -1;
	@%p27 bra 	$L__BB9_48;
// %bb.41:
	add.s64 	%rd801, %rd988, -2;
	and.b64  	%rd994, %rd814, 7;
	setp.lt.u64 	%p28, %rd801, 7;
	mov.u64 	%rd991, 1;
	@%p28 bra 	$L__BB9_45;
// %bb.42:
	and.b64  	%rd337, %rd814, -8;
	add.s64 	%rd338, %rd1, 4;
	mov.u64 	%rd990, 0;
$L__BB9_43:                             // =>This Inner Loop Header: Depth=1
	add.s64 	%rd803, %rd338, %rd990;
	ld.local.u8 	%rs79, [%rd803+-3];
	add.s64 	%rd804, %rd989, %rd990;
	st.u8 	[%rd804+1], %rs79;
	ld.local.u8 	%rs80, [%rd803+-2];
	st.u8 	[%rd804+2], %rs80;
	ld.local.u8 	%rs81, [%rd803+-1];
	st.u8 	[%rd804+3], %rs81;
	ld.local.u8 	%rs82, [%rd803];
	st.u8 	[%rd804+4], %rs82;
	ld.local.u8 	%rs83, [%rd803+1];
	st.u8 	[%rd804+5], %rs83;
	ld.local.u8 	%rs84, [%rd803+2];
	st.u8 	[%rd804+6], %rs84;
	ld.local.u8 	%rs85, [%rd803+3];
	st.u8 	[%rd804+7], %rs85;
	ld.local.u8 	%rs86, [%rd803+4];
	st.u8 	[%rd804+8], %rs86;
	add.s64 	%rd990, %rd990, 8;
	setp.ne.s64 	%p29, %rd337, %rd990;
	@%p29 bra 	$L__BB9_43;
// %bb.44:                              // %.loopexit4
	add.s64 	%rd991, %rd990, 1;
$L__BB9_45:
	setp.eq.s64 	%p30, %rd994, 0;
	@%p30 bra 	$L__BB9_48;
// %bb.46:                              // %.preheader2
	add.s64 	%rd993, %rd1, %rd991;
	add.s64 	%rd992, %rd989, %rd991;
$L__BB9_47:                             // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	ld.local.u8 	%rs87, [%rd993];
	st.u8 	[%rd992], %rs87;
	add.s64 	%rd994, %rd994, -1;
	add.s64 	%rd993, %rd993, 1;
	add.s64 	%rd992, %rd992, 1;
	setp.ne.s64 	%p31, %rd994, 0;
	@%p31 bra 	$L__BB9_47;
$L__BB9_48:
	and.b64  	%rd998, %rd988, 3;
	setp.lt.u64 	%p32, %rd814, 3;
	mov.u64 	%rd995, 0;
	@%p32 bra 	$L__BB9_52;
// %bb.49:
	and.b64  	%rd807, %rd988, -4;
	neg.s64 	%rd353, %rd807;
	add.s64 	%rd808, %rd988, %rd1;
	add.s64 	%rd354, %rd808, -2;
	mov.u64 	%rd1000, 0;
	mov.u64 	%rd999, %rd989;
$L__BB9_50:                             // =>This Inner Loop Header: Depth=1
	add.s64 	%rd809, %rd354, %rd1000;
	ld.local.u8 	%rs88, [%rd809+1];
	st.u8 	[%rd999], %rs88;
	ld.local.u8 	%rs89, [%rd809];
	st.u8 	[%rd999+1], %rs89;
	ld.local.u8 	%rs90, [%rd809+-1];
	st.u8 	[%rd999+2], %rs90;
	ld.local.u8 	%rs91, [%rd809+-2];
	st.u8 	[%rd999+3], %rs91;
	add.s64 	%rd1000, %rd1000, -4;
	add.s64 	%rd999, %rd999, 4;
	setp.eq.s64 	%p33, %rd353, %rd1000;
	@%p33 bra 	$L__BB9_51;
	bra.uni 	$L__BB9_50;
$L__BB9_51:                             // %.loopexit1
	neg.s64 	%rd995, %rd1000;
$L__BB9_52:
	setp.eq.s64 	%p34, %rd998, 0;
	@%p34 bra 	$L__BB9_55;
// %bb.53:                              // %.preheader
	add.s64 	%rd997, %rd989, %rd995;
	sub.s64 	%rd810, %rd814, %rd995;
	add.s64 	%rd996, %rd1, %rd810;
$L__BB9_54:                             // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	ld.local.u8 	%rs92, [%rd996];
	st.u8 	[%rd997], %rs92;
	add.s64 	%rd998, %rd998, -1;
	add.s64 	%rd997, %rd997, 1;
	add.s64 	%rd996, %rd996, -1;
	setp.ne.s64 	%p35, %rd998, 0;
	@%p35 bra 	$L__BB9_54;
$L__BB9_55:
	ret;
                                        // -- End function
}
	// .globl	__power_word            // -- Begin function __power_word
.visible .func __power_word(
	.param .b64 __power_word_param_0,
	.param .b64 __power_word_param_1,
	.param .b64 __power_word_param_2
)                                       // @__power_word
{
	.reg .pred 	%p<11>;
	.reg .b32 	%r<9>;
	.reg .b64 	%rd<130>;

// %bb.0:
	ld.param.u64 	%rd38, [__power_word_param_2];
	ld.param.u64 	%rd43, [__power_word_param_1];
	ld.u64 	%rd116, [%rd43+16];
	ld.u64 	%rd114, [%rd43];
	ld.u64 	%rd117, [%rd43+24];
	ld.u64 	%rd115, [%rd43+8];
	or.b64  	%rd44, %rd115, %rd117;
	or.b64  	%rd45, %rd114, %rd116;
	or.b64  	%rd46, %rd45, %rd44;
	setp.eq.s64 	%p1, %rd46, 0;
	mov.u64 	%rd127, 0;
	mov.u64 	%rd126, 1;
	mov.u64 	%rd128, %rd127;
	mov.u64 	%rd129, %rd127;
	@%p1 bra 	$L__BB10_3;
// %bb.1:
	ld.param.u64 	%rd37, [__power_word_param_0];
	ld.u64 	%rd121, [%rd37+24];
	ld.u64 	%rd120, [%rd37+16];
	ld.u64 	%rd119, [%rd37+8];
	ld.u64 	%rd118, [%rd37];
	mov.u64 	%rd49, 0;
	mov.u64 	%rd126, 1;
	mov.u64 	%rd123, %rd49;
	mov.u64 	%rd128, %rd49;
	mov.u64 	%rd129, %rd49;
$L__BB10_2:                             // =>This Inner Loop Header: Depth=1
	and.b64  	%rd51, %rd114, 1;
	setp.eq.b64 	%p2, %rd51, 1;
	selp.b64 	%rd52, %rd121, 0, %p2;
	selp.b64 	%rd53, %rd120, 0, %p2;
	selp.b64 	%rd54, %rd119, 0, %p2;
	selp.b64 	%rd55, %rd118, 1, %p2;
	mul.hi.u64 	%rd56, %rd55, %rd126;
	mul.lo.s64 	%rd57, %rd54, %rd126;
	mul.hi.u64 	%rd58, %rd54, %rd126;
	add.cc.s64 	%rd59, %rd57, %rd56;
	addc.cc.s64 	%rd60, %rd58, 0;
	mul.lo.s64 	%rd61, %rd55, %rd123;
	mul.hi.u64 	%rd62, %rd55, %rd123;
	add.cc.s64 	%rd127, %rd61, %rd59;
	addc.cc.s64 	%rd63, %rd62, 0;
	add.cc.s64 	%rd65, %rd60, %rd63;
	addc.cc.s64 	%rd66, %rd49, 0;
	mul.lo.s64 	%rd67, %rd54, %rd123;
	mul.hi.u64 	%rd68, %rd54, %rd123;
	add.cc.s64 	%rd69, %rd67, %rd65;
	addc.cc.s64 	%rd70, %rd68, %rd66;
	mul.lo.s64 	%rd71, %rd128, %rd54;
	mul.hi.u64 	%rd72, %rd128, %rd55;
	add.s64 	%rd73, %rd72, %rd71;
	mul.lo.s64 	%rd74, %rd129, %rd55;
	add.s64 	%rd75, %rd73, %rd74;
	mul.hi.u64 	%rd76, %rd126, %rd53;
	mul.lo.s64 	%rd77, %rd126, %rd52;
	add.s64 	%rd78, %rd76, %rd77;
	mul.lo.s64 	%rd79, %rd123, %rd53;
	add.s64 	%rd80, %rd78, %rd79;
	mul.lo.s64 	%rd81, %rd126, %rd53;
	mul.lo.s64 	%rd82, %rd128, %rd55;
	add.cc.s64 	%rd83, %rd82, %rd81;
	addc.cc.s64 	%rd84, %rd75, %rd80;
	add.cc.s64 	%rd128, %rd69, %rd83;
	addc.cc.s64 	%rd129, %rd70, %rd84;
	mul.lo.s64 	%rd126, %rd55, %rd126;
	mul.lo.s64 	%rd85, %rd119, %rd118;
	mul.hi.u64 	%rd86, %rd119, %rd118;
	mul.hi.u64 	%rd87, %rd118, %rd118;
	add.cc.s64 	%rd88, %rd85, %rd87;
	addc.cc.s64 	%rd89, %rd86, 0;
	add.cc.s64 	%rd26, %rd85, %rd88;
	addc.cc.s64 	%rd90, %rd86, 0;
	add.cc.s64 	%rd91, %rd89, %rd90;
	addc.cc.s64 	%rd92, %rd49, 0;
	mul.lo.s64 	%rd93, %rd119, %rd119;
	mul.hi.u64 	%rd94, %rd119, %rd119;
	add.cc.s64 	%rd95, %rd93, %rd91;
	addc.cc.s64 	%rd96, %rd94, %rd92;
	mul.lo.s64 	%rd97, %rd119, %rd120;
	mul.hi.u64 	%rd98, %rd118, %rd120;
	add.s64 	%rd99, %rd98, %rd97;
	mul.lo.s64 	%rd100, %rd118, %rd121;
	add.s64 	%rd101, %rd99, %rd100;
	add.s64 	%rd102, %rd98, %rd100;
	add.s64 	%rd103, %rd102, %rd97;
	mul.lo.s64 	%rd104, %rd118, %rd120;
	add.cc.s64 	%rd105, %rd104, %rd104;
	addc.cc.s64 	%rd106, %rd101, %rd103;
	add.cc.s64 	%rd120, %rd95, %rd105;
	addc.cc.s64 	%rd121, %rd96, %rd106;
	mul.lo.s64 	%rd118, %rd118, %rd118;
	shr.u64 	%rd107, %rd114, 1;
	shl.b64 	%rd108, %rd115, 63;
	or.b64  	%rd29, %rd107, %rd108;
	shr.u64 	%rd109, %rd115, 1;
	shl.b64 	%rd110, %rd116, 63;
	or.b64  	%rd30, %rd109, %rd110;
	shr.u64 	%rd111, %rd116, 1;
	shl.b64 	%rd112, %rd117, 63;
	or.b64  	%rd31, %rd111, %rd112;
	shr.u64 	%rd32, %rd117, 1;
	setp.eq.s64 	%p3, %rd115, 0;
	setp.gt.u64 	%p4, %rd114, 1;
	selp.u32 	%r1, -1, 0, %p4;
	setp.ne.s64 	%p5, %rd115, 0;
	selp.u32 	%r2, -1, 0, %p5;
	selp.b32 	%r3, %r1, %r2, %p3;
	setp.eq.s64 	%p6, %rd117, 0;
	setp.ne.s64 	%p7, %rd116, 0;
	selp.u32 	%r4, -1, 0, %p7;
	setp.ne.s64 	%p8, %rd117, 0;
	selp.u32 	%r5, -1, 0, %p8;
	selp.b32 	%r6, %r4, %r5, %p6;
	or.b64  	%rd113, %rd116, %rd117;
	setp.eq.s64 	%p9, %rd113, 0;
	selp.b32 	%r7, %r3, %r6, %p9;
	and.b32  	%r8, %r7, 1;
	setp.eq.b32 	%p10, %r8, 1;
	mov.u64 	%rd114, %rd29;
	mov.u64 	%rd115, %rd30;
	mov.u64 	%rd116, %rd31;
	mov.u64 	%rd117, %rd32;
	mov.u64 	%rd119, %rd26;
	mov.u64 	%rd123, %rd127;
	@%p10 bra 	$L__BB10_2;
$L__BB10_3:
	st.u64 	[%rd38], %rd126;
	st.u64 	[%rd38+8], %rd127;
	st.u64 	[%rd38+16], %rd128;
	st.u64 	[%rd38+24], %rd129;
	ret;
                                        // -- End function
}
	// .globl	__device_calldatacpy    // -- Begin function __device_calldatacpy
.visible .func __device_calldatacpy(
	.param .b64 __device_calldatacpy_param_0,
	.param .b64 __device_calldatacpy_param_1,
	.param .b64 __device_calldatacpy_param_2,
	.param .b64 __device_calldatacpy_param_3,
	.param .b64 __device_calldatacpy_param_4
)                                       // @__device_calldatacpy
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<6>;
	.reg .b64 	%rd<41>;

// %bb.0:
	ld.param.u64 	%rd24, [__device_calldatacpy_param_4];
	setp.eq.s64 	%p1, %rd24, 0;
	@%p1 bra 	$L__BB11_10;
// %bb.1:
	ld.param.u64 	%rd21, [__device_calldatacpy_param_1];
	add.s64 	%rd25, %rd24, %rd21;
	setp.lt.u64 	%p2, %rd25, %rd24;
	setp.gt.u64 	%p3, %rd25, 727;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB11_10;
// %bb.2:
	ld.param.u64 	%rd23, [__device_calldatacpy_param_3];
	add.s64 	%rd26, %rd24, %rd23;
	setp.lt.u64 	%p5, %rd26, %rd24;
	setp.gt.u64 	%p6, %rd26, 2035;
	or.pred  	%p7, %p5, %p6;
	@%p7 bra 	$L__BB11_10;
// %bb.3:
	min.u64 	%rd1, %rd23, 2036;
	add.s64 	%rd27, %rd1, %rd24;
	min.u64 	%rd2, %rd27, 2036;
	setp.eq.s64 	%p8, %rd2, %rd1;
	@%p8 bra 	$L__BB11_10;
// %bb.4:
	ld.param.u64 	%rd22, [__device_calldatacpy_param_2];
	ld.param.u64 	%rd20, [__device_calldatacpy_param_0];
	sub.s64 	%rd3, %rd2, %rd1;
	not.b64 	%rd29, %rd1;
	add.s64 	%rd30, %rd2, %rd29;
	and.b64  	%rd4, %rd3, 3;
	setp.lt.u64 	%p9, %rd30, 3;
	mov.u64 	%rd37, 0;
	@%p9 bra 	$L__BB11_7;
// %bb.5:
	and.b64  	%rd5, %rd3, -4;
	add.s64 	%rd6, %rd20, %rd21;
	add.s64 	%rd7, %rd22, %rd1;
	mov.u64 	%rd37, 0;
$L__BB11_6:                             // =>This Inner Loop Header: Depth=1
	add.s64 	%rd32, %rd7, %rd37;
	ld.u8 	%rs1, [%rd32];
	add.s64 	%rd33, %rd6, %rd37;
	st.u8 	[%rd33], %rs1;
	ld.u8 	%rs2, [%rd32+1];
	st.u8 	[%rd33+1], %rs2;
	ld.u8 	%rs3, [%rd32+2];
	st.u8 	[%rd33+2], %rs3;
	ld.u8 	%rs4, [%rd32+3];
	st.u8 	[%rd33+3], %rs4;
	add.s64 	%rd37, %rd37, 4;
	setp.ne.s64 	%p10, %rd5, %rd37;
	@%p10 bra 	$L__BB11_6;
$L__BB11_7:
	setp.eq.s64 	%p11, %rd4, 0;
	@%p11 bra 	$L__BB11_10;
// %bb.8:                               // %.preheader
	add.s64 	%rd34, %rd37, %rd21;
	add.s64 	%rd40, %rd20, %rd34;
	add.s64 	%rd35, %rd37, %rd1;
	add.s64 	%rd39, %rd22, %rd35;
	neg.s64 	%rd38, %rd4;
$L__BB11_9:                             // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	ld.u8 	%rs5, [%rd39];
	st.u8 	[%rd40], %rs5;
	add.s64 	%rd40, %rd40, 1;
	add.s64 	%rd39, %rd39, 1;
	add.s64 	%rd38, %rd38, 1;
	setp.ne.s64 	%p12, %rd38, 0;
	@%p12 bra 	$L__BB11_9;
$L__BB11_10:
	ret;
                                        // -- End function
}
	// .globl	__device_calldataload   // -- Begin function __device_calldataload
.visible .func __device_calldataload(
	.param .b64 __device_calldataload_param_0,
	.param .b64 __device_calldataload_param_1,
	.param .b64 __device_calldataload_param_2
)                                       // @__device_calldataload
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<33>;
	.reg .b64 	%rd<7>;

// %bb.0:
	ld.param.u64 	%rd3, [__device_calldataload_param_2];
	ld.param.u64 	%rd1, [__device_calldataload_param_0];
	setp.gt.u64 	%p1, %rd3, -33;
	add.s64 	%rd4, %rd3, 32;
	setp.gt.u64 	%p2, %rd4, 2035;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB12_2;
	bra.uni 	$L__BB12_1;
$L__BB12_2:
	mov.u64 	%rd6, 0;
	st.u64 	[%rd1+24], %rd6;
	st.u64 	[%rd1+16], %rd6;
	st.u64 	[%rd1+8], %rd6;
	st.u64 	[%rd1], %rd6;
	bra.uni 	$L__BB12_3;
$L__BB12_1:
	ld.param.u64 	%rd2, [__device_calldataload_param_1];
	add.s64 	%rd5, %rd2, %rd3;
	ld.u8 	%rs1, [%rd5+31];
	st.u8 	[%rd1], %rs1;
	ld.u8 	%rs2, [%rd5+30];
	st.u8 	[%rd1+1], %rs2;
	ld.u8 	%rs3, [%rd5+29];
	st.u8 	[%rd1+2], %rs3;
	ld.u8 	%rs4, [%rd5+28];
	st.u8 	[%rd1+3], %rs4;
	ld.u8 	%rs5, [%rd5+27];
	st.u8 	[%rd1+4], %rs5;
	ld.u8 	%rs6, [%rd5+26];
	st.u8 	[%rd1+5], %rs6;
	ld.u8 	%rs7, [%rd5+25];
	st.u8 	[%rd1+6], %rs7;
	ld.u8 	%rs8, [%rd5+24];
	st.u8 	[%rd1+7], %rs8;
	ld.u8 	%rs9, [%rd5+23];
	st.u8 	[%rd1+8], %rs9;
	ld.u8 	%rs10, [%rd5+22];
	st.u8 	[%rd1+9], %rs10;
	ld.u8 	%rs11, [%rd5+21];
	st.u8 	[%rd1+10], %rs11;
	ld.u8 	%rs12, [%rd5+20];
	st.u8 	[%rd1+11], %rs12;
	ld.u8 	%rs13, [%rd5+19];
	st.u8 	[%rd1+12], %rs13;
	ld.u8 	%rs14, [%rd5+18];
	st.u8 	[%rd1+13], %rs14;
	ld.u8 	%rs15, [%rd5+17];
	st.u8 	[%rd1+14], %rs15;
	ld.u8 	%rs16, [%rd5+16];
	st.u8 	[%rd1+15], %rs16;
	ld.u8 	%rs17, [%rd5+15];
	st.u8 	[%rd1+16], %rs17;
	ld.u8 	%rs18, [%rd5+14];
	st.u8 	[%rd1+17], %rs18;
	ld.u8 	%rs19, [%rd5+13];
	st.u8 	[%rd1+18], %rs19;
	ld.u8 	%rs20, [%rd5+12];
	st.u8 	[%rd1+19], %rs20;
	ld.u8 	%rs21, [%rd5+11];
	st.u8 	[%rd1+20], %rs21;
	ld.u8 	%rs22, [%rd5+10];
	st.u8 	[%rd1+21], %rs22;
	ld.u8 	%rs23, [%rd5+9];
	st.u8 	[%rd1+22], %rs23;
	ld.u8 	%rs24, [%rd5+8];
	st.u8 	[%rd1+23], %rs24;
	ld.u8 	%rs25, [%rd5+7];
	st.u8 	[%rd1+24], %rs25;
	ld.u8 	%rs26, [%rd5+6];
	st.u8 	[%rd1+25], %rs26;
	ld.u8 	%rs27, [%rd5+5];
	st.u8 	[%rd1+26], %rs27;
	ld.u8 	%rs28, [%rd5+4];
	st.u8 	[%rd1+27], %rs28;
	ld.u8 	%rs29, [%rd5+3];
	st.u8 	[%rd1+28], %rs29;
	ld.u8 	%rs30, [%rd5+2];
	st.u8 	[%rd1+29], %rs30;
	ld.u8 	%rs31, [%rd5+1];
	st.u8 	[%rd1+30], %rs31;
	ld.u8 	%rs32, [%rd5];
	st.u8 	[%rd1+31], %rs32;
$L__BB12_3:
	ret;
                                        // -- End function
}
	// .globl	__device_mstore         // -- Begin function __device_mstore
.visible .func __device_mstore(
	.param .b64 __device_mstore_param_0,
	.param .b64 __device_mstore_param_1,
	.param .b64 __device_mstore_param_2,
	.param .b64 __device_mstore_param_3
)                                       // @__device_mstore
{
	.reg .pred 	%p<10>;
	.reg .b16 	%rs<6>;
	.reg .b64 	%rd<40>;

// %bb.0:
	ld.param.u64 	%rd23, [__device_mstore_param_3];
	ld.param.u64 	%rd21, [__device_mstore_param_1];
	setp.ne.s64 	%p1, %rd23, 0;
	not.b64 	%rd24, %rd21;
	setp.ge.u64 	%p2, %rd24, %rd23;
	and.pred  	%p3, %p1, %p2;
	mov.u64 	%rd25, 728;
	sub.s64 	%rd26, %rd25, %rd23;
	setp.gt.u64 	%p4, %rd26, %rd21;
	and.pred  	%p5, %p3, %p4;
	@!%p5 bra 	$L__BB13_8;
	bra.uni 	$L__BB13_1;
$L__BB13_1:
	ld.param.u64 	%rd22, [__device_mstore_param_2];
	ld.param.u64 	%rd20, [__device_mstore_param_0];
	add.s64 	%rd1, %rd23, -1;
	and.b64  	%rd39, %rd23, 3;
	setp.lt.u64 	%p6, %rd1, 3;
	mov.u64 	%rd36, 0;
	@%p6 bra 	$L__BB13_5;
// %bb.2:
	and.b64  	%rd29, %rd23, -4;
	neg.s64 	%rd3, %rd29;
	add.s64 	%rd34, %rd20, %rd21;
	add.s64 	%rd30, %rd23, %rd22;
	add.s64 	%rd5, %rd30, -2;
	mov.u64 	%rd35, 0;
$L__BB13_3:                             // =>This Inner Loop Header: Depth=1
	add.s64 	%rd31, %rd5, %rd35;
	ld.u8 	%rs1, [%rd31+1];
	st.u8 	[%rd34], %rs1;
	ld.u8 	%rs2, [%rd31];
	st.u8 	[%rd34+1], %rs2;
	ld.u8 	%rs3, [%rd31+-1];
	st.u8 	[%rd34+2], %rs3;
	ld.u8 	%rs4, [%rd31+-2];
	st.u8 	[%rd34+3], %rs4;
	add.s64 	%rd35, %rd35, -4;
	add.s64 	%rd34, %rd34, 4;
	setp.ne.s64 	%p7, %rd3, %rd35;
	@%p7 bra 	$L__BB13_3;
// %bb.4:                               // %.loopexit1
	neg.s64 	%rd36, %rd35;
$L__BB13_5:
	setp.eq.s64 	%p8, %rd39, 0;
	@%p8 bra 	$L__BB13_8;
// %bb.6:                               // %.preheader
	add.s64 	%rd32, %rd36, %rd21;
	add.s64 	%rd38, %rd20, %rd32;
	sub.s64 	%rd33, %rd1, %rd36;
	add.s64 	%rd37, %rd22, %rd33;
$L__BB13_7:                             // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	ld.u8 	%rs5, [%rd37];
	st.u8 	[%rd38], %rs5;
	add.s64 	%rd39, %rd39, -1;
	add.s64 	%rd38, %rd38, 1;
	add.s64 	%rd37, %rd37, -1;
	setp.ne.s64 	%p9, %rd39, 0;
	@%p9 bra 	$L__BB13_7;
$L__BB13_8:
	ret;
                                        // -- End function
}
	// .globl	__device_mload          // -- Begin function __device_mload
.visible .func __device_mload(
	.param .b64 __device_mload_param_0,
	.param .b64 __device_mload_param_1,
	.param .b64 __device_mload_param_2
)                                       // @__device_mload
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<33>;
	.reg .b64 	%rd<6>;

// %bb.0:
	ld.param.u64 	%rd3, [__device_mload_param_2];
	ld.param.u64 	%rd2, [__device_mload_param_1];
	setp.lt.u64 	%p1, %rd2, 696;
	@%p1 bra 	$L__BB14_2;
// %bb.1:
	mov.u64 	%rd5, 0;
	st.u64 	[%rd3+24], %rd5;
	st.u64 	[%rd3+16], %rd5;
	st.u64 	[%rd3+8], %rd5;
	st.u64 	[%rd3], %rd5;
	bra.uni 	$L__BB14_3;
$L__BB14_2:
	ld.param.u64 	%rd1, [__device_mload_param_0];
	add.s64 	%rd4, %rd1, %rd2;
	ld.u8 	%rs1, [%rd4+31];
	st.u8 	[%rd3], %rs1;
	ld.u8 	%rs2, [%rd4+30];
	st.u8 	[%rd3+1], %rs2;
	ld.u8 	%rs3, [%rd4+29];
	st.u8 	[%rd3+2], %rs3;
	ld.u8 	%rs4, [%rd4+28];
	st.u8 	[%rd3+3], %rs4;
	ld.u8 	%rs5, [%rd4+27];
	st.u8 	[%rd3+4], %rs5;
	ld.u8 	%rs6, [%rd4+26];
	st.u8 	[%rd3+5], %rs6;
	ld.u8 	%rs7, [%rd4+25];
	st.u8 	[%rd3+6], %rs7;
	ld.u8 	%rs8, [%rd4+24];
	st.u8 	[%rd3+7], %rs8;
	ld.u8 	%rs9, [%rd4+23];
	st.u8 	[%rd3+8], %rs9;
	ld.u8 	%rs10, [%rd4+22];
	st.u8 	[%rd3+9], %rs10;
	ld.u8 	%rs11, [%rd4+21];
	st.u8 	[%rd3+10], %rs11;
	ld.u8 	%rs12, [%rd4+20];
	st.u8 	[%rd3+11], %rs12;
	ld.u8 	%rs13, [%rd4+19];
	st.u8 	[%rd3+12], %rs13;
	ld.u8 	%rs14, [%rd4+18];
	st.u8 	[%rd3+13], %rs14;
	ld.u8 	%rs15, [%rd4+17];
	st.u8 	[%rd3+14], %rs15;
	ld.u8 	%rs16, [%rd4+16];
	st.u8 	[%rd3+15], %rs16;
	ld.u8 	%rs17, [%rd4+15];
	st.u8 	[%rd3+16], %rs17;
	ld.u8 	%rs18, [%rd4+14];
	st.u8 	[%rd3+17], %rs18;
	ld.u8 	%rs19, [%rd4+13];
	st.u8 	[%rd3+18], %rs19;
	ld.u8 	%rs20, [%rd4+12];
	st.u8 	[%rd3+19], %rs20;
	ld.u8 	%rs21, [%rd4+11];
	st.u8 	[%rd3+20], %rs21;
	ld.u8 	%rs22, [%rd4+10];
	st.u8 	[%rd3+21], %rs22;
	ld.u8 	%rs23, [%rd4+9];
	st.u8 	[%rd3+22], %rs23;
	ld.u8 	%rs24, [%rd4+8];
	st.u8 	[%rd3+23], %rs24;
	ld.u8 	%rs25, [%rd4+7];
	st.u8 	[%rd3+24], %rs25;
	ld.u8 	%rs26, [%rd4+6];
	st.u8 	[%rd3+25], %rs26;
	ld.u8 	%rs27, [%rd4+5];
	st.u8 	[%rd3+26], %rs27;
	ld.u8 	%rs28, [%rd4+4];
	st.u8 	[%rd3+27], %rs28;
	ld.u8 	%rs29, [%rd4+3];
	st.u8 	[%rd3+28], %rs29;
	ld.u8 	%rs30, [%rd4+2];
	st.u8 	[%rd3+29], %rs30;
	ld.u8 	%rs31, [%rd4+1];
	st.u8 	[%rd3+30], %rs31;
	ld.u8 	%rs32, [%rd4];
	st.u8 	[%rd3+31], %rs32;
$L__BB14_3:
	ret;
                                        // -- End function
}
	// .globl	__device_sstore         // -- Begin function __device_sstore
.visible .func __device_sstore(
	.param .b64 __device_sstore_param_0,
	.param .b64 __device_sstore_param_1
)                                       // @__device_sstore
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<52>;

// %bb.0:
	ld.param.u64 	%rd10, [__device_sstore_param_1];
	ld.param.u64 	%rd12, [__device_sstore_param_0];
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	cvt.u64.u32 	%rd1, %r4;
	mov.u64 	%rd13, l1snap_lens;
	add.s64 	%rd2, %rd13, %rd1;
	ld.global.u8 	%rs1, [%rd2];
	setp.eq.s16 	%p1, %rs1, 0;
	ld.u64 	%rd7, [%rd12+24];
	ld.u64 	%rd6, [%rd12+16];
	ld.u64 	%rd5, [%rd12+8];
	ld.u64 	%rd4, [%rd12];
	mov.u64 	%rd51, 0;
	shl.b64 	%rd49, %rd1, 13;
	mov.u64 	%rd50, l1snaps;
	@%p1 bra 	$L__BB15_5;
// %bb.1:                               // %.preheader
	cvt.u64.u16 	%rd51, %rs1;
	mov.u16 	%rs7, 0;
$L__BB15_2:                             // =>This Inner Loop Header: Depth=1
	add.s64 	%rd17, %rd50, %rd49;
	cvt.u32.u16 	%r5, %rs7;
	and.b32  	%r6, %r5, 255;
	mul.wide.u32 	%rd18, %r6, 64;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.u64 	%rd20, [%rd19];
	ld.global.u64 	%rd21, [%rd19+16];
	ld.global.u64 	%rd22, [%rd19+8];
	ld.global.u64 	%rd23, [%rd19+24];
	xor.b64  	%rd24, %rd23, %rd7;
	xor.b64  	%rd25, %rd22, %rd5;
	or.b64  	%rd26, %rd25, %rd24;
	xor.b64  	%rd27, %rd21, %rd6;
	xor.b64  	%rd28, %rd20, %rd4;
	or.b64  	%rd29, %rd28, %rd27;
	or.b64  	%rd30, %rd29, %rd26;
	setp.ne.s64 	%p2, %rd30, 0;
	@%p2 bra 	$L__BB15_4;
	bra.uni 	$L__BB15_3;
$L__BB15_4:                             //   in Loop: Header=BB15_2 Depth=1
	add.s16 	%rs7, %rs7, 1;
	and.b16  	%rs5, %rs7, 255;
	setp.lt.u16 	%p3, %rs5, %rs1;
	@%p3 bra 	$L__BB15_2;
$L__BB15_5:
	add.s64 	%rd42, %rd50, %rd49;
	shl.b64 	%rd43, %rd51, 6;
	add.s64 	%rd44, %rd42, %rd43;
	st.global.u64 	[%rd44+24], %rd7;
	st.global.u64 	[%rd44+16], %rd6;
	st.global.u64 	[%rd44+8], %rd5;
	st.global.u64 	[%rd44], %rd4;
	ld.u64 	%rd45, [%rd10+16];
	ld.u64 	%rd46, [%rd10+8];
	ld.u64 	%rd47, [%rd10];
	ld.u64 	%rd48, [%rd10+24];
	st.global.u64 	[%rd44+56], %rd48;
	st.global.u64 	[%rd44+32], %rd47;
	st.global.u64 	[%rd44+40], %rd46;
	st.global.u64 	[%rd44+48], %rd45;
	add.s16 	%rs6, %rs1, 1;
	st.global.u8 	[%rd2], %rs6;
	bra.uni 	$L__BB15_6;
$L__BB15_3:
	cvt.u64.u16 	%rd14, %rs7;
	and.b64  	%rd8, %rd14, 255;
	ld.u64 	%rd31, [%rd10+8];
	ld.u64 	%rd32, [%rd10];
	ld.u64 	%rd33, [%rd10+24];
	ld.u64 	%rd34, [%rd10+16];
	shl.b64 	%rd38, %rd8, 6;
	add.s64 	%rd39, %rd17, %rd38;
	st.global.u64 	[%rd39+48], %rd34;
	st.global.u64 	[%rd39+56], %rd33;
	st.global.u64 	[%rd39+32], %rd32;
	st.global.u64 	[%rd39+40], %rd31;
$L__BB15_6:
	ret;
                                        // -- End function
}
	// .globl	__device_sload          // -- Begin function __device_sload
.visible .func __device_sload(
	.param .b64 __device_sload_param_0,
	.param .b64 __device_sload_param_1
)                                       // @__device_sload
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<74>;

// %bb.0:
	ld.param.u64 	%rd22, [__device_sload_param_1];
	ld.param.u64 	%rd23, [__device_sload_param_0];
	mov.u32 	%r7, %tid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %ntid.x;
	mad.lo.s32 	%r10, %r9, %r8, %r7;
	cvt.u64.u32 	%rd1, %r10;
	ld.u64 	%rd5, [%rd23+24];
	ld.u64 	%rd4, [%rd23+16];
	ld.u64 	%rd3, [%rd23+8];
	ld.u64 	%rd2, [%rd23];
	mov.u64 	%rd24, l1snap_lens;
	add.s64 	%rd25, %rd24, %rd1;
	ld.global.u8 	%r11, [%rd25];
	setp.eq.s32 	%p1, %r11, 0;
	@%p1 bra 	$L__BB16_4;
// %bb.1:                               // %.preheader1
	shl.b64 	%rd26, %rd1, 13;
	mov.u64 	%rd27, l1snaps;
	add.s64 	%rd28, %rd26, %rd27;
	add.s64 	%rd67, %rd28, 32;
$L__BB16_3:                             // =>This Inner Loop Header: Depth=1
	ld.global.u64 	%rd29, [%rd67+-8];
	ld.global.u64 	%rd30, [%rd67+-24];
	ld.global.u64 	%rd31, [%rd67+-16];
	ld.global.u64 	%rd32, [%rd67+-32];
	xor.b64  	%rd33, %rd32, %rd2;
	xor.b64  	%rd34, %rd31, %rd4;
	or.b64  	%rd35, %rd33, %rd34;
	xor.b64  	%rd36, %rd30, %rd3;
	xor.b64  	%rd37, %rd29, %rd5;
	or.b64  	%rd38, %rd36, %rd37;
	or.b64  	%rd39, %rd35, %rd38;
	setp.eq.s64 	%p2, %rd39, 0;
	@%p2 bra 	$L__BB16_8;
// %bb.2:                               //   in Loop: Header=BB16_3 Depth=1
	add.s32 	%r11, %r11, -1;
	add.s64 	%rd67, %rd67, 64;
	setp.eq.s32 	%p3, %r11, 0;
	@%p3 bra 	$L__BB16_4;
	bra.uni 	$L__BB16_3;
$L__BB16_4:
	shl.b64 	%rd44, %rd1, 2;
	mov.u64 	%rd45, __snap_map;
	add.s64 	%rd46, %rd45, %rd44;
	ld.global.u32 	%rd9, [%rd46];
	mov.u64 	%rd47, l2snap_lens;
	add.s64 	%rd48, %rd47, %rd9;
	ld.global.u8 	%r12, [%rd48];
	setp.eq.s32 	%p4, %r12, 0;
	mov.u64 	%rd70, 0;
	mov.u64 	%rd71, %rd70;
	mov.u64 	%rd72, %rd70;
	mov.u64 	%rd73, %rd70;
	@%p4 bra 	$L__BB16_9;
// %bb.5:                               // %.preheader
	shl.b64 	%rd49, %rd9, 13;
	mov.u64 	%rd50, l2snaps;
	add.s64 	%rd51, %rd49, %rd50;
	add.s64 	%rd67, %rd51, 32;
$L__BB16_7:                             // =>This Inner Loop Header: Depth=1
	ld.global.u64 	%rd52, [%rd67+-8];
	ld.global.u64 	%rd53, [%rd67+-24];
	ld.global.u64 	%rd54, [%rd67+-16];
	ld.global.u64 	%rd55, [%rd67+-32];
	xor.b64  	%rd56, %rd55, %rd2;
	xor.b64  	%rd57, %rd54, %rd4;
	or.b64  	%rd58, %rd56, %rd57;
	xor.b64  	%rd59, %rd53, %rd3;
	xor.b64  	%rd60, %rd52, %rd5;
	or.b64  	%rd61, %rd59, %rd60;
	or.b64  	%rd62, %rd58, %rd61;
	setp.ne.s64 	%p5, %rd62, 0;
	@%p5 bra 	$L__BB16_6;
	bra.uni 	$L__BB16_8;
$L__BB16_6:                             //   in Loop: Header=BB16_7 Depth=1
	add.s32 	%r12, %r12, -1;
	add.s64 	%rd67, %rd67, 64;
	setp.eq.s32 	%p6, %r12, 0;
	mov.u64 	%rd70, 0;
	mov.u64 	%rd71, %rd70;
	mov.u64 	%rd72, %rd70;
	mov.u64 	%rd73, %rd70;
	@%p6 bra 	$L__BB16_9;
	bra.uni 	$L__BB16_7;
$L__BB16_8:
	ld.global.u64 	%rd73, [%rd67+24];
	ld.global.u64 	%rd72, [%rd67+16];
	ld.global.u64 	%rd71, [%rd67+8];
	ld.global.u64 	%rd70, [%rd67];
$L__BB16_9:
	st.u64 	[%rd22], %rd70;
	st.u64 	[%rd22+8], %rd71;
	st.u64 	[%rd22+16], %rd72;
	st.u64 	[%rd22+24], %rd73;
	ret;
                                        // -- End function
}
	// .globl	__simple_hash           // -- Begin function __simple_hash
.visible .func  (.param .b64 func_retval0) __simple_hash(
	.param .b64 __simple_hash_param_0
)                                       // @__simple_hash
{
	.reg .b64 	%rd<10>;

// %bb.0:
	ld.param.u64 	%rd1, [__simple_hash_param_0];
	shr.u64 	%rd2, %rd1, 30;
	xor.b64  	%rd3, %rd2, %rd1;
	mul.lo.s64 	%rd4, %rd3, -4658895280553007687;
	shr.u64 	%rd5, %rd4, 27;
	xor.b64  	%rd6, %rd5, %rd4;
	mul.lo.s64 	%rd7, %rd6, -7723592293110705685;
	shr.u64 	%rd8, %rd7, 31;
	xor.b64  	%rd9, %rd8, %rd7;
	st.param.b64 	[func_retval0+0], %rd9;
	ret;
                                        // -- End function
}
	// .globl	__hashint               // -- Begin function __hashint
.visible .func  (.param .b32 func_retval0) __hashint(
	.param .b32 __hashint_param_0,
	.param .b32 __hashint_param_1
)                                       // @__hashint
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<13>;

// %bb.0:
	ld.param.u32 	%rd1, [__hashint_param_1];
	ld.param.u32 	%rd2, [__hashint_param_0];
	shl.b64 	%rd3, %rd2, 32;
	or.b64  	%rd4, %rd3, %rd1;
	shr.u64 	%rd5, %rd4, 30;
	xor.b64  	%rd6, %rd5, %rd4;
	mul.lo.s64 	%rd7, %rd6, -4658895280553007687;
	shr.u64 	%rd8, %rd7, 27;
	xor.b64  	%rd9, %rd8, %rd7;
	mul.lo.s64 	%rd10, %rd9, -7723592293110705685;
	shr.u64 	%rd11, %rd10, 31;
	xor.b64  	%rd12, %rd11, %rd10;
	cvt.u32.u64 	%r1, %rd12;
	st.param.b32 	[func_retval0+0], %r1;
	ret;
                                        // -- End function
}
	// .globl	__hashword              // -- Begin function __hashword
.visible .func  (.param .b32 func_retval0) __hashword(
	.param .b64 __hashword_param_0
)                                       // @__hashword
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<43>;

// %bb.0:
	ld.param.u64 	%rd1, [__hashword_param_0];
	ld.u64 	%rd2, [%rd1];
	ld.u64 	%rd3, [%rd1+8];
	ld.u64 	%rd4, [%rd1+16];
	ld.u64 	%rd5, [%rd1+24];
	shr.u64 	%rd6, %rd2, 30;
	xor.b64  	%rd7, %rd6, %rd2;
	mul.lo.s64 	%rd8, %rd7, -4658895280553007687;
	shr.u64 	%rd9, %rd8, 27;
	xor.b64  	%rd10, %rd9, %rd8;
	mul.lo.s64 	%rd11, %rd10, -7723592293110705685;
	shr.u64 	%rd12, %rd11, 31;
	shr.u64 	%rd13, %rd3, 30;
	xor.b64  	%rd14, %rd13, %rd3;
	mul.lo.s64 	%rd15, %rd14, -4658895280553007687;
	shr.u64 	%rd16, %rd15, 27;
	xor.b64  	%rd17, %rd16, %rd15;
	mul.lo.s64 	%rd18, %rd17, -7723592293110705685;
	shr.u64 	%rd19, %rd18, 31;
	shr.u64 	%rd20, %rd4, 30;
	xor.b64  	%rd21, %rd20, %rd4;
	mul.lo.s64 	%rd22, %rd21, -4658895280553007687;
	shr.u64 	%rd23, %rd22, 27;
	xor.b64  	%rd24, %rd23, %rd22;
	mul.lo.s64 	%rd25, %rd24, -7723592293110705685;
	shr.u64 	%rd26, %rd25, 31;
	shr.u64 	%rd27, %rd5, 30;
	xor.b64  	%rd28, %rd27, %rd5;
	mul.lo.s64 	%rd29, %rd28, -4658895280553007687;
	shr.u64 	%rd30, %rd29, 27;
	xor.b64  	%rd31, %rd30, %rd29;
	mul.lo.s64 	%rd32, %rd31, -7723592293110705685;
	shr.u64 	%rd33, %rd32, 31;
	xor.b64  	%rd34, %rd12, %rd11;
	xor.b64  	%rd35, %rd34, %rd18;
	xor.b64  	%rd36, %rd35, %rd19;
	xor.b64  	%rd37, %rd36, %rd25;
	xor.b64  	%rd38, %rd37, %rd26;
	xor.b64  	%rd39, %rd38, %rd32;
	xor.b64  	%rd40, %rd39, %rd33;
	shr.u64 	%rd41, %rd40, 32;
	xor.b64  	%rd42, %rd41, %rd40;
	cvt.u32.u64 	%r1, %rd42;
	st.param.b32 	[func_retval0+0], %r1;
	ret;
                                        // -- End function
}
	// .globl	__classify_counts       // -- Begin function __classify_counts
.visible .func __classify_counts(
	.param .b64 __classify_counts_param_0
)                                       // @__classify_counts
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<26>;
	// demoted variable
	.shared .align 1 .b8 count_class_lookup8[256];
// %bb.0:
	mov.u64 	%rd25, 0;
	ld.param.u64 	%rd5, [__classify_counts_param_0];
	mov.u64 	%rd10, count_class_lookup8;
$L__BB20_1:                             // =>This Inner Loop Header: Depth=1
	add.s64 	%rd2, %rd5, %rd25;
	ld.global.u64 	%rd3, [%rd2];
	setp.eq.s64 	%p1, %rd3, 0;
	@%p1 bra 	$L__BB20_3;
	bra.uni 	$L__BB20_2;
$L__BB20_3:                             //   in Loop: Header=BB20_1 Depth=1
	add.s64 	%rd25, %rd25, 8;
	cvt.u32.u64 	%r1, %rd25;
	setp.ne.s32 	%p2, %r1, 4096;
	@%p2 bra 	$L__BB20_1;
	bra.uni 	$L__BB20_4;
$L__BB20_2:                             //   in Loop: Header=BB20_1 Depth=1
	shr.u64 	%rd7, %rd3, 56;
	shr.u64 	%rd8, %rd3, 32;
	and.b64  	%rd9, %rd3, 255;
	add.s64 	%rd11, %rd10, %rd9;
	ld.shared.u8 	%rs1, [%rd11];
	st.global.u8 	[%rd2], %rs1;
	bfe.u64 	%rd12, %rd3, 8, 8;
	add.s64 	%rd13, %rd10, %rd12;
	ld.shared.u8 	%rs2, [%rd13];
	st.global.u8 	[%rd2+1], %rs2;
	bfe.u64 	%rd14, %rd3, 16, 8;
	add.s64 	%rd15, %rd10, %rd14;
	ld.shared.u8 	%rs3, [%rd15];
	st.global.u8 	[%rd2+2], %rs3;
	bfe.u64 	%rd16, %rd3, 24, 8;
	add.s64 	%rd17, %rd10, %rd16;
	ld.shared.u8 	%rs4, [%rd17];
	st.global.u8 	[%rd2+3], %rs4;
	and.b64  	%rd18, %rd8, 255;
	add.s64 	%rd19, %rd10, %rd18;
	ld.shared.u8 	%rs5, [%rd19];
	st.global.u8 	[%rd2+4], %rs5;
	bfe.u64 	%rd20, %rd3, 40, 8;
	add.s64 	%rd21, %rd10, %rd20;
	ld.shared.u8 	%rs6, [%rd21];
	st.global.u8 	[%rd2+5], %rs6;
	bfe.u64 	%rd22, %rd3, 48, 8;
	add.s64 	%rd23, %rd10, %rd22;
	ld.shared.u8 	%rs7, [%rd23];
	st.global.u8 	[%rd2+6], %rs7;
	add.s64 	%rd24, %rd10, %rd7;
	ld.shared.u8 	%rs8, [%rd24];
	st.global.u8 	[%rd2+7], %rs8;
	bra.uni 	$L__BB20_3;
$L__BB20_4:
	ret;
                                        // -- End function
}
	// .globl	updateBits              // -- Begin function updateBits
.visible .entry updateBits(
	.param .b64 updateBits_param_0
)                                       // @updateBits
{
	.reg .pred 	%p<8>;
	.reg .b16 	%rs<5>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<44>;

// %bb.0:
	ld.param.u64 	%rd19, [updateBits_param_0];
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	cvt.u64.u32 	%rd1, %r4;
	mul.wide.u32 	%rd22, %r4, 8;
	mov.u64 	%rd23, __virgin_bits;
	add.s64 	%rd2, %rd23, %rd22;
	mov.u64 	%rd24, __bitmaps;
	add.s64 	%rd40, %rd24, 8;
	mov.u64 	%rd41, 0;
	shl.b64 	%rd26, %rd1, 3;
	mov.u16 	%rs4, 2;
$L__BB21_1:                             // =>This Inner Loop Header: Depth=1
	ld.global.u64 	%rd25, [%rd40+-8];
	add.s64 	%rd5, %rd25, %rd26;
	ld.global.u64 	%rd42, [%rd5];
	setp.eq.s64 	%p1, %rd42, 0;
	@%p1 bra 	$L__BB21_6;
	bra.uni 	$L__BB21_2;
$L__BB21_6:                             //   in Loop: Header=BB21_1 Depth=1
	mov.u64 	%rd31, 0;
	st.global.u64 	[%rd5], %rd31;
	bar.sync 	0;
	ld.global.u64 	%rd32, [%rd40];
	add.s64 	%rd11, %rd32, %rd26;
	ld.global.u64 	%rd43, [%rd11];
	setp.eq.s64 	%p4, %rd43, 0;
	@%p4 bra 	$L__BB21_11;
	bra.uni 	$L__BB21_7;
$L__BB21_11:                            //   in Loop: Header=BB21_1 Depth=1
	st.global.u64 	[%rd11], %rd31;
	bar.sync 	0;
	add.s64 	%rd41, %rd41, 2;
	cvt.u32.u64 	%r5, %rd41;
	add.s64 	%rd40, %rd40, 16;
	setp.eq.s32 	%p7, %r5, 1024;
	@%p7 bra 	$L__BB21_12;
	bra.uni 	$L__BB21_1;
$L__BB21_2:                             //   in Loop: Header=BB21_1 Depth=1
	ld.global.u64 	%rd7, [%rd2];
	and.b64  	%rd27, %rd7, %rd42;
	setp.eq.s64 	%p2, %rd27, 0;
	@%p2 bra 	$L__BB21_6;
// %bb.3:                               //   in Loop: Header=BB21_1 Depth=1
	mov.u64 	%rd28, __hnbs;
	add.s64 	%rd8, %rd28, %rd41;
	ld.global.u8 	%rs1, [%rd8];
	setp.eq.s16 	%p3, %rs1, 3;
	@%p3 bra 	$L__BB21_5;
// %bb.4:                               //   in Loop: Header=BB21_1 Depth=1
	st.global.u8 	[%rd8], %rs4;
	ld.global.u64 	%rd42, [%rd5];
$L__BB21_5:                             //   in Loop: Header=BB21_1 Depth=1
	not.b64 	%rd29, %rd42;
	and.b64  	%rd30, %rd7, %rd29;
	st.global.u64 	[%rd2], %rd30;
	bra.uni 	$L__BB21_6;
$L__BB21_7:                             //   in Loop: Header=BB21_1 Depth=1
	ld.global.u64 	%rd13, [%rd2];
	and.b64  	%rd34, %rd13, %rd43;
	setp.eq.s64 	%p5, %rd34, 0;
	@%p5 bra 	$L__BB21_11;
// %bb.8:                               //   in Loop: Header=BB21_1 Depth=1
	mov.u64 	%rd35, __hnbs;
	add.s64 	%rd14, %rd35, %rd41;
	ld.global.u8 	%rs3, [%rd14+1];
	setp.eq.s16 	%p6, %rs3, 3;
	@%p6 bra 	$L__BB21_10;
// %bb.9:                               //   in Loop: Header=BB21_1 Depth=1
	st.global.u8 	[%rd14+1], %rs4;
	ld.global.u64 	%rd43, [%rd11];
$L__BB21_10:                            //   in Loop: Header=BB21_1 Depth=1
	not.b64 	%rd36, %rd43;
	and.b64  	%rd37, %rd13, %rd36;
	st.global.u64 	[%rd2], %rd37;
	bra.uni 	$L__BB21_11;
$L__BB21_12:
	bar.sync 	0;
	ld.global.u64 	%rd39, [__signals];
	st.global.u64 	[%rd19], %rd39;
	ret;
                                        // -- End function
}
	// .globl	addBugSet               // -- Begin function addBugSet
.visible .func addBugSet(
	.param .b64 addBugSet_param_0
)                                       // @addBugSet
{
	.local .align 8 .b8 	__local_depot22[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<11>;

// %bb.0:
	mov.u64 	%SPL, __local_depot22;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd2, [addBugSet_param_0];
	setp.ne.s64 	%p1, %rd2, 1258295;
	@%p1 bra 	$L__BB22_2;
// %bb.1:
	add.u64 	%rd3, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r2, %tid.x;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r2;
	cvt.u64.u32 	%rd4, %r1;
	mov.u64 	%rd5, __hnbs;
	add.s64 	%rd6, %rd5, %rd4;
	mov.u16 	%rs1, 3;
	st.global.u8 	[%rd6], %rs1;
	or.b64  	%rd7, %rd4, -2401018191707897856;
	st.global.u64 	[__signals], %rd7;
	mov.u32 	%r5, 3;
	st.local.v2.u32 	[%rd1], {%r1, %r5};
	mov.u64 	%rd8, _$_str1;
	cvta.global.u64 	%rd9, %rd8;
	{ // callseq 79, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r6, [retval0+0];
	} // callseq 79
$L__BB22_2:
	ret;
                                        // -- End function
}
	// .globl	parallel_mutate         // -- Begin function parallel_mutate
.visible .entry parallel_mutate(
	.param .b64 parallel_mutate_param_0,
	.param .b32 parallel_mutate_param_1
)                                       // @parallel_mutate
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<28>;
	.reg .b64 	%rd<12>;

// %bb.0:
	ld.param.u64 	%rd5, [parallel_mutate_param_0];
	mov.u32 	%r5, %tid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %ntid.x;
	mad.lo.s32 	%r8, %r7, %r6, %r5;
	shl.b32 	%r9, %r8, 11;
	cvt.u64.u32 	%rd6, %r9;
	add.s64 	%rd1, %rd5, %rd6;
	ld.global.u32 	%r1, [%rd1+64];
	setp.lt.u32 	%p1, %r1, 5;
	mul.wide.u32 	%rd8, %r8, 4;
	mov.u64 	%rd9, cuda_states;
	add.s64 	%rd4, %rd9, %rd8;
	ld.global.u32 	%r27, [%rd4];
	@%p1 bra 	$L__BB23_2;
// %bb.1:
	mad.lo.s32 	%r10, %r27, 1103515245, 12345;
	mad.lo.s32 	%r11, %r10, 1103515245, 12345;
	shr.u32 	%r12, %r10, 6;
	and.b32  	%r13, %r12, 2096128;
	bfe.u32 	%r14, %r11, 16, 10;
	or.b32  	%r15, %r14, %r13;
	mad.lo.s32 	%r27, %r11, 1103515245, 12345;
	shl.b32 	%r16, %r15, 10;
	bfe.u32 	%r17, %r27, 16, 10;
	or.b32  	%r18, %r16, %r17;
	st.global.u32 	[%rd4], %r27;
	mul.hi.u32 	%r19, %r18, 1374389535;
	shr.u32 	%r20, %r19, 5;
	mul.lo.s32 	%r21, %r20, 100;
	sub.s32 	%r22, %r18, %r21;
	setp.lt.u32 	%p2, %r22, 91;
	@%p2 bra 	$L__BB23_5;
$L__BB23_2:
	mad.lo.s32 	%r25, %r27, -2139243339, -1492899873;
	st.global.u32 	[%rd4], %r25;
	and.b32  	%r26, %r25, 65536;
	setp.ne.s32 	%p3, %r26, 0;
	@%p3 bra 	$L__BB23_4;
// %bb.3:
	cvta.global.u64 	%rd2, %rd1;
	{ // callseq 82, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd2;
	call.uni 
	mutateCaller, 
	(
	param0
	);
	} // callseq 82
	bra.uni 	$L__BB23_6;
$L__BB23_4:
	add.s64 	%rd7, %rd1, 32;
	cvta.global.u64 	%rd3, %rd7;
	{ // callseq 81, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd3;
	call.uni 
	mutateCallvalue, 
	(
	param0
	);
	} // callseq 81
	bra.uni 	$L__BB23_6;
$L__BB23_5:
	add.s64 	%rd10, %rd1, 72;
	cvta.global.u64 	%rd11, %rd10;
	add.s32 	%r23, %r1, -4;
	shr.u32 	%r24, %r23, 5;
	{ // callseq 80, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd11;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r24;
	call.uni 
	mutateCalldata, 
	(
	param0, 
	param1
	);
	} // callseq 80
$L__BB23_6:
	bar.sync 	0;
	ret;
                                        // -- End function
}
	// .globl	mutateCaller            // -- Begin function mutateCaller
.visible .func mutateCaller(
	.param .b64 mutateCaller_param_0
)                                       // @mutateCaller
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<33>;
	.reg .b32 	%r<32>;
	.reg .b64 	%rd<12>;

// %bb.0:
	ld.param.u64 	%rd4, [mutateCaller_param_0];
	mov.u32 	%r2, %tid.x;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mad.lo.s32 	%r5, %r4, %r3, %r2;
	mul.wide.u32 	%rd6, %r5, 4;
	mov.u64 	%rd7, cuda_states;
	add.s64 	%rd1, %rd7, %rd6;
	ld.global.u32 	%r6, [%rd1];
	mad.lo.s32 	%r7, %r6, 1103515245, 12345;
	mad.lo.s32 	%r8, %r7, 1103515245, 12345;
	shr.u32 	%r9, %r7, 6;
	and.b32  	%r10, %r9, 2096128;
	bfe.u32 	%r11, %r8, 16, 10;
	or.b32  	%r12, %r11, %r10;
	mad.lo.s32 	%r1, %r8, 1103515245, 12345;
	shl.b32 	%r13, %r12, 10;
	bfe.u32 	%r14, %r1, 16, 10;
	or.b32  	%r15, %r13, %r14;
	st.global.u32 	[%rd1], %r1;
	mul.hi.u32 	%r16, %r15, 1374389535;
	shr.u32 	%r17, %r16, 5;
	mul.lo.s32 	%r18, %r17, 100;
	sub.s32 	%r19, %r15, %r18;
	setp.lt.u32 	%p1, %r19, 80;
	mov.u64 	%rd11, 0;
	@%p1 bra 	$L__BB24_2;
// %bb.1:
	ld.volatile.global.u32 	%r20, [callers_pool_len];
	mad.lo.s32 	%r21, %r1, 1103515245, 12345;
	mad.lo.s32 	%r22, %r21, 1103515245, 12345;
	shr.u32 	%r23, %r21, 6;
	and.b32  	%r24, %r23, 2096128;
	bfe.u32 	%r25, %r22, 16, 10;
	or.b32  	%r26, %r25, %r24;
	mad.lo.s32 	%r27, %r22, 1103515245, 12345;
	shl.b32 	%r28, %r26, 10;
	bfe.u32 	%r29, %r27, 16, 10;
	or.b32  	%r30, %r28, %r29;
	st.global.u32 	[%rd1], %r27;
	rem.u32 	%r31, %r30, %r20;
	cvt.u64.u32 	%rd11, %r31;
$L__BB24_2:
	shl.b64 	%rd8, %rd11, 5;
	mov.u64 	%rd9, callers_pool;
	add.s64 	%rd10, %rd9, %rd8;
	ld.global.u8 	%rs1, [%rd10+31];
	st.u8 	[%rd4+31], %rs1;
	ld.global.u8 	%rs2, [%rd10+30];
	st.u8 	[%rd4+30], %rs2;
	ld.global.u8 	%rs3, [%rd10+29];
	st.u8 	[%rd4+29], %rs3;
	ld.global.u8 	%rs4, [%rd10+28];
	st.u8 	[%rd4+28], %rs4;
	ld.global.u8 	%rs5, [%rd10+27];
	st.u8 	[%rd4+27], %rs5;
	ld.global.u8 	%rs6, [%rd10+26];
	st.u8 	[%rd4+26], %rs6;
	ld.global.u8 	%rs7, [%rd10+25];
	st.u8 	[%rd4+25], %rs7;
	ld.global.u8 	%rs8, [%rd10+24];
	st.u8 	[%rd4+24], %rs8;
	ld.global.u8 	%rs9, [%rd10+23];
	st.u8 	[%rd4+23], %rs9;
	ld.global.u8 	%rs10, [%rd10+22];
	st.u8 	[%rd4+22], %rs10;
	ld.global.u8 	%rs11, [%rd10+21];
	st.u8 	[%rd4+21], %rs11;
	ld.global.u8 	%rs12, [%rd10+20];
	st.u8 	[%rd4+20], %rs12;
	ld.global.u8 	%rs13, [%rd10+19];
	st.u8 	[%rd4+19], %rs13;
	ld.global.u8 	%rs14, [%rd10+18];
	st.u8 	[%rd4+18], %rs14;
	ld.global.u8 	%rs15, [%rd10+17];
	st.u8 	[%rd4+17], %rs15;
	ld.global.u8 	%rs16, [%rd10+16];
	st.u8 	[%rd4+16], %rs16;
	ld.global.u8 	%rs17, [%rd10+15];
	st.u8 	[%rd4+15], %rs17;
	ld.global.u8 	%rs18, [%rd10+14];
	st.u8 	[%rd4+14], %rs18;
	ld.global.u8 	%rs19, [%rd10+13];
	st.u8 	[%rd4+13], %rs19;
	ld.global.u8 	%rs20, [%rd10+12];
	st.u8 	[%rd4+12], %rs20;
	ld.global.u8 	%rs21, [%rd10+11];
	st.u8 	[%rd4+11], %rs21;
	ld.global.u8 	%rs22, [%rd10+10];
	st.u8 	[%rd4+10], %rs22;
	ld.global.u8 	%rs23, [%rd10+9];
	st.u8 	[%rd4+9], %rs23;
	ld.global.u8 	%rs24, [%rd10+8];
	st.u8 	[%rd4+8], %rs24;
	ld.global.u8 	%rs25, [%rd10+7];
	st.u8 	[%rd4+7], %rs25;
	ld.global.u8 	%rs26, [%rd10+6];
	st.u8 	[%rd4+6], %rs26;
	ld.global.u8 	%rs27, [%rd10+5];
	st.u8 	[%rd4+5], %rs27;
	ld.global.u8 	%rs28, [%rd10+4];
	st.u8 	[%rd4+4], %rs28;
	ld.global.u8 	%rs29, [%rd10+3];
	st.u8 	[%rd4+3], %rs29;
	ld.global.u8 	%rs30, [%rd10+2];
	st.u8 	[%rd4+2], %rs30;
	ld.global.u8 	%rs31, [%rd10+1];
	st.u8 	[%rd4+1], %rs31;
	ld.global.u8 	%rs32, [%rd10];
	st.u8 	[%rd4], %rs32;
	ret;
                                        // -- End function
}
	// .globl	mutateCallvalue         // -- Begin function mutateCallvalue
.visible .func mutateCallvalue(
	.param .b64 mutateCallvalue_param_0
)                                       // @mutateCallvalue
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<27>;
	.reg .b64 	%rd<6>;

// %bb.0:
	ld.param.u64 	%rd2, [mutateCallvalue_param_0];
	mov.u32 	%r5, %tid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %ntid.x;
	mad.lo.s32 	%r8, %r7, %r6, %r5;
	mul.wide.u32 	%rd3, %r8, 4;
	mov.u64 	%rd4, cuda_states;
	add.s64 	%rd5, %rd4, %rd3;
	ld.global.u32 	%r9, [%rd5];
	mad.lo.s32 	%r10, %r9, 1103515245, 12345;
	mad.lo.s32 	%r11, %r10, 1103515245, 12345;
	shr.u32 	%r12, %r10, 6;
	and.b32  	%r13, %r12, 2096128;
	bfe.u32 	%r14, %r11, 16, 10;
	or.b32  	%r15, %r14, %r13;
	mad.lo.s32 	%r16, %r11, 1103515245, 12345;
	shl.b32 	%r17, %r15, 10;
	bfe.u32 	%r18, %r16, 16, 10;
	or.b32  	%r19, %r17, %r18;
	st.global.u32 	[%rd5], %r16;
	mul.hi.u32 	%r20, %r19, -1840700269;
	shr.u32 	%r21, %r20, 2;
	mul.lo.s32 	%r22, %r21, 7;
	sub.s32 	%r23, %r19, %r22;
	add.s32 	%r1, %r23, 1;
	add.s64 	%rd1, %rd2, 16;
	mov.u32 	%r26, 1;
$L__BB25_1:                             // =>This Inner Loop Header: Depth=1
	mov.u32 	%r24, 16;
	{ // callseq 83, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r24;
	call.uni 
	cuhavoc, 
	(
	param0, 
	param1
	);
	} // callseq 83
	shr.u32 	%r25, %r26, %r1;
	setp.eq.s32 	%p1, %r25, 0;
	add.s32 	%r26, %r26, 1;
	@%p1 bra 	$L__BB25_1;
// %bb.2:
	ret;
                                        // -- End function
}
	// .globl	mutateCalldata          // -- Begin function mutateCalldata
.visible .func mutateCalldata(
	.param .b64 mutateCalldata_param_0,
	.param .b32 mutateCalldata_param_1
)                                       // @mutateCalldata
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<27>;
	.reg .b32 	%r<99>;
	.reg .b64 	%rd<21>;

// %bb.0:
	ld.param.u32 	%r15, [mutateCalldata_param_1];
	ld.param.u64 	%rd8, [mutateCalldata_param_0];
	mov.u32 	%r16, %tid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %ntid.x;
	mad.lo.s32 	%r19, %r18, %r17, %r16;
	mul.wide.u32 	%rd9, %r19, 4;
	mov.u64 	%rd10, cuda_states;
	add.s64 	%rd1, %rd10, %rd9;
	ld.global.u32 	%r20, [%rd1];
	mad.lo.s32 	%r21, %r20, 1103515245, 12345;
	mad.lo.s32 	%r22, %r21, 1103515245, 12345;
	shr.u32 	%r23, %r21, 6;
	and.b32  	%r24, %r23, 2096128;
	bfe.u32 	%r25, %r22, 16, 10;
	or.b32  	%r26, %r25, %r24;
	mad.lo.s32 	%r27, %r22, 1103515245, 12345;
	shl.b32 	%r28, %r26, 10;
	bfe.u32 	%r29, %r27, 16, 10;
	or.b32  	%r30, %r28, %r29;
	st.global.u32 	[%rd1], %r27;
	rem.u32 	%r98, %r30, %r15;
	mov.u64 	%rd12, argTypeMap;
	mov.u64 	%rd16, 0;
	mov.u64 	%rd18, addresses_pool;
	mov.u16 	%rs4, 0;
	mov.u32 	%r95, %r15;
	bra.uni 	$L__BB26_1;
$L__BB26_20:                            //   in Loop: Header=BB26_1 Depth=1
	add.s32 	%r31, %r98, 1;
	rem.u32 	%r98, %r31, %r15;
$L__BB26_21:                            //   in Loop: Header=BB26_1 Depth=1
	add.s32 	%r95, %r95, -1;
	@%p2 bra 	$L__BB26_1;
	bra.uni 	$L__BB26_22;
$L__BB26_1:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB26_4 Depth 2
	setp.eq.s32 	%p1, %r95, 0;
	@%p1 bra 	$L__BB26_22;
// %bb.2:                               //   in Loop: Header=BB26_1 Depth=1
	cvt.u64.u32 	%rd11, %r98;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.u8 	%rs1, [%rd13];
	cvt.u32.u16 	%r5, %rs1;
	add.s32 	%r6, %r5, -1;
	setp.gt.u32 	%p2, %r6, 65;
	@%p2 bra 	$L__BB26_20;
// %bb.3:                               //   in Loop: Header=BB26_1 Depth=1
	cvt.u64.u16 	%rd2, %rs1;
	ld.global.u32 	%r33, [%rd1];
	mad.lo.s32 	%r34, %r33, 1103515245, 12345;
	mad.lo.s32 	%r35, %r34, 1103515245, 12345;
	shr.u32 	%r36, %r34, 6;
	and.b32  	%r37, %r36, 2096128;
	bfe.u32 	%r38, %r35, 16, 10;
	or.b32  	%r39, %r38, %r37;
	mad.lo.s32 	%r40, %r35, 1103515245, 12345;
	shl.b32 	%r41, %r39, 10;
	bfe.u32 	%r42, %r40, 16, 10;
	or.b32  	%r43, %r41, %r42;
	st.global.u32 	[%rd1], %r40;
	mul.hi.u32 	%r44, %r43, -1840700269;
	shr.u32 	%r45, %r44, 2;
	mul.lo.s32 	%r46, %r45, 7;
	sub.s32 	%r47, %r43, %r46;
	add.s32 	%r7, %r47, 1;
	shl.b32 	%r48, %r98, 5;
	cvt.u64.u32 	%rd14, %r48;
	add.s64 	%rd3, %rd8, %rd14;
	sub.s64 	%rd15, %rd3, %rd2;
	add.s64 	%rd4, %rd15, 32;
	add.s64 	%rd5, %rd3, 12;
	add.s32 	%r8, %r5, -34;
	mov.u32 	%r97, 1;
	bra.uni 	$L__BB26_4;
$L__BB26_5:                             //   in Loop: Header=BB26_4 Depth=2
	add.s16 	%rs3, %rs1, -2;
	setp.lt.u16 	%p6, %rs3, 31;
	@%p6 bra 	$L__BB26_16;
	bra.uni 	$L__BB26_6;
$L__BB26_16:                            //   in Loop: Header=BB26_4 Depth=2
	{ // callseq 84, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r5;
	call.uni 
	cuhavoc, 
	(
	param0, 
	param1
	);
	} // callseq 84
$L__BB26_19:                            //   in Loop: Header=BB26_4 Depth=2
	shr.u32 	%r94, %r97, %r7;
	setp.eq.s32 	%p11, %r94, 0;
	add.s32 	%r97, %r97, 1;
	@%p11 bra 	$L__BB26_4;
	bra.uni 	$L__BB26_21;
$L__BB26_4:                             //   Parent Loop BB26_1 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	setp.gt.s16 	%p3, %rs1, 33;
	@%p3 bra 	$L__BB26_12;
	bra.uni 	$L__BB26_5;
$L__BB26_12:                            //   in Loop: Header=BB26_4 Depth=2
	add.s16 	%rs2, %rs1, -35;
	setp.lt.u16 	%p4, %rs2, 32;
	@%p4 bra 	$L__BB26_18;
	bra.uni 	$L__BB26_13;
$L__BB26_18:                            //   in Loop: Header=BB26_4 Depth=2
	{ // callseq 85, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd3;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r8;
	call.uni 
	cuhavoc, 
	(
	param0, 
	param1
	);
	} // callseq 85
	bra.uni 	$L__BB26_19;
$L__BB26_6:                             //   in Loop: Header=BB26_4 Depth=2
	setp.eq.s16 	%p7, %rs1, 1;
	@%p7 bra 	$L__BB26_15;
// %bb.7:                               //   in Loop: Header=BB26_4 Depth=2
	setp.eq.s16 	%p8, %rs1, 33;
	@%p8 bra 	$L__BB26_8;
	bra.uni 	$L__BB26_19;
$L__BB26_8:                             //   in Loop: Header=BB26_4 Depth=2
	ld.global.u32 	%r52, [%rd1];
	mad.lo.s32 	%r53, %r52, 1103515245, 12345;
	mad.lo.s32 	%r54, %r53, 1103515245, 12345;
	shr.u32 	%r55, %r53, 6;
	and.b32  	%r56, %r55, 2096128;
	bfe.u32 	%r57, %r54, 16, 10;
	or.b32  	%r58, %r57, %r56;
	mad.lo.s32 	%r10, %r54, 1103515245, 12345;
	shl.b32 	%r59, %r58, 10;
	bfe.u32 	%r60, %r10, 16, 10;
	or.b32  	%r61, %r59, %r60;
	st.global.u32 	[%rd1], %r10;
	mul.hi.u32 	%r62, %r61, 1374389535;
	shr.u32 	%r63, %r62, 5;
	mul.lo.s32 	%r64, %r63, 100;
	sub.s32 	%r65, %r61, %r64;
	setp.gt.u32 	%p9, %r65, 89;
	@%p9 bra 	$L__BB26_17;
// %bb.9:                               //   in Loop: Header=BB26_4 Depth=2
	mad.lo.s32 	%r66, %r10, 1103515245, 12345;
	mad.lo.s32 	%r67, %r66, 1103515245, 12345;
	shr.u32 	%r68, %r66, 6;
	and.b32  	%r69, %r68, 2096128;
	bfe.u32 	%r70, %r67, 16, 10;
	or.b32  	%r71, %r70, %r69;
	mad.lo.s32 	%r11, %r67, 1103515245, 12345;
	shl.b32 	%r72, %r71, 10;
	bfe.u32 	%r73, %r11, 16, 10;
	or.b32  	%r74, %r72, %r73;
	st.global.u32 	[%rd1], %r11;
	mul.hi.u32 	%r75, %r74, 1374389535;
	shr.u32 	%r76, %r75, 5;
	mul.lo.s32 	%r77, %r76, 100;
	sub.s32 	%r78, %r74, %r77;
	setp.lt.u32 	%p10, %r78, 80;
	mov.u64 	%rd20, %rd16;
	@%p10 bra 	$L__BB26_11;
// %bb.10:                              //   in Loop: Header=BB26_4 Depth=2
	ld.volatile.global.u32 	%r79, [addresses_pool_len];
	mad.lo.s32 	%r80, %r11, 1103515245, 12345;
	mad.lo.s32 	%r81, %r80, 1103515245, 12345;
	shr.u32 	%r82, %r80, 6;
	and.b32  	%r83, %r82, 2096128;
	bfe.u32 	%r84, %r81, 16, 10;
	or.b32  	%r85, %r84, %r83;
	mad.lo.s32 	%r86, %r81, 1103515245, 12345;
	shl.b32 	%r87, %r85, 10;
	bfe.u32 	%r88, %r86, 16, 10;
	or.b32  	%r89, %r87, %r88;
	st.global.u32 	[%rd1], %r86;
	rem.u32 	%r90, %r89, %r79;
	cvt.u64.u32 	%rd20, %r90;
$L__BB26_11:                            //   in Loop: Header=BB26_4 Depth=2
	shl.b64 	%rd17, %rd20, 5;
	add.s64 	%rd19, %rd18, %rd17;
	ld.global.u8 	%rs5, [%rd19+19];
	st.u8 	[%rd5+19], %rs5;
	ld.global.u8 	%rs6, [%rd19+18];
	st.u8 	[%rd5+18], %rs6;
	ld.global.u8 	%rs7, [%rd19+17];
	st.u8 	[%rd5+17], %rs7;
	ld.global.u8 	%rs8, [%rd19+16];
	st.u8 	[%rd5+16], %rs8;
	ld.global.u8 	%rs9, [%rd19+15];
	st.u8 	[%rd5+15], %rs9;
	ld.global.u8 	%rs10, [%rd19+14];
	st.u8 	[%rd5+14], %rs10;
	ld.global.u8 	%rs11, [%rd19+13];
	st.u8 	[%rd5+13], %rs11;
	ld.global.u8 	%rs12, [%rd19+12];
	st.u8 	[%rd5+12], %rs12;
	ld.global.u8 	%rs13, [%rd19+11];
	st.u8 	[%rd5+11], %rs13;
	ld.global.u8 	%rs14, [%rd19+10];
	st.u8 	[%rd5+10], %rs14;
	ld.global.u8 	%rs15, [%rd19+9];
	st.u8 	[%rd5+9], %rs15;
	ld.global.u8 	%rs16, [%rd19+8];
	st.u8 	[%rd5+8], %rs16;
	ld.global.u8 	%rs17, [%rd19+7];
	st.u8 	[%rd5+7], %rs17;
	ld.global.u8 	%rs18, [%rd19+6];
	st.u8 	[%rd5+6], %rs18;
	ld.global.u8 	%rs19, [%rd19+5];
	st.u8 	[%rd5+5], %rs19;
	ld.global.u8 	%rs20, [%rd19+4];
	st.u8 	[%rd5+4], %rs20;
	ld.global.u8 	%rs21, [%rd19+3];
	st.u8 	[%rd5+3], %rs21;
	ld.global.u8 	%rs22, [%rd19+2];
	st.u8 	[%rd5+2], %rs22;
	ld.global.u8 	%rs23, [%rd19+1];
	st.u8 	[%rd5+1], %rs23;
	ld.global.u8 	%rs24, [%rd19];
	st.u8 	[%rd5], %rs24;
	bra.uni 	$L__BB26_19;
$L__BB26_13:                            //   in Loop: Header=BB26_4 Depth=2
	setp.eq.s16 	%p5, %rs1, 34;
	@%p5 bra 	$L__BB26_14;
	bra.uni 	$L__BB26_19;
$L__BB26_14:                            //   in Loop: Header=BB26_4 Depth=2
	ld.global.u32 	%r91, [%rd1];
	mad.lo.s32 	%r92, %r91, -2139243339, -1492899873;
	shr.u32 	%r93, %r92, 16;
	st.global.u32 	[%rd1], %r92;
	cvt.u16.u32 	%rs25, %r93;
	and.b16  	%rs26, %rs25, 1;
	st.u8 	[%rd3+31], %rs26;
	bra.uni 	$L__BB26_19;
$L__BB26_15:                            //   in Loop: Header=BB26_4 Depth=2
	ld.global.u32 	%r49, [%rd1];
	mad.lo.s32 	%r50, %r49, -2139243339, -1492899873;
	shr.u32 	%r51, %r50, 16;
	st.global.u32 	[%rd1], %r50;
	st.u8 	[%rd3+31], %r51;
	bra.uni 	$L__BB26_19;
$L__BB26_17:                            //   in Loop: Header=BB26_4 Depth=2
	st.u8 	[%rd3+31], %rs4;
	st.u8 	[%rd3+30], %rs4;
	st.u8 	[%rd3+29], %rs4;
	st.u8 	[%rd3+28], %rs4;
	st.u8 	[%rd3+27], %rs4;
	st.u8 	[%rd3+26], %rs4;
	st.u8 	[%rd3+25], %rs4;
	st.u8 	[%rd3+24], %rs4;
	st.u8 	[%rd3+23], %rs4;
	st.u8 	[%rd3+22], %rs4;
	st.u8 	[%rd3+21], %rs4;
	st.u8 	[%rd3+20], %rs4;
	st.u8 	[%rd3+19], %rs4;
	st.u8 	[%rd3+18], %rs4;
	st.u8 	[%rd3+17], %rs4;
	st.u8 	[%rd3+16], %rs4;
	st.u8 	[%rd3+15], %rs4;
	st.u8 	[%rd3+14], %rs4;
	st.u8 	[%rd3+13], %rs4;
	st.u8 	[%rd3+12], %rs4;
	st.u8 	[%rd3+11], %rs4;
	st.u8 	[%rd3+10], %rs4;
	st.u8 	[%rd3+9], %rs4;
	st.u8 	[%rd3+8], %rs4;
	st.u8 	[%rd3+7], %rs4;
	st.u8 	[%rd3+6], %rs4;
	st.u8 	[%rd3+5], %rs4;
	st.u8 	[%rd3+4], %rs4;
	st.u8 	[%rd3+3], %rs4;
	st.u8 	[%rd3+2], %rs4;
	st.u8 	[%rd3+1], %rs4;
	st.u8 	[%rd3], %rs4;
	bra.uni 	$L__BB26_19;
$L__BB26_22:
	ret;
                                        // -- End function
}
	// .globl	cuhavoc                 // -- Begin function cuhavoc
.visible .func cuhavoc(
	.param .b64 cuhavoc_param_0,
	.param .b32 cuhavoc_param_1
)                                       // @cuhavoc
{
	.local .align 1 .b8 	__local_depot27[2048];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<64>;
	.reg .b16 	%rs<43>;
	.reg .b32 	%r<476>;
	.reg .b64 	%rd<206>;

// %bb.0:
	mov.u64 	%SPL, __local_depot27;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r10, [cuhavoc_param_1];
	ld.param.u64 	%rd41, [cuhavoc_param_0];
	mov.u32 	%r12, %tid.x;
	mov.u32 	%r13, %ctaid.x;
	mov.u32 	%r14, %ntid.x;
	mad.lo.s32 	%r1, %r14, %r13, %r12;
	mul.wide.u32 	%rd42, %r1, 4;
	mov.u64 	%rd43, cuda_states;
	add.s64 	%rd1, %rd43, %rd42;
	ld.global.u32 	%r15, [%rd1];
	mad.lo.s32 	%r16, %r15, 1103515245, 12345;
	mad.lo.s32 	%r17, %r16, 1103515245, 12345;
	shr.u32 	%r18, %r16, 6;
	and.b32  	%r19, %r18, 2096128;
	bfe.u32 	%r20, %r17, 16, 10;
	or.b32  	%r21, %r20, %r19;
	mad.lo.s32 	%r2, %r17, 1103515245, 12345;
	shl.b32 	%r22, %r21, 10;
	bfe.u32 	%r23, %r2, 16, 10;
	or.b32  	%r24, %r22, %r23;
	st.global.u32 	[%rd1], %r2;
	mul.hi.u32 	%r25, %r24, 954437177;
	shr.u32 	%r26, %r25, 2;
	mul.lo.s32 	%r27, %r26, 18;
	sub.s32 	%r11, %r24, %r27;
	setp.gt.s32 	%p1, %r11, 8;
	@%p1 bra 	$L__BB27_18;
// %bb.1:
	setp.gt.s32 	%p14, %r11, 3;
	@%p14 bra 	$L__BB27_9;
	bra.uni 	$L__BB27_2;
$L__BB27_9:
	setp.gt.s32 	%p15, %r11, 5;
	@%p15 bra 	$L__BB27_13;
	bra.uni 	$L__BB27_10;
$L__BB27_13:
	setp.eq.s32 	%p16, %r11, 6;
	@%p16 bra 	$L__BB27_44;
// %bb.14:
	setp.eq.s32 	%p17, %r11, 7;
	@%p17 bra 	$L__BB27_47;
// %bb.15:
	setp.eq.s32 	%p18, %r11, 8;
	@%p18 bra 	$L__BB27_16;
	bra.uni 	$L__BB27_76;
$L__BB27_16:
	setp.lt.u32 	%p59, %r10, 4;
	@%p59 bra 	$L__BB27_76;
// %bb.17:
	add.s32 	%r302, %r10, -3;
	mad.lo.s32 	%r303, %r2, 1103515245, 12345;
	mad.lo.s32 	%r304, %r303, 1103515245, 12345;
	shr.u32 	%r305, %r303, 6;
	and.b32  	%r306, %r305, 2096128;
	bfe.u32 	%r307, %r304, 16, 10;
	or.b32  	%r308, %r307, %r306;
	mad.lo.s32 	%r309, %r304, 1103515245, 12345;
	shl.b32 	%r310, %r308, 10;
	bfe.u32 	%r311, %r309, 16, 10;
	or.b32  	%r312, %r310, %r311;
	rem.u32 	%r313, %r312, %r302;
	mad.lo.s32 	%r314, %r309, 1103515245, 12345;
	mad.lo.s32 	%r315, %r314, 1103515245, 12345;
	shr.u32 	%r316, %r314, 6;
	and.b32  	%r317, %r316, 2096128;
	bfe.u32 	%r318, %r315, 16, 10;
	or.b32  	%r319, %r318, %r317;
	mad.lo.s32 	%r320, %r315, 1103515245, 12345;
	shl.b32 	%r321, %r319, 10;
	bfe.u32 	%r322, %r320, 16, 10;
	or.b32  	%r323, %r321, %r322;
	st.global.u32 	[%rd1], %r320;
	mul.hi.u32 	%r324, %r323, -368140053;
	shr.u32 	%r325, %r324, 5;
	mul.lo.s32 	%r326, %r325, 35;
	sub.s32 	%r327, %r323, %r326;
	add.s32 	%r328, %r327, 1;
	cvt.u64.u32 	%rd178, %r313;
	add.s64 	%rd179, %rd41, %rd178;
	ld.u8 	%r329, [%rd179+3];
	ld.u8 	%r330, [%rd179+2];
	shl.b32 	%r331, %r330, 16;
	ld.u8 	%r332, [%rd179];
	ld.u8 	%r333, [%rd179+1];
	mad.lo.s32 	%r334, %r320, -2139243339, -1492899873;
	st.global.u32 	[%rd1], %r334;
	and.b32  	%r335, %r334, 65536;
	setp.eq.s32 	%p60, %r335, 0;
	shl.b32 	%r336, %r333, 16;
	shl.b32 	%r337, %r332, 24;
	or.b32  	%r338, %r337, %r336;
	shr.u32 	%r339, %r331, 8;
	or.b32  	%r340, %r339, %r329;
	or.b32  	%r341, %r338, %r340;
	not.b32 	%r342, %r327;
	selp.b32 	%r343, %r342, %r328, %p60;
	add.s32 	%r344, %r341, %r343;
	shr.u32 	%r345, %r344, 24;
	st.u8 	[%rd179+3], %r344;
	shr.u32 	%r346, %r344, 8;
	st.u8 	[%rd179+2], %r346;
	shr.u32 	%r347, %r344, 16;
	st.u8 	[%rd179+1], %r347;
	st.u8 	[%rd179], %r345;
	bra.uni 	$L__BB27_76;
$L__BB27_18:
	setp.gt.s32 	%p2, %r11, 12;
	@%p2 bra 	$L__BB27_28;
	bra.uni 	$L__BB27_19;
$L__BB27_28:
	setp.gt.s32 	%p3, %r11, 14;
	@%p3 bra 	$L__BB27_34;
	bra.uni 	$L__BB27_29;
$L__BB27_34:
	setp.eq.s32 	%p4, %r11, 15;
	@%p4 bra 	$L__BB27_59;
// %bb.35:
	setp.eq.s32 	%p5, %r11, 16;
	@%p5 bra 	$L__BB27_66;
// %bb.36:
	setp.eq.s32 	%p6, %r11, 17;
	@%p6 bra 	$L__BB27_37;
	bra.uni 	$L__BB27_76;
$L__BB27_37:
	mul.wide.s32 	%rd44, %r1, 4;
	mov.u64 	%rd45, __snap_map;
	add.s64 	%rd46, %rd45, %rd44;
	ld.global.u32 	%rd31, [%rd46];
	mov.u64 	%rd47, l2snap_lens;
	add.s64 	%rd48, %rd47, %rd31;
	ld.global.u8 	%r9, [%rd48];
	setp.eq.s32 	%p26, %r9, 0;
	@%p26 bra 	$L__BB27_76;
// %bb.38:
	mad.lo.s32 	%r28, %r2, 1103515245, 12345;
	mad.lo.s32 	%r29, %r28, 1103515245, 12345;
	shr.u32 	%r30, %r28, 6;
	and.b32  	%r31, %r30, 2096128;
	bfe.u32 	%r32, %r29, 16, 10;
	or.b32  	%r33, %r32, %r31;
	mad.lo.s32 	%r34, %r29, 1103515245, 12345;
	shl.b32 	%r35, %r33, 10;
	bfe.u32 	%r36, %r34, 16, 10;
	or.b32  	%r37, %r35, %r36;
	rem.u32 	%r38, %r37, %r9;
	mad.lo.s32 	%r39, %r34, 1103515245, 12345;
	mad.lo.s32 	%r40, %r39, 1103515245, 12345;
	shr.u32 	%r41, %r39, 6;
	and.b32  	%r42, %r41, 2096128;
	bfe.u32 	%r43, %r40, 16, 10;
	or.b32  	%r44, %r43, %r42;
	mad.lo.s32 	%r45, %r40, 1103515245, 12345;
	shl.b32 	%r46, %r44, 10;
	bfe.u32 	%r47, %r45, 16, 10;
	or.b32  	%r48, %r46, %r47;
	st.global.u32 	[%rd1], %r45;
	mul.hi.u32 	%r49, %r48, 1374389535;
	shr.u32 	%r50, %r49, 5;
	mul.lo.s32 	%r51, %r50, 100;
	sub.s32 	%r52, %r48, %r51;
	setp.gt.u32 	%p27, %r52, 89;
	cvt.u64.u32 	%rd32, %r38;
	@%p27 bra 	$L__BB27_74;
// %bb.39:
	shl.b64 	%rd59, %rd31, 13;
	mov.u64 	%rd60, l2snaps;
	add.s64 	%rd61, %rd60, %rd59;
	shl.b64 	%rd62, %rd32, 6;
	add.s64 	%rd63, %rd61, %rd62;
	cvt.u64.u32 	%rd33, %r10;
	sub.s64 	%rd64, %rd63, %rd33;
	add.s64 	%rd34, %rd64, 64;
	setp.eq.s32 	%p30, %r10, 0;
	mov.u64 	%rd204, 0;
	@%p30 bra 	$L__BB27_76;
$L__BB27_40:                            // %loop-memcpy-expansion18
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd65, %rd34, %rd204;
	ld.global.u8 	%rs7, [%rd65];
	add.s64 	%rd66, %rd41, %rd204;
	st.u8 	[%rd66], %rs7;
	add.s64 	%rd204, %rd204, 1;
	setp.lt.u64 	%p31, %rd204, %rd33;
	@%p31 bra 	$L__BB27_40;
	bra.uni 	$L__BB27_76;
$L__BB27_2:
	setp.gt.s32 	%p21, %r11, 1;
	@%p21 bra 	$L__BB27_6;
// %bb.3:
	setp.eq.s32 	%p24, %r11, 0;
	@%p24 bra 	$L__BB27_41;
// %bb.4:
	setp.eq.s32 	%p25, %r11, 1;
	@%p25 bra 	$L__BB27_5;
	bra.uni 	$L__BB27_76;
$L__BB27_5:
	mad.lo.s32 	%r449, %r2, 1103515245, 12345;
	mad.lo.s32 	%r450, %r449, 1103515245, 12345;
	shr.u32 	%r451, %r449, 6;
	and.b32  	%r452, %r451, 2096128;
	bfe.u32 	%r453, %r450, 16, 10;
	or.b32  	%r454, %r453, %r452;
	mad.lo.s32 	%r455, %r450, 1103515245, 12345;
	shl.b32 	%r456, %r454, 10;
	bfe.u32 	%r457, %r455, 16, 10;
	or.b32  	%r458, %r456, %r457;
	st.global.u32 	[%rd1], %r455;
	rem.u32 	%r459, %r458, %r10;
	cvt.u64.u32 	%rd191, %r459;
	add.s64 	%rd192, %rd41, %rd191;
	ld.u8 	%rs38, [%rd192];
	not.b16 	%rs39, %rs38;
	st.u8 	[%rd192], %rs39;
	bra.uni 	$L__BB27_76;
$L__BB27_19:
	setp.gt.s32 	%p9, %r11, 10;
	@%p9 bra 	$L__BB27_23;
// %bb.20:
	setp.eq.s32 	%p12, %r11, 9;
	@%p12 bra 	$L__BB27_49;
// %bb.21:
	setp.eq.s32 	%p13, %r11, 10;
	@%p13 bra 	$L__BB27_22;
	bra.uni 	$L__BB27_76;
$L__BB27_22:
	mad.lo.s32 	%r248, %r2, 1103515245, 12345;
	mad.lo.s32 	%r249, %r248, 1103515245, 12345;
	shr.u32 	%r250, %r248, 6;
	and.b32  	%r251, %r250, 2096128;
	bfe.u32 	%r252, %r249, 16, 10;
	or.b32  	%r253, %r252, %r251;
	mad.lo.s32 	%r254, %r249, 1103515245, 12345;
	shl.b32 	%r255, %r253, 10;
	bfe.u32 	%r256, %r254, 16, 10;
	or.b32  	%r257, %r255, %r256;
	mul.hi.u32 	%r258, %r257, 954437177;
	shr.u32 	%r259, %r258, 1;
	mul.lo.s32 	%r260, %r259, 9;
	sub.s32 	%r261, %r257, %r260;
	cvt.u64.u32 	%rd118, %r261;
	mov.u64 	%rd119, interesting_8;
	add.s64 	%rd120, %rd119, %rd118;
	ld.const.u8 	%rs17, [%rd120];
	mad.lo.s32 	%r262, %r254, 1103515245, 12345;
	mad.lo.s32 	%r263, %r262, 1103515245, 12345;
	shr.u32 	%r264, %r262, 6;
	and.b32  	%r265, %r264, 2096128;
	bfe.u32 	%r266, %r263, 16, 10;
	or.b32  	%r267, %r266, %r265;
	mad.lo.s32 	%r268, %r263, 1103515245, 12345;
	shl.b32 	%r269, %r267, 10;
	bfe.u32 	%r270, %r268, 16, 10;
	or.b32  	%r271, %r269, %r270;
	st.global.u32 	[%rd1], %r268;
	rem.u32 	%r272, %r271, %r10;
	cvt.u64.u32 	%rd121, %r272;
	add.s64 	%rd122, %rd41, %rd121;
	st.u8 	[%rd122], %rs17;
	bra.uni 	$L__BB27_76;
$L__BB27_10:
	setp.eq.s32 	%p19, %r11, 4;
	@%p19 bra 	$L__BB27_43;
// %bb.11:
	setp.eq.s32 	%p20, %r11, 5;
	@%p20 bra 	$L__BB27_12;
	bra.uni 	$L__BB27_76;
$L__BB27_12:
	mad.lo.s32 	%r403, %r2, -2139243339, -1492899873;
	shr.u32 	%r404, %r403, 16;
	mad.lo.s32 	%r405, %r403, 1103515245, 12345;
	mad.lo.s32 	%r406, %r405, 1103515245, 12345;
	shr.u32 	%r407, %r405, 6;
	and.b32  	%r408, %r407, 2096128;
	bfe.u32 	%r409, %r406, 16, 10;
	or.b32  	%r410, %r409, %r408;
	mad.lo.s32 	%r411, %r406, 1103515245, 12345;
	shl.b32 	%r412, %r410, 10;
	bfe.u32 	%r413, %r411, 16, 10;
	or.b32  	%r414, %r412, %r413;
	st.global.u32 	[%rd1], %r411;
	rem.u32 	%r415, %r414, %r10;
	cvt.u64.u32 	%rd183, %r415;
	add.s64 	%rd184, %rd41, %rd183;
	st.u8 	[%rd184], %r404;
	bra.uni 	$L__BB27_76;
$L__BB27_29:
	setp.eq.s32 	%p7, %r11, 13;
	@%p7 bra 	$L__BB27_56;
// %bb.30:
	setp.eq.s32 	%p8, %r11, 14;
	@%p8 bra 	$L__BB27_31;
	bra.uni 	$L__BB27_76;
$L__BB27_31:
	setp.eq.s32 	%p47, %r10, 0;
	@%p47 bra 	$L__BB27_76;
// %bb.32:
	mad.lo.s32 	%r101, %r2, 1103515245, 12345;
	mad.lo.s32 	%r102, %r101, 1103515245, 12345;
	shr.u32 	%r103, %r101, 6;
	and.b32  	%r104, %r103, 2096128;
	bfe.u32 	%r105, %r102, 16, 10;
	or.b32  	%r106, %r105, %r104;
	mad.lo.s32 	%r107, %r102, 1103515245, 12345;
	shl.b32 	%r108, %r106, 10;
	bfe.u32 	%r109, %r107, 16, 10;
	or.b32  	%r110, %r108, %r109;
	rem.u32 	%r111, %r110, %r10;
	sub.s32 	%r112, %r10, %r111;
	min.u32 	%r113, %r112, 16;
	mad.lo.s32 	%r114, %r107, 1103515245, 12345;
	mad.lo.s32 	%r115, %r114, 1103515245, 12345;
	shr.u32 	%r116, %r114, 6;
	and.b32  	%r117, %r116, 2096128;
	bfe.u32 	%r118, %r115, 16, 10;
	or.b32  	%r119, %r118, %r117;
	mad.lo.s32 	%r120, %r115, 1103515245, 12345;
	shl.b32 	%r121, %r119, 10;
	bfe.u32 	%r122, %r120, 16, 10;
	or.b32  	%r123, %r121, %r122;
	rem.u32 	%r124, %r123, %r113;
	add.s32 	%r125, %r124, 1;
	cvt.u64.u32 	%rd7, %r125;
	mad.lo.s32 	%r126, %r120, -2139243339, -1492899873;
	shr.u32 	%r127, %r126, 16;
	st.global.u32 	[%rd1], %r126;
	cvt.u16.u32 	%rs5, %r127;
	cvt.u64.u32 	%rd97, %r111;
	add.s64 	%rd8, %rd41, %rd97;
	setp.eq.s32 	%p48, %r125, 0;
	mov.u64 	%rd197, 0;
	@%p48 bra 	$L__BB27_76;
$L__BB27_33:                            // %loadstoreloop2
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd98, %rd8, %rd197;
	st.u8 	[%rd98], %rs5;
	add.s64 	%rd197, %rd197, 1;
	setp.lt.u64 	%p49, %rd197, %rd7;
	@%p49 bra 	$L__BB27_33;
	bra.uni 	$L__BB27_76;
$L__BB27_6:
	setp.eq.s32 	%p22, %r11, 2;
	@%p22 bra 	$L__BB27_42;
// %bb.7:
	setp.eq.s32 	%p23, %r11, 3;
	@%p23 bra 	$L__BB27_8;
	bra.uni 	$L__BB27_76;
$L__BB27_8:
	mad.lo.s32 	%r427, %r2, 1103515245, 12345;
	mad.lo.s32 	%r428, %r427, 1103515245, 12345;
	shr.u32 	%r429, %r427, 6;
	and.b32  	%r430, %r429, 2096128;
	bfe.u32 	%r431, %r428, 16, 10;
	or.b32  	%r432, %r431, %r430;
	mad.lo.s32 	%r433, %r428, 1103515245, 12345;
	shl.b32 	%r434, %r432, 10;
	bfe.u32 	%r435, %r433, 16, 10;
	or.b32  	%r436, %r434, %r435;
	st.global.u32 	[%rd1], %r433;
	rem.u32 	%r437, %r436, %r10;
	cvt.u64.u32 	%rd187, %r437;
	add.s64 	%rd188, %rd41, %rd187;
	ld.u8 	%rs34, [%rd188];
	add.s16 	%rs35, %rs34, -1;
	st.u8 	[%rd188], %rs35;
	bra.uni 	$L__BB27_76;
$L__BB27_23:
	setp.eq.s32 	%p10, %r11, 11;
	@%p10 bra 	$L__BB27_51;
// %bb.24:
	setp.eq.s32 	%p11, %r11, 12;
	@%p11 bra 	$L__BB27_25;
	bra.uni 	$L__BB27_76;
$L__BB27_25:
	setp.lt.u32 	%p53, %r10, 4;
	@%p53 bra 	$L__BB27_76;
// %bb.26:
	mad.lo.s32 	%r164, %r2, 1103515245, 12345;
	mad.lo.s32 	%r165, %r164, 1103515245, 12345;
	shr.u32 	%r166, %r164, 6;
	and.b32  	%r167, %r166, 2096128;
	bfe.u32 	%r168, %r165, 16, 10;
	or.b32  	%r169, %r168, %r167;
	mad.lo.s32 	%r170, %r165, 1103515245, 12345;
	shl.b32 	%r171, %r169, 10;
	bfe.u32 	%r172, %r170, 16, 10;
	or.b32  	%r173, %r171, %r172;
	mul.hi.u32 	%r174, %r173, 1272582903;
	shr.u32 	%r175, %r174, 3;
	mul.lo.s32 	%r176, %r175, 27;
	sub.s32 	%r177, %r173, %r176;
	mul.wide.u32 	%rd104, %r177, 4;
	mov.u64 	%rd105, interesting_32;
	add.s64 	%rd106, %rd105, %rd104;
	ld.const.u32 	%r4, [%rd106];
	mad.lo.s32 	%r5, %r170, -2139243339, -1492899873;
	and.b32  	%r178, %r5, 65536;
	setp.eq.s32 	%p54, %r178, 0;
	@%p54 bra 	$L__BB27_55;
	bra.uni 	$L__BB27_27;
$L__BB27_55:
	shr.u32 	%r194, %r4, 24;
	add.s32 	%r195, %r10, -3;
	mad.lo.s32 	%r196, %r5, 1103515245, 12345;
	mad.lo.s32 	%r197, %r196, 1103515245, 12345;
	shr.u32 	%r198, %r196, 6;
	and.b32  	%r199, %r198, 2096128;
	bfe.u32 	%r200, %r197, 16, 10;
	or.b32  	%r201, %r200, %r199;
	mad.lo.s32 	%r202, %r197, 1103515245, 12345;
	shl.b32 	%r203, %r201, 10;
	bfe.u32 	%r204, %r202, 16, 10;
	or.b32  	%r205, %r203, %r204;
	st.global.u32 	[%rd1], %r202;
	rem.u32 	%r206, %r205, %r195;
	cvt.u64.u32 	%rd109, %r206;
	add.s64 	%rd110, %rd41, %rd109;
	st.u8 	[%rd110+3], %r4;
	shr.u32 	%r207, %r4, 8;
	st.u8 	[%rd110+2], %r207;
	shr.u32 	%r208, %r4, 16;
	st.u8 	[%rd110+1], %r208;
	st.u8 	[%rd110], %r194;
	bra.uni 	$L__BB27_76;
$L__BB27_41:
	shl.b32 	%r460, %r10, 3;
	mad.lo.s32 	%r461, %r2, 1103515245, 12345;
	mad.lo.s32 	%r462, %r461, 1103515245, 12345;
	shr.u32 	%r463, %r461, 6;
	and.b32  	%r464, %r463, 2096128;
	bfe.u32 	%r465, %r462, 16, 10;
	or.b32  	%r466, %r465, %r464;
	mad.lo.s32 	%r467, %r462, 1103515245, 12345;
	shl.b32 	%r468, %r466, 10;
	bfe.u32 	%r469, %r467, 16, 10;
	or.b32  	%r470, %r468, %r469;
	st.global.u32 	[%rd1], %r467;
	rem.u32 	%r471, %r470, %r460;
	and.b32  	%r472, %r471, 7;
	mov.u32 	%r473, 128;
	shr.u32 	%r474, %r473, %r472;
	shr.u32 	%r475, %r471, 3;
	cvt.u64.u32 	%rd193, %r475;
	add.s64 	%rd194, %rd41, %rd193;
	ld.u8 	%rs40, [%rd194];
	cvt.u16.u32 	%rs41, %r474;
	xor.b16  	%rs42, %rs40, %rs41;
	st.u8 	[%rd194], %rs42;
	bra.uni 	$L__BB27_76;
$L__BB27_49:
	setp.lt.u32 	%p57, %r10, 8;
	@%p57 bra 	$L__BB27_76;
// %bb.50:
	add.s32 	%r273, %r10, -7;
	mad.lo.s32 	%r274, %r2, 1103515245, 12345;
	mad.lo.s32 	%r275, %r274, 1103515245, 12345;
	shr.u32 	%r276, %r274, 6;
	and.b32  	%r277, %r276, 2096128;
	bfe.u32 	%r278, %r275, 16, 10;
	or.b32  	%r279, %r278, %r277;
	mad.lo.s32 	%r280, %r275, 1103515245, 12345;
	shl.b32 	%r281, %r279, 10;
	bfe.u32 	%r282, %r280, 16, 10;
	or.b32  	%r283, %r281, %r282;
	rem.u32 	%r284, %r283, %r273;
	mad.lo.s32 	%r285, %r280, 1103515245, 12345;
	mad.lo.s32 	%r286, %r285, 1103515245, 12345;
	shr.u32 	%r287, %r285, 6;
	and.b32  	%r288, %r287, 2096128;
	bfe.u32 	%r289, %r286, 16, 10;
	or.b32  	%r290, %r289, %r288;
	mad.lo.s32 	%r291, %r286, 1103515245, 12345;
	shl.b32 	%r292, %r290, 10;
	bfe.u32 	%r293, %r291, 16, 10;
	or.b32  	%r294, %r292, %r293;
	st.global.u32 	[%rd1], %r291;
	mul.hi.u32 	%r295, %r294, -368140053;
	shr.u32 	%r296, %r295, 5;
	mul.lo.s32 	%r297, %r296, 35;
	sub.s32 	%r298, %r294, %r297;
	add.s32 	%r299, %r298, 1;
	cvt.u64.u32 	%rd123, %r299;
	cvt.u64.u32 	%rd124, %r284;
	add.s64 	%rd125, %rd41, %rd124;
	ld.u8 	%rd126, [%rd125];
	ld.u8 	%rd127, [%rd125+1];
	shl.b64 	%rd128, %rd127, 8;
	or.b64  	%rd129, %rd128, %rd126;
	ld.u8 	%rd130, [%rd125+2];
	shl.b64 	%rd131, %rd130, 16;
	ld.u8 	%rd132, [%rd125+3];
	shl.b64 	%rd133, %rd132, 24;
	or.b64  	%rd134, %rd133, %rd131;
	or.b64  	%rd135, %rd134, %rd129;
	ld.u8 	%rd136, [%rd125+4];
	ld.u8 	%rd137, [%rd125+5];
	shl.b64 	%rd138, %rd137, 8;
	or.b64  	%rd139, %rd138, %rd136;
	ld.u8 	%rd140, [%rd125+6];
	shl.b64 	%rd141, %rd140, 16;
	ld.u8 	%rd142, [%rd125+7];
	shl.b64 	%rd143, %rd142, 24;
	or.b64  	%rd144, %rd143, %rd141;
	or.b64  	%rd145, %rd144, %rd139;
	shl.b64 	%rd146, %rd145, 32;
	or.b64  	%rd147, %rd146, %rd135;
	mad.lo.s32 	%r300, %r291, -2139243339, -1492899873;
	st.global.u32 	[%rd1], %r300;
	and.b32  	%r301, %r300, 65536;
	setp.eq.s32 	%p58, %r301, 0;
	shr.u64 	%rd148, %rd147, 24;
	and.b64  	%rd149, %rd148, 16711680;
	shr.u64 	%rd150, %rd147, 8;
	and.b64  	%rd151, %rd150, 4278190080;
	or.b64  	%rd152, %rd151, %rd149;
	bfe.u64 	%rd153, %rd145, 24, 8;
	shr.u64 	%rd154, %rd141, 8;
	or.b64  	%rd155, %rd154, %rd153;
	or.b64  	%rd156, %rd152, %rd155;
	and.b64  	%rd157, %rd147, 4278190080;
	shl.b64 	%rd158, %rd157, 8;
	and.b64  	%rd159, %rd147, 16711680;
	shl.b64 	%rd160, %rd159, 24;
	or.b64  	%rd161, %rd160, %rd158;
	and.b64  	%rd162, %rd135, 65280;
	shl.b64 	%rd163, %rd162, 40;
	shl.b64 	%rd164, %rd126, 56;
	or.b64  	%rd165, %rd164, %rd163;
	or.b64  	%rd166, %rd165, %rd161;
	or.b64  	%rd167, %rd166, %rd156;
	neg.s64 	%rd168, %rd123;
	selp.b64 	%rd169, %rd168, %rd123, %p58;
	add.s64 	%rd170, %rd167, %rd169;
	shr.u64 	%rd171, %rd170, 56;
	st.u8 	[%rd125+7], %rd170;
	shr.u64 	%rd172, %rd170, 8;
	st.u8 	[%rd125+6], %rd172;
	shr.u64 	%rd173, %rd170, 16;
	st.u8 	[%rd125+5], %rd173;
	shr.u64 	%rd174, %rd170, 24;
	st.u8 	[%rd125+4], %rd174;
	shr.u64 	%rd175, %rd170, 32;
	st.u8 	[%rd125+3], %rd175;
	shr.u64 	%rd176, %rd170, 40;
	st.u8 	[%rd125+2], %rd176;
	shr.u64 	%rd177, %rd170, 48;
	st.u8 	[%rd125+1], %rd177;
	st.u8 	[%rd125], %rd171;
	bra.uni 	$L__BB27_76;
$L__BB27_42:
	mad.lo.s32 	%r438, %r2, 1103515245, 12345;
	mad.lo.s32 	%r439, %r438, 1103515245, 12345;
	shr.u32 	%r440, %r438, 6;
	and.b32  	%r441, %r440, 2096128;
	bfe.u32 	%r442, %r439, 16, 10;
	or.b32  	%r443, %r442, %r441;
	mad.lo.s32 	%r444, %r439, 1103515245, 12345;
	shl.b32 	%r445, %r443, 10;
	bfe.u32 	%r446, %r444, 16, 10;
	or.b32  	%r447, %r445, %r446;
	st.global.u32 	[%rd1], %r444;
	rem.u32 	%r448, %r447, %r10;
	cvt.u64.u32 	%rd189, %r448;
	add.s64 	%rd190, %rd41, %rd189;
	ld.u8 	%rs36, [%rd190];
	add.s16 	%rs37, %rs36, 1;
	st.u8 	[%rd190], %rs37;
	bra.uni 	$L__BB27_76;
$L__BB27_51:
	setp.lt.u32 	%p55, %r10, 2;
	@%p55 bra 	$L__BB27_76;
// %bb.52:
	mad.lo.s32 	%r209, %r2, 1103515245, 12345;
	mad.lo.s32 	%r210, %r209, 1103515245, 12345;
	shr.u32 	%r211, %r209, 6;
	and.b32  	%r212, %r211, 2096128;
	bfe.u32 	%r213, %r210, 16, 10;
	or.b32  	%r214, %r213, %r212;
	mad.lo.s32 	%r215, %r210, 1103515245, 12345;
	shl.b32 	%r216, %r214, 10;
	bfe.u32 	%r217, %r215, 16, 10;
	or.b32  	%r218, %r216, %r217;
	mul.hi.u32 	%r219, %r218, 1808407283;
	shr.u32 	%r220, %r219, 3;
	mul.lo.s32 	%r221, %r220, 19;
	sub.s32 	%r222, %r218, %r221;
	mul.wide.u32 	%rd111, %r222, 2;
	mov.u64 	%rd112, interesting_16;
	add.s64 	%rd113, %rd112, %rd111;
	ld.const.u16 	%rs3, [%rd113];
	mad.lo.s32 	%r3, %r215, -2139243339, -1492899873;
	and.b32  	%r223, %r3, 65536;
	setp.eq.s32 	%p56, %r223, 0;
	@%p56 bra 	$L__BB27_54;
	bra.uni 	$L__BB27_53;
$L__BB27_54:
	shr.u16 	%rs16, %rs3, 8;
	add.s32 	%r236, %r10, -1;
	mad.lo.s32 	%r237, %r3, 1103515245, 12345;
	mad.lo.s32 	%r238, %r237, 1103515245, 12345;
	shr.u32 	%r239, %r237, 6;
	and.b32  	%r240, %r239, 2096128;
	bfe.u32 	%r241, %r238, 16, 10;
	or.b32  	%r242, %r241, %r240;
	mad.lo.s32 	%r243, %r238, 1103515245, 12345;
	shl.b32 	%r244, %r242, 10;
	bfe.u32 	%r245, %r243, 16, 10;
	or.b32  	%r246, %r244, %r245;
	st.global.u32 	[%rd1], %r243;
	rem.u32 	%r247, %r246, %r236;
	cvt.u64.u32 	%rd116, %r247;
	add.s64 	%rd117, %rd41, %rd116;
	st.u8 	[%rd117+1], %rs3;
	st.u8 	[%rd117], %rs16;
	bra.uni 	$L__BB27_76;
$L__BB27_44:
	mad.lo.s32 	%r376, %r2, -2139243339, -1492899873;
	and.b32  	%r377, %r376, 65536;
	setp.eq.s32 	%p63, %r377, 0;
	mad.lo.s32 	%r378, %r376, 1103515245, 12345;
	mad.lo.s32 	%r379, %r378, 1103515245, 12345;
	shr.u32 	%r380, %r378, 6;
	and.b32  	%r381, %r380, 2096128;
	bfe.u32 	%r382, %r379, 16, 10;
	or.b32  	%r383, %r382, %r381;
	mad.lo.s32 	%r384, %r379, 1103515245, 12345;
	shl.b32 	%r385, %r383, 10;
	bfe.u32 	%r386, %r384, 16, 10;
	or.b32  	%r387, %r385, %r386;
	mul.hi.u32 	%r388, %r387, -368140053;
	shr.u32 	%r389, %r388, 5;
	mul.lo.s32 	%r390, %r389, 35;
	sub.s32 	%r391, %r387, %r390;
	mad.lo.s32 	%r392, %r384, 1103515245, 12345;
	mad.lo.s32 	%r393, %r392, 1103515245, 12345;
	shr.u32 	%r394, %r392, 6;
	and.b32  	%r395, %r394, 2096128;
	bfe.u32 	%r396, %r393, 16, 10;
	or.b32  	%r397, %r396, %r395;
	mad.lo.s32 	%r398, %r393, 1103515245, 12345;
	shl.b32 	%r399, %r397, 10;
	bfe.u32 	%r400, %r398, 16, 10;
	or.b32  	%r401, %r399, %r400;
	st.global.u32 	[%rd1], %r398;
	rem.u32 	%r402, %r401, %r10;
	cvt.u64.u32 	%rd182, %r402;
	add.s64 	%rd2, %rd41, %rd182;
	ld.u8 	%rs1, [%rd2];
	cvt.u16.u32 	%rs2, %r391;
	@%p63 bra 	$L__BB27_46;
	bra.uni 	$L__BB27_45;
$L__BB27_46:
	not.b16 	%rs30, %rs2;
	add.s16 	%rs31, %rs1, %rs30;
	st.u8 	[%rd2], %rs31;
	bra.uni 	$L__BB27_76;
$L__BB27_47:
	setp.lt.u32 	%p61, %r10, 2;
	@%p61 bra 	$L__BB27_76;
// %bb.48:
	add.s32 	%r348, %r10, -1;
	mad.lo.s32 	%r349, %r2, 1103515245, 12345;
	mad.lo.s32 	%r350, %r349, 1103515245, 12345;
	shr.u32 	%r351, %r349, 6;
	and.b32  	%r352, %r351, 2096128;
	bfe.u32 	%r353, %r350, 16, 10;
	or.b32  	%r354, %r353, %r352;
	mad.lo.s32 	%r355, %r350, 1103515245, 12345;
	shl.b32 	%r356, %r354, 10;
	bfe.u32 	%r357, %r355, 16, 10;
	or.b32  	%r358, %r356, %r357;
	rem.u32 	%r359, %r358, %r348;
	mad.lo.s32 	%r360, %r355, 1103515245, 12345;
	mad.lo.s32 	%r361, %r360, 1103515245, 12345;
	shr.u32 	%r362, %r360, 6;
	and.b32  	%r363, %r362, 2096128;
	bfe.u32 	%r364, %r361, 16, 10;
	or.b32  	%r365, %r364, %r363;
	mad.lo.s32 	%r366, %r361, 1103515245, 12345;
	shl.b32 	%r367, %r365, 10;
	bfe.u32 	%r368, %r366, 16, 10;
	or.b32  	%r369, %r367, %r368;
	st.global.u32 	[%rd1], %r366;
	mul.hi.u32 	%r370, %r369, -368140053;
	shr.u32 	%r371, %r370, 5;
	mul.lo.s32 	%r372, %r371, 35;
	sub.s32 	%r373, %r369, %r372;
	cvt.u16.u32 	%rs18, %r373;
	add.s16 	%rs19, %rs18, 1;
	cvt.u64.u32 	%rd180, %r359;
	add.s64 	%rd181, %rd41, %rd180;
	ld.u8 	%rs20, [%rd181+1];
	ld.u8 	%rs21, [%rd181];
	mad.lo.s32 	%r374, %r366, -2139243339, -1492899873;
	st.global.u32 	[%rd1], %r374;
	and.b32  	%r375, %r374, 65536;
	setp.eq.s32 	%p62, %r375, 0;
	shl.b16 	%rs22, %rs21, 8;
	or.b16  	%rs23, %rs22, %rs20;
	not.b16 	%rs24, %rs18;
	selp.b16 	%rs25, %rs24, %rs19, %p62;
	add.s16 	%rs26, %rs23, %rs25;
	shr.u16 	%rs27, %rs26, 8;
	st.u8 	[%rd181+1], %rs26;
	st.u8 	[%rd181], %rs27;
	bra.uni 	$L__BB27_76;
$L__BB27_59:
	setp.lt.u32 	%p40, %r10, 2;
	@%p40 bra 	$L__BB27_76;
// %bb.60:
	mad.lo.s32 	%r66, %r2, 1103515245, 12345;
	mad.lo.s32 	%r67, %r66, 1103515245, 12345;
	shr.u32 	%r68, %r66, 6;
	and.b32  	%r69, %r68, 2096128;
	bfe.u32 	%r70, %r67, 16, 10;
	or.b32  	%r71, %r70, %r69;
	mad.lo.s32 	%r72, %r67, 1103515245, 12345;
	shl.b32 	%r73, %r71, 10;
	bfe.u32 	%r74, %r72, 16, 10;
	or.b32  	%r75, %r73, %r74;
	rem.u32 	%r76, %r75, %r10;
	mad.lo.s32 	%r77, %r72, 1103515245, 12345;
	mad.lo.s32 	%r78, %r77, 1103515245, 12345;
	shr.u32 	%r79, %r77, 6;
	and.b32  	%r80, %r79, 2096128;
	bfe.u32 	%r81, %r78, 16, 10;
	or.b32  	%r82, %r81, %r80;
	mad.lo.s32 	%r83, %r78, 1103515245, 12345;
	shl.b32 	%r84, %r82, 10;
	bfe.u32 	%r85, %r83, 16, 10;
	or.b32  	%r86, %r84, %r85;
	rem.u32 	%r6, %r86, %r10;
	max.u32 	%r87, %r76, %r6;
	sub.s32 	%r88, %r10, %r87;
	mad.lo.s32 	%r89, %r83, 1103515245, 12345;
	mad.lo.s32 	%r90, %r89, 1103515245, 12345;
	shr.u32 	%r91, %r89, 6;
	and.b32  	%r92, %r91, 2096128;
	bfe.u32 	%r93, %r90, 16, 10;
	or.b32  	%r94, %r93, %r92;
	mad.lo.s32 	%r95, %r90, 1103515245, 12345;
	shl.b32 	%r96, %r94, 10;
	bfe.u32 	%r97, %r95, 16, 10;
	or.b32  	%r98, %r96, %r97;
	st.global.u32 	[%rd1], %r95;
	rem.u32 	%r99, %r98, %r88;
	add.s32 	%r100, %r99, 1;
	cvt.u64.u32 	%rd11, %r100;
	cvt.u64.u32 	%rd84, %r76;
	add.s64 	%rd12, %rd41, %rd84;
	setp.eq.s32 	%p41, %r100, 0;
	mov.u64 	%rd198, 0;
	add.u64 	%rd195, %SP, 0;
	@%p41 bra 	$L__BB27_62;
$L__BB27_61:                            // %loop-memcpy-expansion
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd85, %rd12, %rd198;
	ld.u8 	%rs12, [%rd85];
	add.s64 	%rd87, %rd195, %rd198;
	st.u8 	[%rd87], %rs12;
	add.s64 	%rd198, %rd198, 1;
	setp.lt.u64 	%p42, %rd198, %rd11;
	@%p42 bra 	$L__BB27_61;
$L__BB27_62:                            // %post-loop-memcpy-expansion
	cvt.u64.u32 	%rd89, %r6;
	add.s64 	%rd15, %rd41, %rd89;
	setp.eq.s64 	%p43, %rd11, 0;
	mov.u64 	%rd199, 0;
	@%p43 bra 	$L__BB27_64;
$L__BB27_63:                            // %loop-memcpy-expansion4
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd90, %rd15, %rd199;
	ld.u8 	%rs13, [%rd90];
	add.s64 	%rd91, %rd12, %rd199;
	st.u8 	[%rd91], %rs13;
	add.s64 	%rd199, %rd199, 1;
	setp.lt.u64 	%p44, %rd199, %rd11;
	@%p44 bra 	$L__BB27_63;
$L__BB27_64:                            // %post-loop-memcpy-expansion3
	mov.u64 	%rd200, 0;
	@%p43 bra 	$L__BB27_76;
$L__BB27_65:                            // %loop-memcpy-expansion7
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd94, %rd195, %rd200;
	ld.u8 	%rs14, [%rd94];
	add.s64 	%rd95, %rd15, %rd200;
	st.u8 	[%rd95], %rs14;
	add.s64 	%rd200, %rd200, 1;
	setp.lt.u64 	%p46, %rd200, %rd11;
	@%p46 bra 	$L__BB27_65;
	bra.uni 	$L__BB27_76;
$L__BB27_66:
	ld.global.u32 	%r7, [cbconstants_length];
	setp.eq.s32 	%p32, %r7, 0;
	@%p32 bra 	$L__BB27_76;
// %bb.67:
	mad.lo.s32 	%r53, %r2, 1103515245, 12345;
	mad.lo.s32 	%r54, %r53, 1103515245, 12345;
	shr.u32 	%r55, %r53, 6;
	and.b32  	%r56, %r55, 2096128;
	bfe.u32 	%r57, %r54, 16, 10;
	or.b32  	%r58, %r57, %r56;
	mad.lo.s32 	%r59, %r54, 1103515245, 12345;
	shl.b32 	%r60, %r58, 10;
	bfe.u32 	%r61, %r59, 16, 10;
	or.b32  	%r62, %r60, %r61;
	st.global.u32 	[%rd1], %r59;
	rem.u32 	%r63, %r62, %r7;
	cvt.u64.u32 	%rd67, %r63;
	mul.wide.u32 	%rd68, %r63, 32;
	mov.u64 	%rd69, cbconstants;
	add.s64 	%rd20, %rd69, %rd68;
	mov.u64 	%rd70, cbconstant_sizes;
	add.s64 	%rd71, %rd70, %rd67;
	ld.global.u8 	%rs8, [%rd71];
	cvt.u32.u16 	%r64, %rs8;
	and.b32  	%r8, %r64, 255;
	setp.lt.u32 	%p33, %r8, %r10;
	@%p33 bra 	$L__BB27_70;
	bra.uni 	$L__BB27_68;
$L__BB27_70:
	cvt.u64.u16 	%rd72, %rs8;
	and.b64  	%rd21, %rd72, 255;
	sub.s32 	%r65, %r10, %r8;
	cvt.u64.u32 	%rd25, %r65;
	setp.eq.s32 	%p36, %r65, 0;
	mov.u64 	%rd202, 0;
	@%p36 bra 	$L__BB27_72;
$L__BB27_71:                            // %loadstoreloop13
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd77, %rd41, %rd202;
	mov.u16 	%rs10, 0;
	st.u8 	[%rd77], %rs10;
	add.s64 	%rd202, %rd202, 1;
	setp.lt.u64 	%p37, %rd202, %rd25;
	@%p37 bra 	$L__BB27_71;
$L__BB27_72:                            // %split12
	cvt.u64.u32 	%rd79, %r10;
	sub.s64 	%rd80, %rd79, %rd21;
	add.s64 	%rd28, %rd41, %rd80;
	setp.eq.s64 	%p38, %rd21, 0;
	mov.u64 	%rd203, 0;
	@%p38 bra 	$L__BB27_76;
$L__BB27_73:                            // %loop-memcpy-expansion15
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd81, %rd20, %rd203;
	ld.global.u8 	%rs11, [%rd81];
	add.s64 	%rd82, %rd28, %rd203;
	st.u8 	[%rd82], %rs11;
	add.s64 	%rd203, %rd203, 1;
	setp.lt.u64 	%p39, %rd203, %rd21;
	@%p39 bra 	$L__BB27_73;
	bra.uni 	$L__BB27_76;
$L__BB27_43:
	mad.lo.s32 	%r416, %r2, 1103515245, 12345;
	mad.lo.s32 	%r417, %r416, 1103515245, 12345;
	shr.u32 	%r418, %r416, 6;
	and.b32  	%r419, %r418, 2096128;
	bfe.u32 	%r420, %r417, 16, 10;
	or.b32  	%r421, %r420, %r419;
	mad.lo.s32 	%r422, %r417, 1103515245, 12345;
	shl.b32 	%r423, %r421, 10;
	bfe.u32 	%r424, %r422, 16, 10;
	or.b32  	%r425, %r423, %r424;
	st.global.u32 	[%rd1], %r422;
	rem.u32 	%r426, %r425, %r10;
	cvt.u64.u32 	%rd185, %r426;
	add.s64 	%rd186, %rd41, %rd185;
	ld.u8 	%rs32, [%rd186];
	neg.s16 	%rs33, %rs32;
	st.u8 	[%rd186], %rs33;
	bra.uni 	$L__BB27_76;
$L__BB27_56:
	setp.eq.s32 	%p50, %r10, 0;
	@%p50 bra 	$L__BB27_76;
// %bb.57:
	mad.lo.s32 	%r128, %r2, 1103515245, 12345;
	mad.lo.s32 	%r129, %r128, 1103515245, 12345;
	shr.u32 	%r130, %r128, 6;
	and.b32  	%r131, %r130, 2096128;
	bfe.u32 	%r132, %r129, 16, 10;
	or.b32  	%r133, %r132, %r131;
	mad.lo.s32 	%r134, %r129, 1103515245, 12345;
	shl.b32 	%r135, %r133, 10;
	bfe.u32 	%r136, %r134, 16, 10;
	or.b32  	%r137, %r135, %r136;
	rem.u32 	%r138, %r137, %r10;
	sub.s32 	%r139, %r10, %r138;
	min.u32 	%r140, %r139, 16;
	mad.lo.s32 	%r141, %r134, 1103515245, 12345;
	mad.lo.s32 	%r142, %r141, 1103515245, 12345;
	shr.u32 	%r143, %r141, 6;
	and.b32  	%r144, %r143, 2096128;
	bfe.u32 	%r145, %r142, 16, 10;
	or.b32  	%r146, %r145, %r144;
	mad.lo.s32 	%r147, %r142, 1103515245, 12345;
	shl.b32 	%r148, %r146, 10;
	bfe.u32 	%r149, %r147, 16, 10;
	or.b32  	%r150, %r148, %r149;
	rem.u32 	%r151, %r150, %r140;
	add.s32 	%r152, %r151, 1;
	cvt.u64.u32 	%rd3, %r152;
	mad.lo.s32 	%r153, %r147, 1103515245, 12345;
	mad.lo.s32 	%r154, %r153, 1103515245, 12345;
	shr.u32 	%r155, %r153, 6;
	and.b32  	%r156, %r155, 2096128;
	bfe.u32 	%r157, %r154, 16, 10;
	or.b32  	%r158, %r157, %r156;
	mad.lo.s32 	%r159, %r154, 1103515245, 12345;
	shl.b32 	%r160, %r158, 10;
	bfe.u32 	%r161, %r159, 16, 10;
	or.b32  	%r162, %r160, %r161;
	st.global.u32 	[%rd1], %r159;
	rem.u32 	%r163, %r162, %r10;
	cvt.u64.u32 	%rd100, %r163;
	add.s64 	%rd101, %rd41, %rd100;
	ld.u8 	%rs4, [%rd101];
	cvt.u64.u32 	%rd102, %r138;
	add.s64 	%rd4, %rd41, %rd102;
	setp.eq.s32 	%p51, %r152, 0;
	mov.u64 	%rd196, 0;
	@%p51 bra 	$L__BB27_76;
$L__BB27_58:                            // %loadstoreloop
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd103, %rd4, %rd196;
	st.u8 	[%rd103], %rs4;
	add.s64 	%rd196, %rd196, 1;
	setp.lt.u64 	%p52, %rd196, %rd3;
	@%p52 bra 	$L__BB27_58;
	bra.uni 	$L__BB27_76;
$L__BB27_45:
	add.s16 	%rs28, %rs2, %rs1;
	add.s16 	%rs29, %rs28, 1;
	st.u8 	[%rd2], %rs29;
	bra.uni 	$L__BB27_76;
$L__BB27_74:
	shl.b64 	%rd50, %rd31, 13;
	mov.u64 	%rd51, l2snaps;
	add.s64 	%rd52, %rd51, %rd50;
	shl.b64 	%rd53, %rd32, 6;
	add.s64 	%rd54, %rd52, %rd53;
	cvt.u64.u32 	%rd37, %r10;
	sub.s64 	%rd55, %rd54, %rd37;
	add.s64 	%rd38, %rd55, 32;
	setp.eq.s32 	%p28, %r10, 0;
	mov.u64 	%rd205, 0;
	@%p28 bra 	$L__BB27_76;
$L__BB27_75:                            // %loop-memcpy-expansion21
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd56, %rd38, %rd205;
	ld.global.u8 	%rs6, [%rd56];
	add.s64 	%rd57, %rd41, %rd205;
	st.u8 	[%rd57], %rs6;
	add.s64 	%rd205, %rd205, 1;
	setp.lt.u64 	%p29, %rd205, %rd37;
	@%p29 bra 	$L__BB27_75;
	bra.uni 	$L__BB27_76;
$L__BB27_68:
	cvt.u64.u32 	%rd22, %r10;
	setp.eq.s32 	%p34, %r10, 0;
	mov.u64 	%rd201, 0;
	@%p34 bra 	$L__BB27_76;
$L__BB27_69:                            // %loop-memcpy-expansion10
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd74, %rd20, %rd201;
	ld.global.u8 	%rs9, [%rd74];
	add.s64 	%rd75, %rd41, %rd201;
	st.u8 	[%rd75], %rs9;
	add.s64 	%rd201, %rd201, 1;
	setp.lt.u64 	%p35, %rd201, %rd22;
	@%p35 bra 	$L__BB27_69;
	bra.uni 	$L__BB27_76;
$L__BB27_27:
	add.s32 	%r179, %r10, -3;
	mad.lo.s32 	%r180, %r5, 1103515245, 12345;
	mad.lo.s32 	%r181, %r180, 1103515245, 12345;
	shr.u32 	%r182, %r180, 6;
	and.b32  	%r183, %r182, 2096128;
	bfe.u32 	%r184, %r181, 16, 10;
	or.b32  	%r185, %r184, %r183;
	mad.lo.s32 	%r186, %r181, 1103515245, 12345;
	shl.b32 	%r187, %r185, 10;
	bfe.u32 	%r188, %r186, 16, 10;
	or.b32  	%r189, %r187, %r188;
	st.global.u32 	[%rd1], %r186;
	rem.u32 	%r190, %r189, %r179;
	cvt.u64.u32 	%rd107, %r190;
	add.s64 	%rd108, %rd41, %rd107;
	shr.u32 	%r191, %r4, 24;
	st.u8 	[%rd108+3], %r191;
	shr.u32 	%r192, %r4, 16;
	st.u8 	[%rd108+2], %r192;
	shr.u32 	%r193, %r4, 8;
	st.u8 	[%rd108+1], %r193;
	st.u8 	[%rd108], %r4;
	bra.uni 	$L__BB27_76;
$L__BB27_53:
	add.s32 	%r224, %r10, -1;
	mad.lo.s32 	%r225, %r3, 1103515245, 12345;
	mad.lo.s32 	%r226, %r225, 1103515245, 12345;
	shr.u32 	%r227, %r225, 6;
	and.b32  	%r228, %r227, 2096128;
	bfe.u32 	%r229, %r226, 16, 10;
	or.b32  	%r230, %r229, %r228;
	mad.lo.s32 	%r231, %r226, 1103515245, 12345;
	shl.b32 	%r232, %r230, 10;
	bfe.u32 	%r233, %r231, 16, 10;
	or.b32  	%r234, %r232, %r233;
	st.global.u32 	[%rd1], %r231;
	rem.u32 	%r235, %r234, %r224;
	cvt.u64.u32 	%rd114, %r235;
	add.s64 	%rd115, %rd41, %rd114;
	shr.u16 	%rs15, %rs3, 8;
	st.u8 	[%rd115+1], %rs15;
	st.u8 	[%rd115], %rs3;
$L__BB27_76:
	ret;
                                        // -- End function
}
	// .globl	main_contract           // -- Begin function main_contract
.visible .entry main_contract(
	.param .b64 main_contract_param_0,
	.param .b32 main_contract_param_1
)                                       // @main_contract
{
	.local .align 16 .b8 	__local_depot28[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<9>;
	.reg .b64 	%rd<27>;

// %bb.0:
	mov.u64 	%SPL, __local_depot28;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [main_contract_param_0];
	add.u64 	%rd2, %SP, 0;
	add.u64 	%rd3, %SPL, 0;
	add.u64 	%rd4, %SP, 32;
	add.u64 	%rd5, %SPL, 32;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	cvt.u64.u32 	%rd6, %r4;
	mov.u64 	%rd7, __hnbs;
	add.s64 	%rd8, %rd7, %rd6;
	mov.u16 	%rs1, 0;
	st.global.u8 	[%rd8], %rs1;
	shl.b32 	%r5, %r4, 11;
	cvt.u64.u32 	%rd9, %r5;
	add.s64 	%rd10, %rd1, %rd9;
	ld.global.u64 	%rd11, [%rd10+8];
	ld.global.u64 	%rd12, [%rd10];
	ld.global.u64 	%rd13, [%rd10+24];
	ld.global.u64 	%rd14, [%rd10+16];
	st.local.u64 	[%rd3+16], %rd14;
	st.local.u64 	[%rd3+24], %rd13;
	st.local.u64 	[%rd3], %rd12;
	st.local.u64 	[%rd3+8], %rd11;
	ld.global.u64 	%rd15, [%rd10+40];
	ld.global.u64 	%rd16, [%rd10+32];
	ld.global.u64 	%rd17, [%rd10+56];
	ld.global.u64 	%rd18, [%rd10+48];
	st.local.u64 	[%rd5+16], %rd18;
	st.local.u64 	[%rd5+24], %rd17;
	st.local.u64 	[%rd5], %rd16;
	st.local.u64 	[%rd5+8], %rd15;
	ld.global.u32 	%r6, [%rd10+64];
	add.s64 	%rd19, %rd10, 68;
	cvta.global.u64 	%rd20, %rd19;
	mov.u64 	%rd21, l1snap_lens;
	add.s64 	%rd22, %rd21, %rd6;
	st.global.u8 	[%rd22], %rs1;
	mul.wide.u32 	%rd23, %r4, 8;
	mov.u64 	%rd24, __bitmaps;
	add.s64 	%rd25, %rd24, %rd23;
	ld.global.u64 	%rd26, [%rd25];
	{ // callseq 86, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd2;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd20;
	.param .b32 param3;
	st.param.b32 	[param3+0], %r6;
	.param .b64 param4;
	st.param.b64 	[param4+0], %rd26;
	.param .b32 retval0;
	call.uni (retval0), 
	contract, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	ld.param.b32 	%r7, [retval0+0];
	} // callseq 86
	ret;
                                        // -- End function
}
